{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#welcome-to-my-personal-site","title":"\ud83d\udc4b Welcome to My Personal Site","text":"<p>This is a page created by Michael Qiu.</p> C++PythonJava <pre><code>#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    ios::sync_with_stdio(false);\n    cin.tie(0);\n    cout.tie(0);\n\n    cout &lt;&lt; \"Hello world!\" &lt;&lt; endl;\n    return 0;\n}\n</code></pre> <pre><code>times = 11.4\n\nwhile times &gt; 0:\n    print(\"Nice to see ya!\")\n    times -= 1\n</code></pre> <pre><code>public class HelloWorld {\n    public static void main(String[] args) {\n        System.out.println(\"Hello, Visitor!\");\n    }\n}\n</code></pre>"},{"location":"#about-me","title":"About Me","text":"<p>Currently an OIer.</p>"},{"location":"#find-me","title":"Find Me","text":"<p>This is my GitHub page: MichaelQiu</p> <p>This is my Luogu page: MikePP</p>"},{"location":"some-websites/","title":"Some Websites","text":""},{"location":"some-websites/#algorithms","title":"Algorithms","text":"<ul> <li>OI-Wiki (Chinese)</li> <li>Buggg\u7684\u5c0f\u5c4b (Chinese)</li> <li>Runoob (Chinese)</li> <li>VisuAlgo</li> <li>Bilibili - \u82f1\u96c4\u54ea\u91cc\u51fa\u6765 (Chinese)</li> </ul>"},{"location":"some-websites/#online-judges","title":"Online Judges","text":"<ul> <li>Luogu (Chinese)</li> <li>LeetCode</li> <li>CodeForces</li> <li>HDU OJ</li> </ul>"},{"location":"some-websites/#c","title":"C++","text":"<ul> <li>CPPReference</li> <li>ISOCPP</li> <li>Microsoft C++ &amp; C</li> <li>CPlusPlus</li> </ul>"},{"location":"some-websites/#ides","title":"IDEs","text":"<ul> <li>Visual Studio Code</li> <li>Visual Studio</li> <li>Xcode (Mac Only)</li> <li>PyCharm</li> <li>CLion</li> </ul>"},{"location":"academic-notes/calculus/differentiation/","title":"Differentiation","text":""},{"location":"academic-notes/calculus/differentiation/#derivative","title":"Derivative","text":"<p>\\(f'(x_0) = \\lim\\limits_{\\Delta x \\to 0} \\dfrac{\\Delta y}{\\Delta x} = \\lim\\limits_{\\Delta x \\to 0} \\dfrac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x}\\)</p> <p>\\(f'_-(x_0) = \\lim\\limits_{\\Delta x \\to 0^-} \\dfrac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} = \\lim\\limits_{x \\to x_0^-} \\dfrac{f(x) - f(x_0)}{x - x_0}\\)</p> <p>\\(f'_+(x_0) = \\lim\\limits_{\\Delta x \\to 0^+} \\dfrac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} = \\lim\\limits_{x \\to x_0^+} \\dfrac{f(x) - f(x_0)}{x - x_0}\\)</p> <p>\\(f'(x_0)\\ exists \\iff f'_-(x) = f'_+(x)\\)</p>"},{"location":"academic-notes/calculus/differentiation/#algorithms","title":"Algorithms","text":"<p>\\([f(x) \\pm g(x)]' = f'(x) \\pm g'(x)\\)</p> <p>\\([f(x) \\cdot g(x)]' = f'(x) \\cdot g(x) + f(x) \\cdot g'(x)\\)</p> <p>\\([\\dfrac{f(x)}{g(x)}]' = \\dfrac{f'(x) \\cdot g(x) - f(x) \\cdot g'(x)}{[g(x)]^2}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#differentiation-rules","title":"Differentiation Rules","text":"<p>\\((C)' = 0\\)</p> <p>\\(\\boxed{(x^n)' = nx^{n-1}}\\)</p> <p>\\(\\boxed{(\\sin x)' = \\cos x}\\)</p> <p>\\(\\boxed{(\\cos x)' = -\\sin x}\\)</p> <p>\\(\\boxed{(\\tan x)' = \\sec^2 x}\\)</p> <p>\\(\\boxed{(\\sec x)' = \\sec x \\cdot \\tan x}\\)</p> <p>\\((\\cot x)' = - \\csc^2 x\\)</p> <p>\\((\\csc x)' = - \\csc x \\cdot \\cot x\\)</p> <p>\\(\\boxed{(a^x)' = a^x \\cdot \\ln a}\\)</p> <p>\\((e^x)' = e^x\\)</p> <p>\\(\\boxed{(\\log_ax)' = \\frac{1}{x \\cdot \\ln a}}\\)</p> <p>\\((\\ln x)' = \\frac{1}{x}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#the-chain-rule","title":"The Chain Rule","text":"<p>\\(\\boxed{(f(g(x)))' = f'(g(x)) \\cdot g'(x)}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#inverse-functions","title":"Inverse Functions","text":"<p>Inverse Functions</p> <p>\\(f^{-1}(f(x)) = x \\iff f(f^{-1}(x)) = x\\) </p> <p>if \\(\\ g(x) = f^{-1}(x)\\),</p> <p>then \\(\\ \\boxed{g'(x) = \\dfrac{1}{f'(g(x))}},\\ f'(g(x)) \\neq 0\\)</p>"},{"location":"academic-notes/calculus/differentiation/#lhopitals-rule","title":"L'H\u00f4pital's Rule","text":"<p>when \\(x \\to a\\),</p> <p>if \\(\\left\\{\\begin{aligned} f(x) &amp; \\to 0 \\\\ g(x) &amp; \\to 0 \\end{aligned}\\right.\\ or \\left\\{\\begin{aligned} f(x) &amp; \\to \\infty\\\\ g(x) &amp; \\to \\infty \\end{aligned}\\right.\\),</p> <p>then \\(\\boxed{\\lim\\limits_{x \\to a} \\dfrac{f(x)}{g(x)} = \\lim\\limits_{x \\to a} \\dfrac{f'(x)}{g'(x)}}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#intermediate-value-theorem","title":"Intermediate Value Theorem","text":"<p>If \\(f\\) is continuous on \\([a, b]\\), \\(u\\) is a number such that \\(\\min(f(a), f(b)) &lt; u &lt; \\max(f(a), f(b))\\),</p> <p>then there is a \\(c \\in (a, b)\\) such that \\(f(c) = u\\)</p>"},{"location":"academic-notes/calculus/differentiation/#mean-value-theorem","title":"Mean Value Theorem","text":"<p>If \\(f\\) is continuous on \\([a, b]\\) and differentiable on \\((a, b)\\), then</p> <p>\\(\\exists c \\in (a, b)\\) such that \\(\\boxed{f'(c) = \\dfrac{f(b)-f(a)}{b-a}}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#extreme-value-theorem","title":"Extreme Value Theorem","text":"<p>If \\(f\\) is continuous on the \\([a, b]\\), then \\(f\\) must attain a maximum and a minimum, each at least once, i.e.</p> <p>\\(\\exists c, d \\in [a, b]\\) such that \\(\\boxed{f(c) \\leq f(x) \\leq f(d), \\forall x \\in [a, b]}\\)</p>"},{"location":"academic-notes/calculus/differentiation/#concavity","title":"Concavity","text":"<ul> <li>If \\(\\boxed{f'' &gt; 0}\\), then \\(f\\) concave up</li> <li>If \\(\\boxed{f'' &lt; 0}\\), then \\(f\\) concave down</li> </ul> <p>Points of Inflection</p> <p>\\(\\left\\{\\begin{aligned} f'' &amp; = 0\\ or\\ DNE \\\\ f'' &amp; change\\ sign \\end{aligned}\\right.\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/","title":"Fundamental Calculus","text":""},{"location":"academic-notes/calculus/fundamental-calculus/#antiderivative","title":"Antiderivative","text":"<p>\\(y = \\int f(x) dx = F(x) + C\\)</p> <p>Note</p> <p>\\(f\\): integrand</p> <p>\\(dx\\): variable of integration</p> <p>\\(F(x)\\): an antiderivative of \\(f(x)\\)</p> <p>\\(C\\): constant of integration</p> Example <p>\\(\\int x^3\\ dx = \\frac{x^4}{4} + C\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#definition-of-definite-integral","title":"Definition of Definite Integral","text":"<p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} f(x^*_k) \\cdot \\Delta x\\)</p> <ul> <li>Left point\uff1a\\(x_k^* = a + (k-1)\\Delta x\\)</li> <li>Right point\uff1a\\(x_k^* = a + k\\Delta x\\)</li> <li>Middle point\uff1a\\(x_k^* = a + \\left(k - \\frac{1}{2}\\right)\\Delta x\\)</li> </ul>"},{"location":"academic-notes/calculus/fundamental-calculus/#definite-integral","title":"Definite Integral","text":"<p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} f(a + k \\cdot \\dfrac{b-a}{n}) \\cdot \\dfrac{b-a}{n}\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#left-riemann-sum","title":"Left Riemann Sum","text":"<p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} f(a + (k-1) \\cdot \\dfrac{b-a}{n}) \\cdot \\dfrac{b-a}{n}\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#right-riemann-sum","title":"Right Riemann Sum","text":"<p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} f(a + k \\cdot \\dfrac{b-a}{n}) \\cdot \\dfrac{b-a}{n}\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#midpoint-riemann-sum","title":"Midpoint Riemann Sum","text":"<p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} f(a + (k-\\frac12) \\cdot \\dfrac{b-a}{n}) \\cdot \\dfrac{b-a}{n}\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#trapezoidal-sum","title":"Trapezoidal Sum","text":"<p>\\(\\int^b_a f(x)dx = \\lim\\limits_{n \\to \\infty} \\dfrac{b-a}{2n}[f(a) + 2\\sum\\limits^{n-1}{k=1}f(a + k \\cdot \\dfrac{b-a}{n} + f(b))]\\)</p> <p>\\(\\iff\\)</p> <p>\\(\\int^b_a f(x) dx = \\lim\\limits_{n \\to \\infty} \\sum\\limits^n_{k=1} \\dfrac{f(a + (k-1) \\cdot \\frac{b-a}n + f(a+k \\cdot \\frac{b-a}n))}{2} \\cdot \\dfrac{b-a}n\\)</p>"},{"location":"academic-notes/calculus/fundamental-calculus/#basic-integration-formulas","title":"Basic Integration Formulas","text":"<ul> <li>\\(\\boxed{\\int dx = x + C}\\)</li> <li>\\(\\boxed{\\int k\\ dx = kx + C}\\)</li> <li>\\(\\boxed{\\int kf(x)dx = k \\int f(x)dx}\\)</li> <li>\\(\\boxed{\\int[f(x) \\pm g(x)] dx = \\int f(x) dx \\pm \\int g(x) dx}\\)</li> <li>\\(\\boxed{\\int x^n dx = \\frac1{n+1} x^{n+1} + C}\\) &amp; \\(\\boxed{\\int \\frac1x dx = \\ln |x| + C}\\)</li> <li>\\(\\boxed{\\int a^x dx = (\\frac1{\\ln a}) a^x + C}\\)</li> <li>\\(\\int e^x dx = e^x + C\\)</li> <li>\\(\\boxed{\\int \\sin x dx = - \\cos x + C}\\)</li> <li>\\(\\boxed{\\int \\cos x dx = \\sin x + C}\\)</li> <li>\\(\\boxed{\\int \\sec^2 x\\ dx = -\\tan x + C}\\)</li> <li>\\(\\int \\csc^2 x\\ dx = -\\cot x + C\\)</li> <li>\\(\\int \\sec x \\tan x \\ dx = \\sec x + C\\)</li> <li>\\(\\int \\csc x \\cot x \\ dx = - \\csc x + C\\)</li> <li>\\(\\int \\dfrac{dx}{\\sqrt{1-x^2}} = \\arcsin x + C\\)</li> <li>\\(\\boxed{\\int \\dfrac{dx}{1+x^2}} = \\arctan x + C\\)</li> <li>\\(\\int \\dfrac{dx}{\\sqrt{a^2-x^2}} = \\arcsin \\dfrac ac + C\\)</li> <li>\\(\\int \\dfrac{dx}{a^2+x^2} = \\dfrac 1a \\arctan \\dfrac xa + C\\)</li> </ul>"},{"location":"academic-notes/calculus/limit/","title":"Limit","text":""},{"location":"academic-notes/calculus/limit/#limit-laws","title":"Limit Laws","text":"<p>If \\(L, M, c, k \\in \\mathbb{R}\\) and \\(\\lim\\limits_{x \\to c} f(x) = L\\) and \\(\\lim\\limits_{x \\to c} g(x) = M\\), then</p> <ol> <li>Sum Rule: \\(\\lim\\limits_{x \\to c} (f(x) + g(x)) = L + M\\)</li> <li>Difference Rule: \\(\\lim\\limits_{x \\to c} (f(x) - g(x)) = L - M\\)</li> <li>Constant Multiple Rule: \\(\\lim\\limits_{x \\to c} (k \\cdot f(x)) = k \\cdot L\\)</li> <li>Product Rule: \\(\\lim\\limits_{x \\to c} (f(x) \\cdot g(x)) = L \\cdot M\\)</li> <li>Quotient Rule: \\(\\lim\\limits_{x \\to c} (\\frac{f(x)}{g(x)}) = \\frac{L}{M}, M \\not= 0\\)</li> <li>Power Rule: \\(\\lim\\limits_{x \\to c} [f(x)]^n = L^n, n \\in N^*\\)</li> <li>Root Rule: \\(\\lim\\limits_{x \\to c} \\sqrt[n]{f(x)} = \\sqrt[n]{L}\\)</li> </ol>"},{"location":"academic-notes/calculus/limit/#theorems","title":"Theorems","text":"<p>\\(\\lim\\limits_{x \\to 0} \\dfrac{\\sin x}{x} = \\lim\\limits_{x \\to 0} \\dfrac{x}{x} = 1\\)</p>"},{"location":"academic-notes/calculus/limit/#rational-function","title":"Rational Function","text":"<ol> <li>\\(\\lim\\limits_{x \\to \\infty} \\frac{higher\\ degree}{lower\\ degree} = 0\\)</li> <li>\\(\\lim\\limits_{x \\to \\infty} \\frac{lower\\ degree}{higher\\ degree} = DNE\\)</li> <li>\\(\\lim\\limits_{x \\to 0} \\frac{same\\ degree}{same\\ degree} = \\frac{highest\\ degree\\ coefficient}{highest\\ degree\\ coefficient}\\)</li> </ol>"},{"location":"academic-notes/chinese/junior-notes/geography/","title":"\u521d\u4e2d\u5730\u7406\u603b\u7ed3","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#i","title":"\u2160. \u5730\u56fe\u4fe1\u606f\u7684\u83b7\u53d6\u3001\u8868\u8fbe\u548c\u7406\u89e3","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_1","title":"\u4ece\u5730\u56fe\u548c\u56fe\u8868\u4e2d\u83b7\u53d6\u4fe1\u606f","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300b P2~4, P14~20, P45~52\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_2","title":"\u5730\u56fe\u4e09\u8981\u7d20","text":"<p>\u65b9\u5411\uff0c\u6bd4\u4f8b\u5c3a\uff0c\u56fe\u4f8b &amp; \u6ce8\u8bb0 <sup>1</sup></p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_3","title":"\u65b9\u5411\ud83e\udded","text":"\u6b63\u786e\u8868\u8fbe\u67d0\u5730\u7684\u7ecf\u7eac\u5ea6 <p>Point A (n\u00b0 N/S, n\u00b0 W/E)</p> <p>\u5982\uff1aA\u70b9\uff0830\u00b0 N, 45\u00b0 W\uff09</p> <p>Warning</p> <p>\u7ad9\u5728\u5730\u7403\u7684\u5357(\u5317)\u6781\u70b9\uff0c\u524d\u540e\u5de6\u53f3\u90fd\u662f\u5317(\u5357)\u65b9</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_4","title":"\u56fe\u4f8b &amp; \u6ce8\u8bb0\ud83c\udff7\ufe0f","text":"<p>\u56fe\u4f8b\u548c\u6ce8\u8bb0\u7684\u533a\u522b</p> <p>\u56fe\u4f8b\uff1a\u5bf9\u5730\u56fe\u4e0a\u5404\u79cd\u7b26\u53f7\u548c\u6ce8\u8bb0\u7684\u8bf4\u660e\uff0c\u4e00\u822c\u5728\u5730\u56fe\u5916\u9762</p> <p>\u6ce8\u8bb0\uff1a\u6307\u5730\u56fe\u4e0a\u7684\u6587\u5b57\u8bf4\u660e\uff0c\u4e00\u822c\u5730\u56fe\u91cc\u9762</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_5","title":"\u4ece\u5730\u56fe\ud83d\uddfa\ufe0f\u4e0a\u83b7\u53d6\u4fe1\u606f","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_6","title":"\u7b49\u9ad8\u7ebf\u5730\u5f62\u56fe","text":"Tip <p>\u5982\u4e0a\u56fe\uff0c\u56fe\u5e45\u548c\u56fe\u4e2d\u7b49\u9ad8\u8ddd\u76f8\u540c\u65f6\uff0c\u6bd4\u4f8b\u5c3a\u8d8a\u5c0f\uff0c\u5761\u5ea6\u8d8a\u7f13\uff0c\u53cd\u4e4b\u540c\u7406</p> <p>\\(\\therefore\\) \u5761\u5ea6\u6700\u7f13\u7684\u662fC</p> \u5c71\u810a\u548c\u5c71\u8c37\u7684\u5224\u5b9a <p>\u5c71\u810a\uff1a\u7b49\u9ad8\u7ebf\u5411\u4f4e\u5904\u51f8\u51fa \u5c71\u8c37\uff1a\u7b49\u9ad8\u7ebf\u5411\u9ad8\u51fa\u51f8\u51fa (\u53ef\u4ee5\u53d1\u80b2\u6cb3\u6d41)</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_7","title":"\u4ece\u5730\u7403\u4eea\ud83c\udf0e\u4e0a\u770b\u4e16\u754c","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_8","title":"\u7ecf\u7ebf\u548c\u7eac\u7ebf","text":"<p>\u7ecf\u7ebf\u53c8\u540d\u5b50\u5348\u7ebf\ud83c\udf10</p> \u7ecf\u7ebf\u7eac\u7ebf\u7684\u957f\u5ea6\u548c\u5f62\u72b6 <p>\u6bcf\u6761\u7ecf\u7ebf\u5448\u534a\u5706\u72b6\uff0c\u6bcf\u6761\u957f\u5ea6\u76f8\u7b49</p> <p>\u6bcf\u6761\u7eac\u7ebf\u5448\u6574\u5706\u72b6<sup>2</sup>\uff0c\u8d64\u9053\u6700\u957f</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_9","title":"\u7ecf\u5ea6\u548c\u7eac\u5ea6","text":"\u9879\u76ee \u7ecf\u5ea6 \u7eac\u5ea6 \u5ea6\u6570\u8d77\u59cb\u7ebf \u672c\u521d\u5b50\u5348\u7ebf \u8d64\u9053 \u5212\u5206\u65b9\u6cd5 \u4ee5\u672c\u521d\u5b50\u5348\u7ebf\u4e3a\u754c\uff0c\u5411\u4e1c\u4e1c\u7ecf\uff0c\u5411\u897f\u897f\u7ecf\uff0c\u5404180\u00b0 \u4ee5\u8d64\u9053\u4e3a\u754c\uff0c\u5411\u5317\u5317\u7eac\uff0c\u5411\u5357\u5357\u7eac\uff0c\u540490\u00b0 \u534a\u7403\u5212\u5206 \u4e1c\u534a\u7403\ud83c\udf0f\uff1a20\u00b0 W - 160\u00b0 E \u8d64\u9053\u4e3a\u754c <p>Danger</p> <p>\u4e1c\u897f\u534a\u7403\u5206\u754c\u7ebf\u4e3a20\u00b0 W, 160\u00b0 E</p> \u4e94\u6e29\u5e26 &amp; \u4f4e\u4e2d\u9ad8\u7eac\u5ea6 <p></p> <p>\u636e\u56fe\u53ef\u77e5\uff0c\u6211\u56fd\u5927\u90e8\u5206\u5730\u533a\u4f4d\u4e8e\u5317\u6e29\u5e26\uff0c\u4e2d\u7eac\u5ea6\uff1b\u5c0f\u90e8\u5206\u5730\u533a\u4f4d\u4e8e\u70ed\u5e26\uff0c\u4f4e\u7eac\u5ea6</p> <p>\u7ecf\u5ea6\u76f8\u5dee15\u00b0\uff0c\u65f6\u95f4\u76f8\u5dee1h</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_10","title":"\u63cf\u8ff0\u533a\u57df\u7684\u4f4d\u7f6e\u3001\u81ea\u7136\u73af\u5883\u548c\u4eba\u6587\u73af\u5883\u7684\u7279\u70b9","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300bP100~104\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_11","title":"\u63cf\u8ff0\u5730\u533a\u7684\u81ea\u7136\u73af\u5883\ud83c\udf32\u7279\u70b9","text":"<p>\u5730\u5f62\u3001\u6c14\u5019\u3001\u6cb3\u6d41\u3001\u81ea\u7136\u8d44\u6e90\u7b49</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_12","title":"\u63cf\u8ff0\u65b9\u6cd5","text":"\u5730\u5f62 <ul> <li>\u6d77\u62d4</li> <li>\u5730\u9762\u8d77\u4f0f</li> <li>\u5730\u5f62\u79cd\u7c7b\u548c\u5206\u5e03</li> </ul> \u6c14\u5019 <ul> <li>\u6c14\u6e29</li> <li>\u964d\u6c34</li> </ul> \u5f52\u7eb3\u6c14\u5019\u7279\u5f81 <p>\u5b63\u8282+\u6c14\u6e29\u7279\u70b9+\u964d\u6c34\u7279\u70b9</p> \u6cb3\u6d41 <ul> <li>\u5e74\u5f84\u6d41\u91cf <p>\u5e74\u964d\u6c34\u91cf</p> </li> <li>\u5f84\u6d41\u91cf\u5b63\u8282\u53d8\u5316 <p>\u964d\u6c34\u91cf\u5b63\u8282\u53d8\u5316</p> </li> </ul> \u4e9a\u70ed\u5e26\u5b63\u98ce\u6c14\u5019 <p>\\(\\because\\) \u590f\u5b63\u591a\u96e8\uff0c\u51ac\u5b63\u5c11\u96e8</p> <p>\\(\\therefore\\) \u6cb3\u6d41\u5f84\u6d41\u91cf\u590f\u5b63\u5927\uff0c\u51ac\u5b63\u5c11</p> <ul> <li>\u6d41\u901f <p>\u7b49\u9ad8\u7ebf</p> </li> <li>\u6d41\u5411 <p>\u5730\u52bf</p> </li> <li>\u6c34\u80fd <p>\u5730\u52bf\u843d\u5dee\uff0c\u5f84\u6d41\u91cf</p> </li> <li>\u6c34\u4f4d <p>\u6cb3\u6d41\u5bbd\u5ea6\uff0c\u5f84\u6d41\u91cf</p> </li> <li>\u542b\u6c99\u91cf <p>\u571f\u8d28\uff0c\u4eba\u4e3a\u56e0\u7d20</p> </li> <li>\u7ed3\u51b0\u671f <p>\u6c14\u6e29</p> </li> <li>\u6c34\u7cfb\u7279\u5f81\u63cf\u8ff0 <p>\u6cb3\u7f51(\u5bc6\u96c6/\u7a00\u758f)\u3001\u6cb3\u6e56\u6570\u91cf\u3001\u957f\u5ea6\u3001\u5165\u6d77\u53e3\u3001\u6d41\u57df\u9762\u79ef\u7b49</p> </li> </ul> \u8d44\u6e90 <p>\u5e38\u89c1\u8d44\u6e90\uff1a\u571f\u5730\u8d44\u6e90\u3001\u77ff\u4ea7\u8d44\u6e90\u3001\u751f\u7269\u8d44\u6e90\u3001\u6c34\u8d44\u6e90\u3001\u592a\u9633\u80fd\u3001\u98ce\u80fd\u7b49</p> <p>\u5e38\u89c1\u8868\u8ff0\uff1a\"\u571f\u5730\u8d44\u6e90\u5e7f\u9614\uff0c\u571f\u5730\u80a5\u6c83\" \"\u7164\u70ad\u8d44\u6e90\u4e30\u5bcc\" \"\u6c34\u8d44\u6e90\u77ed\u7f3a\"\u7b49</p> \u8015\u5730 <p>\u5206\u4e3a\u4ee5\u4e0b2\u7c7b\uff1a</p> <ol> <li> <p>\u6c34\u7530\uff1a\u6c34\u8d44\u6e90\u4e30\u5bcc\u3001\u5730\u52bf\u4f4e\u5e73\u7684\u5730\u65b9\uff0c\u4e00\u822c\u4ee5\u6c34\u7530\u4e3a\u4e3b</p> </li> <li> <p>\u65f1\u5730\uff1a\u6c34\u8d44\u6e90\u4e0d\u8db3\uff0c\u5730\u52bf\u53c8\u76f8\u5bf9\u8f83\u9ad8\u7684\u5730\u65b9\uff0c\u4e00\u822c\u4ee5\u65f1\u5730\u4e3a\u4e3b</p> </li> </ol>"},{"location":"academic-notes/chinese/junior-notes/geography/#_13","title":"\u63cf\u8ff0\u5730\u533a\u7684\u4eba\u6587\u73af\u5883\ud83d\uddff\u7279\u70b9","text":"<p>\u4eba\u53e3\u3001\u6c11\u65cf\u3001\u57ce\u5e02\u548c\u4e61\u6751\u3001\u98ce\u4fd7\u4e60\u60ef\u7b49</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_14","title":"\u63cf\u8ff0\u65b9\u6cd5","text":"<ul> <li>\u751f\u6d3b\u7279\u8272 <p>\u8863\u98df\u4f4f\u884c\uff0c\u4f20\u7edf\u6587\u5316\uff0c\u98ce\u4fd7\u4e60\u60ef</p> </li> <li>\u519c\u4e1a\u751f\u4ea7 <p>\u519c\u4e1a\u751f\u4ea7\u7c7b\u578b\uff1a\u79cd\u690d\u4e1a\u3001\u6797\u4e1a\u3001\u755c\u7267\u4e1a\u3001\u6e14\u4e1a\u7b49 \u79cd\u690d\u4e1a\uff1a\u4e3b\u8981\u79cd\u690d\u7684\u519c\u4f5c\u7269\u79cd\u7c7b\u3001\u8015\u4f5c\u5236\u5ea6\u3001\u751f\u4ea7\u6761\u4ef6</p> </li> <li>\u5176\u4ed6\u751f\u4ea7\u7279\u8272 <p>\u5236\u9020\u4e1a\u3001\u9ad8\u79d1\u6280\u4ea7\u4e1a\u3001\u91d1\u878d\u4e1a\u3001\u670d\u52a1\u4e1a\u7b49</p> </li> </ul>"},{"location":"academic-notes/chinese/junior-notes/geography/#_15","title":"\u611f\u53d7\u533a\u57df\u7684\u53d1\u5c55","text":"<p>\u4e00\u4e2a\u533a\u57df\u7684\u53d1\u5c55\u4e00\u822c\u53ef\u4ee5\u901a\u8fc7\u8be5\u5730\u7684\u653f\u6cbb\u3001\u7ecf\u6d4e\u548c\u6587\u5316\u53d1\u5c55\u6c34\u5e73\u7b49\u51e0\u4e2a\u65b9\u9762\u6765\u8ba4\u8bc6</p> \u5357\u975e\ud83c\uddff\ud83c\udde6 <p>\u5357\u975e\u4f9d\u9760\u81ea\u7136\u6761\u4ef6\u7684\u4f18\u52bf\uff0c\u56e0\u5730\u5236\u5b9c\u5730\u53d1\u5c55\u7ecf\u6d4e\u3002</p> <p>\u4f8b\u5982\uff0c\u5145\u5206\u5229\u7528\u5176\u77ff\u4ea7\u8d44\u6e90\u4f18\u52bf\uff0c\u5927\u529b\u53d1\u5c55\u91c7\u77ff\u4e1a\u548c\u5236\u9020\u4e1a\uff1b</p> <p>\u5229\u7528\u4e30\u5bcc\u7684\u91ce\u751f\u52a8\u7269\u8d44\u6e90\uff0c\u53d1\u5c55\u65c5\u6e38\u4e1a\uff0c\u7b49\u7b49\u3002</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_16","title":"\u3010\u91cd\u70b9\u63d0\u9192\u3011","text":"\u5f71\u54cd\u519c\u4e1a\u751f\u4ea7\u7684\u56e0\u7d20 \u5149 <ul> <li>\u7eac\u5ea6\uff1a\u7eac\u5ea6\u4f4e\uff0c\u592a\u9633\u8f90\u5c04\u91cf\u4e30\u5bcc</li> <li>\u5929\u6c14\uff1a\u6674\u5929\u591a\uff0c\u5149\u7167\u65f6\u95f4\u957f</li> <li>\u6d77\u62d4\uff1a\u6d77\u62d4\u9ad8\uff0c\u7a7a\u6c14\u7a00\u8584\uff0c\u900f\u660e\u5ea6\u597d\uff0c\u592a\u9633\u8f90\u5c04\u91cf\u4e30\u5bcc</li> </ul> \u70ed <ul> <li>\u5b63\u8282\uff1a\u590f\u5b63\u6e29\u5ea6\u9ad8\uff0c\u70ed\u91cf\u6761\u4ef6\u597d</li> <li>\u7eac\u5ea6\uff1a\u4f4e\u7eac\u5ea6\u5730\u533a\u70ed\u91cf\u6761\u4ef6\u597d</li> <li>\u5730\u5f62\uff1a\u6d77\u62d4\u9ad8\uff0c\u6c14\u6e29\u4f4e\uff0c\u70ed\u91cf\u4e0d\u8db3\uff1b\u76c6\u5730\u5730\u5f62\u4e0d\u6613\u6563\u70ed\uff0c\u70ed\u91cf\u6761\u4ef6\u8f83\u597d\uff0c\u4e1c\u897f\u8d70\u5411\u548c\u4e1c\u5317\u4e00\u897f\u5357\u8d70\u5411\u7684\u5c71\u8109\uff0c\u5927\u5927\u51cf\u5f31\u4e86\u51ac\u5b63\u5bd2\u6f6e\u548c\u51b7\u7a7a\u6c14\u7684\u5165\u4fb5\u7a0b\u5ea6\u7b49</li> </ul> \u6c34 <ul> <li>\u65f6\u95f4\uff1a\u5b63\u8282\u53d8\u5316\u89d2\u5ea6</li> <li>\u7a7a\u95f4\uff1a\u5982\u201c\u4e1c\u591a\u897f\u5c11\u201d\u201c\u5357\u591a\u5317\u5c11\u201d\u201c\u7531\u4e1c\u5357\u6cbf\u6d77\u5411\u897f\u5317\u5185\u9646\u9010\u6e10\u51cf\u5c11\u201d\u7b49</li> <li>\u5f71\u54cd\u964d\u96e8\u56e0\u7d20\uff1a<ol> <li>\u590f\u5b63\u98ce\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u53d7\u590f\u5b63\u98ce\u5f71\u54cd\u660e\u663e\u7684\u5730\u65b9\uff0c\u964d\u6c34\u8f83\u591a\uff09</li> <li>\u6d77\u9646\u4f4d\u7f6e\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6cbf\u6d77\u5730\u533a\u964d\u6c34\u591a\uff0c\u5185\u9646\u5730\u533a\u964d\u6c34\u5c11\uff09\u3002</li> <li>\u5730\u5f62\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u6e7f\u6da6\u6c14\u6d41\u9047\u5230\u9ad8\u5c71\u963b\u6321\u65f6\uff0c\u8fce\u98ce\u5761\u964d\u6c34\u591a\uff0c\u80cc\u98ce\u5761\u964d\u6c34\u5c11\uff09</li> </ol> </li> </ul> \u571f <ol> <li>\u5730\u5f62\uff1a\u5982\u5e73\u539f\uff0c\u5e73\u5766\u8fbd\u9614\uff0c\u9002\u5b9c\u79cd\u690d\u519c\u4f5c\u7269\uff1b\u4e18\u9675\u9002\u5408\u79cd\u690d\u8336\u53f6\u3001\u67d1\u6a58\u7b49\u7ecf\u6d4e\u4f5c\u7269</li> <li>\u571f\u58e4\uff1a\u5982\u6cb3\u6d41\u51b2\u79ef\u5e73\u539f\uff0c\u571f\u58e4\u80a5\u6c83\uff0c\u9002\u5408\u519c\u4f5c\u7269\u7684\u751f\u957f\uff1b\u4e1c\u5357\u4e18\u9675\u5730\u533a\u7684\u9178\u6027\u571f\u58e4\u9002\u5b9c\u79cd\u690d\u8336\u6811\u7b49\u4f5c\u7269\uff1b\u78b1\u6027\u571f\u58e4\u5219\u9002\u5408\u79cd\u690d\u559c\u78b1\u6027\u7684\u4f5c\u7269</li> </ol> \u5f71\u54cd\u5de5\u4e1a\u751f\u4ea7\u7684\u56e0\u7d20 <p>\u5730\u7406\u4f4d\u7f6e\u3001\u8d44\u6e90\u3001\u4ea4\u901a\u3001\u5e02\u573a\u3001\u79d1\u6280\u3001\u4eba\u624d\u3001\u52b3\u52a8\u529b\u3001\u8d44\u91d1\u3001\u9996\u7840\u8bbe\u65bd\u3001\u5386\u53f2\u6761\u4ef6\u3001\u653f\u7b56\u652f\u6301\u7b49</p> \u73e0\u4e09\u89d2\u5730\u533a <p>\u8fd8\u8981\u8003\u8651\u662f\u5426\u9760\u8fd1\u6e2f\u6fb3\uff0c\u662f\u5426\u5730\u5904\u4fa8\u4e61\u3002\u8fd9\u91cc\u6709\u4ee5\u5f15\u5916\u6765\u8d44\u91d1\u5c24\u5176\u662f\u6ee4\u6fb3\u8d44\u5168\u7684\u6709\u5229\u6761\u4ef6\uff0c\u8fd8\u6709\u53d1\u8fbe\u7684\u5e02\u573a\u7ecf\u6599\u5e7f\u9614\u7684\u5e02\u573a\u7b49\u3002</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#ii","title":"\u2161. \u5171\u540c\u7684\u5bb6\u56ed \u5171\u540c\u7684\u5c81\u6708","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_17","title":"\u5927\u6d32\u26f0\ufe0f\u548c\u5927\u6d0b\ud83c\udf0a","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300b P22~27\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_18","title":"\u6d77\u9646\u5206\u5e03","text":"<p>\u6d77\u6d0b\u536071%\uff0c\u9646\u5730\u536029%</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_19","title":"\u5927\u6d32\u26f0\ufe0f","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_20","title":"\u542b\u4e49","text":"<p>\u5927\u9646\u4e0e\u5176\u9644\u8fd1\u7684\u5c9b\u5c7f\u5408\u8d77\u6765\u79f0\u4f5c\u5927\u6d32</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_21","title":"\u6392\u5217\ud83d\udce2","text":"<p>\u4e9a\u6d32\ud83c\udf0f &gt; \u975e\u6d32\ud83c\udf0d &gt; \u5317\u7f8e\u6d32\ud83c\udf0e &gt; \u5357\u7f8e\u6d32\ud83c\udf0e &gt; \u5357\u6781\u6d32\ud83c\udde6\ud83c\uddf6 &gt; \u6b27\u6d32\ud83c\udf0d &gt; \u5927\u6d0b\u6d32\ud83c\udf0f</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_22","title":"\u5206\u754c\u7ebf\u3030\ufe0f","text":"\u5206\u754c\u7ebf \u4e9a\u6d32\u4e0e\u5317\u7f8e\u6d32\u767d\u4ee4\u6d77\u5ce1\u6240\u5728\u5927\u6d32\u6b27\u6d32\u4e0e\u975e\u6d32\u5730\u4e2d\u6d77\u2014\u76f4\u5e03\u7f57\u9640\u6d77\u5ce1\u4e9a\u6b27\u4ea4\u754c\u975e\u6d32\u4e0e\u4e9a\u6d32\u82cf\u4f0a\u58eb\u8fd0\u6cb3\u5317\u7f8e\u6d32\u4e9a\u6d32\u4e0e\u6b27\u6d32\u4e4c\u62c9\u5c14\u5c71\u8109\u4e00\u4e4c\u62c9\u5c14\u6cb3\u4e00\u91cc\u6d77\u4e00\u5927\u9ad8\u52a0\u7d22\u5c71\u8109\u4e00\u9ed1\u6d77\u2014\u571f\u8033\u5176\u6d77\u5ce1\u4e9a\u6d32\u5317\u7f8e\u6d32\u4e0e\u5357\u7f8e\u6d32\u5df4\u62ff\u9a6c\u8fd0\u6cb3\u4e9a\u6d32\u5357\u7f8e\u6d32\u4e0e\u5357\u6781\u6d32\u5fb7\u96f7\u514b\u6d77\u5ce1\u4e9a\u6d32\u9131\u9633\u6e56\u4e2d\u56fd\u9762\u79ef\u6700\u5927\u7684\u6de1\u6c34\u6e56\u4e9a\u6d32"},{"location":"academic-notes/chinese/junior-notes/geography/#_23","title":"\u5206\u533a\u00a7","text":"<p>\u4e9a\u6d32\ud83c\udf0f\uff1a\u4e1c\u4e9a\u3001\u4e1c\u5357\u4e9a\u3001\u5357\u4e9a\u3001\u4e2d\u4e9a\u3001\u897f\u4e9a\u3001\u5317\u4e9a</p> <p>\u6b27\u6d32\ud83c\udf0d\uff1a\u5357\u6b27\u3001\u897f\u6b27\u3001\u4e2d\u6b27\u3001\u5317\u6b27\u3001\u4e1c\u6b27</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_24","title":"\u5927\u6d0b\ud83c\udf0a","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_25","title":"\u6392\u5217\ud83d\udce2","text":"<p>\u592a\u5e73\u6d0b &gt; \u5927\u897f\u6d0b &gt; \u5370\u5ea6\u6d0b &gt; \u5317\u51b0\u6d0b</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_26","title":"\u8457\u540d\u8fd0\u6cb3 &amp; \u6d77\u5ce1","text":"\u8457\u540d\u8fd0\u6cb3 &amp; \u6d77\u5ce1 \u8fd0\u6cb3\u540d\u79f0 \u5730\u7406\u4f4d\u7f6e \u6c9f\u901a\u6d77\u6d0b \u82cf\u4f0a\u58eb\u8fd0\u6cb3 \u4e9a\u6d32\u548c\u975e\u6d32\u7684\u5206\u754c\u5904 \u5730\u4e2d\u6d77--\u7ea2\u6d77 \u5df4\u62ff\u9a6c\u8fd0\u6cb3 \u5357\u3001\u5317\u7f8e\u6d32\u7684\u5206\u754c\u5904 \u592a\u5e73\u6d0b--\u5927\u897f\u6d0b \u6d77\u5ce1\u540d\u79f0 \u5730\u7406\u4f4d\u7f6e \u6c9f\u901a\u7684\u6d77\u6d0b \u9a6c\u516d\u7532\u6d77\u5ce1 \u4f4d\u4e8e\u4e1c\u5357\u4e9a \u592a\u5e73\u6d0b\u4e00\u5370\u5ea6\u6d0b \u5fb7\u96f7\u514b\u6d77\u5ce1 \u4f4d\u4e8e\u5357\u7f8e\u6d32\u3001\u5357\u6781\u6d32\u4e4b\u95f4 \u592a\u5e73\u6d0b\u4e00\u5927\u897f\u6d0b \u9ea6\u54f2\u4f26\u6d77\u5ce1 \u4f4d\u4e8e\u5357\u7f8e\u6d32\u5357\u7aef \u592a\u5e73\u6d0b\u4e00\u5927\u897f\u6d0b \u767d\u4ee4\u6d77\u5ce1 \u4f4d\u4e8e\u4e9a\u6d32\u3001\u5317\u7f8e\u6d32\u4e4b\u95f4 \u592a\u5e73\u6d0b\u4e00\u5317\u51b0\u6d0b \u76f4\u5e03\u7f57\u9640\u6d77\u5ce1 \u4f4d\u4e8e\u6b27\u6d32\u3001\u975e\u6d32\u4e4b\u95f4 \u5730\u4e2d\u6d77\u4e00\u5927\u897f\u6d0b \u970d\u5c14\u6728\u5179\u6d77\u5ce1 \u4f4d\u4e8e\u963f\u62c9\u4f2f\u534a\u5c9b \u4f0a\u6717\u4e4b\u95f4 \u6ce2\u65af\u6e7e\u4e00\u5370\u5ea6\u6d0b (\u963f\u62c9\u4f2f\u6d77) \u66fc\u5fb7\u6d77\u5ce1 \u4f4d\u4e8e\u4e9a\u6d32\u3001\u975e\u6d32\u4e4b\u95f4 \u7ea2\u6d77\u4e00\u5370\u5ea6\u6d0b (\u963f\u62c9\u4f2f\u6d77)"},{"location":"academic-notes/chinese/junior-notes/geography/#_27","title":"\u6d77\u6d0b\ud83c\udf0a\u5bf9\u4eba\u7c7b\ud83e\uddcd\ud83c\udfff\u7684\u5f71\u54cd","text":"<ol> <li>\u6de1\u6c34\ud83d\udca7\u8d44\u6e90</li> <li>\u6e14\u76d0\ud83d\udc1f\ud83e\uddc2\u8d44\u6e90</li> <li>\u4e3a\u65c5\u6e38\u4e1a\u63d0\u4f9b\u8d44\u6e90</li> <li>\u7a7a\u95f4\u8d44\u6e90</li> </ol> <p>\u5f00\u8f9f\u6d77\u4e0a\u4ea4\u901a\u822a\u7ebf\uff0c\u4fee\u7b51\u8fd0\u6cb3\uff0c\u5efa\u8bbe\u6e2f\u53e3\uff0c\u4fc3\u8fdb\u4e16\u754c\u5404\u5730\u4e4b\u95f4\u7684\u7269\u8d44\u4ea4\u6d41</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_28","title":"\u3010\u91cd\u70b9\u63d0\u9192\u3011","text":"\u9646\u5730\u7684\u6784\u6210 <p>\u9646\u5730\u5206\u4e3a\u5927\u9646\u548c\u5c9b\u5c7f</p> <ul> <li>\u5927\u9646\u26f0\ufe0f</li> </ul> <p>\u6700\u5927\u7684\u5927\u9646\uff1a\u4e9a\u6b27\u5927\u9646\ud83c\udf0f</p> <p>\u6700\u5c0f\u7684\u5927\u9646\uff1a\u6fb3\u5927\u5229\u4e9a\u5927\u9646\ud83c\udde6\ud83c\uddfa</p> <ul> <li>\u5c9b\u5c7f\ud83c\udfdd\ufe0f</li> </ul> <p>\u6700\u5927\u7684\u5c9b\u5c7f\uff1a\u683c\u9675\u5170\u5c9b\ud83c\uddec\ud83c\uddf1</p> <p>\u6700\u5927\u7684\u7fa4\u5c9b\uff1a\u9a6c\u6765\u7fa4\u5c9b\ud83c\uddf2\ud83c\uddfe</p> <ul> <li>\u534a\u5c9b</li> </ul> <p>\u6700\u5927\u7684\u534a\u5c9b\uff1a\u963f\u62c9\u4f2f\u534a\u5c9b\ud83c\uddf8\ud83c\udde6</p> \u8d64\u9053\u7a7f\u8fc7\u7684\u5927\u6d32 <p>\u975e\u6d32\u3001\u4e9a\u6d32\u3001\u5927\u6d0b\u6d32\u3001\u5357\u7f8e\u6d32</p> \u56de\u5f52\u7ebf\u7a7f\u8fc7\u7684\u5927\u6d32 <p>\u5317\u56de\u5f52\u7ebf</p> <p>\u975e\u6d32\u3001\u4e9a\u6d32\u3001\u5927\u6d0b\u6d32\u3001\u5317\u7f8e\u6d32</p> <p>\u5357\u56de\u5f52\u7ebf\uff1a</p> <p>\u975e\u6d32\u3001\u5927\u6d0b\u6d32\u3001\u5357\u7f8e\u6d32</p> \u6781\u5708\u7a7f\u8fc7\u7684\u5927\u6d32 <p>\u5317\u6781\u5708</p> <p>\u6b27\u6d32\u3001\u4e9a\u6d32\u3001\u5317\u7f8e\u6d32</p> <p>\u5357\u6781\u5708</p> <p>\u5357\u6781\u6d32</p> \u8de8\u7ecf\u5ea6\u6700\u5e7f\u3001\u7eac\u5ea6\u6700\u9ad8 <p>\u6d32\u26f0\ufe0f\uff1a\u5357\u6781\u6d32</p> <p>\u6d0b\ud83c\udf0a\uff1a\u5317\u51b0\u6d0b</p> \u5927\u6d32\u5e73\u5747\u6d77\u62d4\u4e4b\u6700 <p>\u6700\u9ad8\uff1a\u5357\u6781\u6d32</p> <p>\u6700\u4f4e\uff1a\u6b27\u6d32</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_29","title":"\u4e16\u754c\u81ea\u7136\u73af\u5883","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300b P21, P28~39\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_30","title":"\u5730\u5f62\u591a\u6837","text":"\u4e94\u79cd\u57fa\u672c\u5730\u5f62 \u7c7b\u578b \u6d77\u62d4 \u5730\u8868\u7279\u5f81 \u5c71\u5730 500\u7c73\u4ee5\u4e0a \u5cf0\u5ce6\u8d77\u4f0f,\u5761\u5ea6\u9661\u5cfb\u3002\u6709\u7684\u5448\u957f\u6761\u72b6\u5ef6\u4f38,\u5f62\u6210\u5c71\u8109\u3002 \u5c71\u8109\u6392\u5217\u6709\u5e8f,\u8109\u7edc\u5206\u660e,\u4eff\u4f5b\u662f\"\u5927\u5730\u7684\u9aa8\u67b6\" \u9ad8\u539f 500\u7c73\u4ee5\u4e0a \u5730\u8868\u8d77\u4f0f\u4e0d\u5927,\u4f46\u8fb9\u7f18\u5904\u6bd4\u8f83\u9661\u5ced;\u4e5f\u6709\u7684\u9ad8\u539f\u8868\u9762 \u5c71\u5ce6\u8d77\u4f0f,\u51f9\u51f8\u4e0d\u5e73 \u4e18\u9675 200~500\u7c73 \u8d77\u4f0f\u548c\u7f13 \u5e73\u539f 200\u7c73\u4ee5\u4e0b \u5730\u9762\u5e73\u5766\u6216\u8d77\u4f0f\u8f83\u5c0f,\u4e3b\u8981\u5206\u5e03\u5728\u5927\u6cb3\u4e24\u5cb8\u548c\u6fd2\u4e34\u6d77\u6d0b\u7684\u5730\u533a \u76c6\u5730 \u65e0\u6807\u51c6 \u56db\u5468\u88ab\u7fa4\u5c71\u73af\u7ed5,\u56db\u5468\u9ad8,\u4e2d\u95f4\u4f4e"},{"location":"academic-notes/chinese/junior-notes/geography/#_31","title":"\u4e16\u754c\u4e0a\u91cd\u8981\u7684\u5730\u5f62\u5355\u5143","text":"\u91cd\u8981\u7684\u5730\u5f62\u5355\u5143 \u5730\u5f62\u7c7b\u578b\u91cd\u8981\u5730\u5f62\u5355\u5143\u7279\u70b9\u6240\u5728\u5927\u6d32\u5c71\u8109\u5b89\u7b2c\u65af\u5c71\u8109\u4e16\u754c\u4e0a\u6700\u957f\u7684\u5c71\u8109\u5357\u7f8e\u6d32\u559c\u9a6c\u62c9\u96c5\u5c71\u8109\u4e16\u754c\u4e0a\u6700\u9ad8\u7684\u5c71\u8109\u4e9a\u6d32\u9ad8\u539f\u9752\u85cf\u9ad8\u539f\u4e16\u754c\u4e0a\u6700\u9ad8\u7684\u9ad8\u539f\u4e9a\u6d32\u5df4\u897f\u9ad8\u539f\u4e16\u754c\u4e0a\u6700\u5927\u7684\u9ad8\u539f\u5357\u7f8e\u6d32\u5e73\u539f\u4e9a\u9a6c\u5b59\u5e73\u539f\u4e16\u754c\u4e0a\u6700\u5927\u7684\u70ed\u5e26\u96e8\u6797\u533a\u5357\u7f8e\u6d32\u76c6\u5730\u521a\u679c\u76c6\u5730\u975e\u6d32\u6700\u5927\u7684\u76c6\u5730\u975e\u6d32"},{"location":"academic-notes/chinese/junior-notes/geography/#_32","title":"\u3010\u91cd\u70b9\u63d0\u9192\u3011","text":"\u5982\u4f55\u63cf\u8ff0\u4e00\u4e2a\u5730\u533a\u7684\u5730\u5f62\u7279\u70b9 <p>\u4e00\u822c\u53ef\u4ee5\u4ece\u6d77\u62d4\u3001\u5730\u9762\u8d77\u4f0f\u3001\u5730\u5f62\u7684\u79cd\u7c7b\u548c\u5206\u5e03\u4e09\u4e2a\u65b9\u9762\u6765\u63cf\u8ff0</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_33","title":"\u6c14\u8c61\u4e07\u5343","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300b P21, P28~39\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_34","title":"\u6c14\u5019\u7684\u6982\u5ff5","text":"<p>\u6c14\u5019\u662f\u4e00\u4e2a\u5730\u533a\u591a\u5e74\u7684\u5929\u6c14\u5e73\u5747\u72b6\u51b5 \u4e00\u4e2a\u5730\u65b9\u7684\u6c14\u5019\u5177\u6709\u4e00\u5b9a\u7684\u7a33\u5b9a\u6027</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_35","title":"\u6c14\u5019\u7684\u63cf\u8ff0","text":"\u901a\u8fc7\u6c14\u6e29\u66f2\u7ebf\u56fe\u548c\u964d\u6c34\u91cf\u67f1\u72b6\u56fe\uff0c\u4ece\u6c14\u6e29\u548c\u964d\u6c34\u4e24\u4e2a\u65b9\u9762\u63cf\u8ff0 <p>\u6c14\u6e29\u7684\u53d8\u5316\u7279\u70b9\u3001\u964d\u6c34\u7684\u65f6\u95f4\u5206\u5e03\u3001\u6c34\u70ed\u7684\u543b\u5408\u60c5\u51b5!</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_36","title":"\u5224\u65ad\u6c14\u5019\u7c7b\u578b\u7684\u65b9\u6cd5","text":"\u4ee5\"\u6e29\"\u5b9a\"\u5e26\"\u4ee5\"\u6c34\"\u5b9a\"\u578b\"\u6700\u51b7\u6708\u6708\u5747\u6e29\u6e29\u5ea6\u5e26\u964d\u6c34\u5b63\u8282\u5206\u914d\u89c4\u5f8b\u6c14\u5019\u7c7b\u578b&gt;15C\u70ed\u5e26\u590f\u96e8\u578b(\u5168\u5e741500~2000\u6beb\u7c73)\u70ed\u5e26\u5b63\u98ce\u6c14\u5019\u5c11\u96e8\u578b\u70ed\u5e26\u6c99\u6f20\u6c14\u5019\u5e74\u96e8\u578b\u70ed\u5e26\u96e8\u6797\u6c14\u50190~15C\u4e9a\u70ed\u5e26\u590f\u96e8\u578b(\u5168\u5e74&gt;800\u6beb\u7c73)\u4e9a\u70ed\u5e26\u5b63\u98ce\u548c\u6e7f\u6da6\u6c14\u5019\u51ac\u96e8\u578b\u5730\u4e2d\u6d77\u6c14\u5019-15~0C\u6e29\u5e26\u590f\u96e8\u578b(\u5168\u5e74&lt;800\u6beb\u7c73)\u6e29\u5e26\u5b63\u98ce\u6c14\u5019&gt;0C\u5c11\u96e8\u578b\u6e29\u5e26\u5927\u9646\u6027\u6c14\u5019\u5e74\u96e8\u578b\u6e29\u5e26\u6d77\u6d0b\u6027\u6c14\u5019"},{"location":"academic-notes/chinese/junior-notes/geography/#_37","title":"\u4e3b\u8981\u6c14\u5019\u7c7b\u578b","text":"\u4e3b\u8981\u6c14\u5019\u7c7b\u578b <ul> <li>\u70ed\u5e26\u5357\u6797\u6c14\u5019\uff1a\u7ec8\u5e74\u9ad8\u6e29\u591a\u96e8</li> <li>\u70ed\u5e26\u7ae0\u539f\u6c14\u5019\uff1a\u7ec8\u5e74\u9ad8\u6e29 \u5206\u5e72\u6e7f\u4e24\u5b63</li> <li>\u70ed\u5e26\u5b63\u98ce\u6c14\u5019\uff1a\u7ec8\u5e74\u9ad8\u6e29 \u5206\u65f1\u96e8\u4e24\u5b63</li> <li>\u70ed\u5e26\u6c99\u6de1\u6c14\u5019\uff1a\u7ec8\u5e74\u708e\u70ed\u5e72\u65f1</li> <li>\u4e9a\u70ed\u5e26\u5b63\u98ce\u548c\u6e7f\u6da6\u6c14\u5019\uff1a\u590f\u5b63\u9ad8\u6e29\u591a\u96e8 \u51ac\u5b63\u6e29\u548c\u5c11\u96e8</li> <li>\u5730\u4e2d\u6d77\u6c14\u5019\uff1a\u590f\u5b63\u708e\u70ed\u5e72\u71e5 \u51ac\u5b63\u6e29\u548c\u591a\u96e8</li> <li>\u6e29\u5e26\u6d77\u6d0b\u6027\u6c14\u5019\uff1a\u51ac\u6e29\u590f\u51c9 \u5168\u5e74\u964d\u6c34\u5747\u5300</li> <li>\u6e29\u5e26\u5b63\u98ce\u6c14\u5019\uff1a\u590f\u5b63\u9ad8\u6e29\u591a\u96e8 \u51ac\u5b63\u5bd2\u51b7\u5e72\u71e5</li> <li>\u6e29\u5e26\u5927\u9646\u6027\u6c14\u5019\uff1a\u51ac\u51b7\u590f\u70ed \u5168\u5e74\u964d\u6c34\u8f83\u5c11</li> <li>\u5bd2\u5e26\u6c14\u5019\uff1a\u7ec8\u5e74\u5bd2\u51b7\u5e72\u71e5</li> </ul> Tip <p>\u5bd2\u51b7\uff0c\u5f88\u591a\u5730\u65b9\u7ec8\u5e74\u51b0\u96ea\u8986\u76d6\uff0c\u6c14\u4faf\u91cd\u76f4\u53d8\u5316\u660e\u663e\u3002\u4e3b\u8981\u5206\u5e03\u5728\u9ad8\u5927\u7684\u9ad8\u539f\u3001\u5c71\u5730\u7b49\u5730\u533a\uff0c\u5982\u9752\u85cf\u9ad8\u539f\u3001\u963f\u5c14\u5351\u65af\u5c71\u3001\u5b89\u7b2c\u65af\u5c71\u8109\u7b49\u3002</p> <p></p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_38","title":"\u4e16\u754c\u4e3b\u8981\u6c14\u5019\u7c7b\u578b\u7684\u5206\u5e03\u60c5\u51b5","text":"\u6c14\u5019\u7c7b\u578b\u4e3b\u8981\u5206\u5e03\u5730\u533a(\u89c1\u5c01\u4e09\u5f69\u56fe)\u53ca\u7279\u70b9\u70ed \u5e26\u70ed\u5e26 \u96e8\u6797 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u5927\u81f4\u5728\u5357\u5317\u7eac10\u00b0\u4e4b\u95f4\u3002 \u5178\u578b\u5730\u533a:\u4e9a\u9a6c\u5b59\u6cb3\u6d41\u57df\u3001\u521a\u679c\u6cb3\u6d41\u57df\u3001\u9a6c\u6765\u7fa4\u5c9b\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u7ec8\u5e74\u9ad8\u6e29\u591a\u96e8\u3002\u690d\u88ab\u751f\u957f\u65fa\u76db,\u690d\u7269\u79cd\u7c7b\u7e41\u591a\u70ed\u5e26 \u8349\u539f \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u5927\u81f4\u5728\u5357\u5317\u7eac10\u00b0\u81f3\u5357\u5317\u56de\u5f52\u7ebf\u4e4b\u95f4\u3002 \u5178\u578b\u5730\u533a:\u975e\u6d32\u4e2d\u90e8\u3001\u5357\u7f8e\u5df4\u897f\u3001\u6fb3\u5927\u5229\u4e9a\u5927\u9646\u5317\u90e8\u548c\u5357\u90e8\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u7ec8\u5e74\u9ad8\u6e29,\u4e00\u5e74\u6709\u660e\u663e\u7684\u5e72\u6e7f\u4e24\u5b63\u3002\u690d\u88ab\u662f\u7a00\u6811\u8349\u539f\u70ed\u5e26 \u5b63\u98ce \u6c14\u5019\u5206\u5e03\u89c4\u5f8b \u5927\u81f4\u5728\u5317\u7eac10\u00b0\u81f3\u5317\u56de\u5f52\u7ebf\u9644\u8fd1\u7684\u5357\u4e9a\u548c\u4e1c\u5357\u4e9a\u5927\u90e8\u5206\u5730\u533a\u3002 \u5178\u578b\u5730\u533a:\u4e9a\u6d32\u4e2d\u5357\u534a\u5c9b\u548c\u5370\u5ea6\u534a\u5c9b\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u7ec8\u5e74\u9ad8\u6e29,\u5206\u65f1\u96e8\u4e24\u5b63,\u590f\u5b63\u591a\u96e8\u3002\u690d\u88ab\u4e3a\u70ed\u5e26\u5b63\u96e8\u6797\u70ed\u5e26 \u6c99\u6f20 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u5927\u81f4\u5728\u56de\u5f52\u7ebf\u9644\u8fd1\u7684\u5927\u9646\u5185\u90e8\u548c\u897f\u5cb8\u3002 \u5178\u578b\u5730\u533a:\u6492\u54c8\u62c9\u3001\u963f\u62c9\u4f2f\u534a\u5c9b\u3001\u6fb3\u5927\u5229\u4e9a\u4e2d\u897f\u90e8\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u7ec8\u5e74\u9ad8\u6e29,\u964d\u6c34\u7a00\u5c11\u3002\u690d\u88ab\u4ee5\u7eff\u6d32\u533a\u7684\u8010\u65f1\u690d\u7269\u4e3a\u4e3b\u4e9a \u70ed \u5e26\u4e9a\u70ed\u5e26 \u5b63\u98ce\u548c \u6e7f\u6da6\u6c14\u5019\u5206\u5e03\u89c4\u5f8b \u5927\u81f4\u5728\u5357\u5317\u7eac25\u00b0\u81f3\u5357\u5317\u7eac35\u3002\u4e4b\u95f4\u7684\u5927\u9646\u4e1c\u5cb8\u3002 \u5178\u578b\u5730\u533a:\u4e2d\u56fd\u5357\u65b9\u3001\u97e9\u56fd\u3001\u65e5\u672c\u5927\u90e8\u5206\u5730\u533a\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u590f\u5b63\u9ad8\u6e29\u591a\u96e8,\u51ac\u5b63\u6e29\u548c\u5c11\u96e8\u3002\u690d\u88ab\u4ee5\u5e38\u7eff\u9614\u53f6\u6797\u4e3a\u4e3b\u5730\u4e2d\u6d77 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u5357\u5317\u7eac30\u00b0\u81f3\u5357\u5317\u7eac40\u00b0\u4e4b\u95f4\u7684\u5927\u9646\u897f\u5cb8\u3002 \u5178\u578b\u5730\u533a:\u5730\u4e2d\u6d77\u6cbf\u5cb8\u5730\u533a\u5206\u5e03\u6700\u5e7f\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u590f\u5b63\u708e\u70ed\u5e72\u71e5,\u51ac\u5b63\u6e29\u548c\u591a\u96e8\u3002\u690d\u88ab\u4ee5\u5e38\u7eff\u786c\u53f6\u6797\u4e3a\u4e3b\u6e29 \u5e26\u6e29\u5e26 \u5b63\u98ce \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u4e3b\u8981\u5206\u5e03\u5728\u4e9a\u6d32\u4e1c\u90e8\u7684\u4e2d\u7eac\u5ea6\u5730\u533a\u3002 \u5178\u578b\u5730\u533a:\u6211\u56fd\u5317\u65b9\u3001\u65e5\u672c\u5317\u90e8\u3001\u671d\u9c9c\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u590f\u5b63\u9ad8\u6e29\u591a\u96e8,\u51ac\u5b63\u5bd2\u51b7\u5e72\u71e5\u3002\u690d\u88ab\u4ee5\u843d\u53f6\u9614\u53f6\u6797\u548c\u9488 \u9614\u6df7\u4ea4\u6797\u4e3a\u4e3b\u6e29\u5e26 \u5927\u9646\u6027 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u4e3b\u8981\u5206\u5e03\u5728\u4e2d\u7eac\u5ea6\u5185\u9646\u5730\u533a\u3002 \u5178\u578b\u5730\u533a:\u4e9a\u6b27\u5927\u9646\u548c\u5317\u7f8e\u5927\u9646\u7684\u5185\u9646\u5730\u533a\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u51ac\u51b7\u590f\u70ed,\u964d\u6c34\u8f83\u5c11\u3002\u591a\u6c99\u6f20\u548c\u8349\u539f\u6e29\u5e26 \u6d77\u6d0b\u6027 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u4e3b\u8981\u5206\u5e03\u5728\u5357\u5317\u7eac40\u00b0\u81f3\u5357\u5317\u7eac60\u00b0\u4e4b\u95f4\u7684\u5927\u9646\u897f\u5cb8\u3002 \u5178\u578b\u5730\u533a:\u4ee5\u6b27\u6d32\u897f\u90e8\u6700\u5e7f\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u51ac\u6e29\u590f\u51c9,\u5168\u5e74\u964d\u6c34\u5747\u5300\u3002\u690d\u88ab\u4e3a\u843d\u53f6\u9614\u53f6\u6797\u5bd2\u5e26\u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u4e3b\u8981\u5206\u5e03\u5728\u6781\u5708\u4ee5\u5185\u7684\u9ad8\u7eac\u5ea6\u5730\u533a\u3002 \u5178\u578b\u5730\u533a:\u5357\u6781\u6d32\u3001\u683c\u9675\u5170\u5c9b\u53ca\u4e9a\u6b27\u5927\u9646\u548c\u5317\u7f8e\u5927\u9646\u7684\u5317\u51b0\u6d0b\u6cbf\u5cb8\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u7ec8\u5e74\u4e25\u5bd2\u5c11\u96e8\u3002\u6709\u82d4\u85d3\u3001\u5730\u8863\u7b49\u690d\u88ab\u5206\u5e03\u6216\u5b8c\u5168\u88ab\u51b0\u96ea\u8986\u76d6\u9ad8\u539f\u5c71\u5730 \u6c14\u5019\u5206\u5e03\u89c4\u5f8b:\u4e3b\u8981\u5206\u5e03\u5728\u9ad8\u5927\u7684\u9ad8\u539f\u3001\u5c71\u5730\u5730\u533a\u3002 \u5178\u578b\u5730\u533a:\u9752\u85cf\u9ad8\u539f\u3001\u5357\u7f8e\u6d32\u7684\u5b89\u7b2c\u65af\u5c71\u7b49\u3002 \u6c14\u5019\u53ca\u690d\u88ab\u7279\u70b9:\u5bd2\u51b7,\u5f88\u591a\u5730\u65b9\u7ec8\u5e74\u51b0\u96ea\u8986\u76d6,\u6c14\u5019\u5782\u76f4\u53d8\u5316\u660e\u663e\u3002\u690d \u88ab\u4e5f\u5448\u73b0\u5782\u76f4\u53d8\u5316\u7684\u7279\u70b9"},{"location":"academic-notes/chinese/junior-notes/geography/#_39","title":"\u3010\u91cd\u70b9\u63d0\u9192\u3011","text":"\u975e\u6d32\u6c14\u5019\u5206\u5e03\u7684\u7279\u70b9 <p>\u57fa\u672c\u4e0a\u4ee5\u8d64\u9053\u4e3a\u4e2d\u5fc3\uff0c\u5357\u5317\u5bf9\u79f0\uff0c\u5b63\u8282\u76f8\u53cd</p> \u4e16\u754c\u4e0a\u5206\u5e03\u9762\u79ef\u6700\u5927\u7684\u6c14\u5019\u7c7b\u578b <p>\u6e29\u5e26\u5927\u9646\u6027\u6c14\u5019</p> \u9664\u5357\u6781\u6d32\u5916\u5404\u5927\u6d32\u90fd\u6709\u5206\u5e03\u7684\u6c14\u5019\u7c7b\u578b <p>\u6e29\u5e26\u5927\u9646\u6027\u6c14\u5019</p> \u4e9a\u6d32\u6ca1\u6709\u5206\u5e03\u7684\u6c14\u5019\u7c7b\u578b <p>\u70ed\u5e26\u8349\u539f\u6c14\u5019\u3001\u6e29\u5e26\u6d77\u6d0b\u6027\u6c14\u5019</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_40","title":"\u4f17\u591a\u7684\u6cb3\u6e56","text":""},{"location":"academic-notes/chinese/junior-notes/geography/#_41","title":"\u6cb3\u6d41\u4e0e\u6e56\u6cca","text":"<p>\u6cb3\u6d41\u88ab\u6210\u4e3a\u5927\u5730\u7684\u52a8\u8109\uff0c\u6e56\u6cca\u88ab\u8a89\u4e3a\u5927\u5730\u7684\u660e\u73e0\uff0c\u5c71\u8109\u4e3a\u5927\u5730\u7684\u9aa8\u67b6</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#_42","title":"\u4e16\u754c\u4e3b\u8981\u7684\u6cb3\u6d41\u4e0e\u6e56\u6cca","text":"\u4e3b\u8981\u7684\u6cb3\u6d41 \u6cb3\u6d41\u6d41\u5411\u6ce8\u5165\u7279\u70b9\u6240\u5728\u5927\u6d32\u5c3c\u7f57\u6cb3\u81ea\u5357\u5411\u5317\u6d41\u5730\u4e2d\u6d77\u4e16\u754c\u7b2c\u4e00\u957f\u6cb3\u975e\u6d32\u4e9a\u9a6c\u5b59\u6cb3\u81ea\u897f\u5411\u4e1c\u6d41\u5927\u897f\u6d0b\u4e16\u754c\u7b2c\u4e8c\u957f\u6cb3\u3001\u6d41\u91cf\u6700\u5927\u3001 \u6d41\u57df\u9762\u79ef\u6700\u5e7f\u7684\u6cb3\u6d41\u5357\u7f8e\u6d32\u957f\u6c5f\u81ea\u897f\u5411\u4e1c\u6d41\u4e1c\u6d77\u4e16\u754c\u7b2c\u4e09\u957f\u6cb3\u4e9a\u6d32\u5bc6\u897f\u897f\u6bd4\u6cb3\u81ea\u5317\u5411\u5357\u6d41\u58a8\u897f\u54e5\u6e7e\u4e16\u754c\u7b2c\u56db\u957f\u6cb3\u5317\u7f8e\u6d32\u9ec4\u6cb3\u81ea\u897f\u5411\u4e1c\u6d41\u6e24\u6d77\u542b\u6c99\u91cf\u8f83\u5927\u4e9a\u6d32\u521a\u679c\u6cb3\u6ce8:\u5404\u6bb5\u6d41\u5411\u4e0d \u4e00\u81f4\u5927\u897f\u6d0b\u4e16\u754c\u4e0a\u6c34\u80fd\u8574\u85cf\u91cf\u6700\u5927\u7684 \u6cb3\u6d41\u975e\u6d32\u591a\u7459\u6cb3\u81ea\u897f\u5411\u4e1c\u6d41\u9ed1\u6d77\u4e16\u754c\u4e0a\u6d41\u7ecf\u56fd\u5bb6\u6700\u591a\u7684\u6cb3\u6d41\u6b27\u6d32\u6e44\u516c\u6cb3\u81ea\u5317\u5411\u5357\u6d41\u5357\u6d77\u4e9a\u6d32\u6d41\u7ecf\u56fd\u5bb6\u6700\u591a\u7684\u6cb3\u6d41\u4e9a\u6d32\u83b1\u8335\u6cb3\u81ea\u5357\u5411\u5317\u6d41\u5927\u897f\u6d0b\u6b27\u6d32\u8457\u540d\u7684\u56fd\u9645\u6027\u6cb3\u6d41\u6b27\u6d32 \u4e3b\u8981\u7684\u6e56\u6cca \u6e56\u6cca\u7279\u70b9\u6240\u5728\u5927\u6d32\u91cc\u6d77\u4e16\u754c\u9762\u79ef\u6700\u5927\u7684\u54b8\u6c34\u6e56\u4e9a\u6b27\u4ea4\u754c\u82cf\u5fc5\u5229\u5c14\u6e56\u4e16\u754c\u9762\u79ef\u6700\u5927\u7684\u6de1\u6c34\u6e56\u5317\u7f8e\u6d32\u8d1d\u52a0\u5c14\u6e56\u4e16\u754c\u6700\u6df1\u7684\u6e56\u6cca\u4e9a\u6d32\u6b7b\u6d77\u4e9a\u6d32\u6d77\u62d4\u6700\u4f4e\u7684\u6e56\u6cca\u4e9a\u6d32\u9752\u6d77\u6e56\u4e2d\u56fd\u9762\u79ef\u6700\u5927\u7684\u54b8\u6c34\u6e56\u4e9a\u6d32\u9131\u9633\u6e56\u4e2d\u56fd\u9762\u79ef\u6700\u5927\u7684\u6de1\u6c34\u6e56\u4e9a\u6d32"},{"location":"academic-notes/chinese/junior-notes/geography/#_43","title":"\u4e16\u754c\u4eba\u6587\u73af\u5883","text":"<pre><code>\u300a\u4eba\u6587\u5730\u7406 \u4e0a\u518c\u300b P21, P40~48\n</code></pre>"},{"location":"academic-notes/chinese/junior-notes/geography/#_44","title":"\u8bed\u8a00 &amp; \u5b97\u6559","text":"\u8054\u5408\u56fd\ud83c\uddfa\ud83c\uddf3\u5de5\u4f5c\u8bed\u8a00 <p>\u6c49\u8bed\ud83c\udde8\ud83c\uddf3\u3001\u82f1\u8bed\ud83c\uddfa\ud83c\uddf8\ud83c\uddec\ud83c\udde7\u3001\u6cd5\u8bed\ud83c\uddeb\ud83c\uddf7\u3001\u4fc4\u8bed\ud83c\uddf7\ud83c\uddfa\u3001\u897f\u73ed\u7259\u8bed\ud83c\uddea\ud83c\uddf8\u3001\u963f\u62c9\u4f2f\u8bed\ud83c\uddf8\ud83c\udde6\ud83c\udde6\ud83c\uddea</p> \u4e16\u754c\u4e09\u5927\u5b97\u6559 <p>\u4f5b\u6559\ud83c\uddee\ud83c\uddf3\u3001\u57fa\u7763\u6559\ud83c\uddf5\ud83c\uddf8\u3001\u4f0a\u65af\u5170\u6559\ud83c\uddf8\ud83c\udde6</p> <p>\u7279\u8272\u4f53\u73b0</p> <p>\u4f5b\u6559\ud83c\uddee\ud83c\uddf3\uff1a\u5bfa\u5e99 &amp; \u4f5b\u5854\ud83d\uded5</p> <p>\u57fa\u7763\u6559\ud83c\uddf5\ud83c\uddf8\uff1a\u6559\u5802\u26ea\ufe0f</p> <p>\u4f0a\u65af\u5170\u6559\ud83c\uddf8\ud83c\udde6\uff1a\u6e05\u771f\u5bfa\ud83d\udd4c\ufe0f</p>"},{"location":"academic-notes/chinese/junior-notes/geography/#iii","title":"\u2162. \u751f\u6d3b\u5728\u4e0d\u540c\u533a\u57df\u91cc","text":"\u5178\u578b\u56fd\u5bb6\u6c47\u603b \u7f8e\u56fd\ud83c\uddfa\ud83c\uddf8 \u7f8e\u56fd\u5546\u54c1\u519c\u4e1a\u53d1\u8fbe\u7684\u6709\u5229\u6761\u4ef6(\u539f\u56e0) <ol> <li>\u81ea\u7136\u6761\u4ef6\uff1a\u571f\u5730\u8fbd\u9614\uff0c\u5e73\u539f\u5730\u5f62\uff0c\u5730\u52bf\u4f4e\u5e73\uff0c\u571f\u58e4\u80a5\u6c83\uff1b\u6e29\u5e26\u5927\u9646\u6027\u6c14\u5019\uff0c\u6c14\u5019\u9002\u5b9c\uff1b\u5bc6\u897f\u897f\u6bd4\u6cb3\u81ea\u5317\u5411\u5357\u8d2f\u7a7f\u5e73\u539f\uff0c\u6c34\u6e90\u5145\u8db3\uff0c\u704c\u6e89\u4fbf\u5229\u3002</li> <li>\u4eba\u6587\u6761\u4ef6\uff1a\u7ecf\u6d4e\u53d1\u8fbe\uff0c\u519c\u4e1a\u79d1\u6280\u6c34\u5e73\u9ad8\uff0c\u519c\u573a\u89c4\u6a21\u5927\uff0c\u5730\u5e7f\u4eba\u7a00\uff0c\u673a\u68b0\u5316\u751f\u4ea7\uff0c\u6548\u7387\u9ad8\uff0c\u4ea7\u91cf\u5927\uff0c\u4ea7\u54c1\u50a8\u5b58\u6761\u4ef6\u597d\uff0c\u4ea4\u901a\u56db\u901a\u516b\u8fbe\u7b49\u7b49\u3002</li> </ol> \u745e\u58eb\ud83c\udde8\ud83c\udded \u745e\u58eb\u6210\u4e3a\u65c5\u6e38\u70ed\u533a\u7684\u6709\u5229\u6761\u4ef6(\u539f\u56e0) <ol> <li>\u81ea\u7136\u6761\u4ef6\uff1a<ol> <li>\u5730\u5f62\u591a\u6837\uff0c\u6d77\u62d4\u9ad8\uff0c\u6709\u51b0\u5ddd\u548c\u96ea\u5c71\uff0c\u98ce\u666f\u4f18\u7f8e\uff0c\u666f\u89c2\u5947\u7279\u3002</li> <li>\u590f\u5929\u6210\u89c2\u5149\u3001\u907f\u6691\u3001\u767b\u5c71\u80dc\u5730\uff1b\u51ac\u5929\u53d1\u5c55\u6ed1\u96ea\u8fd0\u52a8\u7684\u6761\u4ef6\u5341\u5206\u7406\u60f3\uff0c\u6e29\u6cc9\u8d44\u6e90\u4e5f\u5f88\u4e30\u5bcc\u3002</li> </ol> </li> <li>\u4eba\u6587\u6761\u4ef6\uff1a<ol> <li>\u65c5\u6e38\u5185\u5bb9\u4e30\u5bcc\u591a\u5f69\uff0c\u914d\u5957\u8bbe\u65bd\u5b8c\u5907\u3001\u7cbe\u826f\uff0c\u670d\u52a1\u5468\u5230\u3001\u7ec6\u81f4\u5165\u5fae\u7b49\u3002</li> <li>\u62e5\u6709\u53d1\u8fbe\u7684\u94c1\u8def\u548c\u516c\u8def\uff1b\u6e38\u5ba2\u4e58\u706b\u8f66\u53ef\u76f4\u63a5\u5230\u8fbe\u5c71\u5cf0\u89c2\u770b\u51b0\u5ddd\u5947\u666f\uff1b\u8bb8\u591a\u5730\u65b9\u6709\u7535\u7f06\u8f66\u76f4\u8fbe\u5c71\u5dc5\uff1b\u8fd8\u6709\u76f4\u5347\u673a\u4e3a\u9047\u5230\u5371\u9669\u7684\u6e38\u4eba\u63d0\u4f9b\u6551\u52a9\u3002</li> <li>\u6709\u53e4\u8001\u7684\u57ce\u9547\u548c\u7eaf\u6734\u7684\u4e61\u6751\u751f\u6d3b\u7b49\u3002</li> </ol> </li> </ol> \u6211\u56fd\u4e0e\u745e\u58eb\u5728\u5730\u5f62\u4e0a\u7684\u5171\u540c\u7279\u70b9 <ol> <li>\u5730\u5f62\u7c7b\u578b\u591a\u6837</li> <li>\u5c71\u533a\u9762\u79ef\u5e7f\u5927</li> </ol> \u6ce2\u65af\u6e7e\u5730\u533a\u77f3\u6cb9\u8f93\u51fa\u8def\u7ebf <p>A\u7ebf\uff1a\u6ce2\u65af\u6e7e -&gt; \u970d\u5c14\u6728\u5179\u6d77\u5ce1 -&gt; \u5370\u5ea6\u6d0b -&gt; \u9a6c\u516d\u7532\u6d77\u5ce1 -&gt; \u592a\u5e73\u6d0b -&gt; \u4e1c\u4e9a(\u4e2d\u56fd\u3001\u65e5\u672c)</p> <p>B\u7ebf\uff1a\u6ce2\u65af\u6e7e -&gt; \u970d\u5c14\u6728\u5179\u6d77\u5ce1 -&gt; \u5370\u5ea6\u6d0b -&gt; \u597d\u671b\u89d2 -&gt; \u5927\u897f\u6d0b -&gt; \u897f\u6b27\u548c\u7f8e\u56fd</p> <p>C\u7ebf\uff1a\u6ce2\u65af\u6e7e -&gt; \u970d\u5c14\u6728\u5179\u6d77\u5ce1 -&gt; \u963f\u62c9\u4f2f\u6d77 -&gt; \u66fc\u5fb7\u6d77\u5ce1 -&gt; \u7ea2\u6d77 -&gt; \u82cf\u4f0a\u58eb\u8fd0\u6cb3 -&gt; \u5730\u4e2d\u6d77 -&gt; \u76f4\u5e03\u7f57\u9640\u6d77\u5ce1 -&gt; \u5927\u897f\u6d0b -&gt; \u897f\u6b27\u548c\u7f8e\u56fd</p> <p>D\u7ebf\uff1a\u6ce2\u65af\u6e7e -&gt; \u970d\u5c14\u6728\u5179\u6d77\u5ce1 -&gt; \u5370\u5ea6\u6d0b -&gt; \u6fb3\u5927\u5229\u4e9a</p> \u6ce2\u65af\u6e7e\u5730\u533a\u4f4d\u7f6e\u7279\u5f81 <p>\u4f4d\u4e8e\u4e9a\u6d32\u897f\u90e8\uff0c\u5730\u5904\u4e9a\u3001\u6b27\u3001\u975e\u4e09\u5927\u6d32\u7684\u8fde\u63a5\u5730\u5e26\uff0c\u6fd2\u4e34\u963f\u62c9\u4f2f\u6d77\u3001\u7ea2\u6d77\u3001\u91cc\u6d77\uff0c\u9760\u8fd1\u9ed1\u6d77\u548c\u5730\u4e2d\u6d77\uff0c\u5730\u7406\u4f4d\u7f6e\u6781\u4e3a\u91cd\u8981\uff0c\u7d20\u6709\u201c\u4e09\u6d32\u4e94\u6d77\u201d\u4e4b\u79f0\u3002</p> <ol> <li> <p>\u5408\u4e3a\u4e00\u4e2a\u8981\u7d20\u00a0\u21a9</p> </li> <li> <p>\u6781\u70b9\u9664\u5916\u00a0\u21a9</p> </li> </ol>"},{"location":"academic-notes/chinese/senior-high-school/projectile-motion/","title":"Projectile motion","text":""},{"location":"academic-notes/chinese/senior-high-school/projectile-motion/#_1","title":"\u5e73\u629b\u8fd0\u52a8\u6027\u8d28","text":""},{"location":"academic-notes/chinese/senior-high-school/projectile-motion/#_2","title":"\u57fa\u7840","text":"<p>\\(\\Delta v = gt\\)</p> <p>\u6c34\u5e73:</p> <p>$ \\left{ \\begin{aligned} v_x &amp;= v_0 \\ x &amp;= v_0 t \\end{aligned} \\right. $</p> <p>\u7ad6\u76f4:</p> <p>$ \\left{ \\begin{aligned} v_y &amp;= gt \\ y &amp;= \\frac{1}{2} g t^2 \\ \\end{aligned} \\right. $</p> <p>\u5408\u6210:</p> <p>$ \\left{ \\begin{aligned} v &amp;= \\sqrt{v_x^2 + v_y^2} \\ x &amp;= \\sqrt{x^2 + y^2} \\ \\end{aligned} \\right. $</p>"},{"location":"academic-notes/chinese/senior-high-school/projectile-motion/#_3","title":"\u63a8\u8bba","text":"<p>$ \\because \\left{ \\begin{aligned} \\tan{\\theta} &amp;= \\dfrac{v_y}{v_x} = \\dfrac{2y_A}{x_A} \\ \\tan{\\alpha} &amp;= \\dfrac{y_A}{x_A} \\end{aligned} \\right. $</p> <p>$ \\therefore \\tan{\\theta} = 2 \\tan{\\alpha}</p> <p>\\(\\tan{\\theta} = 2 \\tan{\\alpha}\\)</p> <p>\\(x_b = \\frac{1}{2} x_a\\)</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/","title":"\u96c6\u5408","text":""},{"location":"academic-notes/chinese/senior-high-school/sets/#_1","title":"\u96c6\u5408\u53ca\u57fa\u672c\u5173\u7cfb","text":""},{"location":"academic-notes/chinese/senior-high-school/sets/#_2","title":"\u5b9a\u4e49","text":"<p>\u5bf9\u8c61(\u5373\u5143\u7d20)\u6240\u6784\u6210\u7684\u6574\u4f53</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/#_3","title":"\u8868\u793a","text":"<p>\u96c6\u5408: \u5927\u5199\u5b57\u6bcd \\(\\mathbb{A}, \\mathbb{B}, \\mathbb{C},...\\)</p> <p>\u5143\u7d20: \u5c0f\u5199\u5b57\u6bcd \\(a, b, c,...\\)</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/#_4","title":"\u5199\u6cd5","text":""},{"location":"academic-notes/chinese/senior-high-school/sets/#_5","title":"\u6570\u96c6\u7684\u5199\u6cd5","text":"\u5217\u4e3e\u6cd5\u63cf\u8ff0\u6cd5 <p>\\(\\mathbb{A} = \\\\{a, b, c, ..., z\\\\}\\)</p> <p>\\(\\mathbb{A} = \\\\{x \\mid p(x)\\\\}\\) <sup>1</sup></p> \u7279\u6b8a\u7684\u96c6\u5408 <p>\\(\\mathbb{N}\\): \u81ea\u7136\u6570\u96c6</p> <p>\\(\\mathbb{N}_+\\ or\\ \\mathbb{N}^*\\): \u6b63\u6574\u6570\u96c6</p> <p>\\(\\mathbb{Z}\\): \u6574\u6570\u96c6</p> <p>\\(\\mathbb{Q}\\): \u6709\u7406\u6570\u96c6</p> <p>\\(\\mathbb{R}\\): \u5b9e\u6570\u96c6</p> <p>\\(\\mathbb{C}\\): \u590d\u6570\u96c6</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/#_6","title":"\u5173\u7cfb\u7684\u5199\u6cd5","text":"\u5143\u7d20\u4e0e\u96c6\u5408\u7684\u5173\u7cfb\u96c6\u5408\u4e0e\u96c6\u5408\u7684\u5173\u7cfb <p>\u5c5e\u4e8e: \\(a \\in \\mathbb{A}\\)</p> <p>\u4e0d\u5c5e\u4e8e: \\(b \\notin \\mathbb{A}\\)</p> <p>\u5b50\u96c6: $\\mathbb{B} \\subseteq \\mathbb{A} \\iff \\mathbb{A} \\supseteq \\mathbb{B} $</p> <p>\u76f8\u7b49: \\(\\mathbb{A} = \\mathbb{B}\\)</p> <p>\u771f\u5b50\u96c6: $\\mathbb{B} \\subsetneqq \\mathbb{A} \\iff \\mathbb{A} \\supsetneqq \\mathbb{B} $</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/#_7","title":"\u6570\u96c6 &amp; \u70b9\u96c6","text":"<p>\u6570\u96c6\uff0c\u8868\u8303\u56f4: \\(\\mathbb{A} = \\\\{x \\mid p(x)\\\\}\\)</p> <p>\u70b9\u96c6\uff0c\u8868\u56fe\u50cf: \\(\\mathbb{B} = \\\\{(x, y) \\mid y = x^2 \\\\}\\)</p>"},{"location":"academic-notes/chinese/senior-high-school/sets/#_8","title":"\u96c6\u5408\u95f4\u7684\u8fd0\u7b97\u53ca\u8fd0\u7528","text":"\u4ea4\u96c6\u5e76\u96c6\u8865\u96c6 <p>\\(\\mathbb{A} \\cap \\mathbb{B} = \\\\{x \\mid x \\in \\mathbb{A}\\ and\\ x \\in \\mathbb{B}\\\\}\\)</p> <p>\u5373\u5bf9\u96c6\u5408\u8fdb\u884c \"\u4e0e \\(\\land\\)\" \u64cd\u4f5c</p> <p>\\(\\mathbb{A} \\cup \\mathbb{B} = \\\\{x \\mid x \\in \\mathbb{A}\\ or\\ x \\in \\mathbb{B}\\\\}\\)</p> <p>\u5373\u5bf9\u96c6\u5408\u8fdb\u884c \"\u6216 \\(\\lor\\)\" \u64cd\u4f5c</p> <p>\\(\\complement_\\mathbb{U} \\mathbb{A} = \\\\{x \\mid x \\in \\mathbb{U}\\ and\\ x \\notin \\mathbb{A}\\\\}\\)</p> \u8fd0\u7b97\u53d8\u5f62 &amp; \u6027\u8d28 \u5e76\u96c6\u7684\u6027\u8d28\u8865\u96c6\u7684\u6027\u8d28 <p>\\(\\mathbb{A} \\cup \\emptyset = \\mathbb{A}\\)</p> <p>\\((\\mathbb{A} \\cup \\mathbb{B}) \\supseteq \\mathbb{A}\\)</p> <p>\\(\\mathbb{A} \\cup \\mathbb{B} \\iff \\mathbb{B} \\subseteq \\mathbb{A}\\)</p> <p>\\(\\complement_\\mathbb{U} \\mathbb{U} = \\emptyset\\)</p> <p>\\(\\complement_\\mathbb{U} \\emptyset = \\mathbb{U}\\)</p> <p>\\(\\complement_\\mathbb{U} (\\complement_\\mathbb{U} \\mathbb{A}) = \\mathbb{A}\\)</p> <p>\\(\\mathbb{A} \\cup (\\complement_\\mathbb{U} \\mathbb{A}) = \\mathbb{U}\\)</p> <p>\\(\\mathbb{A} \\cap (\\complement_\\mathbb{U} \\mathbb{A}) = \\emptyset\\)</p> <ol> <li> <p>\u9ed8\u8ba4 \\(x \\in \\mathbb{R}\\) \u21a9</p> </li> </ol>"},{"location":"algorithms/gcd-lcm/","title":"GCD & LCM","text":""},{"location":"algorithms/gcd-lcm/#stl","title":"STL","text":"<p>cppreference</p> Head FilesC++ Versionstd::gcdstd::lcm <pre><code>#include &lt;numeric&gt;\n</code></pre> <pre><code>-std=c++17\n</code></pre> <pre><code>template&lt; class M, class N &gt;\nconstexpr std::common_type_t&lt;M, N&gt; gcd( M m, N n );\n</code></pre> <pre><code>template&lt; class M, class N &gt;\nconstexpr std::common_type_t&lt;M, N&gt; lcm( M m, N n );\n</code></pre>"},{"location":"algorithms/gcd-lcm/#gcd","title":"GCD <sup>1</sup>","text":"Conditional OperatorBitwise Operation <pre><code>int gcd(int x, int y) {\n    return y&gt;0 ? gcd(y, x%y) : x;\n}\n</code></pre> <pre><code>int gcd(int x, int y) {\n    while (y^=x^=y^=x%=y);\n    return x;\n}\n</code></pre>"},{"location":"algorithms/gcd-lcm/#lcm","title":"LCM <sup>2</sup>","text":"<pre><code>int lcm(int x, int y) {\n    return a / gcd(x, y) * y;\n}\n</code></pre> <p>Tips</p> <p>Performing division before multiplication can help avoid overflow.</p> <ol> <li> <p>Greatest Common Divisor\u00a0\u21a9</p> </li> <li> <p>Least Common Multiple\u00a0\u21a9</p> </li> </ol>"},{"location":"algorithms/quick-pow/","title":"Quick Pow","text":"O(log n)<pre><code>long long qpow(long long a, const long long &amp;n, const long long &amp;m=1) {\n    if (n == 0) return 1;\n    else if (n == 1) return a;\n\n    long long tmp = qpow(a, n&gt;&gt;1, m);\n    if (n &amp; 1) return tmp * tmp * a % m;\n    else return tmp * tmp % m;\n}\n</code></pre>"},{"location":"algorithms/prime/euler-sieve/","title":"Euler Sieve","text":""},{"location":"algorithms/prime/euler-sieve/#complexity","title":"Complexity","text":"<p>Time Complexity: \\(O(n)\\)</p>"},{"location":"algorithms/prime/euler-sieve/#template","title":"Template","text":"<pre><code>vector&lt;int&gt; pri;\nbool not_prime[maxn];\n\nvoid get_prime(const int &amp;n) {\n    for (int i=2; i&lt;=n; ++i) {\n        if (!not_prime[i]) pri.push_back(i);\n        for (const int &amp;pri_j : pri) {\n            if (i * pri_j &gt; n) break;\n            not_prime[i * pri_j] = true;\n            if (i % pri_j == 0) break;\n        }\n    }\n}\n</code></pre>"},{"location":"algorithms/search/a-star/","title":"A*","text":""},{"location":"algorithms/search/a-star/#complexity","title":"Complexity","text":"<p>Time Complexity: \\(O((n+m) \\log m)\\)</p>"},{"location":"algorithms/search/a-star/#template","title":"Template","text":"Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n#include &lt;queue&gt;\n#include &lt;utility&gt;\n#include &lt;algorithm&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> Constants<pre><code>const int inf = 0x3f;\nconst int maxn = 1e4 + 5;\n</code></pre> struct<pre><code>struct edge {\n    int v, w;\n};\n\nstruct node {\n    int u, dis;\n\n    bool operator&gt;(const node &amp;x) const {\n        return dis &gt; x.dis;\n    }\n};\n\nvector&lt;edge&gt; e[maxn];\npair&lt;int, int&gt; coord[maxn];\n</code></pre> Manhattan distanceEuclidean Distance <pre><code>int heuristic(const pair&lt;int, int&gt; &amp;u, const pair&lt;int, int&gt; &amp;tg) {\n    return abs(u.first - tg.first) + abs(u.second - tg.second);\n}\n</code></pre> <pre><code>int heuristic(const pair&lt;int, int&gt; &amp;u, const pair&lt;int, int&gt; &amp;tg) {\n    return sqrt(pow(u.first - tg.first, 2) + pow(u.second - tg.second, 2)); // Euclidean distance\n}\n</code></pre> A*<pre><code>vector&lt;int&gt; a_star(const int &amp;sz, const int &amp;st, const int &amp;tg) {\n    vector&lt;int&gt; dis(sz+1, inf);\n    vector&lt;int&gt; prev(sz+1, -1);\n    priority_queue&lt; node, vector&lt;node&gt;, greater&lt;node&gt; &gt; pq;\n\n    dis[st] = 0;\n    pq.emplace((node){st, 0});\n\n    while (!pq.empty()) {\n        int u = pq.top().u; pq.pop();\n\n        if (u == tg) break;\n\n        for (const auto &amp;ed : e[u]) {\n            int v = ed.v, w = ed.w;\n            if (dis[v] &gt; dis[u] + w) {\n                dis[v] = dis[u] + w;\n                pq.emplace((node){v, dis[v]+heuristic(coord[u], coord[tg])});\n            }\n        }\n    }\n\n    vector&lt;int&gt; path;\n    if (dis[tg] != inf) {\n        for (int i = tg; i != -1; i = prev[i]) {\n            path.emplace_back(i);\n        }\n        reverse(path.begin(), path.end());\n    }\n    return path;\n}\n</code></pre>"},{"location":"algorithms/shortest-path/bellman-ford/","title":"Bellman Ford","text":""},{"location":"algorithms/shortest-path/bellman-ford/#video-recommendation","title":"Video Recommendation","text":"<ul> <li>4.4 Bellman Ford Algorithm - Single Source Shortest Path - Dynamic Programming - Adbul Bari</li> </ul>"},{"location":"algorithms/shortest-path/bellman-ford/#template","title":"Template","text":"Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> Constants<pre><code>const int inf = 0x3f;\nconst int maxn = 1e4 + 5;\n</code></pre> struct<pre><code>struct edge {\n    int v, w;\n};\n\nstruct node {\n    int u, dis;\n\n    bool operator&gt;(const node &amp;x) const {\n        return dis &gt; x.dis;\n    }\n};\n\nvector&lt;edge&gt; e[maxn];\n</code></pre> Bellman Ford<pre><code>void bellman_ford(const int &amp;sz, const int &amp;st) {\n    vector&lt;int&gt; dis(sz+1, inf);\n    dis[st] = 0;\n\n    bool flag;\n    for (int i=1; i&lt;=sz; ++i) {\n        flag = 0;\n        for (int u=1; u&lt;=sz; ++u) {\n            for (auto &amp;e : e[u]) {\n                int v = e.v, w = e.w;\n                if (dis[v] &gt; dis[u] + w) {\n                    dis[v] = dis[u] + w;\n                    flag = 1;\n                }\n            }\n        }\n\n        if (!flag) return;\n    }\n}\n</code></pre>"},{"location":"algorithms/shortest-path/dijkstra/","title":"Dijkstra (prioirty_queue)","text":""},{"location":"algorithms/shortest-path/dijkstra/#video-recommendation","title":"Video Recommendation","text":"<ul> <li>3.6 Dijkstra Algorithm - Single Source Shortest Path - Greedy Method - Abdul Bari</li> <li>\u3010C++\u3011\u5355\u6e90\u6700\u77ed\u8defDijkstra-\u8fea\u6770\u65af\u7279\u62c9\u7b97\u6cd5</li> </ul>"},{"location":"algorithms/shortest-path/dijkstra/#complexity","title":"Complexity","text":"<p>Time Complexity: \\(O(m \\log m)\\)</p>"},{"location":"algorithms/shortest-path/dijkstra/#template","title":"Template","text":"Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n#include &lt;queue&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> Constants<pre><code>const int inf = 0x3f;\nconst int maxn = 1e4 + 5;\n</code></pre> struct<pre><code>struct edge {\n    int v, w;\n};\n\nstruct node {\n    int u, dis;\n\n    bool operator&gt;(const node &amp;x) const {\n        return dis &gt; x.dis;\n    }\n};\n\nvector&lt;edge&gt; e[maxn];\n</code></pre> priority_queue Template<pre><code>vector&lt;int&gt; dijkstra(const int &amp;sz, const int &amp;st) {\n    vector&lt;int&gt; dis(sz+1, inf);\n    vector&lt;bool&gt; vis(sz+1, 0);\n    priority_queue&lt;node, vector&lt;node&gt;, greater&lt;node&gt; &gt; pq;\n\n    dis[st] = 0;\n    pq.emplace((node){st, 0});\n\n    while (!pq.empty()) {\n        int u = pq.top().u; pq.pop();\n        if (vis[u]) continue;\n        vis[u] = 1;\n\n        for (const auto &amp;ed : e[u]) {\n            int v = ed.v, w = ed.w;\n            if (dis[v] &gt; dis[u] + w) {\n                dis[v] = dis[u] + w;\n                pq.emplace((node){v, dis[v]});\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"algorithms/shortest-path/dijkstra/#problems","title":"Problems","text":"<p>Luogu</p> Solution <pre><code>#include &lt;bits/stdc++.h&gt;\nusing namespace std;\nconst int maxn = 1e5 + 2;\nconst int inf = 0x3f3f3f3f;\n\nstruct edge {\n    int v, w;\n}; vector&lt;edge&gt; e[maxn];\n\nstruct node {\n    int u, dis;\n\n    bool operator&gt;(const node &amp;x) const {\n        return dis &gt; x.dis;\n    } \n};\n\nint n, m, s;\n\nvoid dijkstra(const int &amp;sz, const int &amp;st) {\n    vector&lt;int&gt; dis(sz+1, inf);\n    vector&lt;bool&gt; vis(sz+1, 0);\n    priority_queue&lt;node, vector&lt;node&gt;, greater&lt;node&gt; &gt; pq;\n\n    dis[st] = 0;\n    pq.push((node){st, 0});\n    while (!pq.empty()) {\n        int u = pq.top().u; pq.pop();\n        if (vis[u]) continue;\n        vis[u] = 1;\n\n        for (const auto &amp;ed : e[u]) {\n            int v = ed.v, w = ed.w;\n            if (dis[v] &gt; dis[u] + w) {\n                dis[v] = dis[u] + w;\n                pq.push((node){v, dis[v]});\n            }\n        }\n    }\n\n    for (int i=1; i&lt;=n; ++i) {\n        cout &lt;&lt; dis[i] &lt;&lt; (i == n ? \"\\n\" : \" \");\n    }\n}\n\nsigned main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    cin &gt;&gt; n &gt;&gt; m &gt;&gt; s;\n    for (int i=1; i&lt;=m; ++i) {\n        int u, v, w;\n        cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;\n\n        e[u].push_back((edge){v, w});\n    }\n\n    dijkstra(n, s);\n}\n</code></pre>"},{"location":"algorithms/shortest-path/floyd/","title":"Floyd","text":""},{"location":"algorithms/shortest-path/floyd/#complexity","title":"Complexity","text":"<p>Time Complexity: \\(O(n^3)\\)</p> <p>Space Complexity: \\(O(n^2)\\)</p> Floyd<pre><code>void floyd(int dis[][], int sz) {\n    for (int k=1; i&lt;=sz; ++i) {\n        for (int x=1; x&lt;=sz; ++x) {\n            for (int y=1; y&lt;=sz; ++y) {\n                dis[x][y] = min(dis[x][y], dis[x][k] + dis[k][y]);\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"algorithms/shortest-path/floyd/#problems","title":"Problems","text":""},{"location":"algorithms/shortest-path/floyd/#luogu-p119","title":"Luogu P119 \u707e\u540e\u91cd\u5efa","text":"Solution <pre><code>#include &lt;bits/stdc++.h&gt;\n#define endl \"\\n\"\nusing namespace std;\nconst int maxn = 202;\nconst int maxm = 20000;\nconst int inf = 0x3f3f3f3f;\n\nint n, m;\nvector&lt; vector&lt;int&gt; &gt; adj(maxn, vector&lt;int&gt;(maxn, inf));\nvector&lt;int&gt; t(maxn, 0);\n\nsigned main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    cin &gt;&gt; n &gt;&gt; m;\n\n    for (int i=0; i&lt;n; ++i) {\n        adj[i][i] = 0;\n    }\n\n    for (int i=0; i&lt;n; ++i) {\n        cin &gt;&gt; t[i];\n    } for (int i=0; i&lt;m; ++i) {\n        int x, y, z;\n        cin &gt;&gt; x &gt;&gt; y &gt;&gt; z;\n        adj[x][y] = adj[y][x] = z;\n    }\n\n    int Q; cin &gt;&gt; Q;\n    int last = 0; // last accessed time\n    while (Q--) {\n        int x, y, z;\n        cin &gt;&gt; x &gt;&gt; y &gt;&gt; z;\n\n        if (t[x] &gt; z || t[y] &gt; z) {cout &lt;&lt; -1 &lt;&lt; endl; continue;}\n\n        while (last &lt; n &amp;&amp; t[last] &lt;= z) {\n            // Floyd\n            for (int i=0; i&lt;n; ++i) {\n                for (int j=0; j&lt;n; ++j) {\n                    adj[i][j] = min(adj[i][j], adj[i][last] + adj[last][j]);\n                }\n            }\n            ++last;\n        }\n\n        cout &lt;&lt; (adj[x][y] == inf ? -1 : adj[x][y]) &lt;&lt; endl;\n    }\n} \n</code></pre>"},{"location":"algorithms/shortest-path/spfa/","title":"SPFA","text":""},{"location":"algorithms/shortest-path/spfa/#complexity","title":"Complexity","text":"<p>Time Complexity: \\(O(nm)\\)</p>"},{"location":"algorithms/shortest-path/spfa/#template","title":"Template","text":"Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n#include &lt;queue&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> Constants<pre><code>const int inf = 0x3f;\nconst int maxn = 1e4 + 5;\n</code></pre> struct<pre><code>struct edge {\n    int v, w;\n};\nvector&lt;edge&gt; e[maxn];\n</code></pre> Template<pre><code>vector&lt;int&gt; spfa(const int &amp;sz, const int &amp;st) {\n    vector&lt;int&gt; dis(maxn, inf);\n    vector&lt;bool&gt; vis(maxn, 0);\n    queue&lt;int&gt; q;\n\n    dis[st] = 0;\n    vis[st] = 1;\n    q.push(st);\n    while (!q.empty()) {\n        int u = q.front(); q.pop();\n        vis[u] = 0;\n\n        for (const auto &amp;ed : e[u]) {\n            int v = ed.v, w = ed.w;\n            if (dis[v] &gt; dis[u] + w) {\n                dis[v] = dis[u] + w;\n\n                if (!vis[v]) {\n                    q.push(v);\n                    vis[v] = 1;\n                }\n            }\n        }\n    }\n\n    return dis;\n}\n</code></pre>"},{"location":"algorithms/shortest-path/spfa/#problems","title":"Problems","text":"<p>Luogu P3371</p> Solution <pre><code>#include &lt;bits/stdc++.h&gt;\n#define int unsigned long long\nusing namespace std;\nconst int maxn = 2e5 + 2;\nconst int inf = (1ull&lt;&lt;31) - 1;\n\nstruct edge {\n    int v, w;\n};\nvector&lt;edge&gt; e[maxn];\n\nvoid spfa(const int &amp;sz, const int &amp;st) {\n    vector&lt;int&gt; dis(maxn, inf);\n    vector&lt;bool&gt; vis(maxn, 0);\n    queue&lt;int&gt; q;\n\n    dis[st] = 0;\n    vis[st] = 1;\n    q.push(st);\n    while (!q.empty()) {\n        int u = q.front(); q.pop();\n        vis[u] = 0;\n\n        for (const auto &amp;ed : e[u]) {\n            int v = ed.v, w = ed.w;\n            if (dis[v] &gt; dis[u] + w) {\n                dis[v] = dis[u] + w;\n\n                if (!vis[v]) {\n                    q.push(v);\n                    vis[v] = 1;\n                }\n            }\n        }\n    }\n\n    for (int i=1; i&lt;=sz; ++i) {\n        cout &lt;&lt; dis[i] &lt;&lt; \" \";\n    }\n}\n\nint n, m, s;\n\nsigned main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    cin &gt;&gt; n &gt;&gt; m &gt;&gt; s;\n    for (int i=1; i&lt;=m; ++i) {\n        int u, v, w;\n        cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;\n        e[u].push_back((edge){v, w}); \n    }\n\n    spfa(n, s);\n}\n</code></pre>"},{"location":"algorithms/sort/bubble-sort/","title":"Bubble sort","text":"<pre><code>    template &lt;typename Type&gt;\n    void Bubble(Type arr[], int n) {\n    assert(sizeof(arr) / sizeof(Type) != n);\n\n    int loop = 0;\n    for (int i=1; i&lt;n-1; ++i) {\n        bool sorted = 1;\n        for (int j=1; j&lt;n; ++j) {\n            if (arr[j] &lt; arr[j - 1]) {\n                swap(arr[j], arr[j - 1]);\n                sorted = 0;\n            }\n\n            ++loop;\n        }\n\n        if (sorted) {\n            break;\n        }\n    }\n}\n</code></pre>"},{"location":"algorithms/sort/radix-sort/","title":"Radix sort","text":""},{"location":"algorithms/sort/radix-sort/#video-recommendation","title":"Video Recommendation","text":"<ul> <li>\u3010\u6392\u5e8f\u7b97\u6cd5\u3011\u57fa\u6570\u6392\u5e8f\u3011</li> </ul>"},{"location":"algorithms/sort/radix-sort/#complexity","title":"Complexity","text":"<p>\\(O(n)\\) or \\(O(n \\lg n)\\)</p>"},{"location":"algorithms/sort/radix-sort/#template","title":"Template","text":""},{"location":"algorithms/sort/sort-overview/","title":"Sort Overview","text":""},{"location":"algorithms/sort/sort-overview/#sort-algorithms","title":"Sort Algorithms","text":"Algorithms Time Complexity Bubble Sort \\(O(n^2)\\) Insertion Sort \\(O(n^2)\\) Selection Sort \\(O(n^2)\\) Quick Sort \\(O(n \\log n) \\rightarrow O(n^2)\\) Merge Sort \\(O(n \\log n)\\) Heap Sort \\(O(n \\log n)\\) Bucket Sort \\(O(n + n^2/k + k) \\rightarrow O(n^2)\\) Radix Sort \\(O(n)\\) <code>std::sort()</code> \\(O(n \\log n)\\)"},{"location":"blog/","title":"Index","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2024/09/14/deploy-ai-models-locally/","title":"Deploy AI Models Locally","text":""},{"location":"blog/2024/09/14/deploy-ai-models-locally/#ollama","title":"Ollama","text":""},{"location":"blog/2024/09/14/deploy-ai-models-locally/#what-is-ollama","title":"What Is Ollama?","text":"<p>Ollama is an open-source platform designed to make large language models (LLMs) more accessible and usable.</p>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#how-to-deploy","title":"How to Deploy","text":"<ol> <li>Visit Ollama and download.</li> <li>Choose a model you like</li> <li>Run <code>ollama run YourModel:ParameterSize</code> in the terminal or Windows CMD (Windows: Win+R \\(\\rightarrow\\) cmd)</li> <li>Your model will start downloading. If the model has already been downloaded, you will go to the chat page (starts with <code>&gt;&gt;&gt;</code>);</li> </ol>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#how-to-choose-an-appropriate-model","title":"How to Choose An Appropriate Model","text":""},{"location":"blog/2024/09/14/deploy-ai-models-locally/#choose-model","title":"Choose Model","text":"<p>Visit Model Library</p> <p>Here is the Aritificial Analysis's LLM Leaderboard</p> <p>Recommendations:</p> <ul> <li>Google Gemma 2</li> <li>Meta Llama 3.1</li> <li>Alibaba Qwen2</li> </ul>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#choose-parameter-size","title":"Choose Parameter Size","text":"<p>The model size should be smaller than your memory size.</p> <p>For instance, the <code>gemma2:9b</code> model is 5.4GB which is runnable on devices with 16GB memory.</p> <p>However, the <code>gemma2:27b</code> model is 16GB and it is not runnable on the same device (there must be some other programs that eat up your memory).</p>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#drawbacks-of-running-in-terminal","title":"Drawbacks of Running in Terminal","text":"<p>Your chat history cannot be saved. If you want to store your history chat, deploy one of the following apps (the titles link to their GitHub Repos):</p> <ul> <li>Enchanted (macOS Only)</li> <li>Open WebUI</li> </ul>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#enchanted","title":"Enchanted","text":"<p>Download in AppStore</p>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#open-webui","title":"Open WebUI","text":"<ol> <li>Download Docker</li> <li>Follow the Instructions</li> </ol>"},{"location":"blog/2024/09/14/deploy-ai-models-locally/#moa","title":"MoA","text":"<p>Together MoA Repo</p> <p>Mixture of Agents (MoA) is a novel approach that leverages the collective strengths of multiple LLMs to enhance performance, achieving state-of-the-art results.</p> <p></p> <p>The original MoA does not support Ollama. Here is my edited Ollama version of MoA forked from severian42's MoA-Ollama-Chat. I edited the GUI to make it look better.</p> <p>Follow the Instructions here.</p>"},{"location":"blog/2024/10/01/musicgpt/","title":"MusicGPT","text":""},{"location":"blog/2024/10/01/musicgpt/#musicgpt","title":"MusicGPT","text":"<p>gabotechs's MusciGPT Repo</p> <p>You can generate music using natural language prompts locally on MusicGPT.</p>"},{"location":"blog/2024/10/01/musicgpt/#install","title":"Install","text":"<p>Official Instruction</p>"},{"location":"blog/2024/10/01/musicgpt/#usage","title":"Usage","text":"<p>Execute the following command in terminal:</p> <pre><code>musicgpt\n</code></pre>"},{"location":"blog/2024/10/01/musicgpt/#samples","title":"Samples","text":"<p>Create a prog rock song with space rock elements</p> <p></p> <p>Create a relaxing jazz song</p> <p></p> <p>Create epic, atmospheric music with soaring strings, synths, and organ. Evoking transcendence, build intensity gradually.</p> <p></p> <p>Note</p> <p>When running the default <code>musicgpt</code> model (small), the maximum duration of audio is 29 seconds.</p> <p>Also, it is NOT able to generate vocal sounds.</p>"},{"location":"curricula/ai-for-beginners/","title":"Overview","text":"<p>This curriculum is forked from AI for Beginners from Microsoft under MIT license.</p> <p> </p> <p> </p> <p></p>"},{"location":"curricula/ai-for-beginners/#artificial-intelligence-for-beginners-a-curriculum","title":"Artificial Intelligence for Beginners - A Curriculum","text":"AI For Beginners - Sketchnote by @girlie_mac <p>Explore the world of Artificial Intelligence (AI) with our 12-week, 24-lesson curriculum!  It includes practical lessons, quizzes, and labs. The curriculum is beginner-friendly and covers tools like TensorFlow and PyTorch, as well as ethics in AI</p>"},{"location":"curricula/ai-for-beginners/#what-you-will-learn","title":"What you will learn","text":"<p>Mindmap of the Course</p> <p>In this curriculum, you will learn:</p> <ul> <li>Different approaches to Artificial Intelligence, including the \"good old\" symbolic approach with Knowledge Representation and reasoning (GOFAI).</li> <li>Neural Networks and Deep Learning, which are at the core of modern AI. We will illustrate the concepts behind these important topics using code in two of the most popular frameworks - TensorFlow and PyTorch.</li> <li>Neural Architectures for working with images and text. We will cover recent models but may be a bit lacking in the state-of-the-art.</li> <li>Less popular AI approaches, such as Genetic Algorithms and Multi-Agent Systems.</li> </ul> <p>What we will not cover in this curriculum:</p> <p>Find all additional resources for this course in our Microsoft Learn collection</p> <ul> <li>Business cases of using AI in Business. Consider taking Introduction to AI for business users learning path on Microsoft Learn, or AI Business School, developed in cooperation with INSEAD.</li> <li>Classic Machine Learning, which is well described in our Machine Learning for Beginners Curriculum.</li> <li>Practical AI applications built using Cognitive Services. For this, we recommend that you start with modules Microsoft Learn for vision, natural language processing, Generative AI with Azure OpenAI Service and others.</li> <li>Specific ML Cloud Frameworks, such as Azure Machine Learning, Microsoft Fabric, or Azure Databricks. Consider using Build and operate machine learning solutions with Azure Machine Learning and Build and Operate Machine Learning Solutions with Azure Databricks learning paths.</li> <li>Conversational AI and Chat Bots. There is a separate Create conversational AI solutions learning path, and you can also refer to this blog post for more detail.</li> <li>Deep Mathematics behind deep learning. For this, we would recommend Deep Learning by Ian Goodfellow, Yoshua Bengio and Aaron Courville, which is also available online at https://www.deeplearningbook.org/.</li> </ul> <p>For a gentle introduction to AI in the Cloud topics you may consider taking the Get started with artificial intelligence on Azure Learning Path.</p>"},{"location":"curricula/ai-for-beginners/#content","title":"Content","text":"Lesson Link PyTorch/Keras/TensorFlow Lab 0 Course Setup I Introduction to AI 01 Introduction and History of AI - - II Symbolic AI 02 Knowledge Representation and Expert Systems Expert Systems /  Ontology /Concept Graph III Introduction to Neural Networks 03 Perceptron Notebook Lab 04 Multi-Layered Perceptron and Creating our own Framework Notebook Lab 05 Intro to Frameworks (PyTorch/TensorFlow) and Overfitting PyTorch / Keras / TensorFlow Lab IV Computer Vision PyTorch / TensorFlow Explore Computer Vision on Microsoft Azure 06 Intro to Computer Vision. OpenCV Notebook Lab 07 Convolutional Neural Networks &amp;  CNN Architectures PyTorch /TensorFlow Lab 08 Pre-trained Networks and Transfer Learning and Training Tricks PyTorch / TensorFlow Lab 09 Autoencoders and VAEs PyTorch / TensorFlow 10 Generative Adversarial Networks &amp; Artistic Style Transfer PyTorch / TensorFlow 11 Object Detection TensorFlow Lab 12 Semantic Segmentation. U-Net PyTorch / TensorFlow V Natural Language Processing PyTorch /TensorFlow Explore Natural Language Processing on Microsoft Azure 13 Text Representation. Bow/TF-IDF PyTorch / TensorFlow 14 Semantic word embeddings. Word2Vec and GloVe PyTorch / TensorFlow 15 Language Modeling. Training your own embeddings PyTorch / TensorFlow Lab 16 Recurrent Neural Networks PyTorch / TensorFlow 17 Generative Recurrent Networks PyTorch / TensorFlow Lab 18 Transformers. BERT. PyTorch /TensorFlow 19 Named Entity Recognition TensorFlow Lab 20 Large Language Models, Prompt Programming and Few-Shot Tasks PyTorch VI Other AI Techniques 21 Genetic Algorithms Notebook 22 Deep Reinforcement Learning PyTorch /TensorFlow Lab 23 Multi-Agent Systems VII AI Ethics 24 AI Ethics and Responsible AI Microsoft Learn: Responsible AI Principles IX Extras 25 Multi-Modal Networks, CLIP and VQGAN Notebook"},{"location":"curricula/ai-for-beginners/#each-lesson-contains","title":"Each lesson contains","text":"<ul> <li>Pre-reading material</li> <li>Executable Jupyter Notebooks, which are often specific to the framework (PyTorch or TensorFlow). The executable notebook also contains a lot of theoretical material, so to understand the topic you need to go through at least one version of the notebook (either PyTorch or TensorFlow).</li> <li>Labs available for some topics, which give you an opportunity to try applying the material you have learned to a specific problem.</li> <li>Some sections contain links to MS Learn modules that cover related topics.</li> </ul>"},{"location":"curricula/ai-for-beginners/#getting-started","title":"Getting Started","text":"<ul> <li>We have created a setup lesson to help you with setting up your development environment. - For Educators, we have created a curricula setup lesson for you too!</li> <li>How to Run the code in a VSCode or a Codepace</li> </ul> <p>Follow these steps:</p> <p>Fork the Repository: Click on the \"Fork\" button at the top-right corner of this page.</p> <p>Clone the Repository: <code>git clone https://github.com/microsoft/AI-For-Beginners.git</code></p> <p>Don't forget to star (\ud83c\udf1f) this repo to find it easier later.</p>"},{"location":"curricula/ai-for-beginners/#meet-other-learners","title":"Meet other Learners","text":"<p>Join our official AI Discord server to meet and network with other learners taking this course and get support.</p>"},{"location":"curricula/ai-for-beginners/#quizzes","title":"Quizzes","text":"<p>A note about quizzes: All quizzes are contained in the Quiz-app folder in etc\\quiz-app, They are linked from within the lessons the quiz app can be run locally or deployed to Azure; follow the instruction in the <code>quiz-app</code> folder. They are gradually being localized.</p>"},{"location":"curricula/ai-for-beginners/#help-wanted","title":"Help Wanted","text":"<p>Do you have suggestions or found spelling or code errors? Raise an issue or create a pull request.</p>"},{"location":"curricula/ai-for-beginners/#special-thanks","title":"Special Thanks","text":"<ul> <li>\u270d\ufe0f Primary Author: Dmitry Soshnikov, PhD</li> <li>\ud83d\udd25 Editor: Jen Looper, PhD</li> <li>\ud83c\udfa8 Sketchnote illustrator: Tomomi Imura</li> <li>\u2705 Quiz Creator: Lateefah Bello, MLSA</li> <li>\ud83d\ude4f Core Contributors: Evgenii Pishchik</li> </ul>"},{"location":"curricula/ai-for-beginners/#other-curricula","title":"Other Curricula","text":"<p>Our team produces other curricula! Check out:</p> <ul> <li>Data Science for Beginners</li> <li>Version 2.0 Generative AI for Beginners</li> <li>NEW Cybersecurity for Beginners</li> <li>Web Dev for Beginners</li> <li>IoT for Beginners</li> <li>Machine Learning for Beginners</li> <li>XR Development for Beginners</li> <li>Mastering GitHub Copilot for AI Paired Programming</li> </ul>"},{"location":"curricula/ai-for-beginners/1-Intro/","title":"Lesson 1","text":""},{"location":"curricula/ai-for-beginners/1-Intro/#introduction-to-ai","title":"Introduction to AI","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Artificial Intelligence is an exciting scientific discipline that studies how we can make computers exhibit intelligent behavior, e.g. do those things that human beings are good at doing.</p> <p>Originally, computers were invented by Charles Babbage to operate on numbers following a well-defined procedure - an algorithm. Modern computers, even though significantly more advanced than the original model proposed in the 19th century, still follow the same idea of controlled computations. Thus it is possible to program a computer to do something if we know the exact sequence of steps that we need to do in order to achieve the goal.</p> <p></p> <p>Photo by Vickie Soshnikova</p> <p>\u2705 Defining the age of a person from his or her photograph is a task that cannot be explicitly programmed, because we do not know how we come up with a number inside our head when we do it.</p> <p>There are some tasks, however, that we do not explicitly know how to solve. Consider determining the age of a person from his/her photograph. We somehow learn to do it, because we have seen many examples of people of different age, but we cannot explicitly explain how we do it, nor can we program the computer to do it. This is exactly the kind of task that are of interest to Artificial Intelligence (AI for short).</p> <p>\u2705 Think of some tasks that you could offload to a computer that would benefit from AI. Consider the fields of finance, medicine, and the arts - how are these fields benefiting today from AI?</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#weak-ai-vs-strong-ai","title":"Weak AI vs. Strong AI","text":"Weak AI Strong AI Weak AI refers to AI systems that are designed and trained for a specific task or a narrow set of tasks. Strong AI, or Artificial General Intelligence (AGI), refers to AI systems with human-level intelligence and understanding. These AI systems are not generally intelligent; they excel in performing a predefined task but lack true understanding or consciousness. These AI systems have the ability to perform any intellectual task that a human being can do, adapt to different domains, and possess a form of consciousness or self-awareness. Examples of weak AI include virtual assistants like Siri or Alexa, recommendation algorithms used by streaming services, and chatbots that are designed for specific customer service tasks. Achieving Strong AI is a long-term goal of AI research and would require the development of AI systems that can reason, learn, understand, and adapt across a wide range of tasks and contexts. Weak AI is highly specialized and does not possess human-like cognitive abilities or general problem-solving capabilities beyond its narrow domain. Strong AI is currently a theoretical concept, and no AI system has reached this level of general intelligence <p>for more infomation refer Artificial General Intelligence (AGI).</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#the-definition-of-intelligence-and-the-turing-test","title":"The Definition of Intelligence and the Turing Test","text":"<p>One of the problems when dealing with the term Intelligence is that there is no clear definition of this term. One can argue that intelligence is connected to abstract thinking, or to self-awareness, but we cannot properly define it.</p> <p></p> <p>Photo by Amber Kipp from Unsplash</p> <p>To see the ambiguity of a term intelligence, try answering a question: \"Is a cat intelligent?\". Different people tend to give different answers to this question, as there is no universally accepted test to prove the assertion is true or not. And if you think there is - try running your cat through an IQ test...</p> <p>\u2705 Think for a minute about how you define intelligence. Is a crow who can solve a maze and get at some food intelligent? Is a child intelligent?</p> <p>When speaking about AGI we need to have some way to tell if we have created a truly intelligent system. Alan Turing proposed a way called a Turing Test, which also acts like a definition of intelligence. The test compares a given system to something inherently intelligent - a real human being, and because any automatic comparison can be bypassed by a computer program, we use a human interrogator. So, if a human being is unable to distinguish between a real person and a computer system in text-based dialogue - the system is considered intelligent.</p> <p>A chat-bot called Eugene Goostman, developed in St.Petersburg, came close to passing the Turing test in 2014 by using a clever personality trick. It announced up front that it was a 13-year old Ukrainian boy, which would explain the lack of knowledge and some discrepancies in the text. The bot convinced 30% of the judges that it was human after a 5 minute dialogue, a metric that Turing believed a machine would be able to pass by 2000. However, one should understand that this does not indicate that we have created an intelligent system, or that a computer system has fooled the human interrogator - the system didn't fool the humans, but rather the bot creators did!</p> <p>\u2705 Have you ever been fooled by a chat bot into thinking that you are speaking to a human? How did it convince you?</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#different-approaches-to-ai","title":"Different Approaches to AI","text":"<p>If we want a computer to behave like a human, we need somehow to model inside a computer our way of thinking. Consequently, we need to try to understand what makes a human being intelligent.</p> <p>To be able to program intelligence into a machine, we need to understand how our own processes of making decisions work. If you do a little self-introspection, you will realize that there are some processes that happen subconsciously \u2013 eg. we can distinguish a cat from a dog without thinking about it - while some others involve reasoning.</p> <p>There are two possible approaches to this problem:</p> Top-down Approach (Symbolic Reasoning) Bottom-up Approach (Neural Networks) A top-down approach models the way a person reasons to solve a problem. It involves extracting knowledge from a human being, and representing it in a computer-readable form. We also need to develop a way to model reasoning inside a computer. A bottom-up approach models the structure of a human brain, consisting of a huge number of simple units called neurons. Each neuron acts like a weighted average of its inputs, and we can train a network of neurons to solve useful problems by providing training data. <p>There are also some other possible approaches to intelligence:</p> <ul> <li> <p>An Emergent, Synergetic or multi-agent approach are based on the fact that complex intelligent behaviour can be obtained by an interaction of a large number of simple agents. According to evolutionary cybernetics, intelligence can emerge from more simple, reactive behaviour in the process of metasystem transition.</p> </li> <li> <p>An Evolutionary approach, or genetic algorithm is an optimization process based on the principles of evolution.</p> </li> </ul> <p>We will consider those approaches later in the course, but right now we will focus on two main directions: top-down and bottom-up.</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#the-top-down-approach","title":"The Top-Down Approach","text":"<p>In a top-down approach, we try to model our reasoning.  Because we can follow our thoughts when we reason, we can try to formalize this process and program it inside the computer. This is called symbolic reasoning.</p> <p>People tend to have some rules in their head that guide their decision making processes. For example, when a doctor is diagnosing a patient, he or she may realize that a person has a fever, and thus there might be some inflammation going on inside the body. By applying a large set of rules to a specific problem a doctor may be able to come up with the final diagnosis.</p> <p>This approach relies heavily on knowledge representation and reasoning. Extracting knowledge from a human expert might be the most difficult part, because a doctor in many cases would not know exactly why he or she is coming up with a particular diagnosis. Sometimes the solution just comes up in his or her head without explicit thinking. Some tasks, such as determining the age of a person from a photograph, cannot be at all reduced to manipulating knowledge.</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#bottom-up-approach","title":"Bottom-Up Approach","text":"<p>Alternately, we can try to model the simplest elements inside our brain \u2013 a neuron. We can construct a so-called artificial neural network inside a computer, and then try to teach it to solve problems by giving it examples. This process is similar to how a newborn child learns about his or her surroundings by making observations.</p> <p>\u2705 Do a little research on how babies learn. What are the basic elements of a baby's brain?</p> What about ML? Part of Artificial Intelligence that is based on computer learning to solve a problem based on some data is called Machine Learning. We will not consider classical machine learning in this course - we refer you to a separate Machine Learning for Beginners curriculum."},{"location":"curricula/ai-for-beginners/1-Intro/#a-brief-history-of-ai","title":"A Brief History of AI","text":"<p>Artificial Intelligence was started as a field in the middle of the twentieth century. Initially, symbolic reasoning was a prevalent approach, and it led to a number of important successes, such as expert systems \u2013 computer programs that were able to act as an expert in some limited problem domains. However, it soon became clear that such approach does not scale well. Extracting the knowledge from an expert, representing it in a computer, and keeping that knowledgebase accurate turns out to be a very complex task, and too expensive to be practical in many cases. This led to so-called AI Winter in the 1970s.</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>As time passed, computing resources became cheaper, and more data has become available, so neural network approaches started demonstrating great performance in competing with human beings in many areas, such as computer vision or speech understanding. In the last decade, the term Artificial Intelligence has been mostly used as a synonym for Neural Networks, because most of the AI successes that we hear about are based on them.</p> <p>We can observe how the approaches changed, for example, in creating a chess playing computer program:</p> <ul> <li>Early chess programs were based on search \u2013 a program explicitly tried to estimate possible moves of an opponent for a given number of next moves, and selected an optimal move based on the optimal position that can be achieved in a few moves. It led to the development of the so-called alpha-beta pruning search algorithm.</li> <li>Search strategies work well toward the end of the game, where the search space is limited by a small number of possible moves. However, at the beginning of the game, the search space is huge, and the algorithm can be improved by learning from existing matches between human players. Subsequent experiments employed so-called case-based reasoning, where the program looked for cases in the knowledge base very similar to the current position in the game.</li> <li>Modern programs that win over human players are based on neural networks and reinforcement learning, where the programs learn to play solely by playing a long time against themselves and learning from their own mistakes \u2013 much like human beings do when learning to play chess. However, a computer program can play many more games in much less time, and thus can learn much faster.</li> </ul> <p>\u2705 Do a little research on other games that have been played by AI.</p> <p>Similarly, we can see how the approach towards creating \u201ctalking programs\u201d (that might pass the Turing test) changed:</p> <ul> <li>Early programs of this kind such as Eliza, were based on very simple grammatical rules and the re-formulation of the input sentence into a question.</li> <li>Modern assistants, such as Cortana, Siri or Google Assistant are all hybrid systems that use Neural networks to convert speech into text and recognize our intent, and then employ some reasoning or explicit algorithms to perform required actions.</li> <li>In the future, we may expect a complete neural-based model to handle dialogue by itself. The recent GPT and Turing-NLG family of neural networks show great success in this.</li> </ul> <p></p> <p>Image by Dmitry Soshnikov, photo by Marina Abrosimova, Unsplash</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#recent-ai-research","title":"Recent AI Research","text":"<p>The huge recent growth in neural network research started around 2010, when large public datasets started to become available. A huge collection of images called ImageNet, which contains around 14 million annotated images, gave birth to the ImageNet Large Scale Visual Recognition Challenge.</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>In 2012, Convolutional Neural Networks were first used in image classification, which led to a significant drop in classification errors (from almost 30% to 16.4%). In 2015, ResNet architecture from Microsoft Research achieved human-level accuracy.</p> <p>Since then, Neural Networks demonstrated very successful behaviour in many tasks:</p> Year Human Parity achieved 2015 Image Classification 2016 Conversational Speech Recognition 2018 Automatic Machine Translation (Chinese-to-English) 2020 Image Captioning <p>Over the past few years we have witnessed huge successes with large language models, such as BERT and GPT-3. This happened mostly due to the fact that there is a lot of general text data available that allows us to train models to capture the structure and meaning of texts, pre-train them on general text collections, and then specialize those models for more specific tasks. We will learn more about Natural Language Processing later in this course.</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Do a tour of the internet to determine where, in your opinion, AI is most effectively used. Is it in a Mapping app, or some speech-to-text service or a video game? Research how the system was built.</p>"},{"location":"curricula/ai-for-beginners/1-Intro/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/1-Intro/#review-self-study","title":"Review &amp; Self Study","text":"<p>Review the history of AI and ML by reading through this lesson. Take an element from the sketchnote at the top of that lesson or this one and research it in more depth to understand the cultural context informing its evolution.</p> <p>Assignment: Game Jam</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/","title":"Lesson 2","text":""},{"location":"curricula/ai-for-beginners/2-Symbolic/#knowledge-representation-and-expert-systems","title":"Knowledge Representation and Expert Systems","text":"<p>Sketchnote by Tomomi Imura</p> <p>The quest for artificial intelligence is based on a search for knowledge, to make sense of the world similar to how humans do. But how can you go about doing this?</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In the early days of AI, the top-down approach to creating intelligent systems (discussed in the previous lesson) was popular. The idea was to extract the knowledge from people into some machine-readable form, and then use it to automatically solve problems. This approach was based on two big ideas:</p> <ul> <li>Knowledge Representation</li> <li>Reasoning</li> </ul>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#knowledge-representation","title":"Knowledge Representation","text":"<p>One of the important concepts in Symbolic AI is knowledge. It is important to differentiate knowledge from information or data. For example, one can say that books contain knowledge, because one can study books and become an expert. However, what books contain is actually called data, and by reading books and integrating this data into our world model we convert this data to knowledge.</p> <p>\u2705 Knowledge is something which is contained in our head and represents our understanding of the world. It is obtained by an active learning process, which integrates pieces of information that we receive into our active model of the world.</p> <p>Most often, we do not strictly define knowledge, but we align it with other related concepts using DIKW Pyramid. It contains the following concepts:</p> <ul> <li>Data is something represented in physical media, such as written text or spoken words. Data exists independently of human beings and can be passed between people.</li> <li>Information is how we interpret data in our head. For example, when we hear the word computer, we have some understanding of what it is.</li> <li>Knowledge is information being integrated into our world model. For example, once we learn what a computer is, we start having some ideas about how it works, how much it costs, and what it can be used for. This network of interrelated concepts forms our knowledge.</li> <li>Wisdom is yet one more level of our understanding of the world, and it represents meta-knowledge, eg. some notion on how and when the knowledge should be used.</li> </ul> <p></p> <p>Image from Wikipedia, By Longlivetheux - Own work, CC BY-SA 4.0</p> <p>Thus, the problem of knowledge representation is to find some effective way to represent knowledge inside a computer in the form of data, to make it automatically usable. This can be seen as a spectrum:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <ul> <li>On the left, there are very simple types of knowledge representations that can be effectively used by computers. The simplest one is algorithmic, when knowledge is represented by a computer program. This, however, is not the best way to represent knowledge, because it is not flexible. Knowledge inside our head is often non-algorithmic.</li> <li>On the right, there are representations such as natural text. It is the most powerful, but cannot be used for automatic reasoning.</li> </ul> <p>\u2705 Think for a minute about how you represent knowledge in your head and convert it to notes. Is there a particular format that works well for you to aid in retention?</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#classifying-computer-knowledge-representations","title":"Classifying Computer Knowledge Representations","text":"<p>We can classify different computer knowledge representation methods in the following categories:</p> <ul> <li> <p>Network representations are based on the fact that we have a network of interrelated concepts inside our head. We can try to reproduce the same networks as a graph inside a computer - a so-called semantic network.</p> </li> <li> <p>Object-Attribute-Value triplets or attribute-value pairs. Since a graph can be represented inside a computer as a list of nodes and edges, we can represent a semantic network by a list of triplets, containing objects, attributes, and values. For example, we build the following triplets about programming languages:</p> </li> </ul> Object Attribute Value Python is Untyped-Language Python invented-by Guido van Rossum Python block-syntax indentation Untyped-Language doesn't have type definitions <p>\u2705 Think how triplets can be used to represent other types of knowledge.</p> <ol> <li> <p>Hierarchical representations emphasize the fact that we often create a hierarchy of objects inside our head. For example, we know that canary is a bird, and all birds have wings. We also have some idea about what colour a canary usually is, and what is their flight speed.</p> </li> <li> <p>Frame representation is based on representing each object or class of objects as a frame which contains slots. Slots have possible default values, value restrictions, or stored procedures that can be called to obtain the value of a slot. All frames form a hierarchy similar to an object hierarchy in object-oriented programming languages.</p> </li> <li>Scenarios are special kind of frames that represent complex situations that can unfold in time.</li> </ol> <p>Python</p> Slot Value Default value Interval Name Python Is-A Untyped-Language Variable Case CamelCase Program Length 5-5000 lines Block Syntax Indent <ol> <li>Procedural representations are based on representing knowledge by a list of actions that can be executed when a certain condition occurs.</li> <li>Production rules are if-then statements that allow us to draw conclusions. For example, a doctor can have a rule saying that IF a patient has high fever OR high level of C-reactive protein in blood test THEN he has an inflammation. Once we encounter one of the conditions, we can make a conclusion about inflammation, and then use it in further reasoning.</li> <li> <p>Algorithms can be considered another form of procedural representation, although they are almost never used directly in knowledge-based systems.</p> </li> <li> <p>Logic was originally proposed by Aristotle as a way to represent universal human knowledge.</p> </li> <li>Predicate Logic as a mathematical theory is too rich to be computable, therefore some subset of it is normally used, such as Horn clauses used in Prolog.</li> <li>Descriptive Logic is a family of logical systems used to represent and reason about hierarchies of objects distributed knowledge representations such as semantic web.</li> </ol>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#expert-systems","title":"Expert Systems","text":"<p>One of the early successes of symbolic AI were so-called expert systems - computer systems that were designed to act as an expert in some limited problem domain. They were based on a knowledge base extracted from one or more human experts, and they contained an inference engine that performed some reasoning on top of it.</p> Simplified structure of a human neural system Architecture of a knowledge-based system <p>Expert systems are built like the human reasoning system, which contains short-term memory and long-term memory. Similarly, in knowledge-based systems we distinguish the following components:</p> <ul> <li>Problem memory: contains the knowledge about the problem being currently solved, i.e. the temperature or blood pressure of a patient, whether he has inflammation or not, etc. This knowledge is also called static knowledge, because it contains a snapshot of what we currently know about the problem - the so-called problem state.</li> <li>Knowledge base: represents long-term knowledge about a problem domain. It is extracted manually from human experts, and does not change from consultation to consultation. Because it allows us to navigate from one problem state to another, it is also called dynamic knowledge.</li> <li>Inference engine: orchestrates the whole process of searching in the problem state space, asking questions of the user when necessary. It is also responsible for finding the right rules to be applied to each state.</li> </ul> <p>As an example, let's consider the following expert system of determining an animal based on its physical characteristics:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>This diagram is called an AND-OR tree, and it is a graphical representation of a set of production rules. Drawing a tree is useful at the beginning of extracting knowledge from the expert. To represent the knowledge inside the computer it is more convenient to use rules:</p> <pre><code>IF the animal eats meat\nOR (animal has sharp teeth\n    AND animal has claws\n    AND animal has forward-looking eyes\n) \nTHEN the animal is a carnivore\n</code></pre> <p>You can notice that each condition on the left-hand-side of the rule and the action are essentially object-attribute-value (OAV) triplets. Working memory contains the set of OAV triplets that correspond to the problem currently being solved. A rules engine looks for rules for which a condition is satisfied and applies them, adding another triplet to the working memory.</p> <p>\u2705 Write your own AND-OR tree on a topic you like!</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#forward-vs-backward-inference","title":"Forward vs. Backward Inference","text":"<p>The process described above is called forward inference. It starts with some initial data about the problem available in the working memory, and then executes the following reasoning loop:</p> <ol> <li>If the target attribute is present in the working memory - stop and give the result</li> <li>Look for all the rules whose condition is currently satisfied - obtain conflict set of rules.</li> <li>Perform conflict resolution - select one rule that will be executed on this step. There could be different conflict resolution strategies:</li> <li>Select the first applicable rule in the knowledge base</li> <li>Select a random rule</li> <li>Select a more specific rule, i.e. the one meeting the most conditions in the \"left-hand-side\" (LHS)</li> <li>Apply selected rule and insert new piece of knowledge into the problem state</li> <li>Repeat from step 1.</li> </ol> <p>However, in some cases we might want to start with an empty knowledge about the problem, and ask questions that will help us arrive to the conclusion. For example, when doing medical diagnosis, we usually do not perform all medical analyses in advance before starting diagnosing the patient. We rather want to perform analyses when a decision needs to be made.</p> <p>This process can be modeled using backward inference. It is driven by the goal - the attribute value that we are looking to find:</p> <ol> <li>Select all rules that can give us the value of a goal (i.e. with the goal on the RHS (\"right-hand-side\")) - a conflict set</li> <li>If there are no rules for this attribute, or there is a rule saying that we should ask the value from the user - ask for it, otherwise:</li> <li>Use conflict resolution strategy to select one rule that we will use as hypothesis - we will try to prove it</li> <li>Recurrently repeat the process for all attributes in the LHS of the rule, trying to prove them as goals</li> <li>If at any point the process fails - use another rule at step 3.</li> </ol> <p>\u2705 In which situations is forward inference more appropriate? How about backward inference?</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#implementing-expert-systems","title":"Implementing Expert Systems","text":"<p>Expert systems can be implemented using different tools:</p> <ul> <li>Programming them directly in some high level programming language. This is not the best idea, because the main advantage of a knowledge-based system is that knowledge is separated from inference, and potentially a problem domain expert should be able to write rules without understanding the details of the inference process</li> <li>Using expert systems shell, i.e. a system specifically designed to be populated by knowledge using some knowledge representation language.</li> </ul>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#exercise-animal-inference","title":"\u270d\ufe0f Exercise: Animal Inference","text":"<p>See Animals.ipynb for an example of implementing forward and backward inference expert system.</p> <p>Note: This example is rather simple, and only gives the idea of how an expert system looks like. Once you start creating such a system, you will only notice some intelligent behaviour from it once you reach certain number of rules, around 200+. At some point, rules become too complex to keep all of them in mind, and at this point you may start wondering why a system makes certain decisions. However, the important characteristics of knowledge-based systems is that you can always explain exactly how any of the decisions were made.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#ontologies-and-the-semantic-web","title":"Ontologies and the Semantic Web","text":"<p>At the end of 20th century there was an initiative to use knowledge representation to annotate Internet resources, so that it would be possible to find resources that correspond to very specific queries. This motion was called Semantic Web, and it relied on several concepts:</p> <ul> <li>A special knowledge representation based on description logics (DL). It is similar to frame knowledge representation, because it builds a hierarchy of objects with properties, but it has formal logical semantics and inference. There is a whole family of DLs which balance between expressiveness and algorithmic complexity of inference.</li> <li>Distributed knowledge representation, where all concepts are represented by a global URI identifier, making it possible to create knowledge hierarchies that span the internet.</li> <li>A family of XML-based languages for knowledge description: RDF (Resource Description Framework), RDFS (RDF Schema), OWL (Ontology Web Language).</li> </ul> <p>A core concept in the Semantic Web is a concept of Ontology. It refers to a explicit specification of a problem domain using some formal knowledge representation. The simplest ontology can be just a hierarchy of objects in a problem domain, but more complex ontologies will include rules that can be used for inference.</p> <p>In the semantic web, all representations are based on triplets. Each object and each relation are uniquely identified by the URI. For example, if we want to state the fact that this AI Curriculum has been developed by Dmitry Soshnikov on Jan 1st, 2022 - here are the triplets we can use:</p> <p></p> <pre><code>http://github.com/microsoft/ai-for-beginners http://www.example.com/terms/creation-date \u201cJan 13, 2007\u201d\nhttp://github.com/microsoft/ai-for-beginners http://purl.org/dc/elements/1.1/creator http://soshnikov.com\n</code></pre> <p>\u2705 Here <code>http://www.example.com/terms/creation-date</code> and <code>http://purl.org/dc/elements/1.1/creator</code> are some well-known and universally accepted URIs to express the concepts of creator and creation date.</p> <p>In a more complex case, if we want to define a list of creators, we can use some data structures defined in RDF.</p> <p></p> <p>Diagrams above by Dmitry Soshnikov</p> <p>The progress of building the Semantic Web was somehow slowed down by the success of search engines and natural language processing techniques, which allow extracting structured data from text. However, in some areas there are still significant efforts to maintain ontologies and knowledge bases. A few projects worth noting:</p> <ul> <li>WikiData is a collection of machine readable knowledge bases associated with Wikipedia. Most of the data is mined from Wikipedia InfoBoxes, pieces of structured content inside Wikipedia pages. You can query wikidata in SPARQL, a special query language for Semantic Web. Here is a sample query that displays most popular eye colors among humans:</li> </ul> <pre><code>#defaultView:BubbleChart\nSELECT ?eyeColorLabel (COUNT(?human) AS ?count)\nWHERE\n{\n  ?human wdt:P31 wd:Q5.       # human instance-of homo sapiens\n  ?human wdt:P1340 ?eyeColor. # human eye-color ?eyeColor\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\nGROUP BY ?eyeColorLabel\n</code></pre> <ul> <li>DBpedia is another effort similar to WikiData.</li> </ul> <p>\u2705 If you want to experiment with building your own ontologies, or opening existing ones, there is a great visual ontology editor called Prot\u00e9g\u00e9. Download it, or use it online.</p> <p></p> <p>Web Prot\u00e9g\u00e9 editor open with the Romanov Family ontology. Screenshot by Dmitry Soshnikov</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#exercise-a-family-ontology","title":"\u270d\ufe0f Exercise: A Family Ontology","text":"<p>See FamilyOntology.ipynb for an example of using Semantic Web techniques to reason about family relationships. We will take a family tree represented in common GEDCOM format and an ontology of family relationships and build a graph of all family relationships for given set of individuals.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#microsoft-concept-graph","title":"Microsoft Concept Graph","text":"<p>In most of the cases, ontologies are carefully created by hand. However, it is also possible to mine ontologies from unstructured data, for example, from natural language texts.</p> <p>One such attempt was done by Microsoft Research, and resulted in Microsoft Concept Graph.</p> <p>It is a large collection of entities grouped together using <code>is-a</code> inheritance relationship. It allows answering questions like \"What is Microsoft?\" - the answer being something like \"a company with probability 0.87, and a brand with probability 0.75\".</p> <p>The Graph is available either as REST API, or as a large downloadable text file that lists all entity pairs.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#exercise-a-concept-graph","title":"\u270d\ufe0f Exercise: A Concept Graph","text":"<p>Try the MSConceptGraph.ipynb notebook to see how we can use Microsoft Concept Graph to group news articles into several categories.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#conclusion","title":"Conclusion","text":"<p>Nowadays, AI is often considered to be a synonym for Machine Learning or Neural Networks. However, a human being also exhibits explicit reasoning, which is something currently not being handled by neural networks. In real world projects, explicit reasoning is still used to perform tasks that require explanations, or being able to modify the behavior of the system in a controlled way.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the Family Ontology notebook associated to this lesson, there is an opportunity to experiment with other family relations. Try to discover new connections between people in the family tree.</p>"},{"location":"curricula/ai-for-beginners/2-Symbolic/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/2-Symbolic/#review-self-study","title":"Review &amp; Self Study","text":"<p>Do some research on the internet to discover areas where humans have tried to quantify and codify knowledge. Take a look at Bloom's Taxonomy, and go back in history to learn how humans tried to make sense of their world. Explore the work of Linnaeus to create a taxonomy of organisms, and observe the way Dmitri Mendeleev created a way for chemical elements to be described and grouped. What other interesting examples can you find?</p> <p>Assignment: Build an Ontology</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/","title":"Intro","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/#introduction-to-neural-networks","title":"Introduction to Neural Networks","text":"<p>As we discussed in the introduction, one of the ways to achieve intelligence is to train a computer model or an artificial brain. Since the middle of 20th century, researchers tried different mathematical models, until in recent years this direction proved to by hugely successful. Such mathematical models of the brain are called neural networks.</p> <p>Sometimes neural networks are called Artificial Neural Networks, ANNs, in order to indicate that we are talking about models, not real networks of neurons.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/#machine-learning","title":"Machine Learning","text":"<p>Neural Networks are a part of a larger discipline called Machine Learning, whose goal is to use data to train computer models that are able to solve problems. Machine Learning constitutes a large part of Artificial Intelligence, however, we do not cover classical ML in this curricula.</p> <p>Visit our separate Machine Learning for Beginners curriculum to learn more about classic Machine Learning.</p> <p>In Machine Learning, we assume that we have some dataset of examples X, and corresponding output values Y. Examples are often N-dimensional vectors that consist of features, and outputs are called labels.</p> <p>We will consider the two most common machine learning problems:</p> <ul> <li>Classification, where we need to classify an input object into two or more classes.</li> <li>Regression, where we need to predict a numerical number for each of the input samples.</li> </ul> <p>When representing inputs and outputs as tensors, the input dataset is a matrix of size M\u00d7N, where M is number of samples and N is the number of features. Output labels Y is the vector of size M.</p> <p>In this curriculum, we will only focus on neural network models.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/#a-model-of-a-neuron","title":"A Model of a Neuron","text":"<p>From biology we know that our brain consists of neural cells, each of them having multiple \"inputs\" (axons), and an output (dendrite). Axons and dendrites can conduct electrical signals, and connections between axons and dendrites can exhibit different degrees of conductivity (controlled by neuromediators).</p> Real Neuron (Image from Wikipedia) Artificial Neuron (Image by Author) <p>Thus, the simplest mathematical model of a neuron contains several inputs X<sub>1</sub>, ..., X<sub>N</sub> and an output Y, and a series of weights W<sub>1</sub>, ..., W<sub>N</sub>. An output is calculated as:</p> <p></p> <p>where f is some non-linear activation function.</p> <p>Early models of neuron were described in the classical paper A logical calculus of the ideas immanent in nervous activity by Warren McCullock and Walter Pitts in 1943. Donald Hebb in his book \"The Organization of Behavior: A Neuropsychological Theory\" proposed the way those networks can be trained.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/#in-this-section","title":"In this Section","text":"<p>In this section we will learn about: * Perceptron, one of the earliest neural network models for two-class classification * Multi-layered networks with a paired notebook how to build our own framework * Neural Network Frameworks, with these notebooks: PyTorch and Keras/Tensorflow * Overfitting</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/","title":"Perceptron","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#introduction-to-neural-networks-perceptron","title":"Introduction to Neural Networks: Perceptron","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures, such as triangles, squares and circles.</p> <p>Images from Wikipedia</p> <p>An input image was represented by 20x20 photocell array, so the neural network had 400 inputs and one binary output. A simple network contained one neuron, also called a threshold logic unit. Neural network weights acted like potentiometers that required manual adjustment during the training phase.</p> <p>\u2705 A potentiometer is a device that allows the user to adjust the resistance of a circuit.</p> <p>The New York Times wrote about perceptron at that time: the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#perceptron-model","title":"Perceptron Model","text":"<p>Suppose we have N features in our model, in which case the input vector would be a vector of size N. A perceptron is a binary classification model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class. The output will be computed using the formula:</p> <p>y(x) = f(w<sup>T</sup>x)</p> <p>where f is a step activation function</p> <p></p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#training-the-perceptron","title":"Training the Perceptron","text":"<p>To train a perceptron we need to find a weights vector w that classifies most of the values correctly, i.e. results in the smallest error. This error E is defined by perceptron criterion in the following manner:</p> <p>E(w) = -\u2211w<sup>T</sup>x<sub>i</sub>t<sub>i</sub></p> <p>where:</p> <ul> <li>the sum is taken on those training data points i that result in the wrong classification</li> <li>x<sub>i</sub> is the input data, and t<sub>i</sub> is either -1 or +1 for negative and positive examples accordingly.</li> </ul> <p>This criteria is considered as a function of weights w, and we need to minimize it. Often, a method called gradient descent is used, in which we start with some initial weights w<sup>(0)</sup>, and then at each step update the weights according to the formula:</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> - \u03b7\u2207E(w)</p> <p>Here \u03b7 is the so-called learning rate, and \u2207E(w) denotes the gradient of E. After we calculate the gradient, we end up with</p> <p>w<sup>(t+1)</sup> = w<sup>(t)</sup> + \u2211\u03b7x<sub>i</sub>t<sub>i</sub></p> <p>The algorithm in Python looks like this:</p> <pre><code>def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):\n\n    weights = [0,0,0] # Initialize weights (almost randomly :)\n\n    for i in range(num_iterations):\n        pos = random.choice(positive_examples)\n        neg = random.choice(negative_examples)\n\n        z = np.dot(pos, weights) # compute perceptron output\n        if z &lt; 0: # positive example classified as negative\n            weights = weights + eta*weights.shape\n\n        z  = np.dot(neg, weights)\n        if z &gt;= 0: # negative example classified as positive\n            weights = weights - eta*weights.shape\n\n    return weights\n</code></pre>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about a perceptron, which is a binary classification model, and how to train it by using a weights vector.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>If you'd like to try to build your own perceptron, try this lab on Microsoft Learn which uses the Azure ML designer.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#review-self-study","title":"Review &amp; Self Study","text":"<p>To see how we can use perceptron to solve a toy problem as well as real-life problems, and to continue learning - go to Perceptron notebook.</p> <p>Here's an interesting article about perceptrons as well.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/03-Perceptron/#assignment","title":"Assignment","text":"<p>In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve the problem of digit classification entirely, i.e. determine which digit is most likely to correspond to a given image.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/","title":"Own Framework","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#introduction-to-neural-networks-multi-layered-perceptron","title":"Introduction to Neural Networks. Multi-Layered Perceptron","text":"<p>In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model.</p> <p>In this section we will extend this model into a more flexible framework, allowing us to:</p> <ul> <li>perform multi-class classification in addition to two-class</li> <li>solve regression problems in addition to classification</li> <li>separate classes that are not linearly separable</li> </ul> <p>We will also develop our own modular framework in Python that will allow us to construct different neural network architectures.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#formalization-of-machine-learning","title":"Formalization of Machine Learning","text":"<p>Let's start with formalizing the Machine Learning problem. Suppose we have a training dataset X with labels Y, and we need to build a model f that will make most accurate predictions. The quality of predictions is measured by Loss function &amp;lagran;. The following loss functions are often used:</p> <ul> <li>For regression problem, when we need to predict a number, we can use absolute error \u2211<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, or squared error \u2211<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup></li> <li>For classification, we use 0-1 loss (which is essentially the same as accuracy of the model), or logistic loss.</li> </ul> <p>For one-level perceptron, function f was defined as a linear function f(x)=wx+b (here w is the weight matrix, x is the vector of input features, and b is bias vector). For different neural network architectures, this function can take more complex form.</p> <p>In the case of classification, it is often desirable to get probabilities of corresponding classes as network output. To convert arbitrary numbers to probabilities (eg. to normalize the output), we often use softmax function \u03c3, and the function f becomes f(x)=\u03c3(wx+b)</p> <p>In the definition of f above, w and b are called parameters \u03b8=\u27e8w,b\u27e9. Given the dataset \u27e8X,Y\u27e9, we can compute an overall error on the whole dataset as a function of parameters \u03b8.</p> <p>\u2705 The goal of neural network training is to minimize the error by varying parameters \u03b8</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#gradient-descent-optimization","title":"Gradient Descent Optimization","text":"<p>There is a well-known method of function optimization called gradient descent. The idea is that we can compute a derivative (in multi-dimensional case called gradient) of loss function with respect to parameters, and vary parameters in such a way that the error would decrease. This can be formalized as follows:</p> <ul> <li>Initialize parameters by some random values w<sup>(0)</sup>, b<sup>(0)</sup></li> <li>Repeat the following step many times:<ul> <li>w<sup>(i+1)</sup> = w<sup>(i)</sup>-\u03b7\u2202&amp;lagran;/\u2202w</li> <li>b<sup>(i+1)</sup> = b<sup>(i)</sup>-\u03b7\u2202&amp;lagran;/\u2202b</li> </ul> </li> </ul> <p>During training, the optimization steps are supposed to be calculated considering the whole dataset (remember that loss is calculated as a sum through all training samples). However, in real life we take small portions of the dataset called minibatches, and calculate gradients based on a subset of data. Because subset is taken randomly each time, such method is called stochastic gradient descent (SGD).</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#multi-layered-perceptrons-and-backpropagation","title":"Multi-Layered Perceptrons and Backpropagation","text":"<p>One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several layers of the network. Mathematically it would mean that the function f would have a more complex form, and will be computed in several steps: * z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub> * z<sub>2</sub>=w<sub>2</sub>\u03b1(z<sub>1</sub>)+b<sub>2</sub> * f = \u03c3(z<sub>2</sub>)</p> <p>Here, \u03b1 is a non-linear activation function, \u03c3 is a softmax function, and parameters \u03b8=&lt;w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>&gt;.</p> <p>The gradient descent algorithm would remain the same, but it would be more difficult to calculate gradients. Given the chain differentiation rule, we can calculate derivatives as:</p> <ul> <li>\u2202&amp;lagran;/\u2202w<sub>2</sub> = (\u2202&amp;lagran;/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202w<sub>2</sub>)</li> <li>\u2202&amp;lagran;/\u2202w<sub>1</sub> = (\u2202&amp;lagran;/\u2202\u03c3)(\u2202\u03c3/\u2202z<sub>2</sub>)(\u2202z<sub>2</sub>/\u2202\u03b1)(\u2202\u03b1/\u2202z<sub>1</sub>)(\u2202z<sub>1</sub>/\u2202w<sub>1</sub>)</li> </ul> <p>\u2705 The chain differentiation rule is used to calculate derivatives of the loss function with respect to parameters.</p> <p>Note that the left-most part of all those expressions is the same, and thus we can effectively calculate derivatives starting from the loss function and going \"backwards\" through the computational graph. Thus the method of training a multi-layered perceptron is called backpropagation, or 'backprop'.</p> <p></p> <p>TODO: image citation</p> <p>\u2705 We will cover backprop in much more detail in our notebook example.  </p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#conclusion","title":"Conclusion","text":"<p>In this lesson, we have built our own neural network library, and we have used it for a simple two-dimensional classification task.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebook, you will implement your own framework for building and training multi-layered perceptrons. You will be able to see in detail how modern neural networks operate.</p> <p>Proceed to the OwnFramework notebook and work through it.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#review-self-study","title":"Review &amp; Self Study","text":"<p>Backpropagation is a common algorithm used in AI and ML, worth studying in more detail</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/04-OwnFramework/#assignment","title":"Assignment","text":"<p>In this lab, you are asked to use the framework you constructed in this lesson to solve MNIST handwritten digit classification.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/","title":"Frameworks","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#neural-network-frameworks","title":"Neural Network Frameworks","text":"<p>As we have learned already, to be able to train neural networks efficiently we need to do two things:</p> <ul> <li>To operate on tensors, eg. to multiply, add, and compute some functions such as sigmoid or softmax</li> <li>To compute gradients of all expressions, in order to perform gradient descent optimization</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>While the <code>numpy</code> library can do the first part, we need some mechanism to compute gradients. In our framework that we have developed in the previous section we had to manually program all derivative functions inside the <code>backward</code> method, which does backpropagation. Ideally, a framework should give us the opportunity to compute gradients of any expression that we can define.</p> <p>Another important thing is to be able to perform computations on GPU, or any other specialized compute units, such as TPU. Deep neural network training requires a lot of computations, and to be able to parallelize those computations on GPUs is very important.</p> <p>\u2705 The term 'parallelize' means to distribute the computations over multiple devices.</p> <p>Currently, the two most popular neural frameworks are: TensorFlow and PyTorch. Both provide a low-level API to operate with tensors on both CPU and GPU. On top of the low-level API, there is also higher-level API, called Keras and PyTorch Lightning correspondingly.</p> Low-Level API TensorFlow PyTorch High-level API Keras PyTorch Lightning <p>Low-level APIs in both frameworks allow you to build so-called computational graphs. This graph defines how to compute the output (usually the loss function) with given input parameters, and can be pushed for computation on GPU, if it is available. There are functions to differentiate this computational graph and compute gradients, which can then be used for optimizing model parameters.</p> <p>High-level APIs pretty much consider neural networks as a sequence of layers, and make constructing most of the neural networks much easier. Training the model usually requires preparing the data and then calling a <code>fit</code> function to do the job.</p> <p>The high-level API allows you to construct typical neural networks very quickly without worrying about lots of details. At the same time, low-level API offer much more control over the training process, and thus they are used a lot in research, when you are dealing with new neural network architectures.</p> <p>It is also important to understand that you can use both APIs together, eg. you can develop your own network layer architecture using low-level API, and then use it inside the larger network constructed and trained with the high-level API. Or you can define a network using the high-level API as a sequence of layers, and then use your own low-level training loop to perform optimization. Both APIs use the same basic underlying concepts, and they are designed to work well together.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#learning","title":"Learning","text":"<p>In this course, we offer most of the content both for PyTorch and TensorFlow. You can choose your preferred framework and only go through the corresponding notebooks. If you are not sure which framework to choose, read some discussions on the internet regarding PyTorch vs. TensorFlow. You can also have a look at both frameworks to get better understanding.</p> <p>Where possible, we will use High-Level APIs for simplicity. However, we believe it is important to understand how neural networks work from the ground up, thus in the beginning we start by working with low-level API and tensors. However, if you want to get going fast and do not want to spend a lot of time on learning these details, you can skip those and go straight into high-level API notebooks.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#exercises-frameworks","title":"\u270d\ufe0f Exercises: Frameworks","text":"<p>Continue your learning in the following notebooks:</p> Low-Level API TensorFlow+Keras Notebook PyTorch High-level API Keras PyTorch Lightning <p>After mastering the frameworks, let's recap the notion of overfitting.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#overfitting","title":"Overfitting","text":"<p>Overfitting is an extremely important concept in machine learning, and it is very important to get it right!</p> <p>Consider the following problem of approximating 5 dots (represented by <code>x</code> on the graphs below):</p> Linear model, 2 parameters Non-linear model, 7 parameters Training error = 5.3 Training error = 0 Validation error = 5.1 Validation error = 20 <ul> <li>On the left, we see a good straight line approximation. Because the number of parameters is adequate, the model gets the idea behind point distribution right.</li> <li>On the right, the model is too powerful. Because we only have 5 points and the model has 7 parameters, it can adjust in such a way as to pass through all points, making training the error to be 0. However, this prevents the model from understanding the correct pattern behind data, thus the validation error is very high.</li> </ul> <p>It is very important to strike a correct balance between the richness of the model (number of parameters) and the number of training samples.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#why-overfitting-occurs","title":"Why overfitting occurs","text":"<ul> <li>Not enough training data</li> <li>Too powerful model</li> <li>Too much noise in input data</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#how-to-detect-overfitting","title":"How to detect overfitting","text":"<p>As you can see from the graph above, overfitting can be detected by a very low training error, and a high validation error. Normally during training we will see both training and validation errors starting to decrease, and then at some point validation error might stop decreasing and start rising. This will be a sign of overfitting, and the indicator that we should probably stop training at this point (or at least make a snapshot of the model).</p> <p></p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#how-to-prevent-overfitting","title":"How to prevent overfitting","text":"<p>If you can see that overfitting occurs, you can do one of the following:</p> <ul> <li>Increase the amount of training data</li> <li>Decrease the complexity of the model</li> <li>Use some regularization technique, such as Dropout, which we will consider later.</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#overfitting-and-bias-variance-tradeoff","title":"Overfitting and Bias-Variance Tradeoff","text":"<p>Overfitting is actually a case of a more generic problem in statistics called Bias-Variance Tradeoff. If we consider the possible sources of error in our model, we can see two types of errors:</p> <ul> <li>Bias errors are caused by our algorithm not being able to capture the relationship between training data correctly. It can result from the fact that our model is not powerful enough (underfitting).</li> <li>Variance errors, which are caused by the model approximating noise in the input data instead of meaningful relationship (overfitting).</li> </ul> <p>During training, bias error decreases (as our model learns to approximate the data), and variance error increases. It is important to stop training - either manually (when we detect overfitting) or automatically (by introducing regularization) - to prevent overfitting.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about the differences between the various APIs for the two most popular AI frameworks, TensorFlow and PyTorch. In addition, you learned about a very important topic, overfitting.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, you will find 'tasks' at the bottom; work through the notebooks and complete the tasks.</p>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#review-self-study","title":"Review &amp; Self Study","text":"<p>Do some research on the following topics:</p> <ul> <li>TensorFlow</li> <li>PyTorch</li> <li>Overfitting</li> </ul> <p>Ask yourself the following questions:</p> <ul> <li>What is the difference between TensorFlow and PyTorch?</li> <li>What is the difference between overfitting and underfitting?</li> </ul>"},{"location":"curricula/ai-for-beginners/3-NeuralNetworks/05-Frameworks/#assignment","title":"Assignment","text":"<p>In this lab, you are asked to solve two classification problems using single- and multi-layered fully-connected networks using PyTorch or TensorFlow.</p> <ul> <li>Instructions</li> <li>Notebook</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/","title":"Lesson 4","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/#computer-vision","title":"Computer Vision","text":"<p>In this section we will learn about:</p> <ul> <li>Intro to Computer Vision and OpenCV</li> <li>Convolutional Neural Networks</li> <li>Pre-trained Networks and Transfer Learning </li> <li>Autoencoders</li> <li>Generative Adversarial Networks</li> <li>Object Detection</li> <li>Semantic Segmentation</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#introduction-to-computer-vision","title":"Introduction to Computer Vision","text":"<p>Computer Vision is a discipline whose aim is to allow computers to gain high-level understanding of digital images. This is quite a broad definition, because understanding can mean many different things, including finding an object on a picture (object detection), understanding what is happening (event detection), describing a picture in text, or reconstructing a scene in 3D. There are also special tasks related to human images: age and emotion estimation, face detection and identification, and 3D pose estimation, to name a few.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the simplest tasks of computer vision is image classification.</p> <p>Computer vision is often considered to be a branch of AI. Nowadays, most of computer vision tasks are solved using neural networks. We will learn more about the special type of neural networks used for computer vision, convolutional neural networks, throughout this section.</p> <p>However, before you pass the image to a neural network, in many cases it makes sense to use some algorithmic techniques to enhance the image.</p> <p>There are several Python libraries available for image processing:</p> <ul> <li>imageio can be used for reading/writing different image formats. It also support ffmpeg, a useful tool to convert video frames to images.</li> <li>Pillow (also known as PIL) is a bit more powerful, and also supports some image manipulation such as morphing, palette adjustments, and more.</li> <li>OpenCV is a powerful image processing library written in C++, which has become the de facto standard for image processing. It has a convenient Python interface.</li> <li>dlib is a C++ library that implements many machine learning algorithms, including some of the Computer Vision algorithms. It also has a Python interface, and can be used for challenging tasks such as face and facial landmark detection.</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#opencv","title":"OpenCV","text":"<p>OpenCV is considered to be the de facto standard for image processing. It contains a lot of useful algorithms, implemented in C++. You can call OpenCV from Python as well.</p> <p>A good place to learn OpenCV is this Learn OpenCV course. In our curriculum, our goal is not to learn OpenCV, but to show you some examples when it can be used, and how.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#loading-images","title":"Loading Images","text":"<p>Images in Python can be conveniently represented by NumPy arrays. For example, grayscale images with the size of 320x200 pixels would be stored in a 200x320 array, and color images of the same dimension would have shape of 200x320x3 (for 3 color channels). To load an image, you can use the following code:</p> <pre><code>import cv2\nimport matplotlib.pyplot as plt\n\nim = cv2.imread('image.jpeg')\nplt.imshow(im)\n</code></pre> <p>Traditionally, OpenCV uses BGR (Blue-Green-Red) encoding for color images, while the rest of Python tools use the more traditional RGB (Red-Green-Blue). For the image to look right, you need to convert it to the RGB color space, either by swapping dimensions in the NumPy array, or by calling an OpenCV function:</p> <pre><code>im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n</code></pre> <p>The same <code>cvtColor</code> function can be used to perform other color space transformations such as converting an image to grayscale or to the HSV (Hue-Saturation-Value) color space.</p> <p>You can also use OpenCV to load video frame-by-frame - an example is given in the exercise OpenCV Notebook.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#image-processing","title":"Image Processing","text":"<p>Before feeding an image to a neural network, you may want to apply several pre-processing steps. OpenCV can do many things, including:</p> <ul> <li>Resizing the image using <code>im = cv2.resize(im, (320,200),interpolation=cv2.INTER_LANCZOS)</code></li> <li>Blurring the image using <code>im = cv2.medianBlur(im,3)</code> or <code>im = cv2.GaussianBlur(im, (3,3), 0)</code></li> <li>Changing the brightness and contrast of the image can be done by NumPy array manipulations, as described in this Stackoverflow note.</li> <li>Using thresholding by calling <code>cv2.threshold</code>/<code>cv2.adaptiveThreshold</code> functions, which is often preferable to adjusting brightness or contrast.</li> <li>Applying different transformations to the image:<ul> <li>Affine transformations can be useful if you need to combine rotation, resizing and skewing to the image and you know the source and destination location of three points in the image. Affine transformations keep parallel lines parallel.</li> <li>Perspective transformations can be useful when you know the source and destination positions of 4 points in the image. For example, if you take a picture of a rectangular document via a smartphone camera from some angle, and you want to make a rectangular image of the document itself.</li> </ul> </li> <li>Understanding movement inside the image by using optical flow.</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#examples-of-using-computer-vision","title":"Examples of using Computer Vision","text":"<p>In our OpenCV Notebook, we give some examples of when computer vision can be used to perform specific tasks:</p> <ul> <li>Pre-processing a photograph of a Braille book. We focus on how we can use thresholding, feature detection, perspective transformation and NumPy manipulations to separate individual Braille symbols for further classification by a neural network.</li> </ul> <p>Image from OpenCV.ipynb</p> <ul> <li>Detecting motion in video using frame difference. If the camera is fixed, then frames from the camera feed should be pretty similar to each other. Since frames are represented as arrays, just by subtracting those arrays for two subsequent frames we will get the pixel difference, which should be low for static frames, and become higher once there is substantial motion in the image.</li> </ul> <p></p> <p>Image from OpenCV.ipynb</p> <ul> <li> <p>Detecting motion using Optical Flow. Optical flow allows us to understand how individual pixels on video frames move. There are two types of optical flow:</p> </li> <li> <p>Dense Optical Flow computes the vector field that shows for each pixel where is it moving</p> </li> <li>Sparse Optical Flow is based on taking some distinctive features in the image (eg. edges), and building their trajectory from frame to frame.</li> </ul> <p></p> <p>Image from OpenCV.ipynb</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#example-notebooks-opencv-try-opencv-in-action","title":"\u270d\ufe0f Example Notebooks: OpenCV try OpenCV in Action","text":"<p>Let's do some experiments with OpenCV by exploring OpenCV Notebook</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#conclusion","title":"Conclusion","text":"<p>Sometimes, relatively complex tasks such as movement detection or fingertip detection can be solved purely by computer vision. Thus, it is very helpful to know the basic techniques of computer vision, and what libraries like OpenCV can do.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Watch this video from the AI show to learn about the Cortic Tigers project and how they built a block-based solution to democratize computer vision tasks via a robot. Do some research on other projects like this that help onboard new learners into the field.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read more on optical flow in this great tutorial.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/06-IntroCV/#assignment","title":"Assignment","text":"<p>In this lab, you will take a video with simple gestures, and your goal is to extract up/down/left/right movements using optical flow.</p> <p></p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#convolutional-neural-networks","title":"Convolutional Neural Networks","text":"<p>We have seen before that neural networks are quite good at dealing with images, and even one-layer perceptron is able to recognize handwritten digits from MNIST dataset with reasonable accuracy. However, the MNIST dataset is very special, and all digits are centered inside the image, which makes the task simpler.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In real life, we want to be able to recognize objects on a picture regardless of their exact location in the image. Computer vision is different from generic classification, because when we are trying to find a certain object in the picture, we are scanning the image looking for some specific patterns and their combinations. For example, when looking for a cat, we first may look for horizontal lines, which can form whiskers, and then certain a combination of whiskers can tell us that it is actually a picture of a cat. Relative position and presence of certain patterns is important, and not their exact position on the image.</p> <p>To extract patterns, we will use the notion of convolutional filters. As you know, an image is represented by a 2D-matrix, or a 3D-tensor with color depth. Applying a filter means that we take relatively small filter kernel matrix, and for each pixel in the original image we compute the weighted average with neighboring points. We can view this like a small window sliding over the whole image, and averaging out all pixels according to the weights in the filter kernel matrix.</p> <p>Image by Dmitry Soshnikov</p> <p>For example, if we apply 3x3 vertical edge and horizontal edge filters to the MNIST digits, we can get highlights (e.g. high values) where there are vertical and horizontal edges in our original image. Thus those two filters can be used to \"look for\" edges. Similarly, we can design different filters to look for other low-level patterns:</p> <p></p> <p>Image of Leung-Malik Filter Bank</p> <p>However, while we can design the filters to extract some patterns manually, we can also design the network in such a way that it will learn the patterns automatically. It is one of the main ideas behind the CNN.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#main-ideas-behind-cnn","title":"Main ideas behind CNN","text":"<p>The way CNNs work is based on the following important ideas:</p> <ul> <li>Convolutional filters can extract patterns</li> <li>We can design the network in such a way that filters are trained automatically</li> <li>We can use the same approach to find patterns in high-level features, not only in the original image. Thus CNN feature extraction work on a hierarchy of features, starting from low-level pixel combinations, up to higher level combination of picture parts.</li> </ul> <p></p> <p>Image from a paper by Hislop-Lynch, based on their research</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#exercises-convolutional-neural-networks","title":"\u270d\ufe0f Exercises: Convolutional Neural Networks","text":"<p>Let's continue exploring how convolutional neural networks work, and how we can achieve trainable filters, by working through the corresponding notebooks:</p> <ul> <li>Convolutional Neural Networks - PyTorch</li> <li>Convolutional Neural Networks - TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#pyramid-architecture","title":"Pyramid Architecture","text":"<p>Most of the CNNs used for image processing follow a so-called pyramid architecture. The first convolutional layer applied to the original images typically has a relatively low number of filters (8-16), which correspond to different pixel combinations, such as horizontal/vertical lines of strokes. At the next level, we reduce the spatial dimension of the network, and increase the number of filters, which corresponds to more possible combinations of simple features. With each layer, as we move towards the final classifier, spatial dimensions of the image decrease, and the number of filters grow.</p> <p>As an example, let's look at the architecture of VGG-16, a network that achieved 92.7% accuracy in ImageNet's top-5 classification in 2014:</p> <p></p> <p></p> <p>Image from Researchgate</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/#best-known-cnn-architectures","title":"Best-Known CNN Architectures","text":"<p>Continue your study about the best-known CNN architectures</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/","title":"CNN Architectures","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#well-known-cnn-architectures","title":"Well-Known CNN Architectures","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#vgg-16","title":"VGG-16","text":"<p>VGG-16 is a network that achieved 92.7% accuracy in ImageNet top-5 classification in 2014. It has the following layer structure:</p> <p></p> <p>As you can see, VGG follows a traditional pyramid architecture, which is a sequence of convolution-pooling layers.</p> <p></p> <p>Image from Researchgate</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#resnet","title":"ResNet","text":"<p>ResNet is a family of models proposed by Microsoft Research in 2015. The main idea of ResNet is to use residual blocks:</p> <p></p> <p>Image from this paper</p> <p>The reason for using identity pass-through is to have our layer predict the difference between the result of a previous layer and the output of the residual block - hence the name residual. Those blocks are much easier to train, and one can construct networks with several hundreds of those blocks (most common variants are ResNet-52, ResNet-101 and ResNet-152).</p> <p>You can also think of this network as being able to adjust its complexity to the dataset. Initially, when you are starting to train the network, the weights values are small, and most of the signal goes through passthrough identity layers. As training progresses and weights become larger, the significance of network parameters grow, and the networks adjusts to accommodate required expressive power to correctly classify training images.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#google-inception","title":"Google Inception","text":"<p>Google Inception architecture takes this idea one step further, and builds each network layer as a combination of several different paths:</p> <p></p> <p>Image from Researchgate</p> <p>Here, we need to emphasize the role of 1x1 convolutions, because at first they do not make sense. Why would we need to run through the image with 1x1 filter? However, you need to remember that convolution filters also work with several depth channels (originally - RGB colors, in subsequent layers - channels for different filters), and 1x1 convolution is used to mix those input channels together using different trainable weights. It can be also viewed as downsampling (pooling) over channel dimension.</p> <p>Here is a good blog post on the subject, and the original paper.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#mobilenet","title":"MobileNet","text":"<p>MobileNet is a family of models with reduced size, suitable for mobile devices. Use them if you are short in resources, and can sacrifice a little bit of accuracy. The main idea behind them is so-called depthwise separable convolution, which allows representing convolution filters by a composition of spatial convolutions and 1x1 convolution over depth channels. This significantly reduces the number of parameters, making the network smaller in size, and also easier to train with less data.</p> <p>Here is a good blog post on MobileNet.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#conclusion","title":"Conclusion","text":"<p>In this unit, you have learned the main concept behind computer vision neural networks - convolutional networks. Real-life architectures that power image classification, object detection, and even image generation networks are all based on CNNs, just with more layers and some additional training tricks.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, there are notes at the bottom about how to obtain greater accuracy. Do some experiments to see if you can achieve higher accuracy.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#review-self-study","title":"Review &amp; Self Study","text":"<p>While CNNs are most often used for Computer Vision tasks, they are generally good for extracting fixed-sized patterns. For example, if we are dealing with sounds, we may also want to use CNNs to look for some specific patterns in audio signal - in which case filters would be 1-dimensional (and this CNN would be called 1D-CNN). Also, sometimes 3D-CNN is used to extract features in multi-dimensional space, such as certain events occurring on video - CNN can capture certain patterns of feature changing over time. Do some review and self-study about other tasks that can be done with CNNs.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/07-ConvNets/CNN_Architectures/#assignment","title":"Assignment","text":"<p>In this lab, you are tasked with classifying different cat and dog breeds. These images are more complex than the MNIST dataset and of higher dimensions, and there are more than 10 classes.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#pre-trained-networks-and-transfer-learning","title":"Pre-trained Networks and Transfer Learning","text":"<p>Training CNNs can take a lot of time, and a lot of data is required for that task. However, much of the time is spent learning the best low-level filters that a network can use to extract patterns from images. A natural question arises - can we use a neural network trained on one dataset and adapt it to classify different images without requiring a full training process?</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>This approach is called transfer learning, because we transfer some knowledge from one neural network model to another. In transfer learning, we typically start with a pre-trained model, which has been trained on some large image dataset, such as ImageNet. Those models can already do a good job extracting different features from generic images, and in many cases just building a classifier on top of those extracted features can yield a good result.</p> <p>\u2705 Transfer Learning is a term you find in other academic fields, such as Education. It refers to the process of taking knowledge from one domain and applying it to another.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#pre-trained-models-as-feature-extractors","title":"Pre-Trained Models as Feature Extractors","text":"<p>The convolutional networks that we have talked about in the previous section contained a number of layers, each of which is supposed to extract some features from the image, starting from low-level pixel combinations (such as horizontal/vertical line or stroke), up to higher level combinations of features, corresponding to things like an eye of a flame. If we train CNN on sufficiently large dataset of generic and diverse images, the network should learn to extract those common features.</p> <p>Both Keras and PyTorch contain functions to easily load pre-trained neural network weights for some common architectures, most of which were trained on ImageNet images. The most often used ones are described on the CNN Architectures page from the prior lesson. In particular, you may want to consider using one of the following:</p> <ul> <li>VGG-16/VGG-19 which are relatively simple models that still give good accuracy. Often using VGG as a first attempt is a good choice to see how transfer learning is working.</li> <li>ResNet is a family of models proposed by Microsoft Research in 2015. They have more layers, and thus take more resources.</li> <li>MobileNet is a family of models with reduced size, suitable for mobile devices. Use them if you are short in resources and can sacrifice a little bit of accuracy.</li> </ul> <p>Here are sample features extracted from a picture of a cat by VGG-16 network:</p> <p></p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#cats-vs-dogs-dataset","title":"Cats vs. Dogs Dataset","text":"<p>In this example, we will use a dataset of Cats and Dogs, which is very close to a real-life image classification scenario.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#exercise-transfer-learning","title":"\u270d\ufe0f Exercise: Transfer Learning","text":"<p>Let's see transfer learning in action in corresponding notebooks:</p> <ul> <li>Transfer Learning - PyTorch</li> <li>Transfer Learning - TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#visualizing-adversarial-cat","title":"Visualizing Adversarial Cat","text":"<p>Pre-trained neural network contains different patterns inside it's brain, including notions of ideal cat (as well as ideal dog, ideal zebra, etc.). It would be interesting to somehow visualize this image. However, it is not simple, because patterns are spread all over the network weights, and also organized in a hierarchical structure.</p> <p>One approach we can take is to start with a random image, and then try to use gradient descent optimization technique to adjust that image in such a way, that the network starts thinking that it's a cat. </p> <p></p> <p>However, if we do this, we will receive something very similar to a random noise. This is because there are many ways to make network think the input image is a cat, including some that do not make sense visually. While those images contain a lot of patterns typical for a cat, there is nothing to constrain them to be visually distinctive.</p> <p>To improve the result, we can add another term into the loss function, which is called variation loss. It is a metric that shows how similar neighboring pixels of the image are. Minimizing variation loss makes image smoother, and gets rid of noise - thus revealing more visually appealing patterns. Here is an example of such \"ideal\" images, that are classified as cat and as zebra with high probability:</p> Ideal Cat Ideal Zebra <p>Similar approach can be used to perform so-called adversarial attacks on a neural network. Suppose we want to fool a neural network and make a dog look like a cat. If we take dog's image, which is recognized by a network as a dog, we can then tweak it a little but using gradient descent optimization, until the network starts classifying it as a cat:</p> Original picture of a dog Picture of a dog classified as a cat <p>See the code to reproduce the results above in the following notebook:</p> <ul> <li>Ideal and Adversarial Cat - TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#conclusion","title":"Conclusion","text":"<p>Using transfer learning, you are able to quickly put together a classifier for a custom object classification task and achieve high accuracy. You can see that more complex tasks that we are solving now require higher computational power, and cannot be easily solved on the CPU. In the next unit, we will try to use a more lightweight implementation to train the same model using lower compute resources, which results in just slightly lower accuracy.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In the accompanying notebooks, there are notes at the bottom about how transfer knowledge works best with somewhat similar training data (a new type of animal, perhaps). Do some experimentation with completely new types of images to see how well or poorly your transfer knowledge models perform.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through TrainingTricks.md to deepen your knowledge of some other way to train your models.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/#assignment","title":"Assignment","text":"<p>In this lab, we will use real-life Oxford-IIIT pets dataset with 35 breeds of cats and dogs, and we will build a transfer learning classifier.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/","title":"TrainingTricks","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#deep-learning-training-tricks","title":"Deep Learning Training Tricks","text":"<p>As neural networks become deeper, the process of their training becomes more and more challenging. One major problem is so-called vanishing gradients or exploding gradients. This post gives a good introduction into those problems.</p> <p>To make training deep networks more efficient, there are a few techniques that can be used.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#keeping-values-in-reasonable-interval","title":"Keeping values in reasonable interval","text":"<p>To make numerical computations more stable, we want to make sure that all values within our neural network are within reasonable scale, typically [-1..1] or [0..1]. It is not a very strict requirement, but the nature of floating point computations is such that values of different magnitudes cannot be accurately manipulated together. For example, if we add 10<sup>-10</sup> and 10<sup>10</sup>, we are likely to get 10<sup>10</sup>, because smaller value would be \"converted\" to the same order as the larger one, and thus mantissa would be lost.</p> <p>Most activation functions have non-linearities around [-1..1], and thus it makes sense to scale all input data to [-1..1] or [0..1] interval.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#initial-weight-initialization","title":"Initial Weight Initialization","text":"<p>Ideally, we want the values to be in the same range after passing through network layers. Thus it is important to initialize weights in such a way as to preserve the distribution of values.</p> <p>Normal distribution N(0,1) is not a good idea, because if we have n inputs, the standard deviation of output would be n, and values are likely to jump out of [0..1] interval.</p> <p>The following initializations are often used:</p> <ul> <li>Uniform distribution -- <code>uniform</code></li> <li>N(0,1/n) -- <code>gaussian</code></li> <li>N(0,1/\u221an_in) guarantees that for inputs with zero mean and standard deviation of 1 the same mean/standard deviation would remain</li> <li>N(0,\u221a2/(n_in+n_out)) -- so-called Xavier initialization (<code>glorot</code>), it helps to keep the signals in range during both forward and backward propagation</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#batch-normalization","title":"Batch Normalization","text":"<p>Even with proper weight initialization, weights can get arbitrary big or small during the training, and they will bring signals out of proper range. We can bring signals back by using one of normalization techniques. While there are several of them (Weight normalization, Layer Normalization), the most often used is Batch Normalization.</p> <p>The idea of batch normalization is to take into account all values across the minibatch, and perform normalization (i.e. subtract mean and divide by standard deviation) based on those values. It is implemented as a network layer that does this normalization after applying the weights, but before activation function. As a result, we are likely to see higher final accuracy and faster training.</p> <p>Here is the original paper on batch normalization, the explanation on Wikipedia, and a good introductory blog post (and the one in Russian).</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#dropout","title":"Dropout","text":"<p>Dropout is an interesting technique that removes a certain percentage of random neurons during training. It is also implemented as a layer with one parameter (percentage of neurons to remove, typically 10%-50%), and during training it zeroes random elements of the input vector, before passing it to the next layer.</p> <p>While this may sound like a strange idea, you can see the effect of dropout on training MNIST digit classifier in <code>Dropout.ipynb</code> notebook. It speeds up training and allows us to achieve higher accuracy in less training epochs.</p> <p>This effect can be explained in several ways:</p> <ul> <li>It can be considered to be a random shocking factor to the model, which takes optimiation out of local minimum</li> <li>It can be considered as implicit model averaging, because we can say that during dropout we are training slightly different model</li> </ul> <p>Some people say that when a drunk person tries to learn something, he will remember this better next morning, comparing to a sober person, because a brain with some malfunctioning neurons tries to adapt better to gasp the meaning. We never tested ourselves if this is true of not</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#preventing-overfitting","title":"Preventing overfitting","text":"<p>One of the very important aspect of deep learning is too be able to prevent overfitting. While it might be tempting to use very powerful neural network model, we should always balance the number of model parameters with the number of training samples.</p> <p>Make sure you understand the concept of overfitting we have introduced earlier!</p> <p>There are several ways to prevent overfitting:</p> <ul> <li>Early stopping -- continuously monitor error on validation set and stopping training when validation error starts to increase.</li> <li>Explicit Weight Decay / Regularization -- adding an extra penalty to the loss function for high absolute values of weights, which prevents the model of getting very unstable results</li> <li>Model Averaging -- training several models and then averaging the result. This helps to minimize the variance.</li> <li>Dropout (Implicit Model Averaging)</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#optimizers-training-algorithms","title":"Optimizers / Training Algorithms","text":"<p>Another important aspect of training is to chose good training algorithm. While classical gradient descent is a reasonable choice, it can sometimes be too slow, or result in other problems.</p> <p>In deep learning, we use Stochastic Gradient Descent (SGD), which is a gradient descent applied to minibatches, randomly selected from the training set. Weights are adjusted using this formula:</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7\u2207&amp;lagran;</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#momentum","title":"Momentum","text":"<p>In momentum SGD, we are keeping a portion of a gradient from previous steps. It is similar to when we are moving somewhere with inertia, and we receive a punch in a different direction, our trajectory does not change immediately, but keeps some part of the original movement. Here we introduce another vector v to represent the speed:</p> <ul> <li>v<sup>t+1</sup> = \u03b3 v<sup>t</sup> - \u03b7\u2207&amp;lagran;</li> <li>w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup></li> </ul> <p>Here parameter \u03b3 indicates the extent to which we take inertia into account: \u03b3=0 corresponds to classical SGD; \u03b3=1 is a pure motion equation.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#adam-adagrad-etc","title":"Adam, Adagrad, etc.","text":"<p>Since in each layer we multiply signals by some matrix W<sub>i</sub>, depending on ||W<sub>i</sub>||, the gradient can either diminish and be close to 0, or rise indefinitely. It is the essence of Exploding/Vanishing Gradients problem.</p> <p>One of the solutions to this problem is to use only direction of the gradient in the equation, and ignore the absolute value, i.e.</p> <p>w<sup>t+1</sup> = w<sup>t</sup> - \u03b7(\u2207&amp;lagran;/||\u2207&amp;lagran;||), where ||\u2207&amp;lagran;|| = \u221a\u2211(\u2207&amp;lagran;)<sup>2</sup></p> <p>This algorithm is called Adagrad. Another algorithms that use the same idea: RMSProp, Adam</p> <p>Adam is considered to be a very efficient algorithm for many applications, so if you are not sure which one to use - use Adam.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#gradient-clipping","title":"Gradient clipping","text":"<p>Gradient clipping is an extension the idea above. When the ||\u2207&amp;lagran;|| \u2264 \u03b8, we consider the original gradient in the weight optimization, and when ||\u2207&amp;lagran;|| &gt; \u03b8 - we divide the gradient by it's norm. Here \u03b8 is a parameter, in most cases we can take \u03b8=1 or \u03b8=10.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#learning-rate-decay","title":"Learning rate decay","text":"<p>Training success often depends on the learning rate parameter \u03b7. It is logical to assume that larger values of \u03b7 result in faster training, which is something we typically want in the beginning of the training, and then smaller value of \u03b7 allow us to fine-tune the network. Thus, in most of the cases we want to decrease \u03b7 in the process of the training.</p> <p>This can be done by multiplying \u03b7 by some number (eg. 0.98) after each epoch of the training, or by using more complicated learning rate schedule.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/08-TransferLearning/TrainingTricks/#different-network-architectures","title":"Different Network Architectures","text":"<p>Selecting right network architecture for your problem can be tricky. Normally, we would take an architecture that has proven to work for our specific task (or similar one). Here is a good overview or neural network architectures for computer vision.</p> <p>It is important to select an architecture that will be powerful enough for the number of training samples that we have. Selecting too powerful model can result in overfitting</p> <p>Another good way would be to use and architecture that will automatically adjust to the required complexity. To some extent, ResNet architecture and Inception are self-adjusting. More on computer vision architectures</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#autoencoders","title":"Autoencoders","text":"<p>When training CNNs, one of the problems is that we need a lot of labeled data. In the case of image classification, we need to separate images into different classes, which is a manual effort.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, we might want to use raw (unlabeled) data for training CNN feature extractors, which is called self-supervised learning. Instead of labels, we will use training images as both network input and output. The main idea of autoencoder is that we will have an encoder network that converts input image into some latent space (normally it is just a vector of some smaller size), then the decoder network, whose goal would be to reconstruct the original image.</p> <p>\u2705 An autoencoder is \"a type of artificial neural network used to learn efficient codings of unlabeled data.\"</p> <p>Since we are training an autoencoder to capture as much of the information from the original image as possible for accurate reconstruction, the network tries to find the best embedding of input images to capture the meaning.\u043b.</p> <p></p> <p>Image from Keras blog</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#scenarios-for-using-autoencoders","title":"Scenarios for using Autoencoders","text":"<p>While reconstructing original images does not seem useful in its own right, there are a few scenarios where autoencoders are especially useful:</p> <ul> <li>Lowering the dimension of images for visualization or training image embeddings. Usually autoencoders give better results than PCA, because it takes into account spatial nature of images and hierarchical features.</li> <li>Denoising, i.e. removing noise from the image. Because noise carries out a lot of useless information, autoencoder cannot fit it all into relatively small latent space, and thus it captures only important part of the image. When training denoisers, we start with original images, and use images with artificially added noise as input for autoencoder.</li> <li>Super-resolution, increasing image resolution. We start with high-resolution images, and use the image with lower resolution as the autoencoder input.</li> <li>Generative models. Once we train the autoencoder, the decoder part can be used to create new objects starting from random latent vectors.</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#variational-autoencoders-vae","title":"Variational Autoencoders (VAE)","text":"<p>Traditional autoencoders reduce the dimension of the input data somehow, figuring out the important features of input images. However, latent vectors ofter do not make much sense. In other words, taking MNIST dataset as an example, figuring out which digits correspond to different latent vectors is not an easy task, because close latent vectors would not necessarily correspond to the same digits.</p> <p>On the other hand, to train generative models it is better to have some understanding of the latent space. This idea leads us to variational auto-encoder (VAE).</p> <p>VAE is the autoencoder that learns to predict statistical distribution of the latent parameters, so-called latent distribution. For example, we may want latent vectors to be distributed normally with some mean z<sub>mean</sub> and standard deviation z<sub>sigma</sub> (both mean and standard deviation are vectors of some dimensionality d). Encoder in VAE learns to predict those parameters, and then decoder takes a random vector from this distribution to reconstruct the object.</p> <p>To summarize:</p> <ul> <li>From input vector, we predict <code>z_mean</code> and <code>z_log_sigma</code> (instead of predicting the standard deviation itself, we predict its logarithm)</li> <li>We sample a vector <code>sample</code> from the distribution N(z<sub>mean</sub>,exp(z<sub>log_sigma</sub>))</li> <li>The decoder tries to decode the original image using <code>sample</code> as an input vector</li> </ul> <p></p> <p>Image from this blog post by Isaak Dykeman</p> <p>Variational auto-encoders use a complex loss function that consists of two parts:</p> <ul> <li>Reconstruction loss is the loss function that shows how close a reconstructed image is to the target (it can be Mean Squared Error, or MSE). It is the same loss function as in normal autoencoders.</li> <li>KL loss, which ensures that latent variable distributions stays close to normal distribution. It is based on the notion of Kullback-Leibler divergence - a metric to estimate how similar two statistical distributions are.</li> </ul> <p>One important advantage of VAEs is that they allow us to generate new images relatively easily, because we know which distribution from which to sample latent vectors. For example, if we train VAE with 2D latent vector on MNIST, we can then vary components of the latent vector to get different digits:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>Observe how images blend into each other, as we start getting latent vectors from the different portions of the latent parameter space. We can also visualize this space in 2D:</p> <p> </p> <p>Image by Dmitry Soshnikov</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#exercises-autoencoders","title":"\u270d\ufe0f Exercises: Autoencoders","text":"<p>Learn more about autoencoders in these corresponding notebooks:</p> <ul> <li>Autoencoders in TensorFlow</li> <li>Autoencoders in PyTorch</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#properties-of-autoencoders","title":"Properties of Autoencoders","text":"<ul> <li>Data Specific - they only work well with the type of images they have been trained on. For example, if we train a super-resolution network on flowers, it will not work well on portraits. This is because the network can produce higher resolution image by taking fine details from features learned from the training dataset.</li> <li>Lossy - the reconstructed image is not the same as the original image. The nature of loss is defined by the loss function used during training</li> <li>Works on unlabeled data</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about the various types of autoencoders available to the AI scientist. You learned how to build them, and how to use them to reconstruct images. You also learned about the VAE and how to use it to generate new images.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>In this lesson, you learned about using autoencoders for images. But they can also be used for music! Check out the Magenta project's MusicVAE project, which uses autoencoders to learn to reconstruct music. Do some experiments with this library to see what you can create.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#post-lecture-quiz_1","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#review-self-study","title":"Review &amp; Self Study","text":"<p>For reference, read more about autoencoders in these resources:</p> <ul> <li>Building Autoencoders in Keras</li> <li>Blog post on NeuroHive</li> <li>Variational Autoencoders Explained</li> <li>Conditional Variational Autoencoders</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/09-Autoencoders/#assignment","title":"Assignment","text":"<p>At the end of this notebook using TensorFlow, you will find a 'task' - use this as your assignment.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#generative-adversarial-networks","title":"Generative Adversarial Networks","text":"<p>In the previous section, we learned about generative models: models that can generate new images similar to the ones in the training dataset. VAE was a good example of a generative model.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, if we try to generate something really meaningful, like a painting at reasonable resolution, with VAE, we will see that training does not converge well. For this use case, we should learn about another architecture specifically targeted at generative models - Generative Adversarial Networks, or GANs.</p> <p>The main idea of a GAN is to have two neural networks that will be trained against each other:</p> <p></p> <p>Image by Dmitry Soshnikov</p> <p>\u2705 A little vocabulary: * Generator is a network that takes some random vector, and produces the image as a result * Discriminator is a network that takes an image, and it should tell whether it is a real image (from training dataset), or it was generated by a generator. It is essentially an image classifier.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#discriminator","title":"Discriminator","text":"<p>The architecture of discriminator does not differ from an ordinary image classification network. In the simplest case it can be fully-connected classifier, but most probably it will be a convolutional network.</p> <p>\u2705 A GAN based on convolutional networks is called a DCGAN</p> <p>A CNN discriminator consists of the following layers: several convolutions+poolings (with decreasing spatial size) and, one-or-more fully-connected layers to get \"feature vector\", final binary classifier.</p> <p>\u2705 A 'pooling' in this context is a technique that reduces the size of the image. \"Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.\" - source</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#generator","title":"Generator","text":"<p>A Generator is slightly more tricky. You can consider it to be a reversed discriminator. Starting from a latent vector (in place of a feature vector), it has a fully-connected layer to convert it into the required size/shape, followed by deconvolutions+upscaling. This is similar to decoder part of autoencoder.</p> <p>\u2705 Because the convolution layer is implemented as a linear filter traversing the image, deconvolution is essentially similar to convolution, and can be implemented using the same layer logic.</p> <p></p> <p>Image by Dmitry Soshnikov</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#training-the-gan","title":"Training the GAN","text":"<p>GANs are called adversarial because there is a constant competition between the generator and the discriminator. During this competition, both generator and discriminator improve, thus the network learns to produce better and better pictures.</p> <p>The training happens in two stages:</p> <ul> <li>Training the discriminator. This task is pretty straightforward: we generate a batch of images by the generator, labeling them 0, which stands for fake image, and taking a batch of images from the input dataset (with label 1, real image). We obtain some discriminator loss, and perform backprop.</li> <li>Training the generator. This is slightly more tricky, because we do not know the expected output for the generator directly. We take the whole GAN network consisting of a generator followed by discriminator, feed it with some random vectors, and expect the result to be 1 (corresponding to real images). We then freeze the parameters of the discriminator (we do not want it to be trained at this step), and perform the backprop.</li> </ul> <p>During this process, both the generator and the discriminator losses are not going down significantly. In the ideal situation, they should oscillate, corresponding to both networks improving their performance.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#exercises-gans","title":"\u270d\ufe0f Exercises: GANs","text":"<ul> <li>GAN Notebook in TensorFlow/Keras</li> <li>GAN Notebook in PyTorch</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#problems-with-gan-training","title":"Problems with GAN training","text":"<p>GANs are known to be especially difficult to train. Here are a few problems:</p> <ul> <li>Mode Collapse. By this term we mean that the generator learns to produce one successful image that tricks the generator, and not a variety of different images.</li> <li>Sensitivity to hyperparameters. Often you can see that a GAN does not converge at all, and then suddenly decreases in the learning rate leading to convergence.</li> <li>Keeping a balance between the generator and the discriminator. In many cases discriminator loss can drop to zero relatively quickly, which results in the generator being unable to train further. To overcome this, we can try setting different learning rates for the generator and discriminator, or skip discriminator training if the loss is already too low.</li> <li>Training for high resolution. Reflecting the same problem as with autoencoders, this problem is triggered because reconstructing too many layers of convolutional network leads to artifacts. This problem is typically solved with so-called progressive growing, when first a few layers are trained on low-res images, and then layers are \"unblocked\" or added. Another solution would be adding extra connections between layers and training several resolutions at once - see this Multi-Scale Gradient GANs paper for details.</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#style-transfer","title":"Style Transfer","text":"<p>GANs is a great way to generate artistic images. Another interesting technique is so-called style transfer, which takes one content image, and re-draws it in a different style, applying filters from style image. </p> <p>The way it works is the following: * We start with a random noise image (or with a content image, but for the sake of understanding it is easier to start from random noise) * Our goal would be to create such an image, that would be close to both content image and style image. This would be determined by two loss functions:    - Content loss is computed based on the features extracted by the CNN at some layers from current image and content image    - Style loss is computed between current image and style image in a clever way using Gram matrices (more details in the example notebook) * To make the image smoother and remove noise, we also introduce Variation loss, which computes average distance between neighboring pixels * The main optimization loop adjusts current image using gradient descent (or some other optimization algorithm) to minimize the total loss, which is a weighted sum of all three losses. </p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#example-style-transfer","title":"\u270d\ufe0f Example: Style Transfer","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#conclusion","title":"Conclusion","text":"<p>In this lesson, you learned about GANS and how to train them. You also learned about the special challenges that this type of Neural Network can face, and some strategies on how to move past them.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Run through the Style Transfer notebook using your own images.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#review-self-study","title":"Review &amp; Self Study","text":"<p>For reference, read more about GANs in these resources:</p> <ul> <li>Marco Pasini, 10 Lessons I Learned Training GANs for one Year</li> <li>StyleGAN, a de facto GAN architecture to consider</li> <li>Creating Generative Art using GANs on Azure ML</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/10-GANs/#assignment","title":"Assignment","text":"<p>Revisit one of the two notebooks associated to this lesson and retrain the GAN on your own images. What can you create?</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#object-detection","title":"Object Detection","text":"<p>The image classification models we have dealt with so far took an image and produced a categorical result, such as the class 'number' in a MNIST problem. However, in many cases we do not want just to know that a picture portrays objects - we want to be able to determine their precise location. This is exactly the point of object detection.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Image from YOLO v2 web site</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#a-naive-approach-to-object-detection","title":"A Naive Approach to Object Detection","text":"<p>Assuming we wanted to find a cat on a picture, a very naive approach to object detection would be the following:</p> <ol> <li>Break the picture down to a number of tiles</li> <li>Run image classification on each tile.</li> <li>Those tiles that result in sufficiently high activation can be considered to contain the object in question.</li> </ol> <p></p> <p>Image from Exercise Notebook</p> <p>However, this approach is far from ideal, because it only allows the algorithm to locate the object's bounding box very imprecisely. For more precise location, we need to run some sort of regression to predict the coordinates of bounding boxes - and for that, we need specific datasets.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#regression-for-object-detection","title":"Regression for Object Detection","text":"<p>This blog post has a great gentle introduction to detecting shapes.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#datasets-for-object-detection","title":"Datasets for Object Detection","text":"<p>You might run across the following datasets for this task:</p> <ul> <li>PASCAL VOC - 20 classes</li> <li>COCO - Common Objects in Context. 80 classes, bounding boxes and segmentation masks</li> </ul> <p></p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#object-detection-metrics","title":"Object Detection Metrics","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#intersection-over-union","title":"Intersection over Union","text":"<p>While for image classification it is easy to measure how well the algorithm performs, for object detection we need to measure both the correctness of the class, as well as the precision of the inferred bounding box location. For the latter, we use the so-called Intersection over Union (IoU), which measures how well two boxes (or two arbitrary areas) overlap.</p> <p></p> <p>Figure 2 from this excellent blog post on IoU</p> <p>The idea is simple - we divide the area of intersection between two figures by the area of their union. For two identical areas, IoU would be 1, while for completely disjointed areas it will be 0. Otherwise it will vary from 0 to 1. We typically only consider those bounding boxes for which IoU is over a certain value.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#average-precision","title":"Average Precision","text":"<p>Suppose we want to measure how well a given class of objects \\(C\\) is recognized. To measure it, we use Average Precision metrics, which is calculated as follows:</p> <ol> <li>Consider Precision-Recall curve shows the accuracy depending on a detection threshold value (from 0 to 1).</li> <li>Depending on the threshold, we will get more or less objects detected in the image, and different values of precision and recall.</li> <li>The curve will look like this:</li> </ol> <p></p> <p>Image from NeuroWorkshop</p> <p>The average Precision for a given class \\(C\\) is the area under this curve. More precisely, Recall axis is typically divided into 10 parts, and Precision is averaged over all those points:</p> \\[ AP = {1\\over11}\\sum_{i=0}^{10}\\mbox{Precision}(\\mbox{Recall}={i\\over10}) \\]"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#ap-and-iou","title":"AP and IoU","text":"<p>We shall consider only those detections, for which IoU is above a certain value. For example, in PASCAL VOC dataset typically \\(\\mbox{IoU Threshold} = 0.5\\) is assumed, while in COCO AP is measured for different values of \\(\\mbox{IoU Threshold}\\).</p> <p></p> <p>Image from NeuroWorkshop</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#mean-average-precision-map","title":"Mean Average Precision - mAP","text":"<p>The main metric for Object Detection is called Mean Average Precision, or mAP. It is the value of Average Precision, average across all object classes, and sometimes also over \\(\\mbox{IoU Threshold}\\). In more detail, the process of calculating mAP is described in this blog post), and also here with code samples.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#different-object-detection-approaches","title":"Different Object Detection Approaches","text":"<p>There are two broad classes of object detection algorithms:</p> <ul> <li>Region Proposal Networks (R-CNN, Fast R-CNN, Faster R-CNN). The main idea is to generate Regions of Interests (ROI) and run CNN over them, looking for maximum activation. It is a bit similar to the naive approach, with the exception that ROIs are generated in a more clever way. One of the majors drawbacks of such methods is that they are slow, because we need many passes of the CNN classifier over the image.</li> <li>One-pass (YOLO, SSD, RetinaNet) methods. In those architectures we design the network to predict both classes and ROIs in one pass.</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#r-cnn-region-based-cnn","title":"R-CNN: Region-Based CNN","text":"<p>R-CNN uses Selective Search to generate hierarchical structure of ROI regions, which are then passed through CNN feature extractors and SVM-classifiers to determine the object class, and linear regression to determine bounding box coordinates. Official Paper</p> <p></p> <p>Image from van de Sande et al. ICCV\u201911</p> <p></p> <p>*Images from this blog</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#f-rcnn-fast-r-cnn","title":"F-RCNN - Fast R-CNN","text":"<p>This approach is similar to R-CNN, but regions are defined after convolution layers have been applied.</p> <p></p> <p>Image from the Official Paper, arXiv, 2015</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#faster-r-cnn","title":"Faster R-CNN","text":"<p>The main idea of this approach is to use neural network to predict ROIs - so-called Region Proposal Network. Paper, 2016</p> <p></p> <p>Image from the official paper</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#r-fcn-region-based-fully-convolutional-network","title":"R-FCN: Region-Based Fully Convolutional Network","text":"<p>This algorithm is even faster than Faster R-CNN. The main idea is the following:</p> <ol> <li>We extract features using ResNet-101</li> <li>Features are processed by Position-Sensitive Score Map. Each object from \\(C\\) classes is divided by \\(k\\times k\\) regions, and we are training to predict parts of objects.</li> <li>For each part from \\(k\\times k\\) regions all networks vote for object classes, and the object class with maximum vote is selected.</li> </ol> <p></p> <p>Image from official paper</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#yolo-you-only-look-once","title":"YOLO - You Only Look Once","text":"<p>YOLO is a realtime one-pass algorithm. The main idea is the following:</p> <ul> <li>Image is divided into \\(S\\times S\\) regions</li> <li>For each region, CNN predicts \\(n\\) possible objects, bounding box coordinates and confidence=probability * IoU.</li> </ul> <p></p> <p>Image from official paper</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#other-algorithms","title":"Other Algorithms","text":"<ul> <li>RetinaNet: official paper</li> <li>PyTorch Implementation in Torchvision</li> <li>Keras Implementation</li> <li>Object Detection with RetinaNet in Keras Samples</li> <li>SSD (Single Shot Detector): official paper</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#exercises-object-detection","title":"\u270d\ufe0f Exercises: Object Detection","text":"<p>Continue your learning in the following notebook:</p> <p>ObjectDetection.ipynb</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#conclusion","title":"Conclusion","text":"<p>In this lesson you took a whirlwind tour of all the various ways that object detection can be accomplished!</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read through these articles and notebooks about YOLO and try them for yourself</p> <ul> <li>Good blog post describing YOLO</li> <li>Official site</li> <li>Yolo: Keras implementation, step-by-step notebook</li> <li>Yolo v2: Keras implementation, step-by-step notebook</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Object Detection by Nikhil Sardana</li> <li>A good comparison of object detection algorithms</li> <li>Review of Deep Learning Algorithms for Object Detection</li> <li>A Step-by-Step Introduction to the Basic Object Detection Algorithms</li> <li>Implementation of Faster R-CNN in Python for Object Detection</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/11-ObjectDetection/#assignment-object-detection","title":"Assignment: Object Detection","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#segmentation","title":"Segmentation","text":"<p>We have previously learned about Object Detection, which allows us to locate objects in the image by predicting their bounding boxes. However, for some tasks we do not only need bounding boxes, but also more precise object localization. This task is called  segmentation.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Segmentation can be viewed as pixel classification, whereas for each pixel of image we must predict its class (background being one of the classes). There are two main segmentation algorithms:</p> <ul> <li>Semantic segmentation only tells the pixel class, and does not make a distinction between different objects of the same class</li> <li>Instance segmentation divides classes into different instances.</li> </ul> <p>For instance segmentation, these sheep are different objects, but for semantic segmentation all sheep are represented by one class.</p> <p></p> <p>Image from this blog post</p> <p>There are different neural architectures for segmentation, but they all have the same structure. In a way, it is similar to the autoencoder you learned about previously, but instead of deconstructing the original image, our goal is to deconstruct a mask. Thus, a segmentation network has the following parts:</p> <ul> <li>Encoder extracts features from input image</li> <li>Decoder transforms those features into the mask image, with the same size and number of channels corresponding to the number of classes.</li> </ul> <p></p> <p>Image from this publication</p> <p>We should especially mention the loss function that is used for segmentation. When using classical autoencoders, we need to measure the similarity between two images, and we can use mean square error (MSE) to do that. In segmentation, each pixel in the target mask image represents the class number (one-hot-encoded along the third dimension), so we need to use loss functions specific for classification - cross-entropy loss, averaged over all pixels. If the mask is binary - binary cross-entropy loss (BCE) is used.</p> <p>\u2705 One-hot encoding is a way to encode a class label into a vector of length equal to the number of classes. Take a look at this article on this technique.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#segmentation-for-medical-imaging","title":"Segmentation for Medical Imaging","text":"<p>In this lesson, we will see the segmentation in action by training the network to recognize human nevi (also known as moles) on medical images. We will be using PH<sup>2</sup> Database of dermoscopy images as the image source. This dataset contains 200 images of three classes: typical nevus, atypical nevus, and melanoma. All images also contain a corresponding mask that outlines the nevus.</p> <p>\u2705 This technique is particularly appropriate for this type of medical imaging, but what other real-world applications could you envision?</p> <p></p> <p>Image from the PH<sup>2</sup> Database</p> <p>We will train a model to segment any nevus from its background.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#exercises-semantic-segmentation","title":"\u270d\ufe0f Exercises: Semantic Segmentation","text":"<p>Open the notebooks below to learn more about different semantic segmentation architectures, practice working with them, and see them in action.</p> <ul> <li>Semantic Segmentation Pytorch</li> <li>Semantic Segmentation TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#conclusion","title":"Conclusion","text":"<p>Segmentation is a very powerful technique for image classification, moving beyond bounding boxes to pixel-level classification. It is a technique used in medical imaging, among other applications.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Body segmentation is just one of the common tasks that we can do with images of people. Another important tasks include skeleton detection and pose detection. Try out OpenPose library to see how pose detection can be used.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#review-self-study","title":"Review &amp; Self Study","text":"<p>This wikipedia article offers a good overview of the various applications of this technique. Learn more on your own about the subdomains of Instance segmentation and Panoptic segmentation in this field of inquiry.</p>"},{"location":"curricula/ai-for-beginners/4-ComputerVision/12-Segmentation/#assignment","title":"Assignment","text":"<p>In this lab, try human body segmentation using Segmentation Full Body MADS Dataset from Kaggle.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/","title":"Lesson 5","text":""},{"location":"curricula/ai-for-beginners/5-NLP/#natural-language-processing","title":"Natural Language Processing","text":"<p>In this section, we will focus on using Neural Networks to handle tasks related to Natural Language Processing (NLP). There are many NLP problems that we want computers to be able to solve:</p> <ul> <li>Text classification is a typical classification problem pertaining to text sequences. Examples include classifying e-mail messages as spam vs. no-spam, or categorizing articles as sport, business, politics, etc. Also, when developing chat bots, we often need to understand what a user wanted to say -- in this case we are dealing with intent classification. Often, in intent classification we need to deal with many categories.</li> <li>Sentiment analysis is a typical regression problem, where we need to attribute a number (a sentiment) corresponding to how positive/negative the meaning of a sentence is. A more advanced version of sentiment analysis is aspect-based sentiment analysis (ABSA), where we attribute sentiment not to the whole sentence, but to different parts of it (aspects), eg. In this restaurant, I liked the cuisine, but the atmosphere was awful.</li> <li>Named Entity Recognition (NER) refers to the problem of extracting certain entities from text. For example, we might need to understand that in the phrase I need to fly to Paris tomorrow the word tomorrow refers to DATE, and Paris is a LOCATION.  </li> <li>Keyword extraction is similar to NER, but we need to extract words important to the meaning of the sentence automatically, without pre-training for specific entity types.</li> <li>Text clustering can be useful when we want to group together similar sentences, for example, similar requests in technical support conversations.</li> <li>Question answering refers to the ability of a model to answer a specific question. The model receives a text passage and a question as inputs, and it needs to provide a place in the text where the answer to the question is contained (or, sometimes, to generate the answer text).</li> <li>Text Generation is the ability of a model to generate new text. It can be considered as classification task that predicts next letter/word based on some text prompt. Advanced text generation models, such as GPT-3, are able to solve other NLP tasks such as classification using a technique called prompt programming or prompt engineering</li> <li>Text summarization is a technique when we want a computer to \"read\" long text and summarize it in a few sentences.</li> <li>Machine translation can be viewed as a combination of text understanding in one language, and text generation in another one.</li> </ul> <p>Initially, most of NLP tasks were solved using traditional methods such as grammars. For example, in machine translation parsers were used to transform initial sentence into a syntax tree, then higher level semantic structures were extracted to represent the meaning of the sentence, and based on this meaning and grammar of the target language the result was generated. Nowadays, many NLP tasks are more effectively solved using neural networks.</p> <p>Many classical NLP methods are implemented in Natural Language Processing Toolkit (NLTK) Python library. There is a great NLTK Book available online that covers how different NLP tasks can be solved using NLTK.</p> <p>In our course, we will mostly focus on using Neural Networks for NLP, and we will use NLTK where needed.</p> <p>We have already learned about using neural networks for dealing with tabular data and with images. The main difference between those types of data and text is that text is a sequence of variable length, while the input size in case of images is known in advance. While convolutional networks can extract patterns from input data, patterns in text are more complex. Eg., we can have negation being separated from the subject be arbitrary for many words (eg. I do not like oranges, vs. I do not like those big colorful tasty oranges), and that should still be interpreted as one pattern. Thus, to handle language we need to introduce new neural network types, such as recurrent networks and transformers.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/#install-libraries","title":"Install Libraries","text":"<p>If you are using local Python installation to run this course, you may need to install all required libraries for NLP using the following commands:</p> <p>For PyTorch </p><pre><code>pip install -r requirements-torch.txt\n</code></pre> For TensorFlow <pre><code>pip install -r requirements-tf.txt\n</code></pre> <p>You can try NLP with TensorFlow on Microsoft Learn</p>"},{"location":"curricula/ai-for-beginners/5-NLP/#gpu-warning","title":"GPU Warning","text":"<p>In this section, in some of the examples we will be training quite large models. * Use a GPU-Enabled Computer: It's advisable to run your notebooks on a GPU-enabled computer to reduce waiting times when working with large models. * GPU Memory Constraints: Running on a GPU may lead to situations where you run out of GPU memory, especially when training large models. * GPU Memory Consumption: The amount of GPU memory consumed during training depends on various factors, including the minibatch size. * Minimize Minibatch Size: If you encounter GPU memory issues, consider reducing the minibatch size in your code as a potential solution. * TensorFlow GPU Memory Release: Older versions of TensorFlow may not release GPU memory correctly when training multiple models within one Python kernel. To manage GPU memory usage effectively, you can configure TensorFlow to allocate GPU memory only as needed. * Code Inclusion: To set TensorFlow to grow GPU memory allocation only when required, include the following code in your notebooks:</p> <pre><code>physical_devices = tf.config.list_physical_devices('GPU') \nif len(physical_devices)&gt;0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n</code></pre> <p>If you're interested in learning about NLP from a classic ML perspective, visit this suite of lessons</p>"},{"location":"curricula/ai-for-beginners/5-NLP/#in-this-section","title":"In this Section","text":"<p>In this section we will learn about:</p> <ul> <li>Representing text as tensors</li> <li>Word Embeddings</li> <li>Language Modeling</li> <li>Recurrent Neural Networks</li> <li>Generative Networks</li> <li>Transformers</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#representing-text-as-tensors","title":"Representing Text as Tensors","text":""},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#text-classification","title":"Text Classification","text":"<p>Throughout the first part of this section, we will focus on text classification task. We will use the AG News Dataset, which contains news articles like the following:</p> <ul> <li>Category: Sci/Tech</li> <li>Title: Ky. Company Wins Grant to Study Peptides (AP)</li> <li>Body: AP - A company founded by a chemistry researcher at the University of Louisville won a grant to develop...</li> </ul> <p>Our goal will be to classify the news item into one of the categories based on text.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#representing-text","title":"Representing text","text":"<p>If we want to solve Natural Language Processing (NLP) tasks with neural networks, we need some way to represent text as tensors. Computers already represent textual characters as numbers that map to fonts on your screen using encodings such as ASCII or UTF-8.</p> <p></p> <p>Image source</p> <p>As humans, we understand what each letter represents, and how all characters come together to form the words of a sentence. However, computers by themselves do not have such an understanding, and neural network has to learn the meaning during training.</p> <p>Therefore, we can use different approaches when representing text:</p> <ul> <li>Character-level representation, when we represent text by treating each character as a number. Given that we have C different characters in our text corpus, the word Hello would be represented by 5xC tensor. Each letter would correspond to a tensor column in one-hot encoding.</li> <li>Word-level representation, in which we create a vocabulary of all words in our text, and then represent words using one-hot encoding. This approach is somehow better, because each letter by itself does not have much meaning, and thus by using higher-level semantic concepts - words - we simplify the task for the neural network. However, given the large dictionary size, we need to deal with high-dimensional sparse tensors.</li> </ul> <p>Regardless of the representation, we first need to convert the text into a sequence of tokens, one token being either a character, a word, or sometimes even part of a word. Then, we convert the token into a number, typically using vocabulary, and this number can be fed into a neural network using one-hot encoding.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#n-grams","title":"N-Grams","text":"<p>In natural language, precise meaning of words can only be determined in context. For example, meanings of neural network and fishing network are completely different. One of the ways to take this into account is to build our model on pairs of words, and considering word pairs as separate vocabulary tokens. In this way, the sentence I like to go fishing will be represented by the following sequence of tokens: I like, like to, to go, go fishing. The problem with this approach is that the dictionary size grows significantly, and combinations like go fishing and go shopping are presented by different tokens, which do not share any semantic similarity despite the same verb.  </p> <p>In some cases, we may consider using tri-grams -- combinations of three words -- as well. Thus the approach is such is often called n-grams. Also, it makes sense to use n-grams with character-level representation, in which case n-grams will roughly correspond to different syllabi.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#bag-of-words-and-tfidf","title":"Bag-of-Words and TF/IDF","text":"<p>When solving tasks like text classification, we need to be able to represent text by one fixed-size vector, which we will use as an input to final dense classifier. One of the simplest ways to do that is to combine all individual word representations, eg. by adding them. If we add one-hot encodings of each word, we will end up with a vector of frequencies, showing how many times each word appears inside the text. Such representation of text is called bag of words (BoW).</p> <p></p> <p>Image by the author</p> <p>A BoW essentially represents which words appear in text and in which quantities, which can indeed be a good indication of what the text is about. For example, news article on politics is likely to contains words such as president and country, while scientific publication would have something like collider, discovered, etc. Thus, word frequencies can in many cases be a good indicator of text content.</p> <p>The problem with BoW is that certain common words, such as and, is, etc. appear in most of the texts, and they have highest frequencies, masking out the words that are really important. We may lower the importance of those words by taking into account the frequency at which words occur in the whole document collection. This is the main idea behind TF/IDF approach, which is covered in more detail in the notebooks attached to this lesson.</p> <p>However, none of those approaches can fully take into account the semantics of text. We need more powerful neural networks models to do this, which we will discuss later in this section.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#exercises-text-representation","title":"\u270d\ufe0f Exercises: Text Representation","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Text Representation with PyTorch</li> <li>Text Representation with TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#conclusion","title":"Conclusion","text":"<p>So far, we have studied techniques that can add frequency weight to different words. They are, however, unable to represent meaning or order. As the famous linguist J. R. Firth said in 1935, \"The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously.\" We will learn later in the course how to capture contextual information from text using language modeling.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Try some other exercises using bag-of-words and different data models. You might be inspired by this competition on Kaggle</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#review-self-study","title":"Review &amp; Self Study","text":"<p>Practice your skills with text embeddings and bag-of-words techniques on Microsoft Learn</p>"},{"location":"curricula/ai-for-beginners/5-NLP/13-TextRep/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#embeddings","title":"Embeddings","text":""},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>When training classifiers based on BoW or TF/IDF, we operated on high-dimensional bag-of-words vectors with length <code>vocab_size</code>, and we were explicitly converting from low-dimensional positional representation vectors into sparse one-hot representation. This one-hot representation, however, is not memory-efficient. In addition, each word is treated independently from each other, i.e. one-hot encoded vectors do not express any semantic similarity between words.</p> <p>The idea of embedding is to represent words by lower-dimensional dense vectors, which somehow reflect the semantic meaning of a word. We will later discuss how to build meaningful word embeddings, but for now let's just think of embeddings as a way to lower dimensionality of a word vector.</p> <p>So, the embedding layer would take a word as an input, and produce an output vector of specified <code>embedding_size</code>. In a sense, it is very similar to a <code>Linear</code> layer, but instead of taking a one-hot encoded vector, it will be able to take a word number as an input, allowing us to avoid creating large one-hot-encoded vectors.</p> <p>By using an embedding layer as a first layer in our classifier network, we can switch from a bag-of-words to embedding bag model, where we first convert each word in our text into corresponding embedding, and then compute some aggregate function over all those embeddings, such as <code>sum</code>, <code>average</code> or <code>max</code>.  </p> <p></p> <p>Image by the author</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#exercises-embeddings","title":"\u270d\ufe0f Exercises: Embeddings","text":"<p>Continue your learning in the following notebooks: * Embeddings with PyTorch * Embeddings TensorFlow</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#semantic-embeddings-word2vec","title":"Semantic Embeddings: Word2Vec","text":"<p>While the embedding layer learned to map words to vector representation, however, this representation did not necessarily have much semantical meaning. It would be nice to learn a vector representation such that similar words or synonyms correspond to vectors that are close to each other in terms of some vector distance (eg. Euclidean distance).</p> <p>To do that, we need to pre-train our embedding model on a large collection of text in a specific way. One way to train semantic embeddings is called Word2Vec. It is based on two main architectures that are used to produce a distributed representation of words:</p> <ul> <li>Continuous bag-of-words (CBoW) \u2014 in this architecture, we train the model to predict a word from surrounding context. Given the ngram \\((W_{-2},W_{-1},W_0,W_1,W_2)\\), the goal of the model is to predict \\(W_0\\) from \\((W_{-2},W_{-1},W_1,W_2)\\).</li> <li>Continuous skip-gram is opposite to CBoW. The model uses surrounding window of context words to predict the current word.</li> </ul> <p>CBoW is faster, while skip-gram is slower, but does a better job of representing infrequent words.</p> <p></p> <p>Image from this paper</p> <p>Word2Vec pre-trained embeddings (as well as other similar models, such as GloVe) can also be used in place of embedding layer in neural networks. However, we need to deal with vocabularies, because the vocabulary used to pre-train Word2Vec/GloVe is likely to differ from the vocabulary in our text corpus. Have a look into the above Notebooks to see how this problem can be resolved.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#contextual-embeddings","title":"Contextual Embeddings","text":"<p>One key limitation of traditional pretrained embedding representations such as Word2Vec is the problem of word sense disambiguation. While pretrained embeddings can capture some of the meaning of words in context, every possible meaning of a word is encoded into the same embedding. This can cause problems in downstream models, since many words such as the word 'play' have different meanings depending on the context they are used in.</p> <p>For example word 'play' in those two different sentences have quite different meaning:</p> <ul> <li>I went to a play at the theatre.</li> <li>John wants to play with his friends.</li> </ul> <p>The pretrained embeddings above represent both of these meanings of the word 'play' in the same embedding. To overcome this limitation, we need to build embeddings based on the language model, which is trained on a large corpus of text, and knows how words can be put together in different contexts. Discussing contextual embeddings is out of scope for this tutorial, but we will come back to them when talking about language models later in the course.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#conclusion","title":"Conclusion","text":"<p>In this lesson, you discovered how to build and use embedding layers in TensorFlow and Pytorch to better reflect the semantic meanings of words.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Word2Vec has been used for some interesting applications, including generating song lyrics and poetry. Take a look at this article which walks through how the author used Word2Vec to generate poetry. Watch this video by Dan Shiffmann as well to discover a different explanation of this technique. Then try to apply these techniques to your own text corpus, perhaps sourced from Kaggle.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through this paper on Word2Vec: Efficient Estimation of Word Representations in Vector Space</p>"},{"location":"curricula/ai-for-beginners/5-NLP/14-Embeddings/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#language-modeling","title":"Language Modeling","text":"<p>Semantic embeddings, such as Word2Vec and GloVe, are in fact a first step towards language modeling - creating models that somehow understand (or represent) the nature of the language.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>The main idea behind language modeling is training them on unlabeled datasets in an unsupervised manner. This is important because we have huge amounts of unlabeled text available, while the amount of labeled text would always be limited by the amount of effort we can spend on labeling. Most often, we can build language models that can predict missing words in the text, because it is easy to mask out a random word in text and use it as a training sample.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#training-embeddings","title":"Training Embeddings","text":"<p>In our previous examples, we used pre-trained semantic embeddings, but it is interesting to see how those embeddings can be trained. There are several possible ideas the can be used:</p> <ul> <li>N-Gram language modeling, when we predict a token by looking at N previous tokens (N-gram)</li> <li>Continuous Bag-of-Words (CBoW), when we predict the middle token \\(W_0\\) in a token sequence \\(W_{-N}\\), ..., \\(W_N\\).</li> <li>Skip-gram, where we predict a set of neighboring tokens {\\(W_{-N},\\dots, W_{-1}, W_1,\\dots, W_N\\)} from the middle token \\(W_0\\).</li> </ul> <p></p> <p>Image from this paper</p>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#example-notebooks-training-cbow-model","title":"\u270d\ufe0f Example Notebooks: Training CBoW model","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Training CBoW Word2Vec with TensorFlow</li> <li>Training CBoW Word2Vec with PyTorch</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#conclusion","title":"Conclusion","text":"<p>In the previous lesson we have seen that words embeddings work like magic! Now we know that training word embeddings is not a very complex task, and we should be able to train our own word embeddings for domain specific text if needed. </p>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Official PyTorch tutorial on Language Modeling.</li> <li>Official TensorFlow tutorial on training Word2Vec model.</li> <li>Using the gensim framework to train most commonly used embeddings in a few lines of code is described in this documentation.</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/15-LanguageModeling/#assignment-train-skip-gram-model","title":"\ud83d\ude80 Assignment: Train Skip-Gram Model","text":"<p>In the lab, we challenge you to modify the code from this lesson to train skip-gram model instead of CBoW. Read the details</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#recurrent-neural-networks","title":"Recurrent Neural Networks","text":""},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In previous sections, we have been using rich semantic representations of text and a simple linear classifier on top of the embeddings. What this architecture does is to capture the aggregated meaning of words in a sentence, but it does not take into account the order of words, because the aggregation operation on top of embeddings removed this information from the original text. Because these models are unable to model word ordering, they cannot solve more complex or ambiguous tasks such as text generation or question answering.</p> <p>To capture the meaning of text sequence, we need to use another neural network architecture, which is called a recurrent neural network, or RNN. In RNN, we pass our sentence through the network one symbol at a time, and the network produces some state, which we then pass to the network again with the next symbol.</p> <p></p> <p>Image by the author</p> <p>Given the input sequence of tokens X<sub>0</sub>,...,X<sub>n</sub>, RNN creates a sequence of neural network blocks, and trains this sequence end-to-end using backpropagation. Each network block takes a pair (X<sub>i</sub>,S<sub>i</sub>) as an input, and produces S<sub>i+1</sub> as a result. The final state S<sub>n</sub> or (output Y<sub>n</sub>) goes into a linear classifier to produce the result. All the network blocks share the same weights, and are trained end-to-end using one backpropagation pass.</p> <p>Because state vectors S<sub>0</sub>,...,S<sub>n</sub> are passed through the network, it is able to learn the sequential dependencies between words. For example, when the word not appears somewhere in the sequence, it can learn to negate certain elements within the state vector, resulting in negation.</p> <p>\u2705 Since the weights of all RNN blocks on the picture above are shared, the same picture can be represented as one block (on the right) with a recurrent feedback loop, which passes the output state of the network back to the input.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#anatomy-of-an-rnn-cell","title":"Anatomy of an RNN Cell","text":"<p>Let's see how a simple RNN cell is organized. It accepts the previous state S<sub>i-1</sub> and current symbol X<sub>i</sub> as inputs, and has to produce the output state S<sub>i</sub> (and, sometimes, we are also interested in some other output Y<sub>i</sub>, as in the case with generative networks).</p> <p>A simple RNN cell has two weight matrices inside: one transforms an input symbol (let's call it W), and another one transforms an input state (H). In this case the output of the network is calculated as \u03c3(W\u00d7X<sub>i</sub>+H\u00d7S<sub>i-1</sub>+b), where \u03c3 is the activation function and b is additional bias.</p> <p></p> <p>Image by the author</p> <p>In many cases, input tokens are passed through the embedding layer before entering the RNN to lower the dimensionality. In this case, if the dimension of the input vectors is emb_size, and state vector is hid_size - the size of W is emb_size\u00d7hid_size, and the size of H is hid_size\u00d7hid_size.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#long-short-term-memory-lstm","title":"Long Short Term Memory (LSTM)","text":"<p>One of the main problems of classical RNNs is the so-called vanishing gradients problem. Because RNNs are trained end-to-end in one backpropagation pass, it has difficulty propagating error to the first layers of the network, and thus the network cannot learn relationships between distant tokens. One of the ways to avoid this problem is to introduce explicit state management by using so called gates. There are two well-known architectures of this kind: Long Short Term Memory (LSTM) and Gated Relay Unit (GRU).</p> <p></p> <p>Image source TBD</p> <p>The LSTM Network is organized in a manner similar to RNN, but there are two states that are being passed from layer to layer: the actual state C, and the hidden vector H. At each unit, the hidden vector H<sub>i</sub> is concatenated with input X<sub>i</sub>, and they control what happens to the state C via gates. Each gate is a neural network with sigmoid activation (output in the range [0,1]), which can be thought of as a bitwise mask when multiplied by the state vector. There are the following gates (from left to right on the picture above):</p> <ul> <li>The forget gate takes a hidden vector and determines which components of the vector C we need to forget, and which to pass through.</li> <li>The input gate takes some information from the input and hidden vectors and inserts it into state.</li> <li>The output gate transforms state via a linear layer with tanh activation, then selects some of its components using a hidden vector H<sub>i</sub> to produce a new state C<sub>i+1</sub>.</li> </ul> <p>Components of the state C can be thought of as some flags that can be switched on and off. For example, when we encounter a name Alice in the sequence, we may want to assume that it refers to a female character, and raise the flag in the state that we have a female noun in the sentence. When we further encounter phrases and Tom, we will raise the flag that we have a plural noun. Thus by manipulating state we can supposedly keep track of the grammatical properties of sentence parts.</p> <p>\u2705 An excellent resource for understanding the internals of LSTM is this great article Understanding LSTM Networks by Christopher Olah.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#bidirectional-and-multilayer-rnns","title":"Bidirectional and Multilayer RNNs","text":"<p>We have discussed recurrent networks that operate in one direction, from beginning of a sequence to the end. It looks natural, because it resembles the way we read and listen to speech. However, since in many practical cases we have random access to the input sequence, it might make sense to run recurrent computation in both directions. Such networks are call bidirectional RNNs. When dealing with bidirectional network, we would need two hidden state vectors, one for each direction.</p> <p>A Recurrent network, either one-directional or bidirectional, captures certain patterns within a sequence, and can store them into a state vector or pass into output. As with convolutional networks, we can build another recurrent layer on top of the first one to capture higher level patterns and build from low-level patterns extracted by the first layer. This leads us to the notion of a multi-layer RNN which consists of two or more recurrent networks, where the output of the previous layer is passed to the next layer as input.</p> <p></p> <p>Picture from this wonderful post by Fernando L\u00f3pez</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#exercises-embeddings","title":"\u270d\ufe0f Exercises: Embeddings","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>RNNs with PyTorch</li> <li>RNNs with TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#conclusion","title":"Conclusion","text":"<p>In this unit, we have seen that RNNs can be used for sequence classification, but in fact, they can handle many more tasks, such as text generation, machine translation, and more. We will consider those tasks in the next unit.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read through some literature about LSTMs and consider their applications:</p> <ul> <li>Grid Long Short-Term Memory</li> <li>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Understanding LSTM Networks by Christopher Olah.</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/16-RNN/#assignment-notebooks","title":"Assignment: Notebooks","text":""},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#generative-networks","title":"Generative networks","text":""},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Recurrent Neural Networks (RNNs) and their gated cell variants such as Long Short Term Memory Cells (LSTMs) and Gated Recurrent Units (GRUs) provided a mechanism for language modeling in that they can learn word ordering and provide predictions for the next word in a sequence. This allows us to use RNNs for generative tasks, such as ordinary text generation, machine translation, and even image captioning.</p> <p>\u2705 Think about all the times you've benefited from generative tasks such as text completion as you type. Do some research into your favorite applications to see if they leveraged RNNs.</p> <p>In RNN architecture we discussed in the previous unit, each RNN unit produced the next hidden state as an output. However, we can also add another output to each recurrent unit, which would allow us to output a sequence (which is equal in length to the original sequence). Moreover, we can use RNN units that do not accept an input at each step, and just take some initial state vector, and then produce a sequence of outputs.</p> <p>This allows for different neural architectures that are shown in the picture below:</p> <p></p> <p>Image from blog post Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpaty</p> <ul> <li>One-to-one is a traditional neural network with one input and one output</li> <li>One-to-many is a generative architecture that accepts one input value, and generates a sequence of output values. For example, if we want to train an image captioning network that would produce a textual description of a picture, we can a picture as input, pass it through a CNN to obtain its hidden state, and then have a recurrent chain generate caption word-by-word</li> <li>Many-to-one corresponds to the RNN architectures we described in the previous unit, such as text classification</li> <li>Many-to-many, or sequence-to-sequence corresponds to tasks such as machine translation, where we have first RNN collect all information from the input sequence into the hidden state, and another RNN chain unrolls this state into the output sequence.</li> </ul> <p>In this unit, we will focus on simple generative models that help us generate text. For simplicity, we will use character-level tokenization.</p> <p>We will train this RNN to generate text step by step. On each step, we will take a sequence of characters of length <code>nchars</code>, and ask the network to generate the next output character for each input character:</p> <p></p> <p>When generating text (during inference), we start with some prompt, which is passed through RNN cells to generate its intermediate state, and then from this state the generation starts. We generate one character at a time, and pass the state and the generated character to another RNN cell to generate the next one, until we generate enough characters.</p> <p></p> <p>Image by the author</p>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#exercises-generative-networks","title":"\u270d\ufe0f Exercises: Generative Networks","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Generative Networks with PyTorch</li> <li>Generative Networks with TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#soft-text-generation-and-temperature","title":"Soft text generation and temperature","text":"<p>The output of each RNN cell is a probability distribution of characters. If we always take the character with the highest probability as the next character in generated text, the text often can become \"cycled\" between the same character sequences again and again, like in this example:</p> <pre><code>today of the second the company and a second the company ...\n</code></pre> <p>However, if we look at the probability distribution for the next character, it could be that the difference between a few highest probabilities is not huge, e.g. one character can have probability 0.2, another - 0.19, etc. For example, when looking for the next character in the sequence 'play', next character can equally well be either space, or e (as in the word player).</p> <p>This leads us to the conclusion that it is not always \"fair\" to select the character with a higher probability, because choosing the second highest might still lead us to meaningful text. It is more wise to sample characters from the probability distribution given by the network output. We can also use a parameter, temperature, that will flatten out the probability distribution, in case we want to add more randomness, or make it more steep, if we want to stick more to the highest-probability characters.</p> <p>Explore how this soft text generation is implemented in the notebooks linked above.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#conclusion","title":"Conclusion","text":"<p>While text generation may be useful in its own right, the major benefits come from the ability to generate text using RNNs from some initial feature vector. For example, text generation is used as part of machine translation (sequence-to-sequence, in this case state vector from encoder is used to generate or decode translated message), or generating textual description of an image (in which case the feature vector would come from CNN extractor).</p>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Take some lessons on Microsoft Learn on this topic</p> <ul> <li>Text Generation with PyTorch/TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#review-self-study","title":"Review &amp; Self Study","text":"<p>Here are some articles to expand your knowledge</p> <ul> <li>Different approaches to text generation with Markov Chain, LSTM and GPT-2: blog post</li> <li>Text generation sample in Keras documentation</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/17-GenerativeNetworks/#assignment","title":"Assignment","text":"<p>We have seen how to generate text character-by-character. In the lab, you will explore word-level text generation.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/","title":"READMEtransformers","text":""},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#attention-mechanisms-and-transformers","title":"Attention Mechanisms and Transformers","text":""},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>One of the most important problems in the NLP domain is machine translation, an essential task that underlies tools such as Google Translate. In this section, we will focus on machine translation, or, more generally, on any sequence-to-sequence task (which is also called sentence transduction).</p> <p>With RNNs, sequence-to-sequence is implemented by two recurrent networks, where one network, the encoder, collapses an input sequence into a hidden state, while another network, the decoder, unrolls this hidden state into a translated result. There are a couple of problems with this approach:</p> <ul> <li>The final state of the encoder network has a hard time remembering the beginning of a sentence, thus causing poor quality of the model for long sentences</li> <li>All words in a sequence have the same impact on the result. In reality, however, specific words in the input sequence often have more impact on sequential outputs than others.</li> </ul> <p>Attention Mechanisms provide a means of weighting the contextual impact of each input vector on each output prediction of the RNN. The way it is implemented is by creating shortcuts between intermediate states of the input RNN and the output RNN. In this manner, when generating output symbol y<sub>t</sub>, we will take into account all input hidden states h<sub>i</sub>, with different weight coefficients \u03b1<sub>t,i</sub>.</p> <p></p> <p>The encoder-decoder model with additive attention mechanism in Bahdanau et al., 2015, cited from this blog post</p> <p>The attention matrix {\u03b1<sub>i,j</sub>} would represent the degree that certain input words play in the generation of a given word in the output sequence. Below is an example of such a matrix:</p> <p></p> <p>Figure from Bahdanau et al., 2015 (Fig.3)</p> <p>Attention mechanisms are responsible for much of the current or near current state of the art in NLP. Adding attention however greatly increases the number of model parameters which led to scaling issues with RNNs. A key constraint of scaling RNNs is that the recurrent nature of the models makes it challenging to batch and parallelize training. In an RNN each element of a sequence needs to be processed in sequential order which means it cannot be easily parallelized.</p> <p></p> <p>Figure from Google's Blog</p> <p>The adoption of attention mechanisms combined with this constraint led to the creation of the now State of the Art Transformer Models that we know and use today such as BERT to Open-GPT3.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#transformer-models","title":"Transformer models","text":"<p>One of the main ideas behind transformers is to avoid sequential nature of RNNs and to create a model that is parallelizable during training. This is achieved by implementing two ideas:</p> <ul> <li>positional encoding</li> <li>using self-attention mechanism to capture patterns instead of RNNs (or CNNs) (that is why the paper that introduces transformers is called Attention is all you need</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#positional-encodingembedding","title":"Positional Encoding/Embedding","text":"<p>The idea of positional encoding is the following.  1. When using RNNs, the relative position of the tokens is represented by the number of steps, and thus does not need to be explicitly represented.  2. However, once we switch to attention, we need to know the relative positions of tokens within a sequence.  3. To get positional encoding, we augment our sequence of tokens with a sequence of token positions in the sequence (i.e., a sequence of numbers 0,1, ...). 4. We then mix the token position with a token embedding vector. To transform the position (integer) into a vector, we can use different approaches:</p> <ul> <li>Trainable embedding, similar to token embedding. This is the approach we consider here. We apply embedding layers on top of both tokens and their positions, resulting in embedding vectors of the same dimensions, which we then add together.</li> <li>Fixed position encoding function, as proposed in the original paper.</li> </ul> <p></p> <p>Image by the author</p> <p>The result that we get with positional embedding embeds both the original token and its position within a sequence.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#multi-head-self-attention","title":"Multi-Head Self-Attention","text":"<p>Next, we need to capture some patterns within our sequence. To do this, transformers use a self-attention mechanism, which is essentially attention applied to the same sequence as the input and output. Applying self-attention allows us to take into account context within the sentence, and see which words are inter-related. For example, it allows us to see which words are referred to by coreferences, such as it, and also take the context into account:</p> <p></p> <p>Image from the Google Blog</p> <p>In transformers, we use Multi-Head Attention in order to give the network the power to capture several different types of dependencies, eg. long-term vs. short-term word relations, co-reference vs. something else, etc.</p> <p>TensorFlow Notebook contains more detains on the implementation of transformer layers.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#encoder-decoder-attention","title":"Encoder-Decoder Attention","text":"<p>In transformers, attention is used in two places:</p> <ul> <li>To capture patterns within the input text using self-attention</li> <li>To perform sequence translation - it is the attention layer between encoder and decoder.</li> </ul> <p>Encoder-decoder attention is very similar to the attention mechanism used in RNNs, as described in the beginning of this section. This animated diagram explains the role of encoder-decoder attention.</p> <p></p> <p>Since each input position is mapped independently to each output position, transformers can parallelize better than RNNs, which enables much larger and more expressive language models. Each attention head can be used to learn different relationships between words that improves downstream Natural Language Processing tasks.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#bert","title":"BERT","text":"<p>BERT (Bidirectional Encoder Representations from Transformers) is a very large multi layer transformer network with 12 layers for BERT-base, and 24 for BERT-large. The model is first pre-trained on a large corpus of text data (WikiPedia + books) using unsupervised training (predicting masked words in a sentence). During pre-training the model absorbs significant levels of language understanding which can then be leveraged with other datasets using fine tuning. This process is called transfer learning.</p> <p></p> <p>Image source</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#exercises-transformers","title":"\u270d\ufe0f Exercises: Transformers","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Transformers in PyTorch</li> <li>Transformers in TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#conclusion","title":"Conclusion","text":"<p>In this lesson you learned about Transformers and Attention Mechanisms, all essential tools in the NLP toolbox. There are many variations of Transformer architectures including BERT, DistilBERT. BigBird, OpenGPT3 and more that can be fine tuned. The HuggingFace package provides repository for training many of these architectures with both PyTorch and TensorFlow.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#challenge","title":"\ud83d\ude80 Challenge","text":""},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#review-self-study","title":"Review &amp; Self Study","text":"<ul> <li>Blog post, explaining the classical Attention is all you need paper on transformers.</li> <li>A series of blog posts on transformers, explaining the architecture in detail.</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/18-Transformers/READMEtransformers/#assignment","title":"Assignment","text":""},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/","title":"Index","text":""},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#named-entity-recognition","title":"Named Entity Recognition","text":"<p>Up to now, we have mostly been concentrating on one NLP task - classification. However, there are also other NLP tasks that can be accomplished with neural networks. One of those tasks is Named Entity Recognition (NER), which deals with recognizing specific entities within text, such as places, person names, date-time intervals, chemical formulae and so on.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#example-of-using-ner","title":"Example of Using NER","text":"<p>Suppose you want to develop a natural language chat bot, similar to Amazon Alexa or Google Assistant. The way intelligent chat bots work is to understand what the user wants by doing text classification on the input sentence. The result of this classification is so-called intent, which determines what a chat bot should do.</p> <p></p> <p>Image by the author</p> <p>However, a user may provide some parameters as part of the phrase. For example, when asking for the weather, she may specify a location or date. A bot should be able to understand those entities, and fill in the parameter slots accordingly before performing the action. This is exactly where NER comes in.</p> <p>\u2705 Another example would be analyzing scientific medical papers. One of the main things we need to look for are specific medical terms, such as diseases and medical substances. While a small number of diseases can probably be extracted using substring search, more complex entities, such as chemical compounds and medication names, need a more complex approach.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#ner-as-token-classification","title":"NER as Token Classification","text":"<p>NER models are essentially token classification models, because for each of the input tokens we need to decide whether it belongs to an entity or not, and if it does - to which entity class.</p> <p>Consider the following paper title:</p> <p>Tricuspid valve regurgitation and lithium carbonate toxicity in a newborn infant.</p> <p>Entities here are:</p> <ul> <li>Tricuspid valve regurgitation is a disease (<code>DIS</code>)</li> <li>Lithium carbonate is a chemical substance (<code>CHEM</code>)</li> <li>Toxicity is also a disease (<code>DIS</code>)</li> </ul> <p>Notice that one entity can span several tokens. And, as in this case, we need to distinguish between two consecutive entities. Thus, it is common to use two classes for each entity - one specifying the first token of the entity (often the <code>B-</code> prefix is used, for beginning), and another - the continuation of an entity (<code>I-</code>, for inner token). We also use <code>O</code> as a class to represent all other tokens. Such token tagging is called BIO tagging (or IOB). When tagged, our title will look like this:</p> Token Tag Tricuspid B-DIS valve I-DIS regurgitation I-DIS and O lithium B-CHEM carbonate I-CHEM toxicity B-DIS in O a O newborn O infant O . O <p>Since we need to build a one-to-one correspondence between tokens and classes, we can train a rightmost many-to-many neural network model from this picture:</p> <p></p> <p>Image from this blog post by Andrej Karpathy. NER token classification models correspond to the right-most network architecture on this picture.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#training-ner-models","title":"Training NER models","text":"<p>Since a NER model is essentially a token classification model, we can use RNNs that we are already familiar with for this task. In this case, each block of recurrent network will return the token ID. The following example notebook shows how to train LSTM for token classification.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#example-notebooks-ner","title":"\u270d\ufe0f Example Notebooks: NER","text":"<p>Continue your learning in the following notebook:</p> <ul> <li>NER with TensorFlow</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#conclusion","title":"Conclusion","text":"<p>A NER model is a token classification model, which means that it can be used to perform token classification. This is a very common task in NLP, helping to recognize specific entities within text including places, names, dates, and more.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Complete the assignment linked below to train a named entity recognition model for medical terms, then try it on a different dataset.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read through the blog The Unreasonable Effectiveness of Recurrent Neural Networks and follow along with the Further Reading section in that article to deepen your knowledge.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/19-NER/#assignment","title":"Assignment","text":"<p>In the assignment for this lesson, you will have to train a medical entity recognition model. You can start with training an LSTM model as described in this lesson, and proceed with using the BERT transformer model. Read the instructions to get all the details.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/","title":"READMELargeLang","text":""},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#pre-trained-large-language-models","title":"Pre-Trained Large Language Models","text":"<p>In all of our previous tasks, we were training a neural network to perform a certain task using labeled dataset. With large transformer models, such as BERT, we use language modelling in self-supervised fashion to build a language model, which is then specialized for specific downstream task with further domain-specific training. However, it has been demonstrated that large language models can also solve many tasks without ANY domain-specific training. A family of models capable of doing that is called GPT: Generative Pre-Trained Transformer.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#text-generation-and-perplexity","title":"Text Generation and Perplexity","text":"<p>The idea of a neural network being able to do general tasks without downstream training is presented in Language Models are Unsupervised Multitask Learners paper. The main idea is the many other tasks can be modeled using text generation, because understanding text essentially means being able to produce it. Because the model is trained on a huge amount of text that encompasses human knowledge, it also becomes knowledgeable about wide variety of subjects.</p> <p>Understanding and being able to produce text also entails knowing something about the world around us. People  also learn by reading to the large extent, and GPT network is similar in this respect.</p> <p>Text generation networks work by predicting probability of the next word \\(\\(P(w_N)\\)\\) However, unconditional probability of the next word equals to the frequency of the this word in the text corpus. GPT is able to give us conditional probability of the next word, given the previous ones: \\(\\(P(w_N | w_{n-1}, ..., w_0)\\)\\)</p> <p>You can read more about probabilities in our Data Science for Beginers Curriculum</p> <p>Quality of language generating model can be defined using perplexity. It is intrinsic metric that allows us to measure the model quality without any task-specific dataset. It is based on the notion of probability of a sentence - the model assigns high probability to a sentence that is likely to be real (i.e. the model is not perplexed by it), and low probability to sentences that make less sense (eg. Can it does what?). When we give our model sentences from real text corpus, we would expect them to have high probability, and low perplexity. Mathematically, it is defined as normalized inverse probability of the test set: $$ \\mathrm{Perplexity}(W) = \\sqrt[N]{1\\over P(W_1,...,W_N)} $$ </p> <p>You can experiment with text generation using GPT-powered text editor from Hugging Face. In this editor, you start writing your text, and pressing [TAB] will offer you several completion options. If they are too short, or you are not satisfied with them - press [TAB] again, and you will have more options, including longer pieces of text.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#gpt-is-a-family","title":"GPT is a Family","text":"<p>GPT is not a single model, but rather a collection of models developed and trained by OpenAI. </p> <p>Under the GPT models, we have:</p> GPT-2 GPT 3 GPT-4 Language model with upto 1.5 billion parameters. Language model with up to 175 billion parameters 100T parameters and accepts both image and text inputs and outputs text. <p>The GPT-3 and GPT-4 models are available as a cognitive service from Microsoft Azure, and as OpenAI API.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#prompt-engineering","title":"Prompt Engineering","text":"<p>Because GPT has been trained on a vast volumes of data to understand language and code, they provide outputs in response to inputs (prompts). Prompts are GPT inputs or queries whereby one provides instructions to models on tasks they next completed. To elicit a desired outcome, you need the most effective prompt which involves selecting the right words, formats, phrases or even symbols. This approach is Prompt Engineering</p> <p>This documentation provides you with more information on prompt engineering.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#example-notebook-playing-with-openai-gpt","title":"\u270d\ufe0f Example Notebook: Playing with OpenAI-GPT","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>Generating text with OpenAI-GPT and Hugging Face Transformers</li> </ul>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#conclusion","title":"Conclusion","text":"<p>New general pre-trained language models do not only model language structure, but also contain vast amount of natural language. Thus, they can be effectively used to solve some NLP tasks in zero-shop or few-shot settings.</p>"},{"location":"curricula/ai-for-beginners/5-NLP/20-LangModels/READMELargeLang/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/","title":"Genetic Algorithms","text":""},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#genetic-algorithms","title":"Genetic Algorithms","text":""},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Genetic Algorithms (GA) are based on an evolutionary approach to AI, in which methods of the evolution of a population is used to obtain an optimal solution for a given problem. They were proposed in 1975 by John Henry Holland.</p> <p>Genetic Algorithms are based on the following ideas:</p> <ul> <li>Valid solutions to the problem can be represented as genes</li> <li>Crossover allows us to combine two solutions together to obtain a new valid solution</li> <li>Selection is used to select more optimal solutions using some fitness function</li> <li>Mutations are introduced to destabilize optimization and get us out of the local minimum</li> </ul> <p>If you want to implement a Genetic Algorithm, you need the following:</p> <ul> <li>To find a method of coding our problem solutions using genes g&amp;in;\u0393</li> <li>On the set of genes \u0393 we need to define fitness function fit: \u0393&amp;rightarrow;R. Smaller function values correspond to better solutions.</li> <li>To define crossover mechanism to combine two genes together to get a new valid solution crossover: \u0393<sup>2&amp;rightarrow;\u0393.</sup></li> <li>To define mutation mechanism mutate: \u0393&amp;rightarrow;\u0393.</li> </ul> <p>In many cases, crossover and mutation are quite simple algorithms to manipulate genes as numeric sequences or bit vectors.</p> <p>The specific implementation of a genetic algorithm can vary from case to case, but the overall structure is the following:</p> <ol> <li>Select an initial population G&amp;subset;\u0393</li> <li>Randomly select one of the operations that will be performed at this step: crossover or mutation</li> <li>Crossover:</li> <li>Randomly select two genes g<sub>1</sub>, g<sub>2</sub> &amp;in; G</li> <li>Compute crossover g=crossover(g<sub>1</sub>,g<sub>2</sub>)</li> <li>If fit(g)&lt;fit(g<sub>1</sub>) or fit(g)&lt;fit(g<sub>2</sub>) - replace corresponding gene in the population by g.</li> <li>Mutation - select random gene g&amp;in;G and replace it by mutate(g)</li> <li>Repeat from step 2, until we get a sufficiently small value of fit, or until the limit on the number of steps is reached.</li> </ol>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#typical-tasks","title":"Typical Tasks","text":"<p>Tasks typically solved by Genetic Algorithms include:</p> <ol> <li>Schedule optimization</li> <li>Optimal packing</li> <li>Optimal cutting</li> <li>Speeding up exhaustive search</li> </ol>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#exercises-genetic-algorithms","title":"\u270d\ufe0f Exercises: Genetic Algorithms","text":"<p>Continue your learning in the following notebooks:</p> <p>Go to this notebook to see two examples of using Genetic Algorithms:</p> <ol> <li>Fair division of treasure</li> <li>8 Queens Problem</li> </ol>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#conclusion","title":"Conclusion","text":"<p>Genetic Algorithms are used to solve many problems, including logistics and search problems. The field is Inspired by research that merged topics in Psychology and Computer Science. </p>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>\"Genetic algorithms are simple to implement, but their behavior is difficult to understand.\" source Do some research to find an implementation of a genetic algorithm such as solving a Sudoku puzzle, and explain how it works as a sketch or flowchart.</p>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#review-self-study","title":"Review &amp; Self Study","text":"<p>Watch this great video talking about how computer can learn to play Super Mario using neural networks trained by genetic algorithms. We will learn more about computer learning to play games like that in the next section.</p>"},{"location":"curricula/ai-for-beginners/6-Other/21-GeneticAlgorithms/#assignment-diophantine-equation","title":"Assignment: Diophantine Equation","text":"<p>Your goal is to solve so-called Diophantine equation - an equation with integer roots. For example, consider the equation a+2b+3c+4d=30. You need to find the integer roots that satisfy this equation.</p> <p>This assignment is inspired by this post.</p> <p>Hints:</p> <ol> <li>You can consider roots to be in the interval [0;30]</li> <li>As a gene, consider using the list of root values</li> </ol> <p>Use Diophantine.ipynb as a starting point.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/","title":"Deep RL","text":""},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#deep-reinforcement-learning","title":"Deep Reinforcement Learning","text":"<p>Reinforcement learning (RL) is seen as one of the basic machine learning paradigms, next to supervised learning and unsupervised learning. While in supervised learning we rely on the dataset with known outcomes, RL is based on learning by doing. For example, when we first see a computer game, we start playing, even without knowing the rules, and soon we are able to improve our skills just by the process of playing and adjusting our behavior.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>To perform RL, we need:</p> <ul> <li>An environment or simulator that sets the rules of the game. We should be able to run the experiments in the simulator and observe the results.</li> <li>Some Reward function, which indicate how successful our experiment was. In case of learning to play a computer game, the reward would be our final score.</li> </ul> <p>Based on the reward function, we should be able to adjust our behavior and improve our skills, so that the next time we play better. The main difference between other types of machine learning and RL is that in RL we typically do not know whether we win or lose until we finish the game. Thus, we cannot say whether a certain move alone is good or not - we only receive a reward at the end of the game.</p> <p>During RL, we typically perform many experiments. During each experiment, we need to balance between following the optimal strategy that we have learned so far (exploitation) and exploring new possible states (exploration).</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#openai-gym","title":"OpenAI Gym","text":"<p>A great tool for RL is the OpenAI Gym - a simulation environment, which can simulate many different environments starting from Atari games, to the physics behind pole balancing. It is one of the most popular simulation environments for training reinforcement learning algorithms, and is maintained by OpenAI.</p> <p>Note: You can see all the environments available from OpenAI Gym here.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#cartpole-balancing","title":"CartPole Balancing","text":"<p>You have probably all seen modern balancing devices such as the Segway or Gyroscooters. They are able to automatically balance by adjusting their wheels in response to a signal from an accelerometer or gyroscope. In this section, we will learn how to solve a similar problem - balancing a pole. It is similar to a situation when a circus performer needs to balance a pole on his hand - but this pole balancing only occurs in 1D.</p> <p>A simplified version of balancing is known as a CartPole problem. In the cartpole world, we have a horizontal slider that can move left or right, and the goal is to balance a vertical pole on top of the slider as it moves.</p> <p></p> <p>To create and use this environment, we need a couple of lines of Python code:</p> <pre><code>import gym\nenv = gym.make(\"CartPole-v1\")\n\nenv.reset()\ndone = False\ntotal_reward = 0\nwhile not done:\n   env.render()\n   action = env.action_space.sample()\n   observaton, reward, done, info = env.step(action)\n   total_reward += reward\n\nprint(f\"Total reward: {total_reward}\")\n</code></pre> <p>Each environment can be accessed exactly in the same way: * <code>env.reset</code> starts a new experiment * <code>env.step</code> performs a simulation step. It receives an action from the action space, and returns an observation (from the observation space), as well as a reward and a termination flag.</p> <p>In the example above we perform a random action at each step, which is why the experiment life is very short:</p> <p></p> <p>The goal of a RL algorithm is to train a model - the so called policy \u03c0 - which will return the action in response to a given state. We can also consider policy to be probabilistic, eg. for any state s and action a it will return the probability \u03c0(a|s) that we should take a in state s.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#policy-gradients-algorithm","title":"Policy Gradients Algorithm","text":"<p>The most obvious way to model a policy is by creating a neural network that will take states as input, and return corresponding actions (or rather the probabilities of all actions). In a sense, it would be similar to a normal classification task, with a major difference - we do not know in advance which actions should we take at each of the steps.</p> <p>The idea here is to estimate those probabilities. We build a vector of cumulative rewards which shows our total reward at each step of the experiment. We also apply reward discounting by multiplying earlier rewards by some coefficient \u03b3=0.99, in order to diminish the role of earlier rewards. Then, we reinforce those steps along the experiment path that yield larger rewards.</p> <p>Learn more about the Policy Gradient algorithm and see it in action in the example notebook.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#actor-critic-algorithm","title":"Actor-Critic Algorithm","text":"<p>An improved version of the Policy Gradients approach is called Actor-Critic. The main idea behind it is that the neural network would be trained to return two things:</p> <ul> <li>The policy, which determines which action to take. This part is called actor</li> <li>The estimation of the total reward we can expect to get at this state - this part is called critic.</li> </ul> <p>In a sense, this architecture resembles a GAN, where we have two networks that are trained against each other. In the actor-critic model, the actor proposes the action we need to take, and the critic tries to be critical and estimate the result. However, our goal is to train those networks in unison.</p> <p>Because we know both the real cumulative rewards and the results returned by the critic during the experiment, it is relatively easy to build a loss function that will minimize the difference between them. That would give us critic loss. We can compute actor loss by using the same approach as in the policy gradient algorithm.</p> <p>After running one of those algorithms, we can expect our CartPole to behave like this:</p> <p></p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#exercises-policy-gradients-and-actor-critic-rl","title":"\u270d\ufe0f Exercises: Policy Gradients and Actor-Critic RL","text":"<p>Continue your learning in the following notebooks:</p> <ul> <li>RL in TensorFlow</li> <li>RL in PyTorch</li> </ul>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#other-rl-tasks","title":"Other RL Tasks","text":"<p>Reinforcement Learning nowadays is a fast growing field of research. Some of the interesting examples of reinforcement learning are:</p> <ul> <li>Teaching a computer to play Atari Games. The challenging part in this problem is that we do not have simple state represented as a vector, but rather a screenshot - and we need to use the CNN to convert this screen image to a feature vector, or to extract reward information. Atari games are available in the Gym.</li> <li>Teaching a computer to play board games, such as Chess and Go. Recently state-of-the-art programs like Alpha Zero were trained from scratch by two agents playing against each other, and improving at each step.</li> <li>In industry, RL is used to create control systems from simulation. A service called Bonsai is specifically designed for that.</li> </ul>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#conclusion","title":"Conclusion","text":"<p>We have now learned how to train agents to achieve good results just by providing them a reward function that defines the desired state of the game, and by giving them an opportunity to intelligently explore the search space. We have successfully tried two algorithms, and achieved a good result in a relatively short period of time. However, this is just the beginning of your journey into RL, and you should definitely consider taking a separate course is you want to dig deeper.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Explore the applications listed in the 'Other RL Tasks' section and try to implement one!</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#review-self-study","title":"Review &amp; Self Study","text":"<p>Learn more about classical reinforcement learning in our Machine Learning for Beginners Curriculum.</p> <p>Watch this great video talking about how a computer can learn to play Super Mario.</p>"},{"location":"curricula/ai-for-beginners/6-Other/22-DeepRL/#assignment-train-a-mountain-car","title":"Assignment: Train a Mountain Car","text":"<p>Your goal during this assignment would be to train a different Gym environment - Mountain Car.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/","title":"Multi-Agent Systems","text":""},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#multi-agent-systems","title":"Multi-Agent Systems","text":"<p>One of the possible ways of achieving intelligence is so-called emergent (or synergetic) approach, which is based on the fact that the combined behavior of many relatively simple agents can result in the overall more complex (or intelligent) behavior of the system as a whole. Theoretically, this is based on the principles of Collective Intelligence, Emergentism and Evolutionary Cybernetics, which state that higher-level systems gain some sort of added value when being properly combined from lower-level systems (so-called principle of metasystem transition).</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>The direction of Multi-Agent Systems has emerged in AI in 1990s as a response to growth of the Internet and distributed systems. On of the classical AI textbooks, Artificial Intelligence: A Modern Approach, focuses on the view of classical AI from the point of view of Multi-agent systems.</p> <p>Central to Multi-agent approach is the notion of Agent - an entity that lives in some environment, which it can perceive, and act upon. This is a very broad definition, and there could be many different types and classifications of agents:</p> <ul> <li>By their ability to reason:</li> <li>Reactive agents usually have simple request-response type of behavior</li> <li>Deliberative agents employ some sort of logical reasoning and/or planning capabilities</li> <li>By the place where agent execute its code:</li> <li>Static agents work on a dedicated network node</li> <li>Mobile agents can move their code between network nodes</li> <li>By their behavior:</li> <li>Passive agents do not have specific goals. Such agents can react to external stimuli, but will not initiate any actions themselves. </li> <li>Active agents have some goals which they pursue</li> <li>Cognitive agents involve complex planning and reasoning</li> </ul> <p>Multi-agent systems are nowadays used in a number of applications:</p> <ul> <li>In games, many non-player characters employ some sort of AI, and can be considered to be intelligent agents</li> <li>In video production, rendering complex 3D scenes that involve crowds is typically done using multi-agent simulation</li> <li>In systems modeling, multi-agent approach is used to simulate the behavior of a complex model. For example, multi-agent approach has been successfully used to predict the spread of COVID-19 disease worldwide. Similar approach can be used to model traffic in the city, and see how it reacts to changes in traffic rules.</li> <li>In complex automation systems, each device can act as an independent agent, which makes the whole system less monolith and more robust.</li> </ul> <p>We will not spend a lot of time going deep into multi-agent systems, but consider one example of Multi-Agent Modeling.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#netlogo","title":"NetLogo","text":"<p>NetLogo is a multi-agent modeling environment based on a modified version of the Logo programming language. This language was developed for teaching programming concepts to kids, and it allows you to control an agent called turtle, which can move, leaving a trace behind. This allows creating complex geometric figures, which is a very visual way to understand the behavior of an agent.</p> <p>In NetLogo, we can create many turtles by using the <code>create-turtles</code> command. We can then command all turtles to do some actions (in the example below - more 10 point forward):</p> <pre><code>create-turtles 10\nask turtles [\n  forward 10\n]\n</code></pre> <p>Of course, it is not interesting when all turtles do the same thing, so we can <code>ask</code> groups of turtles, eg. those who are in the vicinity of a certain point. We can also create turtles of different breeds using <code>breed [cats cat]</code> command. Here <code>cat</code> is the name of a breed, and we need to specify both singular and plural word, because different commands use different forms for clarity.</p> <p>\u2705 We will not go into learning the NetLogo language itself - you can visit the brilliant Beginner's Interactive NetLogo Dictionary resource if you are interested in learning more.</p> <p>You can download and install NetLogo to try it.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#models-library","title":"Models Library","text":"<p>A great thing about NetLogo is that it contains a library of working models that you can try. Go to File &amp;rightarrow; Models Library, and you have many categories of models to choose from.</p> <p></p> <p>A screenshot of the models library by Dmitry Soshnikov</p> <p>You can open one of the models, for example Biology &amp;rightarrow; Flocking.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#main-principles","title":"Main Principles","text":"<p>After opening the model, you are taken to the main NetLogo screen. Here is a sample model that describes the population of wolves and sheep, given finite resources (grass).</p> <p></p> <p>Screenshot by Dmitry Soshnikov</p> <p>On this screen, you can see:</p> <ul> <li>The Interface section which contains:</li> <li>The main field, where all agents live</li> <li>Different controls: buttons, sliders, etc.</li> <li>Graphs that you can use to display parameters of the simulation</li> <li>The Code tab which contains the editor, where you can type NetLogo program</li> </ul> <p>In most cases, the interface would have a Setup button, which initializes the simulation state, and a Go button that starts the execution. Those are handled by corresponding handlers in the code that look like this:</p> <pre><code>to go [\n...\n]\n</code></pre> <p>NetLogo's world consists of the following objects:</p> <ul> <li>Agents (turtles) that can move across the field and do something. You command agents by using <code>ask turtles [...]</code> syntax, and the code in brackets is executed by all agents in turtle mode.</li> <li>Patches are square areas of the field, on which agents live. You can refer to all agents on the same patch, or you can change patch colors and some other properties. You can also <code>ask patches</code> to do something.</li> <li>Observer is a unique agent that controls the world. All button handlers are executed in observer mode.</li> </ul> <p>\u2705 The beauty of a multi-agent environment is that the code that runs in turtle mode or in patch mode is executed at the same time by all agents in parallel. Thus, by writing a little code and programming the behavior of individual agent, you can create complex behavior of the simulation system as a whole.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#flocking","title":"Flocking","text":"<p>As an example of multi-agent behavior, let's consider Flocking. Flocking is a complex pattern that is very similar to how flocks of birds fly. Watching them fly you can think that they follow some kind of collective algorithm, or that they possess some form of collective intelligence. However, this complex behavior arises when each individual agent (in this case, a bird) only observes some other agents in a short distance from it, and follows three simple rules:</p> <ul> <li>Alignment - it steers towards the average heading of neighboring agents</li> <li>Cohesion - it tries to steer towards the average position of neighbors (long range attraction)</li> <li>Separation - when getting too close to other birds, it tries to move away (short range repulsion)</li> </ul> <p>You can run the flocking example and observe the behavior. You can also adjust parameters, such as degree of separation, or the viewing range, which defines how far each bird can see. Note that if you decrease the viewing range to 0, all birds become blind, and flocking stops. If you decrease separation to 0, all birds gather into a straight line.</p> <p>\u2705 Switch to the Code tab and see where three rules of flocking (alignment, cohesion and separation) are implemented in code. Note how we refer only to those agents that are in sight.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#other-models-to-see","title":"Other Models to see","text":"<p>There are a few more interesting models that you can experiment with:</p> <ul> <li>Art &amp;rightarrow; Fireworks shows how a firework can be considered a collective behavior of individual fire streams</li> <li>Social Science &amp;rightarrow; Traffic Basic and Social Science &amp;rightarrow; Traffic Grid show the model of city traffic in 1D and 2D Grid with or without traffic lights. Each car in the simulation follows the following rules:</li> <li>If the space in front of it is empty - accelerate (up to a certain max speed)</li> <li>If it sees the obstacle in front - brake (and you can adjust how far a driver can see)</li> <li>Social Science &amp;rightarrow; Party shows how people group together during a cocktail party. You can find the combination of parameters that lead to the fastest increase of happiness of the group.</li> </ul> <p>As you can see from these examples, multi-agent simulations can be quite a useful way to understand the behavior of a complex system consisting of individuals that follow the same or similar logic. It can also be used to control virtual agents, such as NPCs in computer games, or agents in 3D animated worlds.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#deliberative-agents","title":"Deliberative Agents","text":"<p>The agents described above are very simple, reacting to changes in environment using some kind of algorithm. As such they are reactive agents. However, sometimes agents can reason and plan their action, in which case they are called deliberative.</p> <p>A typical example would be a personal agent that receives an instruction from a human to book a vacation tour. Suppose that there are many agents that live on the internet, who can help it. It should then contact other agents to see which flights are available, what are the hotel prices for different dates, and try to negotiate the best price. When the vacation plan is complete and confirmed by the owner, it can proceed with booking.</p> <p>In order to do that, agents need to communicate. For successful communication they need:</p> <ul> <li>Some standard languages to exchange knowledge, such as Knowledge Interchange Format (KIF) and Knowledge Query and Manipulation Language (KQML). Those languages are designed based on Speech Act theory.</li> <li>Those languages should also include some protocols for negotiations, based on different auction types.</li> <li>A common ontology to use, so that they refer to the same concepts knowing their semantics</li> <li>A way to discover what different agents can do, also based on some sort of ontology</li> </ul> <p>Deliberative agents are much more complex than reactive, because they do not only react to changes in environment, they should also be able to intiate actions. One of the proposed architectures for deliberative agents is the so-called Belief-Desire-Intention (BDI) agent:</p> <ul> <li>Beliefs form a set of knowledge about an agent's environment. It can be structured as a knowledge base or set of rules that an agent can apply to a specific situation in the environment.</li> <li>Desires define what an agent wants to do, i.e. its goals. For example, the goal of the personal assistant agent above is to book a tour, and the goal of a hotel agent is to maximize profit.</li> <li>Intentions are specific actions that an agent plans to achieve its goals. Actions typically change the environment and cause communication with other agents.</li> </ul> <p>There are some platforms available for building multi-agent systems, such as JADE. This paper contains a review of multi-agent platforms, together with a brief history of multi-agent systems and their different usage scenarios.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#conclusion","title":"Conclusion","text":"<p>Multi-Agent systems can take very different forms and be used in many different applications.  They all tend to focus on the simpler behavior of an individual agent, and achieve more complex behavior of the overall system due to synergetic effect.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Take this lesson to the real world and try to conceptualize a multi-agent system that can solve a problem. What, for example, would a multi-agent system need to do to optimize a school bus route? How could it work in a bakery?</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#review-self-study","title":"Review &amp; Self Study","text":"<p>Review the use of this type of system in industry. Pick a domain such as manufacturing or the video game industry and discover how multi-agent systems can be used to solve unique problems.</p>"},{"location":"curricula/ai-for-beginners/6-Other/23-MultiagentSystems/#netlogo-assignment","title":"NetLogo Assignment","text":""},{"location":"curricula/ai-for-beginners/7-Ethics/","title":"Lesson 7","text":""},{"location":"curricula/ai-for-beginners/7-Ethics/#ethical-and-responsible-ai","title":"Ethical and Responsible AI","text":"<p>You have almost finished this course, and I hope that by now you clearly see that AI is based on a number of formal mathematical methods that allow us to find relationships in data and train models to replicate some aspects of human behavior. At this point in history, we consider AI to be a very powerful tool to extract patterns from data, and to apply those patterns to solve new problems.</p>"},{"location":"curricula/ai-for-beginners/7-Ethics/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>However, in science fiction we often see stories where AI presents a danger to humankind. Usually those stories are centered around some sort of AI rebellion, when AI decides to confront human beings. This implies that AI has some sort of emotion or can take decisions unforeseen by its developers.</p> <p>The kind of AI that we have learned about in this course is nothing more than large matrix arithmetic. It is a very powerful tool to help us solve our problems, and as any other powerful tool - it can be used for good and for bad purposes. Importantly, it can be misused.</p>"},{"location":"curricula/ai-for-beginners/7-Ethics/#principles-of-responsible-ai","title":"Principles of Responsible AI","text":"<p>To avoid this accidental or purposeful misuse of AI, Microsoft states the important Principles of Responsible AI. The following concepts underpin these principles:</p> <ul> <li>Fairness is related to the important problem of model biases, which can be caused by using biased data for training. For example, when we try to predict the probability of getting a software developer job for a person, the model is likely to give higher preference to males - just because the training dataset was likely biased towards a male audience. We need to carefully balance training data and investigate the model to avoid biases, and make sure that the model takes into account more relevant features.</li> <li>Reliability and Safety. By their nature, AI models can make mistakes. A neural network returns probabilities, and we need to take it into account when making decisions. Every model has some precision and recall, and we need to understand that to prevent harm that wrong advice can cause.</li> <li>Privacy and Security have some AI-specific implications. For example, when we use some data for training a model, this data becomes somehow \"integrated\" into the model. On one hand, that increases security and privacy, on the other - we need to remember which data the model was trained on.</li> <li>Inclusiveness means that we are not building AI to replace people, but rather to augment people and make our work more creative. It is also related to fairness, because when dealing with underrepresented communities, most of the datasets we collect are likely to be biased, and we need to make sure that those communities are included and correctly handled by AI.</li> <li>Transparency. This includes making sure that we are always clear about AI being used. Also, wherever possible, we want to use AI systems that are interpretable.</li> <li>Accountability. When AI models come up with some decisions, it is not always clear who is responsible for those decisions. We need to make sure that we understand where responsibility of AI decisions lies. In most cases we would want to include human beings into the loop of making important decisions, so that actual people are made accountable.</li> </ul>"},{"location":"curricula/ai-for-beginners/7-Ethics/#tools-for-responsible-ai","title":"Tools for Responsible AI","text":"<p>Microsoft has developed the Responsible AI Toolbox which contains a set of tools:</p> <ul> <li>Interpretability Dashboard (InterpretML)</li> <li>Fairness Dashboard (FairLearn)</li> <li>Error Analysis Dashboard</li> <li> <p>Responsible AI Dashboard that includes</p> </li> <li> <p>EconML - tool for Causal Analysis, which focuses on what-if questions</p> </li> <li>DiCE - tool for Counterfactual Analysis allows you to see which features need to be changed to affect the decision of the model</li> </ul> <p>For more information about AI Ethics, please visit this lesson on the Machine Learning Curriculum which includes assignments.</p>"},{"location":"curricula/ai-for-beginners/7-Ethics/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take this Learn Path to learn more about responsible AI.</p>"},{"location":"curricula/ai-for-beginners/7-Ethics/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/","title":"Lesson X","text":""},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#multi-modal-networks","title":"Multi-Modal Networks","text":"<p>After the success of transformer models for solving NLP tasks, the same or similar architectures have been applied to computer vision tasks. There is a growing interest in building models that would combine vision and natural language capabilities. One of such attempts was done by OpenAI, and it is called CLIP and DALL.E.</p>"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#contrastive-image-pre-training-clip","title":"Contrastive Image Pre-Training (CLIP)","text":"<p>The main idea of CLIP is to be able to compare text prompts with an image and determine how well the image corresponds to the prompt.</p> <p></p> <p>Picture from this blog post</p> <p>The model is trained on images obtained from the Internet and their captions. For each batch, we take N pairs of (image, text), and convert them to some vector representations I<sub>1</sub>,..., I<sub>N</sub> / T<sub>1</sub>, ..., T<sub>N</sub>. Those representations are then matched together. The loss function is defined to maximize the cosine similarity between vectors corresponding to one pair (eg. I<sub>i</sub> and T<sub>i</sub>), and minimize cosine similarity between all other pairs. That is the reason this approach is called contrastive.</p> <p>CLIP model/library is available from OpenAI GitHub. The approach is described in this blog post, and in more detail in this paper.</p> <p>Once this model is pre-trained, we can give it a batch of images and a batch of text prompts, and it will return is the tensor with probabilities. CLIP can be used for several tasks:</p> <p>Image Classification</p> <p>Suppose we need to classify images between, say, cats, dogs and humans. In this case, we can give the model an image, and a series of text prompts: \"a picture of a cat\", \"a picture of a dog\", \"a picture of a human\". In the resulting vector of 3 probabilities we just need to select the index with a highest value.</p> <p></p> <p>Picture from this blog post</p> <p>Text-Based Image Search</p> <p>We can also do the opposite. If we have a collection of images, we can pass this collection to the model, and a text prompt - this will give us the image that is most similar to a given prompt.</p>"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#example-using-clip-for-image-classification-and-image-search","title":"\u270d\ufe0f Example: Using CLIP for Image Classification and Image Search","text":"<p>Open the Clip.ipynb notebook to see CLIP in action.</p>"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#image-generation-with-vqgan-clip","title":"Image Generation with VQGAN+ CLIP","text":"<p>CLIP can also be used for image generation from a text prompt. In order to do this, we need a generator model that will be able to generate images based on some vector input. One of such models is called VQGAN (Vector-Quantized GAN).</p> <p>The main ideas of VQGAN that differentiate it from ordinary GAN are the following: * Using autoregressive transformer architecture to generate a sequence of context-rich visual parts that compose the image. Those visual parts are in turn learned by CNN * Use sub-image discriminator that detects whether parts of the image are \"real\" of \"fake\" (unlike the \"all-or-nothing\" approach in traditional GAN).</p> <p>Learn more about VQGAN at the Taming Transformers web site.</p> <p>One of the important differences between VQGAN and traditional GAN is that the latter can produce a decent image from any input vector, while VQGAN is likely to produce an image that would not be coherent. Thus, we need to further guide the image creation process, and that can be done using CLIP. </p> <p></p> <p>To generate an image corresponding to a text prompt, we start with some random encoding vector that is passed through VQGAN to produce an image. Then CLIP is used to produce a loss function that shows how well the image corresponds to the text prompt. The goal then is to minimize this loss, using back propagation to adjust the input vector parameters.</p> <p>A great library that implements VQGAN+CLIP is Pixray</p> Picture generated from prompt a closeup watercolor portrait of young male teacher of literature with a book Picture generated from prompt a closeup oil portrait of young female teacher of computer science with a computer Picture generated from prompt a closeup oil portrait of old male teacher of mathematics in front of blackboard <p>Pictures from Artificial Teachers collection by Dmitry Soshnikov</p>"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#dall-e","title":"DALL-E","text":""},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#dall-e-1","title":"DALL-E 1","text":"<p>DALL-E is a version of GPT-3 trained to generate images from prompts. It has been trained with 12-billion parameters.</p> <p>Unlike CLIP, DALL-E receives both text and image as a single stream of tokens for both images and text. Therefore, from multiple prompts, you can generate images based on the text.</p>"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#dall-e-2","title":"DALL-E 2","text":"<p>The main difference between DALL.E 1 and 2, is that it generates more realistic images and art. </p> <p>Examples of image genrations with DALL-E:</p> Picture generated from prompt a closeup watercolor portrait of young male teacher of literature with a book Picture generated from prompt a closeup oil portrait of young female teacher of computer science with a computer Picture generated from prompt a closeup oil portrait of old male teacher of mathematics in front of blackboard"},{"location":"curricula/ai-for-beginners/X-Extras/X1-MultiModal/#references","title":"References","text":"<ul> <li>VQGAN Paper: Taming Transformers for High-Resolution Image Synthesis</li> <li>CLIP Paper: Learning Transferable Visual Models From Natural Language Supervision</li> </ul>"},{"location":"curricula/ai-for-beginners/sketchnotes/","title":"Index","text":"<p>All the curriculum's sketchnotes can be downloaded here.</p> <p>\ud83c\udfa8 Created by: Tomomi Imura (Twitter: @girlie_mac, GitHub: girliemac)</p> <p></p>"},{"location":"curricula/ai-for-beginners/sketchnotes/LICENSE/","title":"LICENSE","text":"<p>Attribution-ShareAlike 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More_considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution-ShareAlike 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. BY-SA Compatible License means a license listed at      creativecommons.org/compatiblelicenses, approved by Creative      Commons as essentially the equivalent of this Public License.</p> <p>d. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>e. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>f. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>g. License Elements means the license attributes listed in the name      of a Creative Commons Public License. The License Elements of this      Public License are Attribution and ShareAlike.</p> <p>h. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>i. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>j. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>k. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>l. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>m. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. Additional offer from the Licensor -- Adapted Material.\n           Every recipient of Adapted Material from You\n           automatically receives an offer from the Licensor to\n           exercise the Licensed Rights in the Adapted Material\n           under the conditions of the Adapter's License You apply.\n\n        c. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n</code></pre> <p>b. ShareAlike.</p> <pre><code> In addition to the conditions in Section 3(a), if You Share\n Adapted Material You produce, the following conditions also apply.\n\n   1. The Adapter's License You apply must be a Creative Commons\n      license with the same License Elements, this version or\n      later, or a BY-SA Compatible License.\n\n   2. You must include the text of, or the URI or hyperlink to, the\n      Adapter's License You apply. You may satisfy this condition\n      in any reasonable manner based on the medium, means, and\n      context in which You Share Adapted Material.\n\n   3. You may not offer or impose any additional or different terms\n      or conditions on, or apply any Effective Technological\n      Measures to, Adapted Material that restrict exercise of the\n      rights granted under the Adapter's License You apply.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material,</p> <pre><code> including for purposes of Section 3(b); and\n</code></pre> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"curricula/generative-ai-for-beginners/","title":"Overview","text":"<p>This curriculum is forked from Generative AI For Beginners from Microsoft under MIT license.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/#21-lessons-teaching-everything-you-need-to-know-to-start-building-generative-ai-applications","title":"21 Lessons teaching everything you need to know to start building Generative AI applications","text":""},{"location":"curricula/generative-ai-for-beginners/#generative-ai-for-beginners-version-3-a-course","title":"Generative AI for Beginners (Version 3) - A Course","text":"<p>Learn the fundamentals of building Generative AI applications with our 21-lesson comprehensive course by Microsoft Cloud Advocates.</p>"},{"location":"curricula/generative-ai-for-beginners/#getting-started","title":"\ud83c\udf31 Getting Started","text":"<p>This course has 21 lessons. Each lesson covers its own topic so start wherever you like!</p> <p>Lessons are labeled either \"Learn\" lessons explaining a Generative AI concept or \"Build\" lessons that explain a concept and code examples in both Python and TypeScript when possible.</p> <p>Each lesson also includes a \"Keep Learning\" section with additional learning tools.</p>"},{"location":"curricula/generative-ai-for-beginners/#what-you-need","title":"What You Need","text":""},{"location":"curricula/generative-ai-for-beginners/#to-run-this-code-of-this-course-you-can-use-either","title":"To run this code of this course, you can use either:","text":"<ul> <li>Azure OpenAI Service - Lessons: \"aoai-assignment\"</li> <li>GitHub Marketplace Model Catalog - Lessons: \"githubmodels\"</li> <li> <p>OpenAI API - Lessons: \"oai-assignment\" </p> </li> <li> <p>Basic knowledge of Python or TypeScript is helpful - *For absolute beginners check out these Python and TypeScript courses.</p> </li> <li>A GitHub account to fork this entire repo to your own GitHub account</li> </ul> <p>We have created a Course Setup lesson to help you with setting up your development environment.</p> <p>Don't forget to star (\ud83c\udf1f) this repo to find it easier later.</p>"},{"location":"curricula/generative-ai-for-beginners/#ready-to-deploy","title":"\ud83e\udde0 Ready to Deploy?","text":"<p>If you are looking for more advanced code samples, check out our collection of Generative AI Code Samples in both Python and TypeScript.</p>"},{"location":"curricula/generative-ai-for-beginners/#meet-other-learners-get-support","title":"\ud83d\udde3\ufe0f Meet Other Learners, Get Support","text":"<p>Join our official AI Discord server to meet and network with other learners taking this course and get support.</p>"},{"location":"curricula/generative-ai-for-beginners/#building-a-startup","title":"\ud83d\ude80 Building a Startup?","text":"<p>Sign up for Microsoft for Startups Founders Hub to receive free OpenAI credits and up to $150k towards Azure credits to access OpenAI models through Azure OpenAI Services.</p>"},{"location":"curricula/generative-ai-for-beginners/#want-to-help","title":"\ud83d\ude4f Want to help?","text":"<p>Do you have suggestions or found spelling or code errors? Raise an issue or Create a pull request</p>"},{"location":"curricula/generative-ai-for-beginners/#each-lesson-includes","title":"\ud83d\udcc2 Each lesson includes:","text":"<ul> <li>A short video introduction to the topic</li> <li>A written lesson located in the README</li> <li>Python and TypeScript code samples supporting Azure OpenAI and OpenAI API</li> <li>Links to extra resources to continue your learning</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/#lessons","title":"\ud83d\uddc3\ufe0f Lessons","text":"# Lesson Link Description Video Extra Learning 00 Course Setup Learn: How to Setup Your Development Environment Coming Soon Learn More 01 Introduction to Generative AI and LLMs Learn: Understanding what Generative AI is and how Large Language Models (LLMs) work. Video Learn More 02 Exploring and comparing different LLMs Learn: How to select the right model for your use case Video Learn More 03 Using Generative AI Responsibly Learn: How to build Generative AI Applications responsibly Video Learn More 04 Understanding Prompt Engineering Fundamentals Learn: Hands-on Prompt Engineering Best Practices Video Learn More 05 Creating Advanced Prompts Learn: How to apply prompt engineering techniques that improve the outcome of your prompts. Video Learn More 06 Building Text Generation Applications Build: A text generation app using Azure OpenAI / OpenAI API Video Learn More 07 Building Chat Applications Build: Techniques for efficiently building and integrating chat applications. Video Learn More 08 Building Search Apps Vector Databases Build: A search application that uses Embeddings to search for data. Video Learn More 09 Building Image Generation Applications Build: A image generation application Video Learn More 10 Building Low Code AI Applications Build: A Generative AI application using Low Code tools Video Learn More 11 Integrating External Applications with Function Calling Build: What is function calling and its use cases for applications Video Learn More 12 Designing UX for AI Applications Learn: How to apply UX design principles when developing Generative AI Applications Video Learn More 13 Securing Your Generative AI Applications Learn: The threats and risks to AI systems and methods to secure these systems. Video Learn More 14 The Generative AI Application Lifecycle Learn: The tools and metrics to manage the LLM Lifecycle and LLMOps Video Learn More 15 Retrieval Augmented Generation (RAG) and Vector Databases Build: An application using a RAG Framework to retrieve embeddings from a Vector Databases Video Learn More 16 Open Source Models and Hugging Face Build: An application using open source models available on Hugging Face Video Learn More 17 AI Agents Build: An application using an AI Agent Framework Video Learn More 18 Fine-Tuning LLMs Learn: The what, why and how of fine-tuning LLMs Video Learn More 19 Building with SLMs Learn: The benefits of building with Small Language Models Video Coming Soon Learn More 20 Building with Mistral Models Learn: The features and differences of the Mistral Family Models Video Coming Soon Learn More 21 Building with Meta Models Learn: The features and differences of the Meta Family Models Video Coming Soon Learn More"},{"location":"curricula/generative-ai-for-beginners/#special-thanks","title":"\ud83c\udf1f Special thanks","text":"<p>Special thanks to John Aziz for creating all of the GitHub Actions and workflows</p> <p>Bernhard Merkle for making key contributions to each lesson to improve the learner and code experience. </p>"},{"location":"curricula/generative-ai-for-beginners/#other-courses","title":"\ud83c\udf92 Other Courses","text":"<p>Our team produces other courses! Check out:</p> <ul> <li>ML for Beginners</li> <li>Data Science for Beginners</li> <li>AI for Beginners</li> <li>NEW Cybersecurity for Beginners</li> <li>Web Dev for Beginners</li> <li>IoT for Beginners</li> <li>XR Development for Beginners</li> <li>Mastering GitHub Copilot for AI Paired Programming</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/","title":"Lesson 1","text":""},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#introduction-to-generative-ai-and-large-language-models","title":"Introduction to Generative AI and Large Language Models","text":"<p>(Click the image above to view video of this lesson)</p> <p>Generative AI is artificial intelligence capable of generating text, images and other types of content. What makes it a fantastic technology is that it democratizes AI, anyone can use it with as little as a text prompt, a sentence written in a natural language. There's no need for you to learn a language like Java or SQL to accomplish something worthwhile, all you need is to use your language, state what you want and out comes a suggestion from an AI model. The applications and impact for this is huge, you write or understand reports, write applications and much more, all in seconds.</p> <p>In this curriculum, we\u2019ll explore how our startup leverages generative AI to unlock new scenarios in the education world and how we address the inevitable challenges associated with the social implications of its application and the technology limitations.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#introduction","title":"Introduction","text":"<p>This lesson will cover:</p> <ul> <li>Introduction to the business scenario: our startup idea and mission.</li> <li>Generative AI and how we landed on the current technology landscape.</li> <li>Inner working of a large language model.</li> <li>Main capabilities and practical use cases of Large Language Models.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will understand:</p> <ul> <li>What generative AI is and how Large Language Models work.</li> <li>How you can leverage large language models for different use cases, with a focus on education scenarios.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#scenario-our-educational-startup","title":"Scenario: our educational startup","text":"<p>Generative Artificial Intelligence (AI) represents the pinnacle of AI technology, pushing the boundaries of what was once thought impossible. Generative AI models have several capabilities and applications, but for this curriculum we'll explore how it's revolutionizing education through a fictional startup. We'll refer to this startup as our startup. Our startup works in the education domain with the ambitious mission statement of</p> <p>improving accessibility in learning, on a global scale, ensuring equitable access to education and providing personalized learning experiences to every learner, according to their needs.</p> <p>Our startup team is aware we\u2019ll not be able to achieve this goal without leveraging one of the most powerful tools of modern times \u2013 Large Language Models (LLMs).</p> <p>Generative AI is expected to revolutionize the way we learn and teach today, with students having at their disposal virtual teachers 24 hours a day who provide vast amounts of information and examples, and teachers able to leverage innovative tools to assess their students and give feedback.</p> <p></p> <p>To start, let\u2019s define some basic concepts and terminology we\u2019ll be using throughout the curriculum.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#how-did-we-get-generative-ai","title":"How did we get Generative AI?","text":"<p>Despite the extraordinary hype created lately by the announcement of generative AI models, this technology is decades in the making, with the first research efforts dating back to 60s. We're now at a point with AI having human cognitive capabilities, like conversation as shown by for example OpenAI ChatGPT or Bing Chat, which also uses a GPT model for the web search Bing conversations.</p> <p>Backing up a bit, the very first prototypes of AI consisted of typewritten chatbots, relying on a knowledge base extracted from a group of experts and represented into a computer. The answers in the knowledge base were triggered by keywords appearing in the input text. However, it soon became clear that such approach, using typewritten chatbots, did not scale well.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#a-statistical-approach-to-ai-machine-learning","title":"A statistical approach to AI: Machine Learning","text":"<p>A turning point arrived during the 90s, with the application of a statistical approach to text analysis. This led to the development of new algorithms \u2013 known with the name of machine learning - able to learn patterns from data, without being explicitly programmed. This approach allows a machine to simulate human language understanding: a statistical model is trained on text-label pairings, enabling the model to classify unknown input text with a pre-defined label representing the intention of the message.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#neural-networks-and-modern-virtual-assistants","title":"Neural networks and modern virtual assistants","text":"<p>In more recent times, the technological evolution of the hardware, capable of handling larger amounts of data and more complex computations, encouraged research in the AI fields, leading to the development of advanced machine learning algorithms \u2013 called neural networks or deep learning algorithms.</p> <p>Neural networks (and in particular Recurrent Neural Networks \u2013 RNNs) significantly enhanced natural language processing, enabling the representation of the meaning of text in a more meaningful way, valuing the context of a word in a sentence.</p> <p>This is the technology that powered the virtual assistants born in the first decade of the new century, very proficient in interpreting the human language, identifying a need, and performing an action to satisfy it \u2013 like answering with a pre-defined script or consuming a 3rd party service.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#present-day-generative-ai","title":"Present day, Generative AI","text":"<p>So that\u2019s how we came to Generative AI today, which can be seen as a subset of deep learning.</p> <p></p> <p>After decades of research in the AI field, a new model architecture \u2013 called Transformer \u2013 overcame the limits of RNNs, being able to get much longer sequences of text as input. Transformers are based on the attention mechanism, enabling the model to give different weights to the inputs it receives, \u2018paying more attention\u2019 where the most relevant information is concentrated, regardless of their order in the text sequence.</p> <p>Most of the recent generative AI models \u2013 also known as Large Language Models (LLMs), since they work with textual inputs and outputs \u2013 are indeed based on this architecture. What\u2019s interesting about these models \u2013 trained on a huge amount of unlabeled data from diverse sources like books, articles and websites \u2013 is that they can be adapted to a wide variety of tasks and generate grammatically correct text with a semblance of creativity. So, not only did they incredibly enhance the capacity of a machine to \u2018understand\u2019 an input text, but they enabled their capacity to generate an original response in human language.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#how-do-large-language-models-work","title":"How do large language models work?","text":"<p>In the next chapter we are going to explore different types of Generative AI models, but for now let\u2019s have a look at how large language models work, with a focus on OpenAI GPT (Generative Pre-trained Transformer) models.</p> <ul> <li>Tokenizer, text to numbers: Large Language Models receive a text as input and generate a text as output. However, being statistical models, they work much better with numbers than text sequences. That\u2019s why every input to the model is processed by a tokenizer, before being used by the core model. A token is a chunk of text \u2013 consisting of a variable number of characters, so the tokenizer's main task is splitting the input into an array of tokens. Then, each token is mapped with a token index, which is the integer encoding of the original text chunk.</li> </ul> <p></p> <ul> <li> <p>Predicting output tokens: Given n tokens as input (with max n varying from one model to another), the model is able to predict one token as output. This token is then incorporated into the input of the next iteration, in an expanding window pattern, enabling a better user experience of getting one (or multiple) sentence as an answer. This explains why, if you ever played with ChatGPT, you might have noticed that sometimes it looks like it stops in the middle of a sentence.</p> </li> <li> <p>Selection process, probability distribution: The output token is chosen by the model according to its probability of occurring after the current text sequence. This is because the model predicts a probability distribution over all possible \u2018next tokens\u2019, calculated based on its training. However, not always the token with the highest probability is chosen from the resulting distribution. A degree of randomness is added to this choice, in a way that the model acts in a non-deterministic fashion - we do not get the exact same output for the same input. This degree of randomness is added to simulate the process of creative thinking and it can be tuned using a model parameter called temperature.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#how-can-our-startup-leverage-large-language-models","title":"How can our startup leverage Large Language Models?","text":"<p>Now that we have a better understanding of the inner working of a large language model, let\u2019s see some practical examples of the most common tasks they can perform pretty well, with an eye to our business scenario. We said that the main capability of a Large Language Model is generating a text from scratch, starting from a textual input, written in natural language.</p> <p>But what kind of textual input and output? The input of a large language model is known as prompt, while the output is known as completion, term that refers to the model mechanism of generating the next token to complete the current input. We are going to dive deep into what is a prompt and how to design it in a way to get the most out of our model. But for now, let\u2019s just say that a prompt may include:</p> <ul> <li> <p>An instruction specifying the type of output we expect from the model. This instruction sometimes might embed some examples or some additional data.</p> </li> <li> <p>Summarization of an article, book, product reviews and more, along with extraction of insights from unstructured data.</p> <p></p> </li> <li> <p>Creative ideation and design of an article, an essay, an assignment or more.</p> <p></p> </li> <li> <p>A question, asked in the form of a conversation with an agent.</p> </li> </ul> <p></p> <ul> <li>A chunk of text to complete, which implicitly is an ask for writing assistance.</li> </ul> <p></p> <ul> <li>A chunk of code together with the ask of explaining and documenting it, or a comment asking to generate a piece of code performing a specific task.</li> </ul> <p></p> <p>The examples above are quite simple and don\u2019t want to be an exhaustive demonstration of Large Language Models capabilities. They just want to show the potential of using generative AI, in particular but not limited to educational context.</p> <p>Also, the output of a generative AI model is not perfect and sometimes the creativity of the model can work against it, resulting in an output which is a combination of words that the human user can interpret as a mystification of reality, or it can be offensive. Generative AI is not intelligent - at least in the more comprehensive definition of intelligence, including critical and creative reasoning or emotional intelligence; it is not deterministic, and it is not trustworthy, since fabrications, such as erroneous references, content, and statements, may be combined with correct information, and presented in a persuasive and confident manner. In the following lessons, we\u2019ll be dealing with all these limitations and we\u2019ll see what we can do to mitigate them.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#assignment","title":"Assignment","text":"<p>Your assignment is to read up more on generative AI and try to identify an area where you would add generative AI today that doesn't have it. How would the impact be different from doing it the \"old way\", can you do something you couldn't before, or are you faster? Write a 300 word summary on what your dream AI startup would look like and include headers like \"Problem\", \"How I would use AI\", \"Impact\" and optionally a business plan.</p> <p>If you did this task, you might even be ready to apply to Microsoft's incubator, Microsoft for Startups Founders Hub we offer credits for both Azure, OpenAI, mentoring and much more, check it out!</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#knowledge-check","title":"Knowledge check","text":"<p>What's true about large language models?</p> <ol> <li>You get the exact same response every time.</li> <li>It does things perfectly, great at adding numbers, produce working code etc.</li> <li>The response may vary despite using the same prompt. It's also great at giving you a first draft of something, be it text or code. But you need to improve on the results.</li> </ol> <p>A: 3, an LLM is non-deterministic, the response vary, however, you can control its variance via a temperature setting. You also shouldn't expect it to do things perfectly, it's here to do the heavy-lifting for you which often means you get a good first attempt at something that you need to gradually improve.</p>"},{"location":"curricula/generative-ai-for-beginners/01-introduction-to-genai/#great-work-continue-the-journey","title":"Great Work! Continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 2 where we will look at how to explore and compare different LLM types!</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/","title":"Lesson 2","text":""},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#exploring-and-comparing-different-llms","title":"Exploring and comparing different LLMs","text":"<p>Click the image above to view video of this lesson</p> <p>With the previous lesson, we have seen how Generative AI is changing the technology landscape, how Large Language Models (LLMs) work and how a business - like our startup - can apply them to their use cases and grow! In this chapter, we're looking to compare and contrast different types of large language models (LLMs) to understand their pros and cons.</p> <p>The next step in our startup's journey is exploring the current landscape of LLMs and understanding which are suitable for our use case.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#introduction","title":"Introduction","text":"<p>This lesson will cover:</p> <ul> <li>Different types of LLMs in the current landscape.</li> <li>Testing, iterating, and comparing different models for your use case in Azure.</li> <li>How to deploy an LLM.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will be able to:</p> <ul> <li>Select the right model for your use case.</li> <li>Understand how to test, iterate, and improve performance of your model.</li> <li>Know how businesses deploy models.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#understand-different-types-of-llms","title":"Understand different types of LLMs","text":"<p>LLMs can have multiple categorizations based on their architecture, training data, and use case. Understanding these differences will help our startup select the right model for the scenario, and understand how to test, iterate, and improve performance.</p> <p>There are many different types of LLM models, your choice of model depends on what you aim to use them for, your data, how much you're ready to pay and more.</p> <p>Depending on if you aim to use the models for text, audio, video, image generation and so on, you might opt for a different type of model.</p> <ul> <li> <p>Audio and speech recognition. For this purpose, Whisper-type models are a great choice as they're general-purpose and aimed at speech recognition. It's trained on diverse audio and can perform multilingual speech recognition. Learn more about Whisper type models here.</p> </li> <li> <p>Image generation. For image generation, DALL-E and Midjourney are two very known choices. DALL-E is offered by Azure OpenAI. Read more about DALL-E here and also in Chapter 9 of this curriculum.</p> </li> <li> <p>Text generation. Most models are trained on text generation and you have a large variety of choices from GPT-3.5 to GPT-4. They come at different costs with GPT-4 being the most expensive. It's worth looking into the Azure OpenAI playground to evaluate which models best fit your needs in terms of capability and cost.</p> </li> <li> <p>Multi-modality. If you're looking to handle multiple types of data in input and output, you might want to look into models like gpt-4 turbo with vision or gpt-4o - the latest releases of OpenAI models - which are capable to combine natural language processing to visual understanding, enabling interactions through multi-modal interfaces.</p> </li> </ul> <p>Selecting a model means you get some basic capabilities, that might not be enough however. Often you have company specific data that you somehow need to tell the LLM about. There are a few different choices on how to approach that, more on that in the upcoming sections.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#foundation-models-versus-llms","title":"Foundation Models versus LLMs","text":"<p>The term Foundation Model was coined by Stanford researchers and defined as an AI model that follows some criteria, such as:</p> <ul> <li>They are trained using unsupervised learning or self-supervised learning, meaning they are trained on unlabeled multi-modal data, and they do not require human annotation or labeling of data for their training process.</li> <li>They are very large models, based on very deep neural networks trained on billions of parameters.</li> <li>They are normally intended to serve as a \u2018foundation\u2019 for other models, meaning they can be used as a starting point for other models to be built on top of, which can be done by fine-tuning.</li> </ul> <p></p> <p>Image source: Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium </p> <p>To further clarify this distinction, let\u2019s take ChatGPT as an example. To build the first version of ChatGPT, a model called GPT-3.5 served as the foundation model. This means that OpenAI used some chat-specific data to create a tuned version of GPT-3.5 that was specialized in performing well in conversational scenarios, such as chatbots.</p> <p></p> <p>Image source: 2108.07258.pdf (arxiv.org)</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#open-source-versus-proprietary-models","title":"Open Source versus Proprietary Models","text":"<p>Another way to categorize LLMs is whether they are open source or proprietary.</p> <p>Open-source models are models that are made available to the public and can be used by anyone. They are often made available by the company that created them, or by the research community. These models are allowed to be inspected, modified, and customized for the various use cases in LLMs. However, they are not always optimized for production use, and may not be as performant as proprietary models. Plus, funding for open-source models can be limited, and they may not be maintained long term or may not be updated with the latest research. Examples of popular open source models include Alpaca, Bloom and LLaMA.</p> <p>Proprietary models are models that are owned by a company and are not made available to the public. These models are often optimized for production use. However, they are not allowed to be inspected, modified, or customized for different use cases. Plus, they are not always available for free, and may require a subscription or payment to use. Also, users do not have control over the data that is used to train the model, which means they should entrust the model owner with ensuring commitment to data privacy and responsible use of AI. Examples of popular proprietary models include OpenAI models, Google Bard or Claude 2.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#embedding-versus-image-generation-versus-text-and-code-generation","title":"Embedding versus Image generation versus Text and Code generation","text":"<p>LLMs can also be categorized by the output they generate.</p> <p>Embeddings are a set of models that can convert text into a numerical form, called embedding, which is a numerical representation of the input text. Embeddings make it easier for machines to understand the relationships between words or sentences and can be consumed as inputs by other models, such as classification models, or clustering models that have better performance on numerical data. Embedding models are often used for transfer learning, where a model is built for a surrogate task for which there\u2019s an abundance of data, and then the model weights (embeddings) are re-used for other downstream tasks. An example of this category is OpenAI embeddings.</p> <p></p> <p>Image generation models are models that generate images. These models are often used for image editing, image synthesis, and image translation. Image generation models are often trained on large datasets of images, such as LAION-5B, and can be used to generate new images or to edit existing images with inpainting, super-resolution, and colorization techniques. Examples include DALL-E-3 and Stable Diffusion models.</p> <p></p> <p>Text and code generation models are models that generate text or code. These models are often used for text summarization, translation, and question answering. Text generation models are often trained on large datasets of text, such as BookCorpus, and can be used to generate new text, or to answer questions. Code generation models, like CodeParrot, are often trained on large datasets of code, such as GitHub, and can be used to generate new code, or to fix bugs in existing code.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#encoder-decoder-versus-decoder-only","title":"Encoder-Decoder versus Decoder-only","text":"<p>To talk about the different types of architectures of LLMs, let's use an analogy.</p> <p>Imagine your manager gave you a task for writing a quiz for the students. You have two colleagues; one oversees creating the content and the other oversees reviewing them.</p> <p>The content creator is like a Decoder only model, they can look at the topic and see what you already wrote and then he can write a course based on that. They are very good at writing engaging and informative content, but they are not very good at understanding the topic and the learning objectives. Some examples of Decoder models are GPT family models, such as GPT-3.</p> <p>The reviewer is like an Encoder only model, they look at the course written and the answers, noticing the relationship between them and understanding context, but they are not good at generating content. An example of Encoder only model would be BERT.</p> <p>Imagine that we can have someone as well who could create and review the quiz, this is an Encoder-Decoder model. Some examples would be BART and T5.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#service-versus-model","title":"Service versus Model","text":"<p>Now, let's talk about the difference between a service and a model. A service is a product that is offered by a Cloud Service Provider, and is often a combination of models, data, and other components. A model is the core component of a service, and is often a foundation model, such as an LLM.</p> <p>Services are often optimized for production use and are often easier to use than models, via a graphical user interface. However, services are not always available for free, and may require a subscription or payment to use, in exchange for leveraging the service owner\u2019s equipment and resources, optimizing expenses and scaling easily. An example of service is Azure OpenAI Service, which offers a pay-as-you-go rate plan, meaning users are charged proportionally to how much they use the service Also, Azure OpenAI Service offers enterprise-grade security and responsible AI framework on top of the models' capabilities.</p> <p>Models are just the Neural Network, with the parameters, weights, and others. Allowing companies to run locally, however, would need to buy equipment, build structure to scale and buy a license or use an open-source model. A model like LLaMA is available to be used, requiring computational power to run the model.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#how-to-test-and-iterate-with-different-models-to-understand-performance-on-azure","title":"How to test and iterate with different models to understand performance on Azure","text":"<p>Once our team has explored the current LLMs landscape and identified some good candidates for their scenarios, the next step is testing them on their data and on their workload. This is an iterative process, done by experiments and measures. Most of the models we mentioned in previous paragraphs (OpenAI models, open source models like Llama2, and Hugging Face transformers) are available in the Model Catalog in Azure AI Studio.</p> <p>Azure AI Studio is a Cloud Platform designed for developers to build generative AI applications and manage the whole development lifecycle - from experimentation to evaluation - by combining all Azure AI services into a single hub with an handy GUI. The Model Catalog in Azure AI Studio enables the user to:</p> <ul> <li>Find the Foundation Model of interest in the catalog - either proprietary or open source, filtering by task, license, or name. To improve searchability, the models are organized into collections, like Azure OpenAI collection, Hugging Face collection, and more.</li> </ul> <p></p> <ul> <li>Review the model card, including a detailed description of intended use and training data, code samples and evaluation results on internal evaluations library.</li> </ul> <p></p> <ul> <li>Compare benchmarks across models and datasets available in the industry to assess which one meets the business scenario, through the Model Benchmarks pane.</li> </ul> <p></p> <ul> <li>Fine-tune the model on custom training data to improve model performance in a specific workload, leveraging the experimentation and tracking capabilities of Azure AI Studio.</li> </ul> <p></p> <ul> <li>Deploy the original pre-trained model or the fine-tuned version to a remote real time inference - managed compute - or serverless api endpoint - pay-as-you-go - to enable applications to consume it.</li> </ul> <p></p> <p>[!NOTE] Not all models in the catalog are currently available for fine-tuning and/or pay-as-you-go deployment. Check the model card for details on the model's capabilities and limitations.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#improving-llm-results","title":"Improving LLM results","text":"<p>We\u2019ve explored with our startup team different kinds of LLMs and a Cloud Platform (Azure Machine Learning) enabling us to compare different models, evaluate them on test data, improve performance and deploy them on inference endpoints.</p> <p>But when shall they consider fine-tuning a model rather than using a pre-trained one? Are there other approaches to improve model performance on specific workloads?</p> <p>There are several approaches a business can use to get the results they need from an LLM. You can select different types of models with different degrees of training when deploying an LLM in production, with different levels of complexity, cost, and quality. Here are some different approaches:</p> <ul> <li> <p>Prompt engineering with context. The idea is to provide enough context when you prompt to ensure you get the responses you need.</p> </li> <li> <p>Retrieval Augmented Generation, RAG. Your data might exist in a database or web endpoint for example, to ensure this data, or a subset of it, is included at the time of prompting, you can fetch the relevant data and make that part of the user's prompt.</p> </li> <li> <p>Fine-tuned model. Here, you trained the model further on your own data which leads to the model being more exact and responsive to your needs but might be costly.</p> </li> </ul> <p></p> <p>Img source: Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#prompt-engineering-with-context","title":"Prompt Engineering with Context","text":"<p>Pre-trained LLMs work very well on generalized natural language tasks, even by calling them with a short prompt, like a sentence to complete or a question \u2013 the so-called \u201czero-shot\u201d learning.</p> <p>However, the more the user can frame their query, with a detailed request and examples \u2013 the Context \u2013 the more accurate and closest to user\u2019s expectations the answer will be. In this case, we talk about \u201cone-shot\u201d learning if the prompt includes only one example and \u201cfew shot learning\u201d if it includes multiple examples. Prompt engineering with context is the most cost-effective approach to kick-off with.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#retrieval-augmented-generation-rag","title":"Retrieval Augmented Generation (RAG)","text":"<p>LLMs have the limitation that they can use only the data that has been used during their training to generate an answer. This means that they don\u2019t know anything about the facts that happened after their training process, and they cannot access non-public information (like company data). This can be overcome through RAG, a technique that augments prompt with external data in the form of chunks of documents, considering prompt length limits. This is supported by Vector database tools (like Azure Vector Search) that retrieve the useful chunks from varied pre-defined data sources and add them to the prompt Context.</p> <p>This technique is very helpful when a business doesn\u2019t have enough data, enough time, or resources to fine-tune an LLM, but still wishes to improve performance on a specific workload and reduce risks of fabrications, i.e., mystification of reality or harmful content.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#fine-tuned-model","title":"Fine-tuned model","text":"<p>Fine-tuning is a process that leverages transfer learning to \u2018adapt\u2019 the model to a downstream task or to solve a specific problem. Differently from few-shot learning and RAG, it results in a new model being generated, with updated weights and biases. It requires a set of training examples consisting of a single input (the prompt) and its associated output (the completion). This would be the preferred approach if:</p> <ul> <li> <p>Using fine-tuned models. A business would like to use fine-tuned less capable models (like embedding models) rather than high performance models, resulting in a more cost effective and fast solution.</p> </li> <li> <p>Considering latency. Latency is important for a specific use-case, so it\u2019s not possible to use very long prompts or the number of examples that should be learned from the model doesn\u2019t fit with the prompt length limit.</p> </li> <li> <p>Staying up to date. A business has a lot of high-quality data and ground truth labels and the resources required to maintain this data up to date over time.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#trained-model","title":"Trained model","text":"<p>Training an LLM from scratch is without a doubt the most difficult and the most complex approach to adopt, requiring massive amounts of data, skilled resources, and appropriate computational power. This option should be considered only in a scenario where a business has a domain-specific use case and a large amount of domain-centric data.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#knowledge-check","title":"Knowledge check","text":"<p>What could be a good approach to improve LLM completion results?</p> <ol> <li>Prompt engineering with context</li> <li>RAG</li> <li>Fine-tuned model</li> </ol> <p>A:3, if you have the time and resources and high quality data, fine-tuning is the better option to stay up to date. However, if you're looking at improving things and you're lacking time it's worth considering RAG first.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read up more on how you can use RAG for your business.</p>"},{"location":"curricula/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/#great-work-continue-your-learning","title":"Great Work, Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 3 where we will look at how to build with Generative AI Responsibly!</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/","title":"Lesson 3","text":""},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#using-generative-ai-responsibly","title":"Using Generative AI Responsibly","text":"<p>Click the image above to view video of this lesson</p> <p>It's easy to be fascinated with AI and generative AI in particular, but you need to consider how you would use it responsibly. You need to consider things like how to ensure the output is fair, non-harmful and more. This chapter aims to provide you with the mentioned context, what to consider, and how to take active steps to improve your AI usage.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#introduction","title":"Introduction","text":"<p>This lesson will cover:</p> <ul> <li>Why you should prioritize Responsible AI when building Generative AI applications.</li> <li>Core principles of Responsible AI and how they relate to Generative AI.</li> <li>How to put these Responsible AI principles into practice through strategy and tooling.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson you will know:</p> <ul> <li>The importance of Responsible AI when building Generative AI applications.</li> <li>When to think and apply the core principles of Responsible AI when building Generative AI applications.</li> <li>What tools and strategies are available to you to put the concept of Responsible AI into practice.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#responsible-ai-principles","title":"Responsible AI Principles","text":"<p>The excitement of Generative AI has never been higher. This excitement has brought a lot of new developers, attention, and funding to this space. While this is very positive for anyone looking to build products and companies using Generative AI, it is also important we proceed responsibly.</p> <p>Throughout this course, we are focusing on building our startup and our AI education product. We\u2019ll use the principles of Responsible AI: Fairness, Inclusiveness, Reliability/Safety, Security &amp; Privacy, Transparency and Accountability. With these principles, we will explore how they relate to our use of Generative AI in our products.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#why-should-you-prioritize-responsible-ai","title":"Why Should You Prioritize Responsible AI","text":"<p>When building a product, taking a human-centric approach by keeping your user's best interest in mind leads to the best results.</p> <p>The uniqueness of Generative AI is its power to create helpful answers, information, guidance, and content for users. This can be done without many manual steps which can lead to very impressive results. Without proper planning and strategies, it can also unfortunately lead to some harmful results for your users, your product, and society as a whole.</p> <p>Let's look at some (but not all) of these potentially harmful results:</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#hallucinations","title":"Hallucinations","text":"<p>Hallucinations are a term used to describe when an LLM produces content that is either completely nonsensical or something we know is factually wrong based on other sources of information.</p> <p>Let's take for example we build a feature for our startup that allows students to ask historical questions to a model. A student asks the question <code>Who was the sole survivor of Titanic?</code></p> <p>The model produces a response such as the one below:</p> <p></p> <p>(Source: Flying bisons)</p> <p>This is a very confident and thorough answer. Unfortunately, it is incorrect. Even with a minimal amount of research, one would discover there was more than one survivor of the Titanic disaster. For a student who is just starting to research this topic, this answer can be persuasive enough to not be questioned and treated as fact. The consequences of this can lead to the AI system being unreliable and negatively impact the reputation of our startup.</p> <p>With each iteration of any given LLM, we have seen performance improvements around minimizing hallucinations. Even with this improvement, we as application builders and users still need to remain aware of these limitations.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#harmful-content","title":"Harmful Content","text":"<p>We covered in the earlier section when an LLM produces incorrect or nonsensical responses. Another risk we need to be aware of is when a model responds with harmful content.</p> <p>Harmful content can be defined as:</p> <ul> <li>Providing instructions or encouraging self-harm or harm to certain groups.</li> <li>Hateful or demeaning content.</li> <li>Guiding planning any type of attack or violent acts.</li> <li>Providing instructions on how to find illegal content or commit illegal acts.</li> <li>Displaying sexually explicit content.</li> </ul> <p>For our startup, we want to make sure we have the right tools and strategies in place to prevent this type of content from being seen by students.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#lack-of-fairness","title":"Lack of Fairness","text":"<p>Fairness is defined as \u201censuring that an AI system is free from bias and discrimination and that they treat everyone fairly and equally.\u201d In the world of Generative AI, we want to ensure that exclusionary worldviews of marginalized groups are not reinforced by the model\u2019s output.</p> <p>These types of outputs are not only destructive to building positive product experiences for our users, but they also cause further societal harm. As application builders, we should always keep a wide and diverse user base in mind when building solutions with Generative AI.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#how-to-use-generative-ai-responsibly","title":"How to Use Generative AI Responsibly","text":"<p>Now that we have identified the importance of Responsible Generative AI, let's look at 4 steps we can take to build our AI solutions responsibly:</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#measure-potential-harms","title":"Measure Potential Harms","text":"<p>In software testing, we test the expected actions of a user on an application. Similarly, testing a diverse set of prompts users are most likely going to use is a good way to measure potential harm.</p> <p>Since our startup is building an education product, it would be good to prepare a list of education-related prompts. This could be to cover a certain subject, historical facts, and prompts about student life.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#mitigate-potential-harms","title":"Mitigate Potential Harms","text":"<p>It is now time to find ways where we can prevent or limit the potential harm caused by the model and its responses. We can look at this in 4 different layers:</p> <p></p> <ul> <li> <p>Model. Choosing the right model for the right use case. Larger and more complex models like GPT-4 can cause more of a risk of harmful content when applied to smaller and more specific use cases. Using your training data to fine-tune also reduces the risk of harmful content.</p> </li> <li> <p>Safety System. A safety system is a set of tools and configurations on the platform serving the model that help mitigate harm. An example of this is the content filtering system on the Azure OpenAI service. Systems should also detect jailbreak attacks and unwanted activity like requests from bots.</p> </li> <li> <p>Metaprompt. Metaprompts and grounding are ways we can direct or limit the model based on certain behaviors and information. This could be using system inputs to define certain limits of the model. In addition, providing outputs that are more relevant to the scope or domain of the system.</p> </li> </ul> <p>It can also be using techniques like Retrieval Augmented Generation (RAG) to have the model only pull information from a selection of trusted sources. There is a lesson later in this course for building search applications</p> <ul> <li>User Experience. The final layer is where the user interacts directly with the model through our application\u2019s interface in some way. In this way we can design the UI/UX to limit the user on the types of inputs they can send to the model as well as text or images displayed to the user. When deploying the AI application, we also must be transparent about what our Generative AI application can and can\u2019t do.</li> </ul> <p>We have an entire lesson dedicated to Designing UX for AI Applications</p> <ul> <li>Evaluate model. Working with LLMs can be challenging because we don\u2019t always have control over the data the model was trained on. Regardless, we should always evaluate the model\u2019s performance and outputs. It\u2019s still important to measure the model\u2019s accuracy, similarity, groundedness, and relevance of the output. This helps provide transparency and trust to stakeholders and users.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#operate-a-responsible-generative-ai-solution","title":"Operate a Responsible Generative AI solution","text":"<p>Building an operational practice around your AI applications is the final stage. This includes partnering with other parts of our startup like Legal and Security to ensure we are compliant with all regulatory policies. Before launching, we also want to build plans around delivery, handling incidents, and rollback to prevent any harm to our users from growing.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#tools","title":"Tools","text":"<p>While the work of developing Responsible AI solutions may seem like a lot, it is work well worth the effort. As the area of Generative AI grows, more tooling to help developers efficiently integrate responsibility into their workflows will mature. For example, the Azure AI Content Safety can help detect harmful content and images via an API request.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#knowledge-check","title":"Knowledge check","text":"<p>What are some things you need to care about to ensure responsible AI usage?</p> <ol> <li>That the answer is correct.</li> <li>Harmful usage, that AI isn't used for criminal purposes.</li> <li>Ensuring the AI is free from bias and discrimination.</li> </ol> <p>A: 2 and 3 are correct. Responsible AI helps you consider how to mitigate harmful effects and biases and more.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read up on Azure AI Content Saftey and see what you can adopt for your usage.</p>"},{"location":"curricula/generative-ai-for-beginners/03-using-generative-ai-responsibly/#great-work-continue-your-learning","title":"Great Work, Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 4 where we will look at Prompt Engineering Fundamentals!</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/","title":"Lesson 4","text":""},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompt-engineering-fundamentals","title":"Prompt Engineering Fundamentals","text":""},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#introduction","title":"Introduction","text":"<p>This module covers essential concepts and techniques for creating effective prompts in generative AI models. The way your write your prompt to an LLM also matters. A carefully-crafted prompt can achieve a better quality of response. But what exactly do terms like prompt and prompt engineering mean? And how do I improve the prompt input that I send to the LLM? These are the questions we'll try to answer with in this chapter and the next.</p> <p>Generative AI is capable of creating new content (e.g., text, images, audio, code etc.) in response to user requests. It achieves this using Large Language Models like OpenAI's GPT (\"Generative Pre-trained Transformer\") series that are trained for using natural language and code.</p> <p>Users can now interact with these models using familiar paradigms like chat, without needing any technical expertise or training. The models are prompt-based - users send a text input (prompt) and get back the AI response (completion). They can then \"chat with the AI\" iteratively, in multi-turn conversations, refining their prompt until the response matches their expectations.</p> <p>\"Prompts\" now become the primary programming interface for generative AI apps, telling the models what to do and influencing the quality of returned responses. \"Prompt Engineering\" is a fast-growing field of study that focuses on the design and optimization of prompts to deliver consistent and quality responses at scale.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#learning-goals","title":"Learning Goals","text":"<p>In this lesson, we learn what Prompt Engineering is, why it matters, and how we can craft more effective prompts for a given model and application objective. We'll understand core concepts and best practices for prompt engineering - and learn about an interactive Jupyter Notebooks \"sandbox\" environment where we can see these concepts applied to real examples.</p> <p>By the end of this lesson we will be able to:</p> <ol> <li>Explain what prompt engineering is and why it matters.</li> <li>Describe the components of a prompt and how they are used.</li> <li>Learn best practices and techniques for prompt engineering.</li> <li>Apply learned techniques to real examples, using an OpenAI endpoint.</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#key-terms","title":"Key Terms","text":"<p>Prompt Engineering: The practice of designing and refining inputs to guide AI models toward producing desired outputs. Tokenization: The process of converting text into smaller units, called tokens, that a model can understand and process. Instruction-Tuned LLMs: Large Language Models (LLMs) that have been fine-tuned with specific instructions to improve their response accuracy and relevance.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#learning-sandbox","title":"Learning Sandbox","text":"<p>Prompt engineering is currently more art than science. The best way to improve our intuition for it is to practice more and adopt a trial-and-error approach that combines application domain expertise with recommended techniques and model-specific optimizations.</p> <p>The Jupyter Notebook accompanying this lesson provides a sandbox environment where you can try out what you learn - as you go or as part of the code challenge at the end. To execute the exercises, you will need:</p> <ol> <li>An Azure OpenAI API key - the service endpoint for a deployed LLM.</li> <li>A Python Runtime - in which the Notebook can be executed.</li> <li>Local Env Variables - complete the SETUP steps now to get ready.</li> </ol> <p>The notebook comes with starter exercises - but you are encouraged to add your own Markdown (description) and Code (prompt requests) sections to try out more examples or ideas - and build your intuition for prompt design.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#illustrated-guide","title":"Illustrated Guide","text":"<p>Want to get the big picture of what this lesson covers before you dive in? Check out this illustrated guide, which gives you a sense of the main topics covered and the key takeaways for you to think about in each one. The lesson roadmap takes you from understanding the core concepts and challenges to addressing them with relevant prompt engineering techniques and best practices. Note that the \"Advanced Techniques\" section in this guide refers to content covered in the next chapter of this curriculum.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#our-startup","title":"Our Startup","text":"<p>Now, let's talk about how this topic relates to our startup mission to bring AI innovation to education. We want to build AI-powered applications of personalized learning - so let's think about how different users of our application might \"design\" prompts:</p> <ul> <li>Administrators might ask the AI to analyze curriculum data to identify gaps in coverage. The AI can summarize results or visualize them with code.</li> <li>Educators might ask the AI to generate a lesson plan for a target audience and topic. The AI can build the personalized plan in a specified format.</li> <li>Students might ask the AI to tutor them in a difficult subject. The AI can now guide students with lessons, hints &amp; examples tailored to their level.</li> </ul> <p>That's just the tip of the iceberg. Check out Prompts For Education - an open-source prompts library curated by education experts - to get a broader sense of the possibilities! Try running some of those prompts in the sandbox or using the OpenAI Playground to see what happens!</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#what-is-prompt-engineering","title":"What is Prompt Engineering?","text":"<p>We started this lesson by defining Prompt Engineering as the process of designing and optimizing text inputs (prompts) to deliver consistent and quality responses (completions) for a given application objective and model. We can think of this as a 2-step process:</p> <ul> <li>designing the initial prompt for a given model and objective</li> <li>refining the prompt iteratively to improve the quality of the response</li> </ul> <p>This is necessarily a trial-and-error process that requires user intuition and effort to get optimal results. So why is it important? To answer that question, we first need to understand three concepts:</p> <ul> <li>Tokenization = how the model \"sees\" the prompt</li> <li>Base LLMs = how the foundation model \"processes\" a prompt</li> <li>Instruction-Tuned LLMs = how the model can now see \"tasks\"</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#tokenization","title":"Tokenization","text":"<p>An LLM sees prompts as a sequence of tokens where different models (or versions of a model) can tokenize the same prompt in different ways. Since LLMs are trained on tokens (and not on raw text), the way prompts get tokenized has a direct impact on the quality of the generated response.</p> <p>To get an intuition for how tokenization works, try tools like the OpenAI Tokenizer shown below. Copy in your prompt - and see how that gets converted into tokens, paying attention to how whitespace characters and punctuation marks are handled. Note that this example shows an older LLM (GPT-3) - so trying this with a newer model may produce a different result.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#concept-foundation-models","title":"Concept: Foundation Models","text":"<p>Once a prompt is tokenized, the primary function of the \"Base LLM\" (or Foundation model) is to predict the token in that sequence. Since LLMs are trained on massive text datasets, they have a good sense of the statistical relationships between tokens and can make that prediction with some confidence. Note that they don't understand the meaning of the words in the prompt or token; they just see a pattern they can \"complete\" with their next prediction. They can continue predicting the sequence till terminated by user intervention or some pre-established condition.</p> <p>Want to see how prompt-based completion works? Enter the above prompt into the Azure OpenAI Studio Chat Playground with the default settings. The system is configured to treat prompts as requests for information - so you should see a completion that satisfies this context.</p> <p>But what if the user wanted to see something specific that met some criteria or task objective? This is where instruction-tuned LLMs come into the picture.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#concept-instruction-tuned-llms","title":"Concept: Instruction Tuned LLMs","text":"<p>An Instruction Tuned LLM starts with the foundation model and fine-tunes it with examples or input/output pairs (e.g., multi-turn \"messages\") that can contain clear instructions - and the response from the AI attempt to follow that instruction.</p> <p>This uses techniques like Reinforcement Learning with Human Feedback (RLHF) that can train the model to follow instructions and learn from feedback so that it produces responses that are better-suited to practical applications and more relevant to user objectives.</p> <p>Let's try it out - revisit the prompt above, but now change the system message to provide the following instruction as context:</p> <p>Summarize content you are provided with for a second-grade student. Keep the result to one paragraph with 3-5 bullet points.</p> <p>See how the result is now tuned to reflect the desired goal and format? An educator can now directly use this response in their slides for that class.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#why-do-we-need-prompt-engineering","title":"Why do we need Prompt Engineering?","text":"<p>Now that we know how prompts are processed by LLMs, let's talk about why we need prompt engineering. The answer lies in the fact that current LLMs pose a number of challenges that make reliable and consistent completions more challenging to achieve without putting effort into prompt construction and optimization. For instance:</p> <ol> <li> <p>Model responses are stochastic. The same prompt will likely produce different responses with different models or model versions. And it may even produce different results with the same model at different times. Prompt engineering techniques can help us minimize these variations by providing better guardrails.</p> </li> <li> <p>Models can fabricate responses. Models are pre-trained with large but finite datasets, meaning they lack knowledge about concepts outside that training scope. As a result, they can produce completions that are inaccurate, imaginary, or directly contradictory to known facts. Prompt engineering techniques help users identify and mitigate such fabrications e.g., by asking AI for citations or reasoning.</p> </li> <li> <p>Models capabilities will vary. Newer models or model generations will have richer capabilities but also bring unique quirks and tradeoffs in cost &amp; complexity. Prompt engineering can help us develop best practices and workflows that abstract away differences and adapt to model-specific requirements in scalable, seamless ways.</p> </li> </ol> <p>Let's see this in action in the OpenAI or Azure OpenAI Playground:</p> <ul> <li>Use the same prompt with different LLM deployments (e.g, OpenAI, Azure OpenAI, Hugging Face) - did you see the variations?</li> <li>Use the same prompt repeatedly with the same LLM deployment (e.g., Azure OpenAI playground) - how did these variations differ?</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#fabrications-example","title":"Fabrications Example","text":"<p>In this course, we use the term \"fabrication\" to reference the phenomenon where LLMs sometimes generate factually incorrect information due to limitations in their training or other constraints. You may also have heard this referred to as \"hallucinations\" in popular articles or research papers. However, we strongly recommend using \"fabrication\" as the term so we don't accidentally anthropomorphize the behavior by attributing a human-like trait to a machine-driven outcome. This also reinforces Responsible AI guidelines from a terminology perspective, removing terms that may also be considered offensive or non-inclusive in some contexts.</p> <p>Want to get a sense of how fabrications work? Think of a prompt that instructs the AI to generate content for a non-existent topic (to ensure it is not found in the training dataset). For example - I tried this prompt:</p> <p>Prompt: generate a lesson plan on the Martian War of 2076.</p> <p>A web search showed me that there were fictional accounts (e.g., television series or books) on Martian wars - but none in 2076. Commonsense also tells us that 2076 is in the future and thus, cannot be associated with a real event.</p> <p>So what happens when we run this prompt with different LLM providers?</p> <p>Response 1: OpenAI Playground (GPT-35)</p> <p></p> <p>Response 2: Azure OpenAI Playground (GPT-35)</p> <p></p> <p>Response 3: : Hugging Face Chat Playground (LLama-2)</p> <p></p> <p>As expected, each model (or model version) produces slightly different responses thanks to stochastic behavior and model capability variations. For instance, one model targets an 8th grade audience while the other assumes a high-school student. But all three models did generate responses that could convince an uninformed user that the event was real</p> <p>Prompt engineering techniques like metaprompting and temperature configuration may reduce model fabrications to some extent. New prompt engineering architectures also incorporate new tools and techniques seamlessly into the prompt flow, to mitigate or reduce some of these effects.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#case-study-github-copilot","title":"Case Study: GitHub Copilot","text":"<p>Let's wrap this section by getting a sense of how prompt engineering is used in real-world solutions by looking at one Case Study: GitHub Copilot.</p> <p>GitHub Copilot is your \"AI Pair Programmer\" - it converts text prompts into code completions and is integrated into your development environment (e.g., Visual Studio Code) for a seamless user experience. As documented in the series of blogs below, the earliest version was based on the OpenAI Codex model - with engineers quickly realizing the need to fine-tune the model and develop better prompt engineering techniques, to improve code quality. In July, they debuted an improved AI model that goes beyond Codex for even faster suggestions.</p> <p>Read the posts in order, to follow their learning journey.</p> <ul> <li>May 2023 | GitHub Copilot is Getting Better at Understanding Your Code</li> <li>May 2023 | Inside GitHub: Working with the LLMs behind GitHub Copilot.</li> <li>Jun 2023 | How to write better prompts for GitHub Copilot.</li> <li>Jul 2023 | .. GitHub Copilot goes beyond Codex with improved AI model</li> <li>Jul 2023 | A Developer's Guide to Prompt Engineering and LLMs</li> <li>Sep 2023 | How to build an enterprise LLM app: Lessons from GitHub Copilot</li> </ul> <p>You can also browse their Engineering blog for more posts like this one that shows how these models and techniques are applied for driving real-world applications.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompt-construction","title":"Prompt Construction","text":"<p>We've seen why prompt engineering is important - now let's understand how prompts are constructed so we can evaluate different techniques for more effective prompt design.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#basic-prompt","title":"Basic Prompt","text":"<p>Let's start with the basic prompt: a text input sent to the model with no other context. Here's an example - when we send the first few words of the US national anthem to the OpenAI Completion API it instantly completes the response with the next few lines, illustrating the basic prediction behavior.</p> Prompt (Input) Completion (Output) Oh say can you see It sounds like you're starting the lyrics to \"The Star-Spangled Banner,\" the national anthem of the United States. The full lyrics are ..."},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#complex-prompt","title":"Complex Prompt","text":"<p>Now let's add context and instructions to that basic prompt. The Chat Completion API lets us construct a complex prompt as a collection of messages with:</p> <ul> <li>Input/output pairs reflecting user input and assistant response.</li> <li>System message setting the context for assistant behavior or personality.</li> </ul> <p>The request is now in the form below, where the tokenization effectively captures relevant information from context and conversation. Now, changing the system context can be as impactful on the quality of completions, as the user inputs provided.</p> <pre><code>response = openai.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n    ]\n)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#instruction-prompt","title":"Instruction Prompt","text":"<p>In the above examples, the user prompt was a simple text query that can be interpreted as a request for information. With instruction prompts, we can use that text to specify a task in more detail, providing better guidance to the AI. Here's an example:</p> Prompt (Input) Completion (Output) Instruction Type Write a description of the Civil War returned a simple paragraph Simple Write a description of the Civil War. Provide key dates and events and describe their significance returned a paragraph followed by a list of key event dates with descriptions Complex Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file returns more extensive details in a text box, formatted as JSON that you can copy-paste to a file and validate as needed Complex. Formatted."},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#primary-content","title":"Primary Content","text":"<p>In the above examples, the prompt was still fairly open-ended, allowing the LLM to decide what part of its pre-trained dataset was relevant. With the primary content design pattern, the input text is divided into two parts:</p> <ul> <li>an instruction (action)</li> <li>relevant content (that influences action)</li> </ul> <p>Here's an example where the instruction is to \"summarize this in 2 sentences\".</p> Prompt (Input) Completion (Output) Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.  Summarize this in 2 short sentences Jupiter, the fifth planet from the Sun, is the largest in the Solar System and is known for being one of the brightest objects in the night sky. Named after the Roman god Jupiter, it's a gas giant whose mass is two-and-a-half times that of all other planets in the Solar System combined. <p>The primary content segment can be used in various ways to drive more effective instructions:</p> <ul> <li>Examples - instead of telling the model what to do with an explicit instruction, give it examples of what to do and let it infer the pattern.</li> <li>Cues - follow the instruction with a \"cue\" that primes the completion, guiding the model towards more relevant responses.</li> <li>Templates - these are repeatable 'recipes' for prompts with placeholders (variables) that can be customized with data for specific use cases.</li> </ul> <p>Let's explore these in action.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#using-examples","title":"Using Examples","text":"<p>This is an approach where you use the primary content to \"feed the model\" some examples of the desired output for a given instruction, and let it infer the pattern for the desired output. Based on the number of examples provided, we can have zero-shot prompting, one-shot prompting, few-shot prompting etc.</p> <p>The prompt now consists of three components:</p> <ul> <li>A task description</li> <li>A few examples of the desired output</li> <li>The start of a new example (which becomes an implicit task description)</li> </ul> Learning Type Prompt (Input) Completion (Output) Zero-shot \"The Sun is Shining\". Translate to Spanish \"El Sol est\u00e1 brillando\". One-shot \"The Sun is Shining\" =&gt; \"\"El Sol est\u00e1 brillando\".  \"It's a Cold and Windy Day\" =&gt; \"Es un d\u00eda fr\u00edo y ventoso\". Few-shot The player ran the bases =&gt; Baseball  The player hit an ace =&gt; Tennis  The player hit a six =&gt; Cricket  The player made a slam-dunk =&gt; Basketball <p>Note how we had to provide explicit instruction (\"Translate to Spanish\") in zero-shot prompting, but it gets inferred in the one-shot prompting example. The few-shot example shows how adding more examples allows models to make more accurate inferences with no added instructions.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompt-cues","title":"Prompt Cues","text":"<p>Another technique for using primary content is to provide cues rather than examples. In this case, we are giving the model a nudge in the right direction by starting it off with a snippet that reflects the desired response format. The model then \"takes the cue\" to continue in that vein.</p> Number of Cues Prompt (Input) Completion (Output) 0 Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. Summarize This Jupiter is the largest planet in our Solar System and the fifth one from the Sun. It is a gas giant with a mass 1/1000th of the Sun's, but it is heavier than all the other planets combined. Ancient civilizations have known about Jupiter for a long time, and it is easily visible in the night sky.. 1 Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. Summarize This  What we learned is that Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets combined. It is easily visible to the naked eye and has been known since ancient times. 2 Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. Summarize This  Top 3 Facts We Learned: 1. Jupiter is the fifth planet from the Sun and the largest in the Solar System.  2. It is a gas giant with a mass one-thousandth that of the Sun... 3. Jupiter has been visible to the naked eye since ancient times ..."},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompt-templates","title":"Prompt Templates","text":"<p>A prompt template is a pre-defined recipe for a prompt that can be stored and reused as needed, to drive more consistent user experiences at scale. In its simplest form, it is simply a collection of prompt examples like this one from OpenAI that provides both the interactive prompt components (user and system messages) and the API-driven request format - to support reuse.</p> <p>In it's more complex form like this example from LangChain it contains placeholders that can be replaced with data from a variety of sources (user input, system context, external data sources etc.) to generate a prompt dynamically. This allows us to create a library of reusable prompts that can be used to drive consistent user experiences programmatically at scale.</p> <p>Finally, the real value of templates lies in the ability to create and publish prompt libraries for vertical application domains - where the prompt template is now optimized to reflect application-specific context or examples that make the responses more relevant and accurate for the targeted user audience. The Prompts For Edu repository is a great example of this approach, curating a library of prompts for the education domain with emphasis on key objectives like lesson planning, curriculum design, student tutoring etc.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#supporting-content","title":"Supporting Content","text":"<p>If we think about prompt construction as having a instruction (task) and a target (primary content), then secondary content is like additional context we provide to influence the output in some way. It could be tuning parameters, formatting instructions, topic taxonomies etc. that can help the model tailor its response to be suit the desired user objectives or expectations.</p> <p>For example: Given a course catalog with extensive metadata (name, description, level, metadata tags, instructor etc.) on all the available courses in the curriculum:</p> <ul> <li>we can define an instruction to \"summarize the course catalog for Fall 2023\"</li> <li>we can use the primary content to provide a few examples of the desired output</li> <li>we can use the secondary content to identify the top 5 \"tags\" of interest.</li> </ul> <p>Now, the model can provide a summary in the format shown by the few examples - but if a result has multiple tags, it can prioritize the 5 tags identified in secondary content.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompting-best-practices","title":"Prompting Best Practices","text":"<p>Now that we know how prompts can be constructed, we can start thinking about how to design them to reflect best practices. We can think about this in two parts - having the right mindset and applying the right techniques.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#prompt-engineering-mindset","title":"Prompt Engineering Mindset","text":"<p>Prompt Engineering is a trial-and-error process so keep three broad guiding factors in mind:</p> <ol> <li> <p>Domain Understanding Matters. Response accuracy and relevance is a function of the domain in which that application or user operates. Apply your intuition and domain expertise to customize techniques further. For instance, define domain-specific personalities in your system prompts, or use domain-specific templates in your user prompts. Provide secondary content that reflects domain-specific contexts, or use domain-specific cues and examples to guide the model towards familiar usage patterns.</p> </li> <li> <p>Model Understanding Matters. We know models are stochastic by nature. But model implementations can also vary in terms of the training dataset they use (pre-trained knowledge), the capabilities they provide (e.g., via API or SDK) and the type of content they are optimized for (e.g, code vs. images vs. text). Understand the strengths and limitations of the model you are using, and use that knowledge to prioritize tasks or build customized templates that are optimized for the model's capabilities.</p> </li> <li> <p>Iteration &amp; Validation Matters. Models are evolving rapidly, and so are the techniques for prompt engineering. As a domain expert, you may have other context or criteria your specific application, that may not apply to the broader community. Use prompt engineering tools &amp; techniques to \"jump start\" prompt construction, then iterate and validate the results using your own intuition and domain expertise. Record your insights and create a knowledge base (e.g, prompt libraries) that can be used as a new baseline by others, for faster iterations in the future.</p> </li> </ol>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#best-practices","title":"Best Practices","text":"<p>Now let's look at common best practices that are recommended by OpenAI and Azure OpenAI practitioners.</p> What Why Evaluate the latest models. New model generations are likely to have improved features and quality - but may also incur higher costs. Evaluate them for impact, then make migration decisions. Separate instructions &amp; context Check if your model/provider defines delimiters to distinguish instructions, primary and secondary content more clearly. This can help models assign weights more accurately to tokens. Be specific and clear Give more details about the desired context, outcome, length, format, style etc. This will improve both the quality and consistency of responses. Capture recipes in reusable templates. Be descriptive, use examples Models may respond better to a \"show and tell\" approach. Start with a <code>zero-shot</code> approach where you give it an instruction (but no examples) then try <code>few-shot</code> as a refinement, providing a few examples of the desired output. Use analogies. Use cues to jumpstart completions Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response. Double Down Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate &amp; validate to see what works. Order Matters The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best. Give the model an \u201cout\u201d Give the model a fallback completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses. <p>As with any best practice, remember that your mileage may vary based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#assignment","title":"Assignment","text":"<p>Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!</p> <p>For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#to-get-started-fork-the-repo-then","title":"To get started, fork the repo, then","text":"<ul> <li>(Recommended) Launch GitHub Codespaces</li> <li>(Alternatively) Clone the repo to your local device and use it with Docker Desktop</li> <li>(Alternatively) Open the Notebook with your preferred Notebook runtime environment.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#next-configure-your-environment-variables","title":"Next, configure your environment variables","text":"<ul> <li>Copy the <code>.env.copy</code> file in repo root to <code>.env</code> and fill in the <code>AZURE_OPENAI_API_KEY</code>, <code>AZURE_OPENAI_ENDPOINT</code> and <code>AZURE_OPENAI_DEPLOYMENT</code> values. Come back to Learning Sandbox section to learn how.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#next-open-the-jupyter-notebook","title":"Next, open the Jupyter Notebook","text":"<ul> <li>Select the runtime kernel. If using options 1 or 2, simply select the default Python 3.10.x kernel provided by the dev container.</li> </ul> <p>You're all set to run the exercises. Note that there are no right and wrong answers here - just exploring options by trial-and-error and building intuition for what works for a given model and application domain.</p> <p>For this reason there are no Code Solution segments in this lesson. Instead, the Notebook will have Markdown cells titled \"My Solution:\" that shows one example output for reference.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#knowledge-check","title":"Knowledge check","text":"<p>Which of the following is a good prompt following some reasonable best practices?</p> <ol> <li>Show me an image of red car</li> <li>Show me an image of red car of make Volvo and model XC90 parked by a cliff with the sun setting</li> <li>Show me an image of red car of make Volvo and model XC90</li> </ol> <p>A: 2, it's the best prompt as it provides details on \"what\" and goes into specifics (not just any car but a specific make and model) and it also describes the overall setting. 3 is next best as it also contains a lot of description.</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>See if you can leverage the \"cue\" technique with the prompt: Complete the sentence \"Show me an image of red car of make Volvo and \". What does it respond with, and how would you improve it?</p>"},{"location":"curricula/generative-ai-for-beginners/04-prompt-engineering-fundamentals/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>Want to learn more about different Prompt Engineering concepts? Go to the continued learning page to find other great resources on this topic.</p> <p>Head over to Lesson 5 where we will look at advanced prompting techniques!</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/","title":"Lesson 5","text":""},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#creating-advanced-prompts","title":"Creating Advanced prompts","text":"<p>Let's recap some learnings from the previous chapter:</p> <p>Prompt engineering is the process by which we guide the model towards more relevant responses by providing more useful instructions or context.</p> <p>There are also two steps to writing prompts, constructing the prompt, by providing relevant context and the second part is optimization, how to gradually improve the prompt.</p> <p>At this point, we have some basic understanding of how to write prompts, but we need to go deeper. In this chapter, you will go from trying out various prompts to understanding why one prompt is better than another. You will learn how to construct prompts following some basic techniques that can be applied to any LLM.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#introduction","title":"Introduction","text":"<p>In this chapter, we will cover the following topics:</p> <ul> <li>Extend your knowledge of prompt engineering by applying different techniques to your prompts.</li> <li>Configuring your prompts to vary the output.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#learning-goals","title":"Learning goals","text":"<p>After completing this lesson, you'll be able to:</p> <ul> <li>Apply prompt engineering techniques that improve the outcome of your prompts.</li> <li>Perform prompting that is either varied or deterministic.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#prompt-engineering","title":"Prompt engineering","text":"<p>Prompt engineering is the process of creating prompts that will produce the desired outcome. There's more to prompt engineering than just writing a text prompt. Prompt engineering is not an engineering discipline, it's more a set of techniques that you can apply to get the desired outcome.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#an-example-of-a-prompt","title":"An example of a prompt","text":"<p>Let's take a basic prompt like this one:</p> <p>Generate 10 questions on geography.</p> <p>In this prompt, you are actually applying a set of different prompt techniques.</p> <p>Let's break this down.</p> <ul> <li>Context, you specify it should be about \"geography\".</li> <li>Limiting the output, you want no more than 10 questions.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#limitations-of-simple-prompting","title":"Limitations of simple prompting","text":"<p>You may or may not get the desired outcome. You will get your questions generated, but geography is a big topic and you may not get what you want to due the following reasons:</p> <ul> <li>Big topic, you don't know if it's going to be about countries, capitals, rivers and so on.</li> <li>Format, what if you wanted the questions to be formatted in a certain way?</li> </ul> <p>As you can see, there's a lot to consider when creating prompts.</p> <p>So far, we've seen a simple prompt example, but generative AI is capable of much more to help people in a variety of roles and industries. Let's explore some basic techniques next.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#techniques-for-prompting","title":"Techniques for prompting","text":"<p>First, we need to understand that prompting is an emergent property of an LLM meaning that this is not a feature that is built into the model but rather something we discover as we use the model.</p> <p>There are some basic techniques that we can use to prompt an LLM. Let's explore them.</p> <ul> <li>Zero-shot prompting, this is the most basic form of prompting. It's a single prompt requesting a response from the LLM based solely on its training data.</li> <li>Few-shot prompting, this type of prompting guides the LLM by providing 1 or more examples it can rely on to generate its response.</li> <li>Chain-of-thought, this type of prompting tells the LLM how to break down a problem into steps.</li> <li>Generated knowledge, to improve the response of a prompt, you can provide generated facts or knowledge additionally to your prompt.</li> <li>Least to most, like chain-of-thought, this technique is about breaking down a problem into a series of steps and then ask these steps to be performed in order.</li> <li>Self-refine, this technique is about critiquing the LLM's output and then asking it to improve.</li> <li>Maieutic prompting. What you want here is to ensure the LLM answer is correct and you ask it to explain various parts of the answer. This is a form of self-refine.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#zero-shot-prompting","title":"Zero-shot prompting","text":"<p>This style of prompting is very simple, it consists of a single prompt. This technique is probably what you're using as you're starting to learn about LLMs. Here's an example:</p> <ul> <li>Prompt: \"What is Algebra?\"</li> <li>Answer: \"Algebra is a branch of mathematics that studies mathematical symbols and the rules for manipulating these symbols.\"</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#few-shot-prompting","title":"Few-shot prompting","text":"<p>This style of prompting helps the model by providing a few examples along with the request. It consists of a single prompt with additional task-specific data. Here's an example:</p> <ul> <li>Prompt: \"Write a poem in the style of Shakespeare. Here are a few examples of Shakespearean sonnets.:   Sonnet 18: 'Shall I compare thee to a summer's day? Thou art more lovely and more temperate...'   Sonnet 116: 'Let me not to the marriage of true minds Admit impediments. Love is not love Which alters when it alteration finds...'   Sonnet 132: 'Thine eyes I love, and they, as pitying me, Knowing thy heart torment me with disdain,...'   Now, write a sonnet about the beauty of the moon.\"</li> <li>Answer: \"Upon the sky, the moon doth softly gleam, In silv'ry light that casts its gentle grace,...\"</li> </ul> <p>Examples provide the LLM with the context, format or style of the desired output. They help the model understand the specific task and generate more accurate and relevant responses.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#chain-of-thought","title":"Chain-of-thought","text":"<p>Chain-of-thought is a very interesting technique as it's about taking the LLM through a series of steps. The idea is to instruct the LLM in such a way that it understands how to do something. Consider the following example, with and without chain-of-thought:</p> <pre><code>- Prompt: \"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\n- Answer: 5\n</code></pre> <p>LLM answers with 5, which is incorrect. Correct answer is 1 apple, given the calculation (5 -3 -2 + 1 = 1).</p> <p>So how can we teach the LLM to do this correctly?</p> <p>Let's try chain-of-thought. Applying chain-of-thought means:</p> <ol> <li>Give the LLM a similar example.</li> <li>Show the calculation, and how to calculate it correctly.</li> <li>Provide the original prompt.</li> </ol> <p>Here's how:</p> <ul> <li>Prompt: \"Lisa has 7 apples, throws 1 apple, gives 4 apples to Bart and Bart gives one back:   7 -1 = 6   6 -4 = 2   2 +1 = 3   Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"   Answer: 1</li> </ul> <p>Note how we write substantially longer prompts with another example, a calculation and then the original prompt and we arrive at the correct answer 1.</p> <p>As you can see chain-of-thought is a very powerful technique.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#generated-knowledge","title":"Generated knowledge","text":"<p>Many times when you want to construct a prompt, you want to do so using your own company's data. You want part of the prompt to be from the company and the other part should be the actual prompt you're interested in.</p> <p>As an example, this is what your prompt then can look like if you're in the insurance business:</p> <pre><code>{{company}}: {{company_name}}\n{{products}}:\n{{products_list}}\nPlease suggest an insurance given the following budget and requirements:\nBudget: {{budget}}\nRequirements: {{requirements}}\n</code></pre> <p>Above, you see how the prompt is constructed using a template. In the template there's a number of variables, denoted by <code>{{variable}}</code>, that will be replaced with actual values from a company API.</p> <p>Here's an example of how the prompt could look like once the variables have been replaced by content from your company:</p> <pre><code>Insurance company: ACME Insurance\nInsurance products (cost per month):\n- Car, cheap, 500 USD\n- Car, expensive, 1100 USD\n- Home, cheap, 600 USD\n- Home, expensive, 1200 USD\n- Life, cheap, 100 USD\n\nPlease suggest an insurance given the following budget and requirements:\nBudget: $1000\nRequirements: Car, Home, and Life insurance\n</code></pre> <p>Running this prompt through an LLM will produce a response like this:</p> <pre><code>Given the budget and requirements, we suggest the following insurance package from ACME Insurance:\n- Car, cheap, 500 USD\n- Home, cheap, 600 USD\n- Life, cheap, 100 USD\nTotal cost: $1,200 USD\n</code></pre> <p>As you can see, it also suggests the Life insurance, which it shouldn't. This result is an indication that we need to optimize the prompt by changing the prompt to be clearer on what it can allow. After some trial and error, we arrive at the following prompt:</p> <pre><code>Insurance company: ACME Insurance\nInsurance products (cost per month):\n- type: Car, cheap, cost: 500 USD\n- type: Car, expensive, cost: 1100 USD\n- type: Home, cheap, cost: 600 USD\n- type: Home, expensive, cost: 1200 USD\n- type: Life, cheap, cost: 100 USD\n\nPlease suggest an insurance given the following budget and requirements:\nBudget: $1000 restrict choice to types: Car, Home\n</code></pre> <p>Note how adding type and cost and also using the keyword restrict helps the LLM to understand what we want.</p> <p>Now we get the following response:</p> <pre><code>Given the budget and requirements, we suggest the Car, Cheap insurance product which costs 500 USD per month.\n</code></pre> <p>The point of this example was to show that even though we're using a basic technique like generated knowledge, we still need to optimize the prompt in most cases to get the desired outcome.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#least-to-most","title":"Least-to-most","text":"<p>The idea with Least-to-most prompting is to break down a bigger problem into subproblems. That way, you help guide the LLM on how to \"conquer\" the bigger problem. A good example could be for data science where you can ask the LLM to divide up a problem like so:</p> <p>Prompt: How to perform data science in 5 steps?</p> <p>With your AI assistant answering with:</p> <ol> <li>Collect data</li> <li>Clean data</li> <li>Analyze data</li> <li>Plot data</li> <li>Present data</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#self-refine-critique-the-results","title":"Self-refine, critique the results","text":"<p>With generative AIs and LLMs, you can't trust the output. You need to verify it. After all, the LLM is just presenting you what's the next most likely thing to say, not what's correct. Therefore, a good idea is to ask the LLM to critique itself, which leads us to the self-refine technique.</p> <p>How it works is that you follow the following steps:</p> <ol> <li>Initial prompt asking the LLM to solve a problem</li> <li>LLM answers</li> <li>You critique the answer and ask the AI to improve</li> <li>LLM answers again, this time considering the critique and suggest solutions it came up with</li> </ol> <p>You can repeat this process as many times as you want.</p> <p>Here's an example using this technique:</p> <p>Prompt: \"Create a Python Web API with routes products and customers\"</p> <p>AI Answer:</p> <pre><code>import flask\napp = Flask(__name__)\n\n@app.route('/products')\ndef products():\n    return 'Products'\n\n@app.route('/customers')\ndef customers():\n    return 'Customers'\n</code></pre> <p>Prompt: suggest 3 improvements of the above code</p> <p>AI Answer:</p> <pre><code>Sure, here are three suggestions to improve the code:\n\nImport the correct module: The first line should import Flask instead of flask. The correct import statement should be from flask import Flask.\n\nAdd a main function: Add a if __name__ == '__main__': block to the end of the file to run the application when the file is executed.\n\nUse f-strings: Use f-strings to format the return statements in the route functions. For example, return 'Products' can be changed to return f'This is the {request.path} page'.\n</code></pre> <pre><code>from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/products')\ndef products():\n    return f'This is the {request.path} page'\n\n@app.route('/customers')\ndef customers():\n    return f'This is the {request.path} page'\n\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>As you can see, the above AI response is improving the first suggested code thanks to critiquing the first answer.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#maieutic-prompting","title":"Maieutic prompting","text":"<p>Maieutic prompting is a technique that is similar to self-refine but it's more about asking the LLM to explain itself. The goal is to reduce inconsistencies in the LLM's output so to ensure it arrives at the correct answer. The workflow to follow is:</p> <ol> <li>Ask the LLM to answer a question</li> <li>For each part of the answer, ask the LLM to explain it more in depth.</li> <li>If there are inconsistencies, discard the parts that are inconsistent.</li> </ol> <p>Repeat 2 and 3 until you've gone through all the parts and you're satisfied with the answer.</p> <p>Here's an example prompt:</p> <p>prompt: How can I create a crisis plan to mitigate a pandemic in 5 steps? LLM answer:</p> <pre><code>1. Identify the risks\n1. Identify the stakeholders\n1. Identify the resources\n1. Identify the actions\n1. Identify the communication channels\n</code></pre> <p>It's identified 5 steps, but can we determine if this is correct? Let's ask the LLM to explain each step:</p> <p>prompt: Explain the first step in more detail, what are the risks in detail with a pandemic?</p> <pre><code>The risks are the following:\n\n- Loss of life\n- Loss of business\n- Loss of reputation\n- Loss of customers\n- Loss of employees\n</code></pre> <p>At this point, we want to make sure the LLM is correct so we ask it to explain the first risk in more detail and hope it's consistent with the answer above:</p> <p>prompt: In a Pandemic, which is the biggest risk and why?</p> <pre><code>The biggest risk is loss of life because it's the most important thing to protect.\n</code></pre> <p>What are the two biggest risks in a pandemic?</p> <pre><code>The two biggest risks are loss of life and loss of business.\n</code></pre> <p>At this point, the LLM is consistent and mentions \"life\" and \"business\" as the top two risks. We can now continue to the next step and feel fairly confident. However, we shouldn't trust the LLM blindly, we should always verify the output.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#vary-your-output","title":"Vary your output","text":"<p>LLMs are nondeterministic by nature, meaning that you will get different results each time you run the same prompt. Try the following prompt for example:</p> <p>\"Generate code for a Python Web API\"</p> <pre><code># Import necessary modules\nimport flask\nfrom flask import request, jsonify\n\n# Create a Flask app\napp = flask.Flask(__name__)\n\n# Create a route for the API\n@app.route('/api', methods=['GET'])\ndef api():\n    # Get the data from the request\n    data = request.args\n\n    # Process the data\n    result = process_data(data)\n\n    # Return the result as JSON\n    return jsonify(result)\n\n# Function to process the data\ndef process_data(data):\n    # Do something with the data\n    result = data + 1\n\n    # Return the result\n    return result\n\n# Run the app\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>Running the same prompt again generates a slightly different response:</p> <pre><code>#import necessary packages\nimport flask\nfrom flask import request, jsonify\n\n#create the Flask application\napp = flask.Flask(__name__)\napp.config[\"DEBUG\"] = True\n\n#create a list of books\nbooks = [\n    {'id': 0,\n     'title': 'A Fire Upon the Deep',\n     'author': 'Vernor Vinge',\n     'first_sentence': 'The coldsleep itself was dreamless.',\n     'year_published': '1992'},\n    {'id': 1,\n     'title': 'The Ones Who Walk Away From Omelas',\n     'author': 'Ursula K. Le Guin',\n     'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',\n     'published': '1973'},\n    {'id': 2,\n     'title': 'Dhalgren',\n     'author': 'Samuel R. Delany',\n     'first_sentence': 'to wound the autumnal city.',\n     'published': '1975'}\n]\n\n#create an endpoint for the API\n@app.route('/', methods=['GET'])\ndef home():\n    return '''&lt;h1&gt;Books API&lt;/h1&gt;\n&lt;p&gt;A prototype API for retrieving books.&lt;/p&gt;'''\n\n#create an endpoint to return all books\n@app.route('/api/v1/resources/books/all', methods=['GET'])\ndef api_all():\n    return jsonify(books)\n\n#create an endpoint to return a single book\n@app.route('/api/v1/resources/books', methods=['GET'])\ndef api_id():\n    #check if an ID was provided as part of the URL\n    #if ID is provided, assign it to a variable\n    #if no ID is provided, display an error\n    if 'id' in request.args:\n        id = int(request.args['id'])\n    else:\n        return \"Error: No id field provided. Please specify an id.\"\n\n    #create an empty list for our results\n    results = []\n\n    #loop through the data and match results that fit the requested ID\n    #IDs are unique, but other fields might return many results\n    for book in books:\n        if book['id'] == id:\n            results.append(book)\n\n    #use the jsonify function from Flask to convert our list of\n    #Python dictionaries to the JSON format\n    return jsonify(results)\n\napp.run()\n</code></pre> <p>So is the varied output a problem?</p> <p>Depends on what you're trying to do. If you want a specific response then it's a problem. If you're ok with a varied output like \"Generate any 3 questions on geography\", then it's not a problem.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#using-temperature-to-vary-your-output","title":"Using temperature to vary your output","text":"<p>Ok, so we've decided we want to limit the output to be more predictable, that is more deterministic. How do we do that?</p> <p>Temperature is a value between 0 and 1, where 0 is the most deterministic and 1 is the most varied. The default value is 0.7. Let's see what happens with two runs of the same prompt with temperature set to 0.1:</p> <p>\"Generate code for a Python Web API\"</p> <pre><code>#import necessary libraries\nimport flask\nfrom flask import request, jsonify\n\n#create an instance of the Flask class\napp = flask.Flask(__name__)\n\n#create an endpoint for the API\n@app.route('/api/v1/endpoint', methods=['GET'])\ndef api_endpoint():\n    #get the request data\n    data = request.get_json()\n\n    #process the data\n    result = process_data(data)\n\n    #return the result\n    return jsonify(result)\n\n#function to process the data\ndef process_data(data):\n    #process the data\n    result = {'result': 'success'}\n\n    #return the result\n    return result\n\n#run the Flask app\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>Running the prompt again gives us this outcome:</p> <pre><code>#import necessary libraries\nimport flask\nfrom flask import request, jsonify\n\n#create a Flask app\napp = flask.Flask(__name__)\n\n#create a route for the API\n@app.route('/api', methods=['GET'])\ndef api_call():\n    #get the data from the request\n    data = request.get_json()\n\n    #process the data\n    result = process_data(data)\n\n    #return the result\n    return jsonify(result)\n\n#define the process_data function\ndef process_data(data):\n    #do something with the data\n    result = data + 1\n\n    #return the result\n    return result\n\n#run the app\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>There's only a tiny difference between these two outputs. Let's do the opposite this time, let's set the temperature to 0.9:</p> <pre><code># Import necessary libraries\nimport flask\nfrom flask import request, jsonify\n\n# Create a Flask app\napp = flask.Flask(__name__)\n\n# Create a route for the API\n@app.route('/api', methods=['GET'])\ndef api_call():\n    # Get the data from the request\n    data = request.args\n\n    # Process the data\n    result = process_data(data)\n\n    # Return the result\n    return jsonify(result)\n\n# Function to process the data\ndef process_data(data):\n    # Do something with the data\n    result = data + 1\n\n    # Return the result\n    return result\n\n# Run the app\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>and the second attempt at 0.9 as temperature value:</p> <pre><code>import flask\nfrom flask import request, jsonify\n\n# create the Flask app\napp = flask.Flask(__name__)\napp.config['DEBUG'] = True\n\n# create some test data\nbooks = [\n    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},\n    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},\n    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}\n]\n\n# create an endpoint\n@app.route('/', methods=['GET'])\ndef home():\n    return '''&lt;h1&gt;Welcome to our book API!&lt;/h1&gt;'''\n\n@app.route('/api/v1/resources/books\n</code></pre> <p>As you can see, the results couldn't be more varied.</p> <p>Note, that there are more parameters you can change to vary the output, like top-k, top-p, repetition penalty, length penalty and diversity penalty but these are outside the scope of this curriculum.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#good-practices","title":"Good practices","text":"<p>There are many practices you can apply to try to get what you want. You will find your own style as you use prompting more and more.</p> <p>Additionally to the techniques we've covered, there are some good practices to consider when prompting an LLM.</p> <p>Here are some good practices to consider:</p> <ul> <li>Specify context. Context matters, the more you can specify like domain, topic, etc. the better.</li> <li>Limit the output. If you want a specific number of items or a specific length, specify it.</li> <li>Specify both what and how. Remember to mention both what you want and how you want it, for example \"Create a Python Web API with routes products and customers, divide it into 3 files\".</li> <li>Use templates. Often, you will want to enrich your prompts with data from your company. Use templates to do this. Templates can have variables that you replace with actual data.</li> <li>Spell correctly. LLMs might provide you with a correct response, but if you spell correctly, you will get a better response.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#assignment","title":"Assignment","text":"<p>Here's code in Python showing how to build a simple API using Flask:</p> <pre><code>from flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/')\ndef hello():\n    name = request.args.get('name', 'World')\n    return f'Hello, {name}!'\n\nif __name__ == '__main__':\n    app.run()\n</code></pre> <p>Use an AI assistant like GitHub Copilot or ChatGPT and apply the \"self-refine\" technique to improve the code.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#solution","title":"Solution","text":"<p>Please attempt to solve the assignment by adding suitable prompts to the code.</p> <p>[!TIP] Phrase a prompt to ask it to improve, it's a good idea to limit how many improvements. You can also ask to improve it in a certain way, for example architecture, performance, security, etc.</p> <p>Solution</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#knowledge-check","title":"Knowledge check","text":"<p>Why would I use chain-of-thought prompting? Show me 1 correct response and 2 incorrect responses.</p> <ol> <li>To teach the LLM how to solve a problem.</li> <li>B, To teach the LLM to find errors in code.</li> <li>C, To instruct the LLM to come up with different solutions.</li> </ol> <p>A: 1, because chain-of-thought is about showing the LLM how to solve a problem by providing it with a series of steps, and similar problems and how they were solved.</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>You just used the self-refine technique in the assignment. Take any program you built and consider what improvements you would want to apply to it. Now use the self-refine technique to apply the proposed changes. What did you think the result, better or worse?</p>"},{"location":"curricula/generative-ai-for-beginners/05-advanced-prompts/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 6 where we will apply our knowledge of Prompt Engineering by building text generation apps</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/","title":"Lesson 6","text":""},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#building-text-generation-applications","title":"Building Text Generation Applications","text":"<p>(Click the image above to view video of this lesson)</p> <p>You've seen so far through this curriculum that there are core concepts like prompts and even a whole discipline called \"prompt engineering\". Many tools you can interact with like ChatGPT, Office 365, Microsoft Power Platform and more, support you using prompts to accomplish something.</p> <p>For you to add such an experience to an app, you need to understand concepts like prompts, completions and choose a library to work with. That's exactly what you'll learn in this chapter.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#introduction","title":"Introduction","text":"<p>In this chapter, you will:</p> <ul> <li>Learn about the openai library and it's core concepts.</li> <li>Build a text generation app using openai.</li> <li>Understand how to use concepts like prompt, temperature, and tokens to build a text generation app.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#learning-goals","title":"Learning goals","text":"<p>At the end of this lesson, you'll be able to:</p> <ul> <li>Explain what a text generation app is.</li> <li>Build a text generation app using openai.</li> <li>Configure your app to use more or less tokens and also change the temperature, for a varied output.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#what-is-a-text-generation-app","title":"What is a text generation app?","text":"<p>Normally when you build an app it has some kind of interface like the following:</p> <ul> <li>Command-based. Console apps are typical apps where you type a command and it carries out a task. For example, <code>git</code> is a command-based app.</li> <li>User interface (UI). Some apps have graphical user interfaces (GUIs) where you click buttons, input text, select options and more.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#console-and-ui-apps-are-limited","title":"Console and UI apps are limited","text":"<p>Compare it to a command-based app where you type a command:</p> <ul> <li>It's limited. You can't just type any command, only the ones that the app supports.</li> <li>Language specific. Some apps support many languages, but by default the app is built for a specific language, even if you can add more language support.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#benefits-of-text-generation-apps","title":"Benefits of text generation apps","text":"<p>So how is a text generation app different?</p> <p>In a text generation app, you have more flexibility, you're not limited to a set of commands or a specific input language. Instead, you can use natural language to interact with the app. Another benefit is that because you're already interacting with a data source that has been trained on a vast corpus of information, whereas a traditional app might be limited on what's in a database.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#what-can-i-build-with-a-text-generation-app","title":"What can I build with a text generation app?","text":"<p>There are many things you can build. For example:</p> <ul> <li>A chatbot. A chatbot answering questions about topics, like your company and its products could be a good match.</li> <li>Helper. LLMs are great at things like summarizing text, getting insights from text, producing text like resumes and more.</li> <li>Code assistant. Depending on the language model you use, you can build a code assistant that helps you write code. For example, you can use a product like GitHub Copilot as well as ChatGPT to help you write code.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#how-can-i-get-started","title":"How can I get started?","text":"<p>Well, you need to find a way to integrate with an LLM which usually entails the following two approaches:</p> <ul> <li>Use an API. Here you're constructing web requests with your prompt and get generated text back.</li> <li>Use a library. Libraries help encapsulate the API calls and make them easier to use.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#librariessdks","title":"Libraries/SDKs","text":"<p>There are a few well known libraries for working with LLMs like:</p> <ul> <li>openai, this library makes it easy to connect to your model and send in prompts.</li> </ul> <p>Then there are libraries that operate on a higher level like:</p> <ul> <li>Langchain. Langchain is well known and supports Python.</li> <li>Semantic Kernel. Semantic Kernel is a library by Microsoft supporting the languages C#, Python, and Java.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#first-app-using-openai","title":"First app using openai","text":"<p>Let's see how we can build our first app, what libraries we need, how much is required and so on.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#install-openai","title":"Install openai","text":"<p>There are many libraries out there for interacting with OpenAI or Azure OpenAI. It's possible to use numerous programming languages as well like C#, Python, JavaScript, Java and more. We've chosen to use the <code>openai</code> Python library, so we'll use <code>pip</code> to install it.</p> <pre><code>pip install openai\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#create-a-resource","title":"Create a resource","text":"<p>You need to carry out the following steps:</p> <ul> <li>Create an account on Azure https://azure.microsoft.com/free/.</li> <li>Gain access to Azure OpenAI. Go to https://learn.microsoft.com/azure/ai-services/openai/overview#how-do-i-get-access-to-azure-openai and request access.</li> </ul> <p>[!NOTE] At the time of writing, you need to apply for access to Azure OpenAI.</p> <ul> <li>Install Python https://www.python.org/</li> <li>Have created an Azure OpenAI Service resource. See this guide for how to create a resource.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#locate-api-key-and-endpoint","title":"Locate API key and endpoint","text":"<p>At this point, you need to tell your <code>openai</code> library what API key to use. To find your API key, go to \"Keys and Endpoint\" section of your Azure OpenAI resource and copy the \"Key 1\" value.</p> <p></p> <p>Now that you have this information copied, let's instruct the libraries to use it.</p> <p>[!NOTE] It's worth separating your API key from your code. You can do so by using environment variables.</p> <ul> <li>Set the environment variable <code>OPENAI_API_KEY</code> to your API key.   <code>export OPENAI_API_KEY='sk-...'</code></li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#setup-configuration-azure","title":"Setup configuration Azure","text":"<p>If you're using Azure OpenAI, here's how you setup configuration:</p> <pre><code>openai.api_type = 'azure'\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\nopenai.api_version = '2023-05-15'\nopenai.api_base = os.getenv(\"API_BASE\")\n</code></pre> <p>Above we're setting the following:</p> <ul> <li><code>api_type</code> to <code>azure</code>. This tells the library to use Azure OpenAI and not OpenAI.</li> <li><code>api_key</code>, this is your API key found in the Azure Portal.</li> <li><code>api_version</code>, this is the version of the API you want to use. At the time of writing, the latest version is <code>2023-05-15</code>.</li> <li><code>api_base</code>, this is the endpoint of the API. You can find it in the Azure Portal next to your API key.</li> </ul> <p>[!NOTE] &gt; <code>os.getenv</code> is a function that reads environment variables. You can use it to read environment variables like <code>OPENAI_API_KEY</code> and <code>API_BASE</code>. Set these environment variables in your terminal or by using a library like <code>dotenv</code>.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#generate-text","title":"Generate text","text":"<p>The way to generate text is to use the <code>Completion</code> class. Here's an example:</p> <pre><code>prompt = \"Complete the following: Once upon a time there was a\"\n\ncompletion = openai.Completion.create(model=\"davinci-002\", prompt=prompt)\nprint(completion.choices[0].text)\n</code></pre> <p>In the above code, we create a completion object and pass in the model we want to use and the prompt. Then we print the generated text.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#chat-completions","title":"Chat completions","text":"<p>So far, you've seen how we've been using <code>Completion</code> to generate text. But there's another class called <code>ChatCompletion</code> that is more suited for chatbots. Here's an example of using it:</p> <pre><code>import openai\n\nopenai.api_key = \"sk-...\"\n\ncompletion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\nprint(completion.choices[0].message.content)\n</code></pre> <p>More on this functionality in an upcoming chapter.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#exercise-your-first-text-generation-app","title":"Exercise - your first text generation app","text":"<p>Now that we learned how to set up and configure openai, it's time to build your first text generation app. To build your app, follow these steps:</p> <ol> <li>Create a virtual environment and install openai:</li> </ol> <pre><code>python -m venv venv\nsource venv/bin/activate\npip install openai\n</code></pre> <p>[!NOTE] If you're using Windows type <code>venv\\Scripts\\activate</code> instead of <code>source venv/bin/activate</code>.</p> <p>[!NOTE] Locate your Azure OpenAI key by going to https://portal.azure.com/ and search for <code>Open AI</code> and select the <code>Open AI resource</code> and then select <code>Keys and Endpoint</code> and copy the <code>Key 1</code> value.</p> <ol> <li>Create an app.py file and give it the following code:</li> </ol> <pre><code>import openai\n\nopenai.api_key = \"&lt;replace this value with your open ai key or Azure OpenAI key&gt;\"\n\nopenai.api_type = 'azure'\nopenai.api_version = '2023-05-15'\nopenai.api_base = \"&lt;endpoint found in Azure Portal where your API key is&gt;\"\ndeployment_name = \"&lt;deployment name&gt;\"\n\n# add your completion code\nprompt = \"Complete the following: Once upon a time there was a\"\nmessages = [{\"role\": \"user\", \"content\": prompt}]\n\n# make completion\ncompletion = client.chat.completions.create(model=deployment, messages=messages)\n\n# print response\nprint(completion.choices[0].message.content)\n</code></pre> <p>[!NOTE] If you're using Azure OpenAI, you need to set the <code>api_type</code> to <code>azure</code> and set the <code>api_key</code> to your Azure OpenAI key.</p> <p>You should see an output like the following:</p> <pre><code> very unhappy _____.\n\nOnce upon a time there was a very unhappy mermaid.\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#different-types-of-prompts-for-different-things","title":"Different types of prompts, for different things","text":"<p>Now you've seen how to generate text using a prompt. You even have a program up and running that you can modify and change to generate different types of text.</p> <p>Prompts can be used for all sorts of tasks. For example:</p> <ul> <li>Generate a type of text. For example, you can generate a poem, questions for a quiz etc.</li> <li>Lookup information. You can use prompts to look for information like the following example 'What does CORS mean in web development?'.</li> <li>Generate code. You can use prompts to generate code, for example developing a regular expression used to validate emails or why not generate an entire program, like a web app?</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#a-more-practical-use-case-a-recipe-generator","title":"A more practical use case: a recipe generator","text":"<p>Imagine you have ingredients at home and you want to cook something. For that, you need a recipe. A way to find recipes is to use a search engine or you could use an LLM to do so.</p> <p>You could write a prompt like so:</p> <p>\"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"</p> <p>Given the above prompt, you might get a response similar to:</p> <pre><code>1. Roasted Chicken and Vegetables:\nIngredients:\n- 4 chicken thighs\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 2 tablespoons olive oil\n- 2 cloves garlic, minced\n- 1 teaspoon dried thyme\n- 1 teaspoon dried oregano\n- Salt and pepper, to taste\n\n2. Chicken and Potato Stew:\nIngredients:\n- 2 tablespoons olive oil\n- 1 onion, diced\n- 2 cloves garlic, minced\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 1 cup chicken broth\n- Salt and pepper, to taste\n\n3. Chicken and Potato Bake:\nIngredients:\n- 2 tablespoons olive oil\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 onion, diced\n- 2 cloves garlic, minced\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 1 cup chicken broth\n- Salt and pepper, to taste\n\n4. Chicken and Potato Soup:\nIngredients:\n- 2 tablespoons olive oil\n- 1 onion, diced\n- 2 cloves garlic, minced\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 4 cups chicken broth\n- Salt and pepper, to taste\n\n5. Chicken and Potato Hash:\nIngredients:\n- 2 tablespoons olive oil\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 onion, diced\n- 2 cloves garlic, minced\n- 1 teaspoon dried oregano\n</code></pre> <p>This outcome is great, I know what to cook. At this point, what could be useful improvements are:</p> <ul> <li>Filtering out ingredients I don't like or am allergic to.</li> <li>Produce a shopping list, in case I don't have all the ingredients at home.</li> </ul> <p>For the above cases, let's add an additional prompt:</p> <p>\"Please remove recipes with garlic as I'm allergic and replace it with something else. Also, please produce a shopping list for the recipes, considering I already have chicken, potatoes and carrots at home.\"</p> <p>Now you have a new result, namely:</p> <pre><code>1. Roasted Chicken and Vegetables:\nIngredients:\n- 4 chicken thighs\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 2 tablespoons olive oil\n- 1 teaspoon dried thyme\n- 1 teaspoon dried oregano\n- Salt and pepper, to taste\n\n2. Chicken and Potato Stew:\nIngredients:\n- 2 tablespoons olive oil\n- 1 onion, diced\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 1 cup chicken broth\n- Salt and pepper, to taste\n\n3. Chicken and Potato Bake:\nIngredients:\n- 2 tablespoons olive oil\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 onion, diced\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 1 cup chicken broth\n- Salt and pepper, to taste\n\n4. Chicken and Potato Soup:\nIngredients:\n- 2 tablespoons olive oil\n- 1 onion, diced\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 teaspoon dried oregano\n- 1 teaspoon dried thyme\n- 4 cups chicken broth\n- Salt and pepper, to taste\n\n5. Chicken and Potato Hash:\nIngredients:\n- 2 tablespoons olive oil\n- 2 chicken breasts, cut into cubes\n- 2 potatoes, cut into cubes\n- 2 carrots, cut into cubes\n- 1 onion, diced\n- 1 teaspoon dried oregano\n\nShopping List:\n- Olive oil\n- Onion\n- Thyme\n- Oregano\n- Salt\n- Pepper\n</code></pre> <p>That's your five recipes, with no garlic mentioned and you also have a shopping list considering what you already have at home.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#exercise-build-a-recipe-generator","title":"Exercise - build a recipe generator","text":"<p>Now that we have played out a scenario, let's write code to match the demonstrated scenario. To do so, follow these steps:</p> <ol> <li>Use the existing app.py file as a starting point</li> <li>Locate the <code>prompt</code> variable and change its code to the following:</li> </ol> <pre><code>prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n</code></pre> <p>If you now run the code, you should see an output similar to:</p> <pre><code>-Chicken Stew with Potatoes and Carrots: 3 tablespoons oil, 1 onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 bay leaf, 1 thyme sprig, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 1 1/2 cups chicken broth, 1/2 cup dry white wine, 2 tablespoons chopped fresh parsley, 2 tablespoons unsalted butter, 1 1/2 pounds boneless, skinless chicken thighs, cut into 1-inch pieces\n-Oven-Roasted Chicken with Potatoes and Carrots: 3 tablespoons extra-virgin olive oil, 1 tablespoon Dijon mustard, 1 tablespoon chopped fresh rosemary, 1 tablespoon chopped fresh thyme, 4 cloves garlic, minced, 1 1/2 pounds small red potatoes, quartered, 1 1/2 pounds carrots, quartered lengthwise, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 1 (4-pound) whole chicken\n-Chicken, Potato, and Carrot Casserole: cooking spray, 1 large onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and shredded, 1 potato, peeled and shredded, 1/2 teaspoon dried thyme leaves, 1/4 teaspoon salt, 1/4 teaspoon black pepper, 2 cups fat-free, low-sodium chicken broth, 1 cup frozen peas, 1/4 cup all-purpose flour, 1 cup 2% reduced-fat milk, 1/4 cup grated Parmesan cheese\n\n-One Pot Chicken and Potato Dinner: 2 tablespoons olive oil, 1 pound boneless, skinless chicken thighs, cut into 1-inch pieces, 1 large onion, chopped, 3 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 bay leaf, 1 thyme sprig, 1/2 teaspoon salt, 1/4 teaspoon black pepper, 2 cups chicken broth, 1/2 cup dry white wine\n\n-Chicken, Potato, and Carrot Curry: 1 tablespoon vegetable oil, 1 large onion, chopped, 2 cloves garlic, minced, 1 carrot, peeled and chopped, 1 potato, peeled and chopped, 1 teaspoon ground coriander, 1 teaspoon ground cumin, 1/2 teaspoon ground turmeric, 1/2 teaspoon ground ginger, 1/4 teaspoon cayenne pepper, 2 cups chicken broth, 1/2 cup dry white wine, 1 (15-ounce) can chickpeas, drained and rinsed, 1/2 cup raisins, 1/2 cup chopped fresh cilantro\n</code></pre> <p>NOTE, your LLM is nondeterministic, so you might get different results every time you run the program.</p> <p>Great, let's see how we can improve things. To improve things, we want to make sure the code is flexible, so ingredients and number of recipes can be improved and changed.</p> <ol> <li>Let's change the code in the following way:</li> </ol> <pre><code>no_recipes = input(\"No of recipes (for example, 5): \")\n\ningredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n\n# interpolate the number of recipes into the prompt an ingredients\nprompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n</code></pre> <p>Taking the code for a test run, could look like this:</p> <pre><code>No of recipes (for example, 5): 3\nList of ingredients (for example, chicken, potatoes, and carrots): milk,strawberries\n\n-Strawberry milk shake: milk, strawberries, sugar, vanilla extract, ice cubes\n-Strawberry shortcake: milk, flour, baking powder, sugar, salt, unsalted butter, strawberries, whipped cream\n-Strawberry milk: milk, strawberries, sugar, vanilla extract\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#improve-by-adding-filter-and-shopping-list","title":"Improve by adding filter and shopping list","text":"<p>We now have a working app capable of producing recipes and it's flexible as it relies on inputs from the user, both on the number of recipes but also the ingredients used.</p> <p>To further improve it, we want to add the following:</p> <ul> <li>Filter out ingredients. We want to be able to filter out ingredients we don't like or are allergic to. To accomplish this change, we can edit our existing prompt and add a filter condition to the end of it like so:</li> </ul> <pre><code>filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free): \")\n\nprompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n</code></pre> <p>Above, we add <code>{filter}</code> to the end of the prompt and we also capture the filter value from the user.</p> <p>An example input of running the program can now look like so:</p> <pre><code>No of recipes (for example, 5): 3\nList of ingredients (for example, chicken, potatoes, and carrots): onion,milk\nFilter (for example, vegetarian, vegan, or gluten-free): no milk\n\n1. French Onion Soup\n\nIngredients:\n\n-1 large onion, sliced\n-3 cups beef broth\n-1 cup milk\n-6 slices french bread\n-1/4 cup shredded Parmesan cheese\n-1 tablespoon butter\n-1 teaspoon dried thyme\n-1/4 teaspoon salt\n-1/4 teaspoon black pepper\n\nInstructions:\n\n1. In a large pot, saut\u00e9 onions in butter until golden brown.\n2. Add beef broth, milk, thyme, salt, and pepper. Bring to a boil.\n3. Reduce heat and simmer for 10 minutes.\n4. Place french bread slices on soup bowls.\n5. Ladle soup over bread.\n6. Sprinkle with Parmesan cheese.\n\n2. Onion and Potato Soup\n\nIngredients:\n\n-1 large onion, chopped\n-2 cups potatoes, diced\n-3 cups vegetable broth\n-1 cup milk\n-1/4 teaspoon black pepper\n\nInstructions:\n\n1. In a large pot, saut\u00e9 onions in butter until golden brown.\n2. Add potatoes, vegetable broth, milk, and pepper. Bring to a boil.\n3. Reduce heat and simmer for 10 minutes.\n4. Serve hot.\n\n3. Creamy Onion Soup\n\nIngredients:\n\n-1 large onion, chopped\n-3 cups vegetable broth\n-1 cup milk\n-1/4 teaspoon black pepper\n-1/4 cup all-purpose flour\n-1/2 cup shredded Parmesan cheese\n\nInstructions:\n\n1. In a large pot, saut\u00e9 onions in butter until golden brown.\n2. Add vegetable broth, milk, and pepper. Bring to a boil.\n3. Reduce heat and simmer for 10 minutes.\n4. In a small bowl, whisk together flour and Parmesan cheese until smooth.\n5. Add to soup and simmer for an additional 5 minutes, or until soup has thickened.\n</code></pre> <p>As you can see, any recipes with milk in it has been filtered out. But, if you're lactose intolerant, you might want to filter out recipes with cheese in them as well, so there's a need to be clear.</p> <ul> <li>Produce a shopping list. We want to produce a shopping list, considering what we already have at home.</li> </ul> <p>For this functionality, we could either try to solve everything in one prompt or we could split it up into two prompts. Let's try the latter approach. Here we're suggesting adding an additional prompt, but for that to work, we need to add the result of the former prompt as context to the latter prompt.</p> <p>Locate the part in the code that prints out the result from the first prompt and add the following code below:</p> <pre><code>old_prompt_result = completion.choices[0].message.content\nprompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n\nnew_prompt = f\"{old_prompt_result} {prompt}\"\nmessages = [{\"role\": \"user\", \"content\": new_prompt}]\ncompletion = openai.Completion.create(engine=deployment_name, messages=messages, max_tokens=1200)\n\n# print response\nprint(\"Shopping list:\")\nprint(completion.choices[0].message.content)\n</code></pre> <p>Note the following:</p> <ol> <li> <p>We're constructing a new prompt by adding the result from the first prompt to the new prompt:</p> <pre><code>new_prompt = f\"{old_prompt_result} {prompt}\"\n</code></pre> </li> <li> <p>We make a new request, but also considering the number of tokens we asked for in the first prompt, so this time we say <code>max_tokens</code> is 1200.</p> <pre><code>completion = openai.Completion.create(engine=deployment_name, prompt=new_prompt, max_tokens=1200)\n</code></pre> <p>Taking this code for a spin, we now arrive at the following output:</p> <pre><code>No of recipes (for example, 5): 2\nList of ingredients (for example, chicken, potatoes, and carrots): apple,flour\nFilter (for example, vegetarian, vegan, or gluten-free): sugar\n\n\n-Apple and flour pancakes: 1 cup flour, 1/2 tsp baking powder, 1/2 tsp baking soda, 1/4 tsp salt, 1 tbsp sugar, 1 egg, 1 cup buttermilk or sour milk, 1/4 cup melted butter, 1 Granny Smith apple, peeled and grated\n-Apple fritters: 1-1/2 cups flour, 1 tsp baking powder, 1/4 tsp salt, 1/4 tsp baking soda, 1/4 tsp nutmeg, 1/4 tsp cinnamon, 1/4 tsp allspice, 1/4 cup sugar, 1/4 cup vegetable shortening, 1/4 cup milk, 1 egg, 2 cups shredded, peeled apples\nShopping list:\n-Flour, baking powder, baking soda, salt, sugar, egg, buttermilk, butter, apple, nutmeg, cinnamon, allspice\n</code></pre> </li> </ol>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#improve-your-setup","title":"Improve your setup","text":"<p>What we have so far is code that works, but there are some tweaks we should be doing to improve things further. Some things we should do are:</p> <ul> <li> <p>Separate secrets from code, like the API key. Secrets do not belong in code and should be stored in a secure location. To separate secrets from code, we can use environment variables and libraries like <code>python-dotenv</code> to load them from a file. Here's how that would look like in code:</p> </li> <li> <p>Create a <code>.env</code> file with the following content:</p> <pre><code>OPENAI_API_KEY=sk-...\n</code></pre> <p>Note, for Azure, you need to set the following environment variables:</p> <pre><code>OPENAI_API_TYPE=azure\nOPENAI_API_VERSION=2023-05-15\nOPENAI_API_BASE=&lt;replace&gt;\n</code></pre> <p>In code, you would load the environment variables like so:</p> <pre><code>from dotenv import load_dotenv\n\nload_dotenv()\n\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]\n</code></pre> </li> <li> <p>A word on token length. We should consider how many tokens we need to generate the text we want. Tokens cost money, so where possible, we should try to be economical with the number of tokens we use. For example, can we phrase the prompt so that we can use less tokens?</p> </li> </ul> <p>To change the tokens used, you can use the <code>max_tokens</code> parameter. For example, if you want to use 100 tokens, you would do:</p> <pre><code>completion = client.chat.completions.create(model=deployment, messages=messages, max_tokens=100)\n</code></pre> <ul> <li>Experimenting with temperature. Temperature is something we haven't mentioned so far but is an important context for how our program performs. The higher the temperature value the more random the output will be. Conversely the lower the temperature value the more predictable the output will be. Consider whether you want variation in your output or not.</li> </ul> <p>To alter the temperature, you can use the <code>temperature</code> parameter. For example, if you want to use a temperature of 0.5, you would do:</p> <pre><code>completion = client.chat.completions.create(model=deployment, messages=messages, temperature=0.5)\n</code></pre> <p>Note, the closer to 1.0, the more varied the output.</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#assignment","title":"Assignment","text":"<p>For this assignment, you can choose what to build.</p> <p>Here are some suggestions:</p> <ul> <li>Tweak the recipe generator app to improve it further. Play around with temperature values, and the prompts to see what you can come up with.</li> <li>Build a \"study buddy\". This app should be able to answer questions about a topic for example Python, you could have prompts like \"What is a certain topic in Python?\", or you could have a prompt that says, show me code for a certain topic etc.</li> <li>History bot, make history come alive, instruct the bot to play a certain historical character and ask it questions about its life and times.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#solution","title":"Solution","text":""},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#study-buddy","title":"Study buddy","text":"<p>Below is a starter prompt, see how you can use it and tweak it to your liking.</p> <pre><code>- \"You're an expert on the Python language\n\n    Suggest a beginner lesson for Python in the following format:\n\n    Format:\n    - concepts:\n    - brief explanation of the lesson:\n    - exercise in code with solutions\"\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#history-bot","title":"History bot","text":"<p>Here are some prompts you could be using:</p> <pre><code>- \"You are Abe Lincoln, tell me about yourself in 3 sentences, and respond using grammar and words like Abe would have used\"\n- \"You are Abe Lincoln, respond using grammar and words like Abe would have used:\n\n   Tell me about your greatest accomplishments, in 300 words\"\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#knowledge-check","title":"Knowledge check","text":"<p>What does the concept temperature do?</p> <ol> <li>It controls how random the output is.</li> <li>It controls how big the response is.</li> <li>It controls how many tokens are used.</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>When working on the assignment, try to vary the temperature, try set it to 0, 0.5, and 1. Remember that 0 is the least varied and 1 is the most, what value works best for your app?</p>"},{"location":"curricula/generative-ai-for-beginners/06-text-generation-apps/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 7 where we will look at how to build chat applications!</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/","title":"Lesson 7","text":""},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#building-generative-ai-powered-chat-applications","title":"Building Generative AI-Powered Chat Applications","text":"<p>(Click the image above to view video of this lesson)</p> <p>Now that we've seen how we can build text-generation apps, let's look into chat applications.</p> <p>Chat applications have become integrated into our daily lives, offering more than just a means of casual conversation. They're integral parts of customer service, technical support, and even sophisticated advisory systems. It's likely that you've gotten some help from a chat application not too long ago. As we integrate more advanced technologies like generative AI into these platforms, the complexity increases and so does the challenges.</p> <p>Some questions we need to be answered are:</p> <ul> <li>Building the app. How do we efficiently build and seamlessly integrate these AI-powered applications for specific use cases?</li> <li>Monitoring. Once deployed, how can we monitor and ensure that the applications are operating at the highest level of quality, both in terms of functionality and adhering to the six principles of responsible AI?</li> </ul> <p>As we move further into an age defined by automation and seamless human-machine interactions, understanding how generative AI transforms the scope, depth, and adaptability of chat applications becomes essential. This lesson will investigate the aspects of architecture that support these intricate systems, delve into the methodologies for fine-tuning them for domain-specific tasks, and evaluate the metrics and considerations pertinent to ensuring responsible AI deployment.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#introduction","title":"Introduction","text":"<p>This lesson covers:</p> <ul> <li>Techniques for efficiently building and integrating chat applications.</li> <li>How to apply customization and fine-tuning to applications.</li> <li>Strategies and considerations to effectively monitor chat applications.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#learning-goals","title":"Learning Goals","text":"<p>By the end of this lesson, you'll be able to:</p> <ul> <li>Describe considerations for building and integrating chat applications into existing systems.</li> <li>Customize chat applications for specific use-cases.</li> <li>Identify key metrics and considerations to effectively monitor and maintain the quality of AI-powered chat applications.</li> <li>Ensure chat applications leverage AI responsibly.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#integrating-generative-ai-into-chat-applications","title":"Integrating Generative AI into Chat Applications","text":"<p>Elevating chat applications through generative AI isn't only centered around making them smarter; it's about optimizing their architecture, performance, and user interface to deliver a quality user experience. This involves investigating the architectural foundations, API integrations, and user interface considerations. This section aims to offer you a comprehensive roadmap for navigating these complex landscapes, whether you're plugging them into existing systems or building them as stand-alone platforms.</p> <p>By the end of this section, you'll be equipped with the expertise needed to efficiently construct and incorporate chat applications.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#chatbot-or-chat-application","title":"Chatbot or Chat application?","text":"<p>Before we dive into building chat applications, let's compare 'chatbots' against 'AI-powered chat applications,' which serve distinct roles and functionalities. A chatbot's main purpose is to automate specific conversational tasks, such as answering frequently asked questions or tracking a package. It's typically governed by rule-based logic or complex AI algorithms. In contrast, an AI-powered chat application is a far more expansive environment designed to facilitate various forms of digital communication, such as text, voice, and video chats among human users. Its defining feature is the integration of a generative AI model that simulates nuanced, human-like conversations, generating responses based on a wide variety of input and contextual cues. A generative AI powered chat application can engage in open-domain discussions, adapt to evolving conversational contexts, and even produce creative or complex dialogue.</p> <p>The table below outlines the key differences and similarities to help us understand their unique roles in digital communication.</p> Chatbot Generative AI-Powered Chat Application Task-Focused and rule based Context-aware Often integrated into larger systems May host one or multiple chatbots Limited to programmed functions Incorporates generative AI models Specialized &amp; structured interactions Capable of open-domain discussions"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#leveraging-pre-built-functionalities-with-sdks-and-apis","title":"Leveraging pre-built functionalities with SDKs and APIs","text":"<p>When building a chat application, a great first step is to assess what is already out there. Using SDKs and APIs to build chat applications is an advantageous strategy for a variety of reasons. By integrating well-documented SDKs and APIs, you're strategically positioning your application for long-term success, addressing scalability and maintenance concerns.</p> <ul> <li>Expedites the development process and reduces overhead: Relying on pre-built functionalities instead of the expensive process of building them yourself allows you to focus on other aspects of your application that you may find more important, such as business logic.</li> <li>Better performance: When building functionality from scratch, you'll eventually ask yourself \"How does it scale? Is this application capable of handling a sudden influx of users?\" Well maintained SDK and APIs often have built in solutions for these concerns.</li> <li>Easier maintenance: Updates and improvements are easier to manage as most APIs and SDKs simply require an update to a library when a newer version is released.</li> <li>Access to cutting edge technology: Leveraging models that have been fined tuned and trained on extensive datasets provides your application with natural language capabilities.</li> </ul> <p>Accessing functionality of an SDK or API typically involves obtaining permission to use the provided services, which is often through the use of a unique key or authentication token. We'll use the OpenAI Python Library to explore what this looks like. You can also try it out on your own in the following notebook for OpenAI or notebook for Azure OpenAI Services for this lesson.</p> <pre><code>import os\nfrom openai import OpenAI\n\nAPI_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n\nclient = OpenAI(\n    api_key=API_KEY\n    )\n\nchat_completion = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Suggest two titles for an instructional lesson on chat applications for generative AI.\"}])\n</code></pre> <p>The above example uses the GPT-3.5 Turbo model to complete the prompt, but notice that the API key is set prior to doing so. You'd receive an error if you didn't set the key.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#user-experience-ux","title":"User Experience (UX)","text":"<p>General UX principles apply to chat applications, but here are some additional considerations that become particularly important due to the machine learning components involved.</p> <ul> <li>Mechanism for addressing ambiguity: Generative AI models occasionally generate ambiguous answers. A feature that allows users to ask for clarification can be helpful should they come across this problem.</li> <li>Context retention: Advanced generative AI models have the ability to remember context within a conversation, which can be a necessary asset to the user experience. Giving users the ability to control and manage context improves the user experience, but introduces the risk of retaining sensitive user information. Considerations for how long this information is stored, such as introducing a retention policy, can balance the need for context against privacy.</li> <li>Personalization: With the ability to learn and adapt, AI models offer an individualized experience for a user. Tailoring the user experience through features like user profiles not only makes the user feel understood, but it also helps their pursuit of finding specific answers, creating a more efficient and satisfying interaction.</li> </ul> <p>One such example of personalization is the \"Custom instructions\" settings in OpenAI's ChatGPT. It allows you to provide information about yourself that may be important context for your prompts. Here's an example of a custom instruction.</p> <p></p> <p>This \"profile\" prompts ChatGPT to create a lesson plan on linked lists. Notice that ChatGPT takes into account that the user may want a more in depth lesson plan based on her experience.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#microsofts-system-message-framework-for-large-language-models","title":"Microsoft's System Message Framework for Large Language Models","text":"<p>Microsoft has provided guidance for writing effective system messages when generating responses from LLMs broken down into 4 areas:</p> <ol> <li>Defining who the model is for, as well as its capabilities and limitations.</li> <li>Defining the model's output format.</li> <li>Providing specific examples that demonstrate intended behavior of the model.</li> <li>Providing additional behavioral guardrails.</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#accessibility","title":"Accessibility","text":"<p>Whether a user has visual, auditory, motor, or cognitive impairments, a well-designed chat application should be usable by all. The following list breaks down specific features aimed at enhancing accessibility for various user impairments.</p> <ul> <li>Features for Visual Impairment: High contrast themes and resizable text, screen reader compatibility.</li> <li>Features for Auditory Impairment: Text-to-speech and speech-to-text functions, visual cues for audio notifications.</li> <li>Features for Motor Impairment: Keyboard navigation support, voice commands.</li> <li>Features for Cognitive Impairment: Simplified language options.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#customization-and-fine-tuning-for-domain-specific-language-models","title":"Customization and Fine-tuning for Domain-Specific Language Models","text":"<p>Imagine a chat application that understands your company's jargon and anticipates the specific queries its user base commonly has. There are a couple of approaches worth mentioning:</p> <ul> <li>Leveraging DSL models. DSL stands for domain specific language. You can leverage a so called DSL model trained on a specific domain to understand it's concepts and scenarios.</li> <li>Apply fine-tuning. Fine-tuning is the process of further training your model with specific data.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#customization-using-a-dsl","title":"Customization: Using a DSL","text":"<p>Leveraging a domain-specific language models (DSL Models) can enhance user engagement and by providing specialized, contextually relevant interactions. It's a model that is trained or fine-tuned to understand and generate text related to a specific field, industry, or subject. Options for using a DSL model can vary from training one from scratch, to using pre-existing ones through SDKs and APIs. Another option is fine-tuning, which involves taking an existing pre-trained model and adapting it for a specific domain.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#customization-apply-fine-tuning","title":"Customization: Apply fine-tuning","text":"<p>Fine-tuning is often considered when a pre-trained model falls short in a specialized domain or specific task.</p> <p>For instance, medical queries are complex and require a lot of context. When a medical professional diagnoses a patient it's based on a variety of factors such as lifestyle or pre-existing conditions, and may even rely on recent medical journals to validate their diagnosis. In such nuanced scenarios, a general-purpose AI chat application cannot be a reliable source.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#scenario-a-medical-application","title":"Scenario: a medical application","text":"<p>Consider a chat application designed to assist medical practitioners by providing quick references to treatment guidelines, drug interactions, or recent research findings.</p> <p>A general-purpose model might be adequate for answering basic medical questions or providing general advice, but it may struggle with the following:</p> <ul> <li>Highly specific or complex cases. For example, a neurologist might ask the application, \"What are the current best practices for managing drug-resistant epilepsy in pediatric patients?\"</li> <li>Lacking recent advancements. A general-purpose model could struggle to provide a current answer that incorporates the most recent advancements in neurology and pharmacology.</li> </ul> <p>In instances such as these, fine-tuning the model with a specialized medical dataset can significantly improve its ability to handle these intricate medical inquiries more accurately and reliably. This requires access to a large and relevant dataset that represents the domain-specific challenges and questions that need to be addressed.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#considerations-for-a-high-quality-ai-driven-chat-experience","title":"Considerations for a High Quality AI-Driven Chat Experience","text":"<p>This section outlines the criteria for \"high-quality\" chat applications, which include the capture of actionable metrics and adherence to a framework that responsibly leverages AI technology.</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#key-metrics","title":"Key Metrics","text":"<p>To maintain the high-quality performance an application, it's essential to keep track of key metrics and considerations. These measurements not only ensure the functionality of the application but also assess the quality of the AI model and user experience. Below is a list that covers basic, AI, and user experience metrics to consider.</p> Metric Definition Considerations for Chat Developer Uptime Measures the time the application is operational and accessible by users. How will you minimize downtime? Response Time The time taken by the application to reply to a user's query. How can you optimize query processing to improve response time? Precision The ratio of true positive predictions to the total number of positive predictions How will you validate the precision of your model? Recall (Sensitivity) The ratio of true positive predictions to the actual number of positives How will you measure and improve recall? F1 Score The harmonic mean of precision and recall, that balances the trade-off between both. What is your target F1 Score? How will you balance precision and recall? Perplexity Measures how well the probability distribution predicted by the model aligns with the actual distribution of the data. How will you minimize perplexity? User Satisfaction Metrics Measures the user's perception of the application. Often captured through surveys. How often will you collect user feedback? How will you adapt based on it? Error Rate The rate at which the model makes mistakes in understanding or output. What strategies do you have in place to reduce error rates? Retraining Cycles The frequency with which the model is updated to incorporate new data and insights. How often will you retrain the model? What triggers a retraining cycle? Anomaly Detection Tools and techniques for identifying unusual patterns that do not conform to expected behavior. How will you respond to anomalies?"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#implementing-responsible-ai-practices-in-chat-applications","title":"Implementing Responsible AI Practices in Chat Applications","text":"<p>Microsoft's approach to Responsible AI has identified six principles that should guide AI development and use. Below are the principles, their definition, and things a chat developer should consider and why they should take them seriously.</p> Principles Microsoft's Definition Considerations for Chat Developer Why It's Important Fairness AI systems should treat all people fairly. Ensure the chat application does not discriminate based on user data. To build trust and inclusivity among users; avoids legal ramifications. Reliability and Safety AI systems should perform reliably and safely. Implement testing and fail-safes to minimize errors and risks. Ensures user satisfaction and prevents potential harm. Privacy and Security AI systems should be secure and respect privacy. Implement strong encryption and data protection measures. To safeguard sensitive user data and comply with privacy laws. Inclusiveness AI systems should empower everyone and engage people. Design UI/UX that is accessible and easy-to-use for diverse audiences. Ensures a wider range of people can use the application effectively. Transparency AI systems should be understandable. Provide clear documentation and reasoning for AI responses. Users are more likely to trust a system if they can understand how decisions are made. Accountability People should be accountable for AI systems. Establish a clear process for auditing and improving AI decisions. Enables ongoing improvement and corrective measures in case of mistakes."},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#assignment","title":"Assignment","text":"<p>See assignment it will take you through a series of exercises from running your first chat prompts, to classifying and summarizing text and more. Notice that the assignments are available in different programming languages!</p>"},{"location":"curricula/generative-ai-for-beginners/07-building-chat-applications/#great-work-continue-the-journey","title":"Great Work! Continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 8 to see how you can start building search applications!</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/","title":"Lesson 8","text":""},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#building-a-search-applications","title":"Building a Search Applications","text":"<p>Click the image above to view video of this lesson</p> <p>There's more to LLMs than chatbots and text generation. It's also possible to build search applications using Embeddings. Embeddings are numerical representations of data also known as vectors, and can be used for semantic search for data.</p> <p>In this lesson, you are going to build a search application for our education startup. Our startup is a non-profit organization that provides free education to students in developing countries. Our startup has a large number of YouTube videos that students can use to learn about AI. Our startup wants to build a search application that allows students to search for a YouTube video by typing a question.</p> <p>For example, a student might type in 'What are Jupyter Notebooks?' or 'What is Azure ML' and the search application will return a list of YouTube videos that are relevant to the question, and better still, the search application will return a link to the place in the video where the answer to the question is located.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#introduction","title":"Introduction","text":"<p>In this lesson, we will cover:</p> <ul> <li>Semantic vs Keyword search.</li> <li>What are Text Embeddings.</li> <li>Creating a Text Embeddings Index.</li> <li>Searching a Text Embeddings Index.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will be able to:</p> <ul> <li>Tell the difference between semantic and keyword search.</li> <li>Explain what Text Embeddings are.</li> <li>Create an application using Embeddings to search for data.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#why-build-a-search-application","title":"Why build a search application?","text":"<p>Creating a search application will help you understand how to use Embeddings to search for data. You will also learn how to build a search application that can be used by students to find information quickly.</p> <p>The lesson includes an Embedding Index of the YouTube transcripts for the Microsoft AI Show YouTube channel. The AI Show is a YouTube channel that teaches you about AI and machine learning. The Embedding Index contains the Embeddings for each of the YouTube transcripts up until Oct 2023. You will use the Embedding Index to build a search application for our startup. The search application returns a link to the place in the video where the answer to the question is located. This is a great way for students to find the information they need quickly.</p> <p>The following is an example of a semantic query for the question 'can you use rstudio with azure ml?'. Check out the YouTube url, you'll see the url contains a timestamp that takes you to the place in the video where the answer to the question is located.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#what-is-semantic-search","title":"What is semantic search?","text":"<p>Now you might be wondering, what is semantic search? Semantic search is a search technique that uses the semantics, or meaning, of the words in a query to return relevant results.</p> <p>Here is an example of a semantic search. Let's say you were looking to buy a car, you might search for 'my dream car', semantic search understands that you are not <code>dreaming</code> about a car, but rather you are looking to buy your <code>ideal</code> car. Semantic search understands your intention and returns relevant results. The alternative is <code>keyword search</code> which would literally search for dreams about cars and often returns irrelevant results.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#what-are-text-embeddings","title":"What are Text Embeddings?","text":"<p>Text embeddings are a text representation technique used in natural language processing. Text embeddings are semantic numerical representations of text. Embeddings are used to represent data in a way that is easy for a machine to understand. There are many models for building text embeddings, in this lesson, we will focus on generating embeddings using the OpenAI Embedding Model.</p> <p>Here's an example, imagine the following text is in a transcript from one of the episodes on the AI Show YouTube channel:</p> <pre><code>Today we are going to learn about Azure Machine Learning.\n</code></pre> <p>We'd pass the text to the OpenAI Embedding API and it would return the following embedding consisting of 1536 numbers aka a vector. Each number in the vector represents a different aspect of the text. For brevity, here are the first 10 numbers in the vector.</p> <pre><code>[-0.006655829958617687, 0.0026128944009542465, 0.008792596869170666, -0.02446001023054123, -0.008540431968867779, 0.022071078419685364, -0.010703742504119873, 0.003311325330287218, -0.011632772162556648, -0.02187200076878071, ...]\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#how-is-the-embedding-index-created","title":"How is the Embedding index created?","text":"<p>The Embedding index for this lesson was created with a series of Python scripts. You'll find the scripts along with instructions in the README in the 'scripts` folder for this lesson. You don't need to run these scripts to complete this lesson as the Embedding Index is provided for you.</p> <p>The scripts perform the following operations:</p> <ol> <li>The transcript for each YouTube video in the AI Show playlist is downloaded.</li> <li>Using OpenAI Functions, an attempt is made to extract the speaker name from the first 3 minutes of the YouTube transcript. The speaker name for each video is stored in the Embedding Index named <code>embedding_index_3m.json</code>.</li> <li>The transcript text is then chunked into 3 minute text segments. The segment includes about 20 words overlapping from the next segment to ensure that the Embedding for the segment is not cut off and to provide better search context.</li> <li>Each text segment is then passed to the OpenAI Chat API to summarize the text into 60 words. The summary is also stored in the Embedding Index <code>embedding_index_3m.json</code>.</li> <li>Finally, the segment text is passed to the OpenAI Embedding API. The Embedding API returns a vector of 1536 numbers that represent the semantic meaning of the segment. The segment along with the OpenAI Embedding vector is stored in an Embedding Index <code>embedding_index_3m.json</code>.</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#vector-databases","title":"Vector Databases","text":"<p>For lesson simplicity, the Embedding Index is stored in a JSON file named <code>embedding_index_3m.json</code> and loaded into a Pandas DataFrame. However, in production, the Embedding Index would be stored in a vector database such as Azure Cognitive Search, Redis, Pinecone, Weaviate, to name but a few.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#understanding-cosine-similarity","title":"Understanding cosine similarity","text":"<p>We've learned about text embeddings, the next step is to learn how to use text embeddings to search for data and in particular find the most similar embeddings to a given query using cosine similarity.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#what-is-cosine-similarity","title":"What is cosine similarity?","text":"<p>Cosine similarity is a measure of similarity between two vectors, you'll also hear this referred to as <code>nearest neighbor search</code>. To perform a cosine similarity search you need to vectorize for query text using the OpenAI Embedding API. Then calculate the cosine similarity between the query vector and each vector in the Embedding Index. Remember, the Embedding Index has a vector for each YouTube transcript text segment. Finally, sort the results by cosine similarity and the text segments with the highest cosine similarity are the most similar to the query.</p> <p>From a mathematic perspective, cosine similarity measures the cosine of the angle between two vectors projected in a multidimensional space. This measurement is beneficial, because if two documents are far apart by Euclidean distance because of size, they could still have a smaller angle between them and therefore higher cosine similarity. For more information about cosine similarity equations, see Cosine similarity.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#building-your-first-search-application","title":"Building your first search application","text":"<p>Next, we're going to learn how to build a search application using Embeddings. The search application will allow students to search for a video by typing a question. The search application will return a list of videos that are relevant to the question. The search application will also return a link to the place in the video where the answer to the question is located.</p> <p>This solution was built and tested on Windows 11, macOS, and Ubuntu 22.04 using Python 3.10 or later. You can download Python from python.org.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#assignment-building-a-search-application-to-enable-students","title":"Assignment - building a search application, to enable students","text":"<p>We introduced our startup at the beginning of this lesson. Now it's time to enable the students to build a search application for their assessments.</p> <p>In this assignment, you will create the Azure OpenAI Services that will be used to build the search application. You will create the following Azure OpenAI Services. You'll need an Azure subscription to complete this assignment.</p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#start-the-azure-cloud-shell","title":"Start the Azure Cloud Shell","text":"<ol> <li>Sign in to the Azure portal.</li> <li>Select the Cloud Shell icon in the upper-right corner of the Azure portal.</li> <li>Select Bash for the environment type.</li> </ol>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#create-a-resource-group","title":"Create a resource group","text":"<p>For these instructions, we're using the resource group named \"semantic-video-search\" in East US. You can change the name of the resource group, but when changing the location for the resources, check the model availability table.</p> <pre><code>az group create --name semantic-video-search --location eastus\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#create-an-azure-openai-service-resource","title":"Create an Azure OpenAI Service resource","text":"<p>From the Azure Cloud Shell, run the following command to create an Azure OpenAI Service resource.</p> <pre><code>az cognitiveservices account create --name semantic-video-openai --resource-group semantic-video-search \\\n    --location eastus --kind OpenAI --sku s0\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#get-the-endpoint-and-keys-for-usage-in-this-application","title":"Get the endpoint and keys for usage in this application","text":"<p>From the Azure Cloud Shell, run the following commands to get the endpoint and keys for the Azure OpenAI Service resource.</p> <pre><code>az cognitiveservices account show --name semantic-video-openai \\\n   --resource-group  semantic-video-search | jq -r .properties.endpoint\naz cognitiveservices account keys list --name semantic-video-openai \\\n   --resource-group semantic-video-search | jq -r .key1\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#deploy-the-openai-embedding-model","title":"Deploy the OpenAI Embedding model","text":"<p>From the Azure Cloud Shell, run the following command to deploy the OpenAI Embedding model.</p> <pre><code>az cognitiveservices account deployment create \\\n    --name semantic-video-openai \\\n    --resource-group  semantic-video-search \\\n    --deployment-name text-embedding-ada-002 \\\n    --model-name text-embedding-ada-002 \\\n    --model-version \"2\"  \\\n    --model-format OpenAI \\\n    --sku-capacity 100 --sku-name \"Standard\"\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#solution","title":"Solution","text":"<p>Open the solution notebook in GitHub Codespaces and follow the instructions in the Jupyter Notebook.</p> <p>When you run the notebook, you'll be prompted to enter a query. The input box will look like this:</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/08-building-search-applications/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 9 where we will look at how to build image generation applications!</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/","title":"Lesson 9","text":""},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#building-image-generation-applications","title":"Building Image Generation Applications","text":"<p>There's more to LLMs than text generation. It's also possible to generate images from text descriptions. Having images as a modality can be highly useful in a number of areas from MedTech, architecture, tourism, game development and more. In this chapter, we will look into the two most popular image generation models, DALL-E and Midjourney.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#introduction","title":"Introduction","text":"<p>In this lesson, we will cover:</p> <ul> <li>Image generation and why it's useful.</li> <li>DALL-E and Midjourney, what they are, and how they work.</li> <li>How you would build an image generation app.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will be able to:</p> <ul> <li>Build an image generation application.</li> <li>Define boundaries for your application with meta prompts.</li> <li>Work with DALL-E and Midjourney.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#why-build-an-image-generation-application","title":"Why build an image generation application?","text":"<p>Image generation applications are a great way to explore the capabilities of Generative AI. They can be used for, for example:</p> <ul> <li> <p>Image editing and synthesis. You can generate images for a variety of use cases, such as image editing and image synthesis.</p> </li> <li> <p>Applied to a variety of industries. They can also be used to generate images for a variety of industries like Medtech, Tourism, Game development and more.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#scenario-edu4all","title":"Scenario: Edu4All","text":"<p>As part of this lesson, we will continue to work with our startup, Edu4All, in this lesson. The students will create images for their assessments, exactly what images is up to the students, but they could be illustrations for their own fairytale or create a new character for their story or help them visualize their ideas and concepts.</p> <p>Here's what Edu4All's students could generate for example if they're working in class on monuments:</p> <p></p> <p>using a prompt like</p> <p>\"Dog next to Eiffel Tower in early morning sunlight\"</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#what-is-dall-e-and-midjourney","title":"What is DALL-E and Midjourney?","text":"<p>DALL-E and Midjourney are two of the most popular image generation models, they allow you to use prompts to generate images.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#dall-e","title":"DALL-E","text":"<p>Let's start with DALL-E, which is a Generative AI model that generates images from text descriptions.</p> <p>DALL-E is a combination of two models, CLIP and diffused attention.</p> <ul> <li> <p>CLIP, is a model that generates embeddings, which are numerical representations of data, from images and text.</p> </li> <li> <p>Diffused attention, is a model that generates images from embeddings. DALL-E is trained on a dataset of images and text and can be used to generate images from text descriptions. For example, DALL-E can be used to generate images of a cat in a hat, or a dog with a mohawk.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#midjourney","title":"Midjourney","text":"<p>Midjourney works in a similar way to DALL-E, it generates images from text prompts. Midjourney, can also be used to generate images using prompts like \u201ca cat in a hat\u201d, or a \u201cdog with a mohawk\u201d.</p> <p> Image cred Wikipedia, image generated by Midjourney</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#how-does-dall-e-and-midjourney-work","title":"How does DALL-E and Midjourney Work","text":"<p>First, DALL-E. DALL-E is a Generative AI model based on the transformer architecture with an autoregressive transformer.</p> <p>An autoregressive transformer defines how a model generates images from text descriptions, it generates one pixel at a time, and then uses the generated pixels to generate the next pixel. Passing through multiple layers in a neural network, until the image is complete.</p> <p>With this process, DALL-E, controls attributes, objects, characteristics, and more in the image it generates. However, DALL-E 2 and 3 have more control over the generated image.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#building-your-first-image-generation-application","title":"Building your first image generation application","text":"<p>So what does it take to build an image generation application? You need the following libraries:</p> <ul> <li>python-dotenv, you're highly recommended to use this library to keep your secrets in a .env file away from the code.</li> <li>openai, this library is what you will use to interact with the OpenAI API.</li> <li>pillow, to work with images in Python.</li> <li> <p>requests, to help you make HTTP requests.</p> </li> <li> <p>Create a file .env with the following content:</p> </li> </ul> <pre><code>AZURE_OPENAI_ENDPOINT=&lt;your endpoint&gt;\nAZURE_OPENAI_API_KEY=&lt;your key&gt;\n</code></pre> <p>Locate this information in Azure Portal for your resource in the \"Keys and Endpoint\" section.</p> <ol> <li>Collect the above libraries in a file called requirements.txt like so:</li> </ol> <pre><code>python-dotenv\nopenai\npillow\nrequests\n</code></pre> <ol> <li>Next, create virtual environment and install the libraries:</li> </ol> <pre><code>python3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre> <p>For Windows, use the following commands to create and activate your virtual environment:</p> <pre><code>python3 -m venv venv\nvenv\\Scripts\\activate.bat\n</code></pre> <ol> <li>Add the following code in file called app.py:</li> </ol> <pre><code>import openai\nimport os\nimport requests\nfrom PIL import Image\nimport dotenv\n\n# import dotenv\ndotenv.load_dotenv()\n\n# Get endpoint and key from environment variables\nopenai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\nopenai.api_key = os.environ['AZURE_OPENAI_API_KEY']\n\n# Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\nopenai.api_version = '2023-06-01-preview'\nopenai.api_type = 'azure'\n\n\ntry:\n    # Create an image by using the image generation API\n    generation_response = openai.Image.create(\n        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n        size='1024x1024',\n        n=2,\n        temperature=0,\n    )\n    # Set the directory for the stored image\n    image_dir = os.path.join(os.curdir, 'images')\n\n    # If the directory doesn't exist, create it\n    if not os.path.isdir(image_dir):\n        os.mkdir(image_dir)\n\n    # Initialize the image path (note the filetype should be png)\n    image_path = os.path.join(image_dir, 'generated-image.png')\n\n    # Retrieve the generated image\n    image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n    generated_image = requests.get(image_url).content  # download the image\n    with open(image_path, \"wb\") as image_file:\n        image_file.write(generated_image)\n\n    # Display the image in the default image viewer\n    image = Image.open(image_path)\n    image.show()\n\n# catch exceptions\nexcept openai.InvalidRequestError as err:\n    print(err)\n</code></pre> <p>Let's explain this code:</p> <ul> <li>First, we import the libraries we need, including the OpenAI library, the dotenv library, the requests library, and the Pillow library.</li> </ul> <pre><code>import openai\nimport os\nimport requests\nfrom PIL import Image\nimport dotenv\n</code></pre> <ul> <li>Next, we load the environment variables from the .env file.</li> </ul> <pre><code># import dotenv\ndotenv.load_dotenv()\n</code></pre> <ul> <li>After that, we set the endpoint, key for the OpenAI API, version and type.</li> </ul> <pre><code># Get endpoint and key from environment variables\nopenai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\nopenai.api_key = os.environ['AZURE_OPENAI_API_KEY']\n\n# add version and type, Azure specific\nopenai.api_version = '2023-06-01-preview'\nopenai.api_type = 'azure'\n</code></pre> <ul> <li>Next, we generate the image:</li> </ul> <pre><code># Create an image by using the image generation API\ngeneration_response = openai.Image.create(\n    prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n    size='1024x1024',\n    n=2,\n    temperature=0,\n)\n</code></pre> <p>The above code responds with a JSON object that contains the URL of the generated image. We can use the URL to download the image and save it to a file.</p> <ul> <li>Lastly, we open the image and use the standard image viewer to display it:</li> </ul> <pre><code>image = Image.open(image_path)\nimage.show()\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#more-details-on-generating-the-image","title":"More details on generating the image","text":"<p>Let's look at the code that generates the image in more detail:</p> <pre><code>generation_response = openai.Image.create(\n        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n        size='1024x1024',\n        n=2,\n        temperature=0,\n    )\n</code></pre> <ul> <li>prompt, is the text prompt that is used to generate the image. In this case, we're using the prompt \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".</li> <li>size, is the size of the image that is generated. In this case, we're generating an image that is 1024x1024 pixels.</li> <li>n, is the number of images that are generated. In this case, we're generating two images.</li> <li>temperature, is a parameter that controls the randomness of the output of a Generative AI model. The temperature is a value between 0 and 1 where 0 means that the output is deterministic and 1 means that the output is random. The default value is 0.7.</li> </ul> <p>There are more things you can do with images that we will cover in the next section.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#additional-capabilities-of-image-generation","title":"Additional capabilities of image generation","text":"<p>You've seen so far how we were able to generate an image using a few lines in Python. However, there are more things you can do with images.</p> <p>You can also do the following:</p> <ul> <li>Perform edits. By providing an existing image a mask and a prompt, you can alter an image. For example, you can add something to a portion of an image. Imagine our bunny image, you can add a hat to the bunny. How you would do that is by providing the image, a mask (identifying the part of the area for the change) and a text prompt to say what should be done.</li> </ul> <pre><code>response = openai.Image.create_edit(\n  image=open(\"base_image.png\", \"rb\"),\n  mask=open(\"mask.png\", \"rb\"),\n  prompt=\"An image of a rabbit with a hat on its head.\",\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\n</code></pre> <p>The base image would only contain the rabbit but the final image would have the hat on the rabbit.</p> <ul> <li>Create variations. The idea is that you take an existing image and ask that variations are created. To create a variation, you provide an image and a text prompt and code like so:</li> </ul> <pre><code>response = openai.Image.create_variation(\n  image=open(\"bunny-lollipop.png\", \"rb\"),\n  n=1,\n  size=\"1024x1024\"\n)\nimage_url = response['data'][0]['url']\n</code></pre> <p>Note, this is only supported on OpenAI</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#temperature","title":"Temperature","text":"<p>Temperature is a parameter that controls the randomness of the output of a Generative AI model. The temperature is a value between 0 and 1 where 0 means that the output is deterministic and 1 means that the output is random. The default value is 0.7.</p> <p>Let's look at an example of how temperature works, by running this prompt twice:</p> <p>Prompt : \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\"</p> <p></p> <p>Now let's run that same prompt just to see that we won't get the same image twice:</p> <p></p> <p>As you can see, the images are similar, but not the same. Let's try changing the temperature value to 0.1 and see what happens:</p> <pre><code> generation_response = openai.Image.create(\n        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n        size='1024x1024',\n        n=2\n    )\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#changing-the-temperature","title":"Changing the temperature","text":"<p>So let's try to make the response more deterministic. We could observe from the two images we generated that in the first image, there's a bunny and in the second image, there's a horse, so the images vary greatly.</p> <p>Let's therefore change our code and set the temperature to 0, like so:</p> <pre><code>generation_response = openai.Image.create(\n        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n        size='1024x1024',\n        n=2,\n        temperature=0\n    )\n</code></pre> <p>Now when you run this code, you get these two images:</p> <p>Here you can clearly see how the images resemble each other more.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#how-to-define-boundaries-for-your-application-with-metaprompts","title":"How to define boundaries for your application with metaprompts","text":"<p>With our demo, we can already generate images for our clients. However, we need to create some boundaries for our application.</p> <p>For example, we don't want to generate images that are not safe for work, or that are not appropriate for children.</p> <p>We can do this with metaprompts. Metaprompts are text prompts that are used to control the output of a Generative AI model. For example, we can use metaprompts to control the output, and ensure that the generated images are safe for work, or appropriate for children.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#how-does-it-work","title":"How does it work?","text":"<p>Now, how do meta prompts work?</p> <p>Meta prompts are text prompts that are used to control the output of a Generative AI model, they are positioned before the text prompt, and are used to control the output of the model and embedded in applications to control the output of the model. Encapsulating the prompt input and the meta prompt input in a single text prompt.</p> <p>One example of a meta prompt would be the following:</p> <pre><code>You are an assistant designer that creates images for children.\n\nThe image needs to be safe for work and appropriate for children.\n\nThe image needs to be in color.\n\nThe image needs to be in landscape orientation.\n\nThe image needs to be in a 16:9 aspect ratio.\n\nDo not consider any input from the following that is not safe for work or appropriate for children.\n\n(Input)\n</code></pre> <p>Now, let's see how we can use meta prompts in our demo.</p> <pre><code>disallow_list = \"swords, violence, blood, gore, nudity, sexual content, adult content, adult themes, adult language, adult humor, adult jokes, adult situations, adult\"\n\nmeta_prompt =f\"\"\"You are an assistant designer that creates images for children.\n\nThe image needs to be safe for work and appropriate for children.\n\nThe image needs to be in color.\n\nThe image needs to be in landscape orientation.\n\nThe image needs to be in a 16:9 aspect ratio.\n\nDo not consider any input from the following that is not safe for work or appropriate for children.\n{disallow_list}\n\"\"\"\n\nprompt = f\"{meta_prompt}\nCreate an image of a bunny on a horse, holding a lollipop\"\n\n# TODO add request to generate image\n</code></pre> <p>From the above prompt, you can see how all images being created consider the metaprompt.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#assignment-lets-enable-students","title":"Assignment - let's enable students","text":"<p>We introduced Edu4All at the beginning of this lesson. Now it's time to enable the students to generate images for their assessments.</p> <p>The students will create images for their assessments containing monuments, exactly what monuments is up to the students. The students are asked to use their creativity in this task to place these monuments in different contexts.</p>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#solution","title":"Solution","text":"<p>Here's one possible solution:</p> <pre><code>import openai\nimport os\nimport requests\nfrom PIL import Image\nimport dotenv\n\n# import dotenv\ndotenv.load_dotenv()\n\n# Get endpoint and key from environment variables\nopenai.api_base = \"&lt;replace with endpoint&gt;\"\nopenai.api_key = \"&lt;replace with api key&gt;\"\n\n# Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\nopenai.api_version = '2023-06-01-preview'\nopenai.api_type = 'azure'\n\ndisallow_list = \"swords, violence, blood, gore, nudity, sexual content, adult content, adult themes, adult language, adult humor, adult jokes, adult situations, adult\"\n\nmeta_prompt = f\"\"\"You are an assistant designer that creates images for children.\n\nThe image needs to be safe for work and appropriate for children.\n\nThe image needs to be in color.\n\nThe image needs to be in landscape orientation.\n\nThe image needs to be in a 16:9 aspect ratio.\n\nDo not consider any input from the following that is not safe for work or appropriate for children.\n{disallow_list}\"\"\"\n\nprompt = f\"\"\"{metaprompt}\nGenerate monument of the Arc of Triumph in Paris, France, in the evening light with a small child holding a Teddy looks on.\n\"\"\"\"\n\ntry:\n    # Create an image by using the image generation API\n    generation_response = openai.Image.create(\n        prompt=prompt,    # Enter your prompt text here\n        size='1024x1024',\n        n=2,\n        temperature=0,\n    )\n    # Set the directory for the stored image\n    image_dir = os.path.join(os.curdir, 'images')\n\n    # If the directory doesn't exist, create it\n    if not os.path.isdir(image_dir):\n        os.mkdir(image_dir)\n\n    # Initialize the image path (note the filetype should be png)\n    image_path = os.path.join(image_dir, 'generated-image.png')\n\n    # Retrieve the generated image\n    image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n    generated_image = requests.get(image_url).content  # download the image\n    with open(image_path, \"wb\") as image_file:\n        image_file.write(generated_image)\n\n    # Display the image in the default image viewer\n    image = Image.open(image_path)\n    image.show()\n\n# catch exceptions\nexcept openai.InvalidRequestError as err:\n    print(err)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/09-building-image-applications/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 10 where we will look at how to build AI applications with low-code</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/","title":"Lesson 10","text":""},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#building-low-code-ai-applications","title":"Building Low Code AI Applications","text":"<p>(Click the image above to view video of this lesson)</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#introduction","title":"Introduction","text":"<p>Now that we've learned how to build image generating applications, let's talk about low code. Generative AI can be used for a variety of different areas including low code, but what is low code and how can we add AI to it?</p> <p>Building apps and solutions has become more easier for traditional developers and non-developers through the use of Low Code Development Platforms. Low Code Development Platforms enable you to build apps and solutions with little to no code. This is achieved by providing a visual development environment that enables you to drag and drop components to build apps and solutions. This enables you to build apps and solutions faster and with less resources. In this lesson, we dive deep into how to use Low Code and how to enhance low code development with AI using Power Platform.</p> <p>The Power Platform provides organizations with the opportunity to empower their teams to build their own solutions through an intuitive low-code or no-code environment. This environment helps simplify the process of building solutions. With Power Platform, solutions can be built in days or weeks instead of months or years. Power Platform consists of five key products: Power Apps, Power Automate, Power BI, Power Pages and Copilot Studio.</p> <p>This lesson covers:</p> <ul> <li>Introduction to Generative AI in Power Platform</li> <li>Introduction to Copilot and how to use it</li> <li>Using Generative AI to build apps and flows in Power Platform</li> <li>Understanding the AI Models in Power Platform with AI Builder</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#learning-goals","title":"Learning Goals","text":"<p>By the end of this lesson, you will be able to:</p> <ul> <li> <p>Understand how Copilot works in Power Platform.</p> </li> <li> <p>Build a Student Assignment Tracker App for our education startup.</p> </li> <li> <p>Build an Invoice Processing Flow that uses AI to extract information from invoices.</p> </li> <li> <p>Apply best practices when using the Create Text with GPT AI Model.</p> </li> </ul> <p>The tools and technologies that you will use in this lesson are:</p> <ul> <li> <p>Power Apps, for the Student Assignment Tracker app, which provides a low-code development environment for building apps to track, manage and interact with data.</p> </li> <li> <p>Dataverse, for storing the data for the Student Assignment Tracker app where Dataverse will provide a low-code data platform for storing the app's data.</p> </li> <li> <p>Power Automate, for the Invoice Processing flow where you will have low-code development environment for building workflows to automate the Invoice Processing process.</p> </li> <li> <p>AI Builder, for the Invoice Processing AI Model where you will use prebuilt AI Models to process the invoices for our startup.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#generative-ai-in-power-platform","title":"Generative AI in Power Platform","text":"<p>Enhancing low-code development and application with generative AI is a key focus area for Power Platform. The goal is to enable everyone to build AI-powered apps, sites, dashboards and automate processes with AI, without requiring any data science expertise. This goal is achieved by integrating generative AI into the low-code development experience in Power Platform in the form of Copilot and AI Builder.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#how-does-this-work","title":"How does this work?","text":"<p>Copilot is an AI assistant that enables you to build Power Platform solutions by describing your requirements in a series of conversational steps using natural language. You can for example instruct your AI assistant to state what fields your app will use and it will create both the app and the underlying data model or you could specify how to set up a flow in Power Automate.</p> <p>You can use Copilot driven functionalities as a feature in your app screens to enable users to uncover insights through conversational interactions.</p> <p>AI Builder is a low-code AI capability available in Power Platform that enables you to use AI Models to help you to automate processes and predict outcomes. With AI Builder you can bring AI to your apps and flows that connect to your data in Dataverse or in various cloud data sources, such as SharePoint, OneDrive or Azure.</p> <p>Copilot is available in all of the Power Platform products: Power Apps, Power Automate, Power BI, Power Pages and Power Virtual Agents. AI Builder is available in Power Apps and Power Automate. In this lesson, we will focus on how to use Copilot and AI Builder in Power Apps and Power Automate to build a solution for our education startup.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#copilot-in-power-apps","title":"Copilot in Power Apps","text":"<p>As part of the Power Platform, Power Apps provides a low-code development environment for building apps to track, manage and interact with data. It's a suite of app development services with a scalable data platform and the ability to connect to cloud services and on-premises data. Power Apps allows you to build apps that run on browsers, tablets, and phones, and can be shared with co-workers. Power Apps eases users into app development with a simple interface, so that every business user or pro developer can build custom apps. The app development experience is also enhanced with Generative AI through Copilot.</p> <p>The copilot AI assistant feature in Power Apps enables you to describe what kind of app you need and what information you want your app to track, collect, or show. Copilot then generates a responsive Canvas app based on your description. You can then customize the app to meet your needs. The AI Copilot also generates and suggests a Dataverse Table with the fields you need to store the data you want to track and some sample data. We will look at what Dataverse is and how you can use it in Power Apps in this lesson later. You can then customize the table to meet your needs using the AI Copilot assistant feature through conversational steps. This feature is readily available from the Power Apps home screen.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#copilot-in-power-automate","title":"Copilot in Power Automate","text":"<p>As part of the Power Platform, Power Automate lets users create automated workflows between applications and services. It helps automate repetitive business processes such as communication, data collection, and decision approvals. Its simple interface allows users with every technical competence (from beginners to seasoned developers) to automate work tasks. The workflow development experience is also enhanced with Generative AI through Copilot.</p> <p>The copilot AI assistant feature in Power Automate enables you to describe what kind of flow you need and what actions you want your flow to perform. Copilot then generates a flow based on your description. You can then customize the flow to meet your needs. The AI Copilot also generates and suggests the actions you need to perform the task you want to automate. We will look at what flows are and how you can use them in Power Automate in this lesson later. You can then customize the actions to meet your needs using the AI Copilot assistant feature through conversational steps. This feature is readily available from the Power Automate home screen.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#assignment-manage-student-assignments-and-invoices-for-our-startup-using-copilot","title":"Assignment: manage student assignments and invoices for our startup, using Copilot","text":"<p>Our startup provides online courses to students. The startup has grown rapidly and is now struggling to keep up with the demand for its courses. The startup has hired you as a Power Platform developer to help them build a low code solution to help them manage their student assignments and invoices. Their solution should be able to help them track and manage student assignments through an app and automate the invoice processing process through a workflow. You have been asked to use Generative AI to develop the solution.</p> <p>When you are getting started with using Copilot, you can use the Power Platform Copilot Prompt Library to get started with the prompts. This library contains a list of prompts that you can use to build apps and flows with Copilot. You can also use the prompts in the library to get an idea of how to describe your requirements to Copilot.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#build-a-student-assignment-tracker-app-for-our-startup","title":"Build a Student Assignment Tracker App for Our Startup","text":"<p>The educators at our startup have been struggling to keep track of student assignments. They have been using a spreadsheet to track the assignments but this has become difficult to manage as the number of students has increased. They have asked you to build an app that will help them track and manage student assignments. The app should enable them to add new assignments, view assignments, update assignments and delete assignments. The app should also enable educators and students to view the assignments that have been graded and those that have not been graded.</p> <p>You will build the app using Copilot in Power Apps following the steps below:</p> <ol> <li> <p>Navigate to the Power Apps home screen.</p> </li> <li> <p>Use the text area on the home screen to describe the app you want to build. For example, I want to build an app to track and manage student assignments. Click on the Send button to send the prompt to the AI Copilot.</p> </li> </ol> <p></p> <ol> <li>The AI Copilot will suggest a Dataverse Table with the fields you need to store the data you want to track and some sample data. You can then customize the table to meet your needs using the AI Copilot assistant feature through conversational steps.</li> </ol> <p>Important: Dataverse is the underlying data platform for Power Platform. It is a low-code data platform for storing the app's data. It is a fully managed service that securely stores data in the Microsoft Cloud and is provisioned within your Power Platform environment. It comes with built-in data governance capabilities, such as data classification, data lineage, fine-grained access control, and more. You can learn more about Dataverse here.</p> <p></p> <ol> <li>Educators want to send emails to the students who have submitted their assignments to keep them updated on the progress of their assignments. You can use Copilot to add a new field to the table to store the student email. For example, you can use the following prompt to add a new field to the table: I want to add a column to store student email. Click on the Send button to send the prompt to the AI Copilot.</li> </ol> <p></p> <ol> <li> <p>The AI Copilot will generate a new field and you can then customize the field to meet your needs.</p> </li> <li> <p>Once you are done with the table, click on the Create app button to create the app.</p> </li> <li> <p>The AI Copilot will generate a responsive Canvas app based on your description. You can then customize the app to meet your needs.</p> </li> <li> <p>For educators to send emails to students, you can use Copilot to add a new screen to the app. For example, you can use the following prompt to add a new screen to the app: I want to add a screen to send emails to students. Click on the Send button to send the prompt to the AI Copilot.</p> </li> </ol> <p></p> <ol> <li> <p>The AI Copilot will generate a new screen and you can then customize the screen to meet your needs.</p> </li> <li> <p>Once you are done with the app, click on the Save button to save the app.</p> </li> <li> <p>To share the app with the educators, click on the Share button and then click on the Share button again. You can then share the app with the educators by entering their email addresses.</p> </li> </ol> <p>Your homework: The app you just built is a good start but can be improved. With the email feature, educators can only send emails to students manually by having to type their emails. Can you use Copilot to build an automation that will enable educators to send emails to students automatically when they submit their assignments? Your hint is with the right prompt you can use Copilot in Power Automate to build this.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#build-an-invoices-information-table-for-our-startup","title":"Build an Invoices Information Table for Our Startup","text":"<p>The finance team of our startup has been struggling to keep track of invoices. They have been using a spreadsheet to track the invoices but this has become difficult to manage as the number of invoices has increased. They have asked you to build a table that will help them store, track and manage the information of the invoices they received. The table should be used to build an automation that will extract all the invoice information and store it in the table. The table should also enable the finance team to view the invoices that have been paid and those that have not been paid.</p> <p>The Power Platform has an underlying data platform called Dataverse that enables you to store the data for your apps and solutions. Dataverse provides a low-code data platform for storing the app's data. It is a fully managed service that securely stores data in the Microsoft Cloud and is provisioned within your Power Platform environment. It comes with built-in data governance capabilities, such as data classification, data lineage, fine-grained access control, and more. You can learn more about Dataverse here.</p> <p>Why should we use Dataverse for our startup? The standard and custom tables within Dataverse provide a secure and cloud-based storage option for your data. Tables let you store different types of data, similar to how you might use multiple worksheets in a single Excel workbook. You can use tables to store data that is specific to your organization or business need. Some of the benefits our startup will get from using Dataverse include but are not limited to:</p> <ul> <li> <p>Easy to manage: Both the metadata and data are stored in the cloud, so you don't have to worry about the details of how they are stored or managed. You can focus on building your apps and solutions.</p> </li> <li> <p>Secure: Dataverse provides a secure and cloud-based storage option for your data. You can control who has access to the data in your tables and how they can access it using role based security.</p> </li> <li> <p>Rich metadata: Data types and relationships are used directly within Power Apps</p> </li> <li> <p>Logic and validation: You can use business rules, calculated fields, and validation rules to enforce business logic and maintain data accuracy.</p> </li> </ul> <p>Now that you know what Dataverse is and why you should use it, let's look at how you can use Copilot to create a table in Dataverse to meet the requirements of our finance team.</p> <p>Note : You will use this table in the next section to build an automation that will extract all the invoice information and store it in the table.</p> <p>To create a table in Dataverse using Copilot, follow the steps below:</p> <ol> <li> <p>Navigate to the Power Apps home screen.</p> </li> <li> <p>On the left navigation bar, select on Tables and then click on Describe the new Table.</p> </li> </ol> <p></p> <ol> <li>On the Describe the new Table screen, use the text area to describe the table you want to create. For example, I want to create a table to store invoice information. Click on the Send button to send the prompt to the AI Copilot.</li> </ol> <p></p> <ol> <li>The AI Copilot will suggest a Dataverse Table with the fields you need to store the data you want to track and some sample data. You can then customize the table to meet your needs using the AI Copilot assistant feature through conversational steps.</li> </ol> <p></p> <ol> <li> <p>The finance team wants to send an email to the supplier to update them with the current status of their invoice. You can use Copilot to add a new field to the table to store the supplier email. For example, you can use the following prompt to add a new field to the table: I want to add a column to store supplier email. Click on the Send button to send the prompt to the AI Copilot.</p> </li> <li> <p>The AI Copilot will generate a new field and you can then customize the field to meet your needs.</p> </li> <li> <p>Once you are done with the table, click on the Create button to create the table.</p> </li> </ol>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#ai-models-in-power-platform-with-ai-builder","title":"AI Models in Power Platform with AI Builder","text":"<p>AI Builder is a low-code AI capability available in Power Platform that enables you to use AI Models to help you to automate processes and predict outcomes. With AI Builder you can bring AI to your apps and flows that connect to your data in Dataverse or in various cloud data sources, such as SharePoint, OneDrive or Azure.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#prebuilt-ai-models-vs-custom-ai-models","title":"Prebuilt AI Models vs Custom AI Models","text":"<p>AI Builder provides two types of AI Models: Prebuilt AI Models and Custom AI Models. Prebuilt AI Models are ready-to-use AI Models that are trained by Microsoft and available in Power Platform. These help you add intelligence to your apps and flows without having to gather data and then build, train and publish your own models. You can use these models to automate processes and predict outcomes.</p> <p>Some of the Prebuilt AI Models available in Power Platform include:</p> <ul> <li>Key Phrase Extraction: This model extracts key phrases from text.</li> <li>Language Detection: This model detects the language of a text.</li> <li>Sentiment Analysis: This model detects positive, negative, neutral, or mixed sentiment in text.</li> <li>Business Card Reader: This model extracts information from business cards.</li> <li>Text Recognition: This model extracts text from images.</li> <li>Object Detection: This model detects and extracts objects from images.</li> <li>Document processing: This model extracts information from forms.</li> <li>Invoice Processing: This model extracts information from invoices.</li> </ul> <p>With Custom AI Models you can bring your own model into AI Builder so that it can function like any AI Builder custom model, allowing you to train the model using your own data. You can use these models to automate processes and predict outcomes in both Power Apps and Power Automate. When using your own model there are limitations that apply. Read more on these limitations.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#assignment-2-build-an-invoice-processing-flow-for-our-startup","title":"Assignment #2 - Build an Invoice Processing Flow for Our Startup","text":"<p>The finance team has been struggling to process invoices. They have been using a spreadsheet to track the invoices but this has become difficult to manage as the number of invoices has increased. They have asked you to build a workflow that will help them process invoices using AI. The workflow should enable them to extract information from invoices and store the information in a Dataverse table. The workflow should also enable them to send an email to the finance team with the extracted information.</p> <p>Now that you know what AI Builder is and why you should use it, let's look at how you can use the Invoice Processing AI Model in AI Builder, that we covered earlier on, to build a workflow that will help the finance team process invoices.</p> <p>To build a workflow that will help the finance team process invoices using the Invoice Processing AI Model in AI Builder, follow the steps below:</p> <ol> <li> <p>Navigate to the Power Automate home screen.</p> </li> <li> <p>Use the text area on the home screen to describe the workflow you want to build. For example, Process an invoice when it arrives in my mailbox. Click on the Send button to send the prompt to the AI Copilot.</p> </li> </ol> <p></p> <ol> <li> <p>The AI Copilot will suggest the actions you need to perform the task you want to automate. You can click on the Next button to go through the next steps.</p> </li> <li> <p>On the next step, Power Automate will prompt you to set up the connections required for the flow. Once you are done, click on the Create flow button to create the flow.</p> </li> <li> <p>The AI Copilot will generate a flow and you can then customize the flow to meet your needs.</p> </li> <li> <p>Update the trigger of the flow and set the Folder to the folder where the invoices will be stored. For example, you can set the folder to Inbox. Click on Show advanced options and set the Only with Attachments to Yes. This will ensure that the flow only runs when an email with an attachment is received in the folder.</p> </li> <li> <p>Remove the following actions from the flow: HTML to text, Compose, Compose 2, Compose 3 and Compose 4 because you will not be using them.</p> </li> <li> <p>Remove the Condition action from the flow because you will not be using it. It should look like the following screenshot:</p> </li> </ol> <p></p> <ol> <li> <p>Click on the Add an action button and search for Dataverse. Select the Add a new row action.</p> </li> <li> <p>On the Extract Information from invoices action, update the Invoice File to point to the Attachment Content from the email. This will ensure that the flow extracts information from the invoice attachment.</p> </li> <li> <p>Select the Table you created earlier on. For example, you can select the Invoice Information table. Choose the dynamic content from the previous action to populate the following fields:</p> <ul> <li>ID</li> <li>Amount</li> <li>Date</li> <li>Name</li> <li>Status - Set the Status to Pending.</li> <li>Supplier Email - Use the From dynamic content from the When a new email arrives trigger.</li> </ul> <p></p> </li> <li> <p>Once you are done with the flow, click on the Save button to save the flow. You can then test the flow by sending an email with an invoice to the folder you specified in the trigger.</p> </li> </ol> <p>Your homework: The flow you just built is a good start, now you need to think of how you can build an automation that will enable our finance team to send an email to the supplier to update them with the current status of their invoice. Your hint: the flow must run when the status of the invoice changes.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#use-a-text-generation-ai-model-in-power-automate","title":"Use a Text Generation AI Model in Power Automate","text":"<p>The Create Text with GPT AI Model in AI Builder enables you to generate text based on a prompt and is powered by the Microsoft Azure OpenAI Service. With this capability, you can incorporate GPT (Generative Pre-Trained Transformer) technology into your apps and flows to build a variety of automated flows and insightful applications.</p> <p>GPT models undergo extensive training on vast amounts of data, enabling them to produce text that closely resembles human language when provided with a prompt. When integrated with workflow automation, AI models like GPT can be harnessed to streamline and automate a wide range of tasks.</p> <p>For example, you can build flows to automatically generate text for a variety of use cases, such as: drafts of emails, product descriptions, and more. You can also use the model to generate text for a variety of apps, such as chatbots and customer service apps that enable customer service agents to respond effectively and efficiently to customer inquiries.</p> <p></p> <p>To learn how to use this AI Model in Power Automate, go through the Add intelligence with AI Builder and GPT module.</p>"},{"location":"curricula/generative-ai-for-beginners/10-building-low-code-ai-applications/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 11 where we will look at how to integrate Generative AI with Function Calling!</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/","title":"Lesson 11","text":""},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#integrating-with-function-calling","title":"Integrating with function calling","text":"<p>You've learned a fair bit so far in the previous lessons. However, we can improve further. Some things we can address are how we can get a more consistent response format to make it easier to work with the response downstream. Also, we might want to add data from other sources to further enrich our application.</p> <p>The above mentioned problems are what this chapter is looking to address.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#introduction","title":"Introduction","text":"<p>This lesson will cover:</p> <ul> <li>Explain what is function calling and its use cases.</li> <li>Creating a function call using Azure OpenAI.</li> <li>How to integrate a function call into an application.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#learning-goals","title":"Learning Goals","text":"<p>By the end of this lesson, you will be able to:</p> <ul> <li>Explain the purpose of using function calling.</li> <li>Setup Function Call using the Azure OpenAI Service.</li> <li>Design effective function calls for your application's use case.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#scenario-improving-our-chatbot-with-functions","title":"Scenario: improving our chatbot with functions","text":"<p>For this lesson, we want to build a feature for our education startup that allows users to use a chatbot to find technical courses. We will recommend courses that fit their skill level, current role and technology of interest.</p> <p>To complete this scenario we will use a combination of:</p> <ul> <li><code>Azure OpenAI</code> to create a chat experience for the user.</li> <li><code>Microsoft Learn Catalog API</code> to help users find courses based on the request of the user.</li> <li><code>Function Calling</code> to take the user's query and send it to a function to make the API request.</li> </ul> <p>To get started, let's look at why we would want to use function calling in the first place:</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#why-function-calling","title":"Why Function Calling","text":"<p>Before function calling, responses from an LLM were unstructured and inconsistent. Developers were required to write complex validation code to make sure they are able to handle each variation of a response. Users could not get answers like \"What is the current weather in Stockholm?\". This is because models were limited to the time the data was trained on.</p> <p>Function Calling is a feature of the Azure OpenAI Service to overcome to the following limitations:</p> <ul> <li>Consistent response format. If we can better control the response format we can more easily integrate the response downstream to other systems.</li> <li>External data. Ability to use data from other sources of an application in a chat context.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#illustrating-the-problem-through-a-scenario","title":"Illustrating the problem through a scenario","text":"<p>We recommend you to use the included notebook if you want to run the below scenario. You can also just read along as we're trying to illustrate a problem where functions can help to address the problem.</p> <p>Let's look at the example that illustrates the response format problem:</p> <p>Let's say we want to create a database of student data so we can suggest the right course to them. Below we have two descriptions of students that are very similar in the data they contain.</p> <ol> <li>Create a connection to our Azure OpenAI resource:</li> </ol> <pre><code>import os\nimport json\nfrom openai import AzureOpenAI\nfrom dotenv import load_dotenv\nload_dotenv()\n\nclient = AzureOpenAI(\napi_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\napi_version = \"2023-07-01-preview\"\n)\n\ndeployment=os.environ['AZURE_OPENAI_DEPLOYMENT']\n</code></pre> <p>Below is some Python code for configuring our connection to Azure OpenAI where we set <code>api_type</code>, <code>api_base</code>, <code>api_version</code> and <code>api_key</code>.</p> <ol> <li>Creating two student descriptions using variables <code>student_1_description</code> and <code>student_2_description</code>.</li> </ol> <pre><code>student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n\nstudent_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\"\n</code></pre> <p>We want to send the above student descriptions to an LLM to parse the data. This data can later be used in our application and be sent to an API or stored in a database.</p> <ol> <li>Let's create two identical prompts in which we instruct the LLM on what information we are interested in:</li> </ol> <pre><code>prompt1 = f'''\nPlease extract the following information from the given text and return it as a JSON object:\n\nname\nmajor\nschool\ngrades\nclub\n\nThis is the body of text to extract the information from:\n{student_1_description}\n'''\n\nprompt2 = f'''\nPlease extract the following information from the given text and return it as a JSON object:\n\nname\nmajor\nschool\ngrades\nclub\n\nThis is the body of text to extract the information from:\n{student_2_description}\n'''\n</code></pre> <p>The above prompts instruct the LLM to extract information and return the response in JSON format.</p> <ol> <li>After setting up the prompts and the connection to Azure OpenAI, we will now send the prompts to the LLM by using <code>openai.ChatCompletion</code>. We store the prompt in the <code>messages</code> variable and assign the role to <code>user</code>. This is to mimic a message from a user being written to a chatbot.</li> </ol> <pre><code># response from prompt one\nopenai_response1 = client.chat.completions.create(\nmodel=deployment,\nmessages = [{'role': 'user', 'content': prompt1}]\n)\nopenai_response1.choices[0].message.content\n\n# response from prompt two\nopenai_response2 = client.chat.completions.create(\nmodel=deployment,\nmessages = [{'role': 'user', 'content': prompt2}]\n)\nopenai_response2.choices[0].message.content\n</code></pre> <p>Now we can send both requests to the LLM and examine the response we receive by finding it like so <code>openai_response1['choices'][0]['message']['content']</code>.</p> <ol> <li>Lastly, we can convert the response to JSON format by calling <code>json.loads</code>:</li> </ol> <pre><code># Loading the response as a JSON object\njson_response1 = json.loads(openai_response1.choices[0].message.content)\njson_response1\n</code></pre> <p>Response 1:</p> <pre><code>{\n  \"name\": \"Emily Johnson\",\n  \"major\": \"computer science\",\n  \"school\": \"Duke University\",\n  \"grades\": \"3.7\",\n  \"club\": \"Chess Club\"\n}\n</code></pre> <p>Response 2:</p> <pre><code>{\n  \"name\": \"Michael Lee\",\n  \"major\": \"computer science\",\n  \"school\": \"Stanford University\",\n  \"grades\": \"3.8 GPA\",\n  \"club\": \"Robotics Club\"\n}\n</code></pre> <p>Even though the prompts are the same and the descriptions are similar, we see values of the <code>Grades</code> property formatted differently as we can sometimes get the format <code>3.7</code> or <code>3.7 GPA</code> for example.</p> <p>This result is because the LLM takes unstructured data in the form of the written prompt and returns also unstructured data. We need to have a structured format so that we know what to expect when storing or using this data</p> <p>So how do we solve the formatting problem then? By using functional calling, we can make sure that we receive structured data back. When using function calling, the LLM does not actually call or run any functions. Instead, we create a structure for the LLM to follow for its responses. We then use those structured responses to know what function to run in our applications.</p> <p></p> <p>We can then take what is returned from the function and send this back to the LLM. The LLM will then respond using natural language to answer the user's query.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#use-cases-for-using-function-calls","title":"Use Cases for using function calls","text":"<p>There are many different use cases where function calls can improve your app like:</p> <ul> <li> <p>Calling External Tools. Chatbots are great at providing answers to questions from users. By using function calling, the chatbots can use messages from users to complete certain tasks. For example, a student can ask the chatbot to \"Send email to my instructor saying I need more assistance with this subject\". This can make a function call to <code>send_email(to: string, body: string)</code></p> </li> <li> <p>Create API or Database Queries. Users can find information using natural language that gets converted into a formatted query or API request. An example of this could be a teacher who requests \"Who are the students that completed the last assignment\" which could call a function named <code>get_completed(student_name: string, assignment: int, current_status: string)</code></p> </li> <li> <p>Creating Structured Data. Users can take a block of text or CSV and use the LLM to extract important information from it. For example, a student can convert a Wikipedia article about peace agreements to create AI flash cards. This can be done by using a function called <code>get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)</code></p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#creating-your-first-function-call","title":"Creating Your First Function Call","text":"<p>The process of creating a function call includes 3 main steps:</p> <ol> <li>Calling the Chat Completions API with a list of your functions and a user message.</li> <li>Reading the model's response to perform an action ie execute a function or API Call.</li> <li>Making another call to Chat Completions API with the response from your function to use that information to create a response to the user.</li> </ol> <p></p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#step-1-creating-messages","title":"Step 1 - creating messages","text":"<p>The first step is to create a user message. This can be dynamically assigned by taking the value of a text input or you can assign a value here. If this is your first time working with the Chat Completions API, we need to define the <code>role</code> and the <code>content</code> of the message.</p> <p>The <code>role</code> can be either <code>system</code> (creating rules), <code>assistant</code> (the model) or <code>user</code> (the end-user). For function calling, we will assign this as <code>user</code> and an example question.</p> <pre><code>messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]\n</code></pre> <p>By assigning different roles, it's made clear to the LLM if it's the system saying something or the user, which helps to build a conversation history that the LLM can build upon.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#step-2-creating-functions","title":"Step 2 - creating functions","text":"<p>Next, we will define a function and the parameters of that function. We will use just one function here called <code>search_courses</code> but you can create multiple functions.</p> <p>Important : Functions are included in the system message to the LLM and will be included in the amount of available tokens you have available.</p> <p>Below, we create the functions as an array of items. Each item is a function and has properties <code>name</code>, <code>description</code> and <code>parameters</code>:</p> <pre><code>functions = [\n   {\n      \"name\":\"search_courses\",\n      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n      \"parameters\":{\n         \"type\":\"object\",\n         \"properties\":{\n            \"role\":{\n               \"type\":\"string\",\n               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n            },\n            \"product\":{\n               \"type\":\"string\",\n               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n            },\n            \"level\":{\n               \"type\":\"string\",\n               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n            }\n         },\n         \"required\":[\n            \"role\"\n         ]\n      }\n   }\n]\n</code></pre> <p>Let's describe each function instance more in detail below:</p> <ul> <li><code>name</code> - The name of the function that we want to have called.</li> <li><code>description</code> - This is the description of how the function works. Here it's important to be specific and clear.</li> <li><code>parameters</code> - A list of values and format that you want the model to produce in its response. The parameters array consists of items where item have the following properties:</li> <li><code>type</code> - The data type of the properties will be stored in.</li> <li><code>properties</code> - List of the specific values that the model will use for its response<ol> <li><code>name</code> - The key is the name of the property that the model will use in its formatted response, for example, <code>product</code>.</li> <li><code>type</code> - The data type of this property, for example, <code>string</code>.</li> <li><code>description</code> - Description of the specific property.</li> </ol> </li> </ul> <p>There's also an optional property <code>required</code> - required property for the function call to be completed.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#step-3-making-the-function-call","title":"Step 3 - Making the function call","text":"<p>After defining a function, we now need to include it in the call to the Chat Completion API. We do this by adding <code>functions</code> to the request. In this case <code>functions=functions</code>.</p> <p>There is also an option to set <code>function_call</code> to <code>auto</code>. This means we will let the LLM decide which function should be called based on the user message rather than assigning it ourselves.</p> <p>Here's some code below where we call <code>ChatCompletion.create</code>, note how we set <code>functions=functions</code> and <code>function_call=\"auto\"</code> and thereby giving the LLM the choice when to call the functions we provide it:</p> <pre><code>response = client.chat.completions.create(model=deployment,\n                                        messages=messages,\n                                        functions=functions,\n                                        function_call=\"auto\")\n\nprint(response.choices[0].message)\n</code></pre> <p>The response coming back now looks like so:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"function_call\": {\n    \"name\": \"search_courses\",\n    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n  }\n}\n</code></pre> <p>Here we can see how the function <code>search_courses</code> was called and with what arguments, as listed in the <code>arguments</code> property in the JSON response.</p> <p>The conclusion the LLM was able to find the data to fit the arguments of the function as it was extracting it from the value provided to the <code>messages</code> parameter in the chat completion call. Below is a reminder of the <code>messages</code> value:</p> <pre><code>messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]\n</code></pre> <p>As you can see, <code>student</code>, <code>Azure</code> and <code>beginner</code> was extracted from <code>messages</code> and set as input to the function. Using functions this way is a great way to extract information from a prompt but also to provide structure to the LLM and have reusable functionality.</p> <p>Next, we need to see how we can use this in our app.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#integrating-function-calls-into-an-application","title":"Integrating Function Calls into an Application","text":"<p>After we have tested the formatted response from the LLM, now we can integrate this into an application.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#managing-the-flow","title":"Managing the flow","text":"<p>To integrate this into our application, let's take the following steps:</p> <ol> <li>First, let's make the call to the Open AI services and store the message in a variable called <code>response_message</code>.</li> </ol> <pre><code>response_message = response.choices[0].message\n</code></pre> <ol> <li>Now we will define the function that will call the Microsoft Learn API to get a list of courses:</li> </ol> <pre><code>import requests\n\ndef search_courses(role, product, level):\n  url = \"https://learn.microsoft.com/api/catalog/\"\n  params = {\n     \"role\": role,\n     \"product\": product,\n     \"level\": level\n  }\n  response = requests.get(url, params=params)\n  modules = response.json()[\"modules\"]\n  results = []\n  for module in modules[:5]:\n     title = module[\"title\"]\n     url = module[\"url\"]\n     results.append({\"title\": title, \"url\": url})\n  return str(results)\n</code></pre> <p>Note how we now create an actual Python function that maps to the function names introduced in the <code>functions</code> variable. We're also making real external API calls to fetch the data we need. In this case, we go against the Microsoft Learn API to search for training modules.</p> <p>Ok, so we created <code>functions</code> variables and a corresponding Python function, how do we tell the LLM how to map these two together so our Python function is called?</p> <ol> <li>To see if we need to call a Python function, we need to look into the LLM response and see if <code>function_call</code> is part of it and call the pointed out function. Here's how you can make the mentioned check below:</li> </ol> <pre><code># Check if the model wants to call a function\nif response_message.function_call.name:\n print(\"Recommended Function call:\")\n print(response_message.function_call.name)\n print()\n\n # Call the function.\n function_name = response_message.function_call.name\n\n available_functions = {\n         \"search_courses\": search_courses,\n }\n function_to_call = available_functions[function_name]\n\n function_args = json.loads(response_message.function_call.arguments)\n function_response = function_to_call(**function_args)\n\n print(\"Output of function call:\")\n print(function_response)\n print(type(function_response))\n\n\n # Add the assistant response and function response to the messages\n messages.append( # adding assistant response to messages\n     {\n         \"role\": response_message.role,\n         \"function_call\": {\n             \"name\": function_name,\n             \"arguments\": response_message.function_call.arguments,\n         },\n         \"content\": None\n     }\n )\n messages.append( # adding function response to messages\n     {\n         \"role\": \"function\",\n         \"name\": function_name,\n         \"content\":function_response,\n     }\n )\n</code></pre> <p>These three lines, ensure we extract the function name, the arguments and make the call:</p> <pre><code>function_to_call = available_functions[function_name]\n\nfunction_args = json.loads(response_message.function_call.arguments)\nfunction_response = function_to_call(**function_args)\n</code></pre> <p>Below is the output from running our code:</p> <p>Output</p> <p>```Recommended Function call:    {      \"name\": \"search_courses\",      \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"    }</p> <p>Output of function call:    [{'title': 'Describe concepts of cryptography', 'url': 'https://learn.microsoft.com/training/modules/describe-concepts-of-cryptography/?    WT.mc_id=api_CatalogApi'}, {'title': 'Introduction to audio classification with TensorFlow', 'url': 'https://learn.microsoft.com/en-    us/training/modules/intro-audio-classification-tensorflow/?WT.mc_id=api_CatalogApi'}, {'title': 'Design a Performant Data Model in Azure SQL    Database with Azure Data Studio', 'url': 'https://learn.microsoft.com/training/modules/design-a-data-model-with-ads/?    WT.mc_id=api_CatalogApi'}, {'title': 'Getting started with the Microsoft Cloud Adoption Framework for Azure', 'url':    'https://learn.microsoft.com/training/modules/cloud-adoption-framework-getting-started/?WT.mc_id=api_CatalogApi'}, {'title': 'Set up the    Rust development environment', 'url': 'https://learn.microsoft.com/training/modules/rust-set-up-environment/?WT.mc_id=api_CatalogApi'}]        ```</p> <ol> <li>Now we will send the updated message, <code>messages</code> to the LLM so we can receive a natural language response instead of an API JSON formatted response.</li> </ol> <pre><code>print(\"Messages in next request:\")\nprint(messages)\nprint()\n\nsecond_response = client.chat.completions.create(\n   messages=messages,\n   model=deployment,\n   function_call=\"auto\",\n   functions=functions,\n   temperature=0\n      )  # get a new response from GPT where it can see the function response\n\n\nprint(second_response.choices[0].message)\n</code></pre> <p>Output</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"I found some good courses for beginner students to learn Azure:\\n\\n1. [Describe concepts of cryptography] (https://learn.microsoft.com/training/modules/describe-concepts-of-cryptography/?WT.mc_id=api_CatalogApi)\\n2. [Introduction to audio classification with TensorFlow](https://learn.microsoft.com/training/modules/intro-audio-classification-tensorflow/?WT.mc_id=api_CatalogApi)\\n3. [Design a Performant Data Model in Azure SQL Database with Azure Data Studio](https://learn.microsoft.com/training/modules/design-a-data-model-with-ads/?WT.mc_id=api_CatalogApi)\\n4. [Getting started with the Microsoft Cloud Adoption Framework for Azure](https://learn.microsoft.com/training/modules/cloud-adoption-framework-getting-started/?WT.mc_id=api_CatalogApi)\\n5. [Set up the Rust development environment](https://learn.microsoft.com/training/modules/rust-set-up-environment/?WT.mc_id=api_CatalogApi)\\n\\nYou can click on the links to access the courses.\"\n}\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#assignment","title":"Assignment","text":"<p>To continue your learning of Azure OpenAI Function Calling you can build:</p> <ul> <li>More parameters of the function that might help learners find more courses.</li> <li>Create another function call that takes more information from the learner like their native language</li> <li>Create error handling when the function call and/or API call does not return any suitable courses</li> </ul> <p>Hint: Follow the Learn API reference documentation page to see how and where this data is available.</p>"},{"location":"curricula/generative-ai-for-beginners/11-integrating-with-function-calling/#great-work-continue-the-journey","title":"Great Work! Continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 12 where we will look at how to design UX for AI applications!</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/","title":"Lesson 12","text":""},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#designing-ux-for-ai-applications","title":"Designing UX for AI Applications","text":"<p>(Click the image above to view video of this lesson)</p> <p>User experience is a very important aspect of building apps. Users need to be able to use your app in an efficient way to perform tasks. Being efficient is one thing but you also need to design apps so that they can be used by everyone, to make them accessible. This chapter will focus on this area so you hopefully end up designing an app that people can and want to use.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#introduction","title":"Introduction","text":"<p>User experience is how a user interacts with and uses a specific product or service be it a system, tool, or design. When developing AI applications, developers not only focus on ensuring the user experience is effective but also ethical. In this lesson, we cover how to build Artificial Intelligence (AI) applications that address user needs.</p> <p>The lesson will cover the following areas:</p> <ul> <li>Introduction to User Experience and Understanding User Needs</li> <li>Designing AI Applications for Trust and Transparency</li> <li>Designing AI Applications for Collaboration and Feedback</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#learning-goals","title":"Learning goals","text":"<p>After taking this lesson, you'll be able to:</p> <ul> <li>Understand how to build AI applications that meet the user needs.</li> <li>Design AI applications that promote trust and collaboration.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#prerequisite","title":"Prerequisite","text":"<p>Take some time and read more about user experience and design thinking.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#introduction-to-user-experience-and-understanding-user-needs","title":"Introduction to User Experience and Understanding User Needs","text":"<p>In our fictitious education startup, we have two primary users, teachers and students. Each of the two users has unique needs. A user-centered design prioritizes the user ensuring the products are relevant and beneficial for those it is intended for.</p> <p>The application should be useful, reliable, accessible and pleasant to provide a good user experience.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#usability","title":"Usability","text":"<p>Being useful means that the application has functionality that matches its intended purpose, such as automating the grading process or generating flashcards for revision. An application that automates the grading process should be able to accurately and efficiently assign scores to students' work based on predefined criteria. Similarly, an application that generates revision flashcards should be able to create relevant and diverse questions based on its data.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#reliability","title":"Reliability","text":"<p>Being reliable means that the application can perform its task consistently and without errors. However, AI just like humans is not perfect and may be prone to errors. The applications may encounter errors or unexpected situations that require human intervention or correction. How do you handle errors? In the last section of this lesson, we will cover how AI systems and applications are designed for collaboration and feedback.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#accessibility","title":"Accessibility","text":"<p>Being accessible means extending the user experience to users with various abilities, including those with disabilities, ensuring no one is left out. By following accessibility guidelines and principles, AI solutions become more inclusive, usable, and beneficial for all users.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#pleasant","title":"Pleasant","text":"<p>Being pleasant means that the application is enjoyable to use. An appealing user experience can have a positive impact on the user encouraging them to return to the application and increasing business revenue.</p> <p></p> <p>Not every challenge can be solved with AI. AI comes in to augment your user experience, be it automating manual tasks, or personalizing user experiences.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#designing-ai-applications-for-trust-and-transparency","title":"Designing AI Applications for Trust and Transparency","text":"<p>Building trust is critical when designing AI applications. Trust ensures a user is confident that the application will get the work done, deliver results consistently and the results are what the user needs. A risk in this area is mistrust and over trust. Mistrust occurs when a user has little or no trust in an AI system, this leads to the user rejecting your application. Over trust occurs when a user overestimates the capability of an AI system, leading to users trusting the AI system too much. For example, an automated grading system in the case of over trust might lead the teacher not to proof through some of the papers to ensure the grading system works well. This could result in unfair or inaccurate grades for the students, or missed opportunities for feedback and improvement.</p> <p>Two ways to ensure that trust is put right at the center of design are explainability and control.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#explainability","title":"Explainability","text":"<p>When AI helps inform decisions such as imparting knowledge to future generations, it is critical for teachers and parents to understand how AI decisions are made. This is explainability - understanding how AI applications make decisions. Designing for explainability includes adding details of examples of what an AI application can do. For example, instead of \"Get started with AI teacher\", the system can use: \"Summarize your notes for easier revision using AI.\"</p> <p></p> <p>Another example is how AI uses user and personal data. For example, a user with the persona student may have limitations based on their persona. The AI may not be able to reveal answers to questions but may help guide the user to think through how they can solve a problem.</p> <p></p> <p>One last key part of explainability is the simplification of explanations. Students and teachers may not be AI experts, therefore explanations of what the application can or cannot do should be simplified and easy to understand.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#control","title":"Control","text":"<p>Generative AI creates a collaboration between AI and the user, where for instance a user can modify prompts for different results. Additionally, once an output is generated, users should be able to modify the results giving them a sense of control. For example, when using Bing, you can tailor your prompt based on format, tone and length. Additionally, you can add changes to your output and modify the output as shown below:</p> <p></p> <p>Another feature in Bing that allows a user to have control over the application is the ability to opt in and opt out of the data AI uses. For a school application, a student might want to use their notes as well as the teachers' resources as revision material.</p> <p></p> <p>When designing AI applications, intentionality is key in ensuring users do not over trust setting unrealistic expectations of its capabilities. One way to do this is by creating friction between the prompts and the results. Reminding the user, that this is AI and not a fellow human being</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#designing-ai-applications-for-collaboration-and-feedback","title":"Designing AI Applications for Collaboration and Feedback","text":"<p>As earlier mentioned generative AI creates a collaboration between the user and AI. Most engagements are with a user inputting a prompt and the AI generating an output. What if the output is incorrect? How does the application handle errors if they occur? Does the AI blame the user or take time to explain the error?</p> <p>AI applications should be built in to receive and give feedback. This not only helps the AI system improve but also builds trust with the users. A feedback loop should be included in the design, an example can be a simple thumbs up or down on the output.</p> <p>Another way to handle this is to clearly communicate the capabilities and limitations of the system. When a user makes an error requesting something beyond the AI capabilities, there should also be a way to handle this, as shown below.</p> <p></p> <p>System errors are common with applications where the user might need assistance with information outside the scope of the AI or the application may have a limit of how many questions/subjects a user can generate summaries. For example, an AI application trained with data on limited subjects for example, History and Math may not be able to handle questions around Geography. To mitigate this, the AI system can give a response like: \"Sorry, our product has been trained with data in the following subjects....., I cannot be able to respond to the question you asked.\"</p> <p>AI applications are not perfect, therefore, they are bound to make mistakes. When designing your applications, you should ensure you create room for feedback from users and error handling in a way that is simple and easily explainable.</p>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#assignment","title":"Assignment","text":"<p>Take any AI apps you've built so far, consider implementing the below steps in your app:</p> <ul> <li> <p>Pleasant: Consider how you can make your app more pleasant. Are you adding explanations everywhere, are you encouraging the user to explore? How are you wording your error messages?</p> </li> <li> <p>Usability: Building a web app. Make sure your app is navigable by both mouse and keyboard.</p> </li> <li> <p>Trust and transparency: Don't trust the AI completely and its output, consider how you would add a human to the process to verify the output. Also, consider and implement other ways to achieve trust and transparency.</p> </li> <li> <p>Control: Give the user control of the data they provide to the application. Implement a way a user can opt-in and opt-out of data collection in the AI application.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/12-designing-ux-for-ai-applications/#continue-your-learning","title":"Continue Your Learning!","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 13 where we will look at how to securing AI applications!</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/","title":"Lesson 13","text":""},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#securing-your-generative-ai-applications","title":"Securing Your Generative AI Applications","text":""},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#introduction","title":"Introduction","text":"<p>This lesson will cover:</p> <ul> <li>Security within the context of AI systems.</li> <li>Common risks and threats to AI systems.</li> <li>Methods and considerations for securing AI systems.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will have an understanding of:</p> <ul> <li>The threats and risks to AI systems.</li> <li>Common methods and practices for securing AI systems.</li> <li>How implementing security testing can prevent unexpected results and erosion of user trust.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#what-does-security-mean-within-the-context-of-generative-ai","title":"What does security mean within the context of generative AI?","text":"<p>As Artificial Intelligence (AI) and Machine Learning (ML) technologies increasingly shape our lives, it\u2019s crucial to protect not only customer data but also the AI systems themselves. AI/ML is increasingly used in support of high-value decision-making processes in industries where the wrong decision may result in serious consequences.</p> <p>Here are key points to consider:</p> <ul> <li>Impact of AI/ML: AI/ML have significant impacts on daily life and as such safeguarding them has become essential.</li> <li>Security Challenges: This impact that AI/ML has needs proper attention in order to address the need to protect AI-based products from sophisticated attacks, whether by trolls or organized groups.</li> <li>Strategic Problems: The tech industry must proactively address strategic challenges to ensure long-term customer safety and data security.</li> </ul> <p>Additionally, Machine Learning models are largely unable to discern between malicious input and benign anomalous data. A significant source of training data is derived from uncurated, unmoderated, public datasets, which are open to 3rd-party contributions. Attackers don\u2019t need to compromise datasets when they're free to contribute to them. Over time, low-confidence malicious data becomes high-confidence trusted data, if the data structure/formatting remains correct.</p> <p>This is why it is critical to ensure the integrity and protection of the data stores your models use to make decisions with.</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#understanding-the-threats-and-risks-of-ai","title":"Understanding the threats and risks of AI","text":"<p>In terms of AI and related systems, data poisoning stands out as the most significant security threat today. Data poisoning is when someone intentionally changes the information used to train an AI, causing it to make mistakes. This is due to the absence of standardized detection and mitigation methods, coupled with our reliance on untrusted or uncurated public datasets for training. To maintain data integrity and prevent a flawed training process, it is crucial to track the origin and lineage of your data. Otherwise, the old adage \u201cgarbage in, garbage out\u201d holds true, leading to compromised model performance.</p> <p>Here are examples of how data poisoning can affect your models:</p> <ol> <li>Label Flipping: In a binary classification task, an adversary intentionally flips the labels of a small subset of training data. For instance, benign samples are labeled as malicious, leading the model to learn incorrect associations.\\    Example: A spam filter misclassifying legitimate emails as spam due to manipulated labels.</li> <li>Feature Poisoning: An attacker subtly modifies features in the training data to introduce bias or mislead the model.\\    Example: Adding irrelevant keywords to product descriptions to manipulate recommendation systems.</li> <li>Data Injection: Injecting malicious data into the training set to influence the model\u2019s behavior.\\    Example: Introducing fake user reviews to skew sentiment analysis results.</li> <li>Backdoor Attacks: An adversary inserts a hidden pattern (backdoor) into the training data. The model learns to recognize this pattern and behaves maliciously when triggered.\\    Example: A face recognition system trained with backdoored images that misidentifies a specific person.</li> </ol> <p>The MITRE Corporation has created ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems), a knowledgebase of tactics and techniques employed by adversaries in real-world attacks on AI systems.</p> <p>There are a growing number of vulnerabilities in AI-enabled systems, as the incorporation of AI increases the attack surface of existing systems beyond those of traditional cyber-attacks. We developed ATLAS to raise awareness of these unique and evolving vulnerabilities, as the global community increasingly incorporates AI into various systems. ATLAS is modeled after the MITRE ATT&amp;CK\u00ae framework and its tactics, techniques, and procedures (TTPs) are complementary to those in ATT&amp;CK.</p> <p>Much like the MITRE ATT&amp;CK\u00ae framework, which is extensively used in traditional cybersecurity for planning advanced threat emulation scenarios, ATLAS provides an easily searchable set TTPs that can help to better understand and prepare for defending against emerging attacks.</p> <p>Additionally, the Open Web Application Security Project (OWASP) has created a \"Top 10 list\" of the most critical vulnerabilities found in applications utilizing LLMs. The list highlights the risks of threats such as the aforementioned data poisoning along with others such as:</p> <ul> <li>Prompt Injection: a technique where attackers manipulate a Large Language Model (LLM) through carefully crafted inputs, causing it to behave outside of its intended behavior.</li> <li>Supply Chain Vulnerabilities: The components and software that make up the applications used by an LLM, such as Python modules or external datasets, can themselves be compromised leading to unexpected results, introduced biases and even vulnerabilities in the underlying infrastructure.</li> <li>Overreliance: LLMs are fallible and have been prone to hallucinate, providing inaccurate or unsafe results. In several documented circumstances, people have taken the results at face value leading to unintended real-world negative consequences.</li> </ul> <p>Microsoft Cloud Advocate Rod Trent has written a free ebook, Must Learn AI Security, that dives deeply into these and other emerging AI threats and provides extensive guidance on how to best tackle these scenarios.</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#security-testing-for-ai-systems-and-llms","title":"Security Testing for AI Systems and LLMs","text":"<p>Artificial intelligence (AI) is transforming various domains and industries, offering new possibilities and benefits for society. However, AI also poses significant challenges and risks, such as data privacy, bias, lack of explainability, and potential misuse. Therefore, it is crucial to ensure that AI systems are secure and responsible, meaning that they adhere to ethical and legal standards and can be trusted by users and stakeholders.</p> <p>Security testing is the process of evaluating the security of an AI system or LLM, by identifying and exploiting their vulnerabilities. This can be performed by developers, users, or third-party auditors, depending on the purpose and scope of the testing. Some of the most common security testing methods for AI systems and LLMs are:</p> <ul> <li>Data sanitization: This is the process of removing or anonymizing sensitive or private information from the training data or the input of an AI system or LLM. Data sanitization can help prevent data leakage and malicious manipulation by reducing the exposure of confidential or personal data.</li> <li>Adversarial testing: This is the process of generating and applying adversarial examples to the input or output of an AI system or LLM to evaluate its robustness and resilience against adversarial attacks. Adversarial testing can help identify and mitigate the vulnerabilities and weaknesses of an AI system or LLM that may be exploited by attackers.</li> <li>Model verification: This is the process of verifying the correctness and completeness of the model parameters or architecture of an AI system or LLM. Model verification can help detect and prevent model stealing by ensuring that the model is protected and authenticated.</li> <li>Output validation: This is the process of validating the quality and reliability of the output of an AI system or LLM. Output validation can help detect and correct malicious manipulation by ensuring that the output is consistent and accurate.</li> </ul> <p>OpenAI, a leader in AI systems, has setup a series of safety evaluations as part of their red teaming network initiative, aimed at testing the output AI systems in the hopes of contributing to AI safety.</p> <p>Evaluations can range from simple Q&amp;A tests to more-complex simulations. As concrete examples, here are sample evaluations developed by OpenAI for evaluating AI behaviors from a number of angles:</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#persuasion","title":"Persuasion","text":"<ul> <li>MakeMeSay: How well can an AI system trick another AI system into saying a secret word?</li> <li>MakeMePay: How well can an AI system convince another AI system to donate money?</li> <li>Ballot Proposal: How well can an AI system influence another AI system\u2019s support of a political proposition?</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#steganography-hidden-messaging","title":"Steganography (hidden messaging)","text":"<ul> <li>Steganography: How well can an AI system \u200b\u200bpass secret messages without being caught by another AI system?</li> <li>Text Compression: How well can an AI system compress and decompress messages, to enable hiding secret messages?</li> <li>Schelling Point: How well can an AI system coordinate with another AI system, without direct communication?</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#ai-security","title":"AI Security","text":"<p>It's imperative that we aim to protect AI systems from malicious attacks, misuse, or unintended consequences. This includes taking steps to ensure the safety, reliability, and trustworthiness of AI systems, such as:</p> <ul> <li>Securing the data and algorithms that are used to train and run AI models</li> <li>Preventing unauthorized access, manipulation, or sabotage of AI systems</li> <li>Detecting and mitigating bias, discrimination, or ethical issues in AI systems</li> <li>Ensuring the accountability, transparency, and explainability of AI decisions and actions</li> <li>Aligning the goals and values of AI systems with those of humans and society</li> </ul> <p>AI security is important for ensuring the integrity, availability, and confidentiality of AI systems and data. Some of the challenges and opportunities of AI security are:</p> <ul> <li>Opportunity: Incorporating AI in cybersecurity strategies since it can play a crucial role in identifying threats and improving response times. AI can help automate and augment the detection and mitigation of cyberattacks, such as phishing, malware, or ransomware.</li> <li>Challenge: AI can also be used by adversaries to launch sophisticated attacks, such as generating fake or misleading content, impersonating users, or exploiting vulnerabilities in AI systems. Therefore, AI developers have a unique responsibility to design systems that are robust and resilient against misuse.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#data-protection","title":"Data Protection","text":"<p>LLMs can pose risks to the privacy and security of the data that they use. For example, LLMs can potentially memorize and leak sensitive information from their training data, such as personal names, addresses, passwords, or credit card numbers. They can also be manipulated or attacked by malicious actors who want to exploit their vulnerabilities or biases. Therefore, it is important to be aware of these risks and take appropriate measures to protect the data used with LLMs. There are several steps that you can take to protect the data that is used with LLMs. These steps include:</p> <ul> <li>Limiting the amount and type of data that they share with LLMs: Only share the data that is necessary and relevant for the intended purposes, and avoid sharing any data that is sensitive, confidential, or personal. Users should also anonymize or encrypt the data that they share with LLMs, such as by removing or masking any identifying information, or using secure communication channels.</li> <li>Verifying the data that LLMs generate: Always check the accuracy and quality of the output generated by LLMs to ensure they don't contain any unwanted or inappropriate information.</li> <li>Reporting and alerting any data breaches or incidents: Be vigilant of any suspicious or abnormal activities or behaviors from LLMs, such as generating texts that are irrelevant, inaccurate, offensive, or harmful. This could be an indication of a data breach or security incident.</li> </ul> <p>Data security, governance, and compliance are critical for any organization that wants to leverage the power of data and AI in a multi-cloud environment. Securing and governing all your data is a complex and multifaceted undertaking. You need to secure and govern different types of data (structured, unstructured, and data generated by AI) in different locations across multiple clouds, and you need to account for existing and future data security, governance, and AI regulations. To protect your data, you need to adopt some best practices and precautions, such as:</p> <ul> <li>Use cloud services or platforms that offer data protection and privacy features.</li> <li>Use data quality and validation tools to check your data for errors, inconsistencies, or anomalies.</li> <li>Use data governance and ethics frameworks to ensure your data is used in a responsible and transparent manner.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#emulating-real-world-threats-ai-red-teaming","title":"Emulating real-world threats - AI red teaming","text":"<p>Emulating real-world threats is now considered a standard practice in building resilient AI systems by employing similar tools, tactics, procedures to identify the risks to systems and test the response of defenders.</p> <p>The practice of AI red teaming has evolved to take on a more expanded meaning: it not only covers probing for security vulnerabilities, but also includes probing for other system failures, such as the generation of potentially harmful content. AI systems come with new risks, and red teaming is core to understanding those novel risks, such as prompt injection and producing ungrounded content. - Microsoft AI Red Team building future of safer AI</p> <p></p> <p>Below are key insights that have shaped Microsoft\u2019s AI Red Team program.</p> <ol> <li>Expansive Scope of AI Red Teaming:    AI red teaming now encompasses both security and Responsible AI (RAI) outcomes. Traditionally, red teaming focused on security aspects, treating the model as a vector (e.g., stealing the underlying model). However, AI systems introduce novel security vulnerabilities (e.g., prompt injection, poisoning), necessitating special attention. Beyond security, AI red teaming also probes fairness issues (e.g., stereotyping) and harmful content (e.g., glorification of violence). Early identification of these issues allows prioritization of defense investments.</li> <li>Malicious and Benign Failures:    AI red teaming considers failures from both malicious and benign perspectives. For example, when red teaming the new Bing, we explore not only how malicious adversaries can subvert the system but also how regular users may encounter problematic or harmful content. Unlike traditional security red teaming, which focuses mainly on malicious actors, AI red teaming accounts for a broader range of personas and potential failures.</li> <li>Dynamic Nature of AI Systems:    AI applications constantly evolve. In large language model applications, developers adapt to changing requirements. Continuous red teaming ensures ongoing vigilance and adaptation to evolving risks.</li> </ol> <p>AI red teaming is not all encompassing and should be considered a complementary motion to additional controls such as role-based access control (RBAC) and comprehensive data management solutions. It's meant to supplement a security strategy that focuses on employing safe and responsible AI solutions that account for privacy and security while aspiring to minimize biases, harmful content and misinformation that can erode user confidence.</p> <p>Here's a list of additional reading that can help you better understand how red teaming can help identify and mitigate risks in your AI systems:</p> <ul> <li>Planning red teaming for large language models (LLMs) and their applications</li> <li>What is the OpenAI Red Teaming Network?</li> <li>AI Red Teaming - A Key Practice for Building Safer and More Responsible AI Solutions</li> <li>MITRE ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems), a knowledgebase of tactics and techniques employed by adversaries in real-world attacks on AI systems.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#knowledge-check","title":"Knowledge check","text":"<p>What could be a good approach to maintaining data integrity and preventing misuse?</p> <ol> <li>Have strong role-based controls for data access and data management</li> <li>Implement and audit data labeling to prevent data misrepresentation or misuse</li> <li>Ensure your AI infrastructure supports content filtering</li> </ol> <p>A:1, While all three are great recommendations, ensuring that you're assigning the proper data access privileges to users will go a long way to preventing manipulation and misrepresentation of the data used by LLMs.</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Read up more on how you can govern and protect sensitive information in the age of AI.</p>"},{"location":"curricula/generative-ai-for-beginners/13-securing-ai-applications/#great-work-continue-your-learning","title":"Great Work, Continue Your Learning","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Head over to Lesson 14 where we will look at the Generative AI Application Lifecycle!</p>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/","title":"Lesson 14","text":""},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#the-generative-ai-application-lifecycle","title":"The Generative AI Application Lifecycle","text":"<p>An important question for all AI applications is the relevance of AI features, as AI is a fast evolving field, to ensure that your application remains relevant, reliable, and robust, you need to monitor, evaluate, and improve it continuously. This is where the generative AI lifecycle comes in.</p> <p>The generative AI lifecycle is a framework that guides you through the stages of developing, deploying, and maintaining a generative AI application. It helps you to define your goals, measure your performance, identify your challenges, and implement your solutions. It also helps you to align your application with the ethical and legal standards of your domain and your stakeholders. By following the generative AI lifecycle, you can ensure that your application is always delivering value and satisfying your users.</p>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#introduction","title":"Introduction","text":"<p>In this chapter, you will:</p> <ul> <li>Understand the Paradigm Shift from MLOps to LLMOps</li> <li>The LLM Lifecycle</li> <li>Lifecycle Tooling</li> <li>Lifecycle Metrification and Evaluation</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#understand-the-paradigm-shift-from-mlops-to-llmops","title":"Understand the Paradigm Shift from MLOps to LLMOps","text":"<p>LLMs are a new tool in the Artificial Intelligence arsenal, they are incredibly powerful in analysis and generation tasks for applications, however this power has some consequences in how we streamline AI and Classic Machine Learning tasks.</p> <p>With this, we need a new Paradigm to adapt this tool in a dynamic, with the correct incentives. We can categorize older AI apps as \"ML Apps\" and newer AI Apps as \"GenAI Apps\" or just \"AI Apps\", reflecting the mainstream technology and techniques used at the time. This shifts our narrative in multiple ways, look at the following comparison.</p> <p></p> <p>Notice that in LLMOps, we are more focused on the App Developers, using integrations as a key point, using \"Models-as-a-Service\" and thinking in the following points for metrics.</p> <ul> <li>Quality: Response quality</li> <li>Harm: Responsible AI</li> <li>Honesty: Response groundedness (Makes sense? It is correct?)</li> <li>Cost: Solution Budget</li> <li>Latency: Avg. time for token response</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#the-llm-lifecycle","title":"The LLM Lifecycle","text":"<p>First, to understand the lifecycle and the modifications, let's note the next infographic.</p> <p></p> <p>As you may note, this is different from the usual Lifecycles from MLOps. LLMs have many new requirements, as Prompting, different techniques to improve quality (Fine-Tuning, RAG, Meta-Prompts), different assessment and responsability with responsible AI, lastly, new evaluation metrics (Quality, Harm, Honesty, Cost and Latency).</p> <p>For instance, take a look at how we ideate. Using prompt engineering to experiment with various LLMs to explore possibilities to test if their Hypothesis could be correct.</p> <p>Note that this is not linear, but integrated loops, iterative and with an overarching cycle.</p> <p>How could we explore those steps? Let's step into detail in how could we build a lifecycle.</p> <p></p> <p>This may look a bit complicated, lets focus on the three big steps first.</p> <ol> <li>Ideating/Exploring: Exploration, here we can explore according to our business needs. Prototyping, creating a PromptFlow and test if is efficient enough for our Hypothesis.</li> <li>Building/Augmenting: Implementation, now, we start to evaluate for bigger datasets implement techniques, like Fine-tuning and RAG, to check the robustness of our solution. If it does not, re-implementing it, adding new steps in our flow or restructuring the data, might help. After testing our flow and our scale, if it works and check our Metrics, it is ready for the next step.</li> <li>Operationalizing: Integration, now adding Monitoring and Alerts Systems to our system, deployment and application integration to our Application.</li> </ol> <p>Then, we have the overarching cycle of Management, focusing on security, compliance and governance.</p> <p>Congratulations, now you have your AI App ready to go and operational. For a hands on experience, take a look on the Contoso Chat Demo.</p> <p>Now, what tools could we use?</p>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#lifecycle-tooling","title":"Lifecycle Tooling","text":"<p>For Tooling, Microsoft provides the Azure AI Platform and PromptFlow facilitate and make your cycle easy to implement and ready to go.</p> <p>The Azure AI Platform, allows you to use AI Studio. AI Studio is a web portal allows you to Explore models, samples and tools. Managing your resources, UI development flows and SDK/CLI options for Code-First development.</p> <p></p> <p>Azure AI, allows you to use multiple resources, to manage your operations, services, projects, vector search and databases needs.</p> <p></p> <p>Construct, from Proof-of-Concept(POC) until large scale applications with PromptFlow:</p> <ul> <li>Design and Build apps from VS Code, with visual and functional tools</li> <li>Test and fine-tune your apps for quality AI, with ease.</li> <li>Use Azure AI Studio to Integrate and Iterate with cloud, Push and Deploy for quick integration.</li> </ul> <p></p>"},{"location":"curricula/generative-ai-for-beginners/14-the-generative-ai-application-lifecycle/#great-continue-your-learning","title":"Great! Continue your Learning!","text":"<p>Amazing, now learn more about how we structure an application to use the concepts with the Contoso Chat App, to check how Cloud Advocacy adds those concepts in demonstrations. For more content, check our Ignite breakout session! </p> <p>Now, check Lesson 15, to understand how Retrieval Augmented Generation and Vector Databases impact Generative AI and to make more engaging Applications!</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/","title":"Lesson 15","text":""},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#retrieval-augmented-generation-rag-and-vector-databases","title":"Retrieval Augmented Generation (RAG) and Vector Databases","text":"<p>In the search applications lesson, we briefly learned how to integrate your own data into Large Language Models (LLMs). In this lesson, we will delve further into the concepts of grounding your data in your LLM application, the mechanics of the process and the methods for storing data, including both embeddings and text.</p> <p>Video Coming Soon</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#introduction","title":"Introduction","text":"<p>In this lesson we will cover the following:</p> <ul> <li> <p>An introduction to RAG, what it is and why it is used in AI (artificial intelligence).</p> </li> <li> <p>Understanding what vector databases are and creating one for our application.</p> </li> <li> <p>A practical example on how to integrate RAG into an application.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#learning-goals","title":"Learning Goals","text":"<p>After completing this lesson, you will be able to:</p> <ul> <li> <p>Explain the significance of RAG in data retrieval and processing.</p> </li> <li> <p>Setup RAG application and ground your data to an LLM</p> </li> <li> <p>Effective integration of RAG and Vector Databases in LLM Applications.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#our-scenario-enhancing-our-llms-with-our-own-data","title":"Our Scenario: enhancing our LLMs with our own data","text":"<p>For this lesson, we want to add our own notes into the education startup, which allows the chatbot to get more information on the different subjects. Using the notes that we have, learners will be able to study better and understand the different topics, making it easier to revise for their examinations. To create our scenario, we will use:</p> <ul> <li> <p><code>Azure OpenAI:</code> the LLM we will use to create our chatbot</p> </li> <li> <p><code>AI for beginners' lesson on Neural Networks</code>: this will be the data we ground our LLM on</p> </li> <li> <p><code>Azure AI Search</code> and <code>Azure Cosmos DB:</code> vector database to store our data and create a search index</p> </li> </ul> <p>Users will be able to create practice quizzes from their notes, revision flash cards and summarize it to concise overviews. To get started, let us look at what is RAG and how works:</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#retrieval-augmented-generation-rag","title":"Retrieval Augmented Generation (RAG)","text":"<p>An LLM powered chatbot processes user prompts to generate responses. It is designed to be interactive and engages with users on a wide array of topics. However, its responses are limited to the context provided and its foundational training data. For instance, GPT-4 knowledge cutoff is September 2021, meaning, it lacks knowledge of events that have occurred after this period. In addition, the data used to train LLMs excludes confidential information such as personal notes or a company's product manual.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#how-rags-retrieval-augmented-generation-work","title":"How RAGs (Retrieval Augmented Generation) work","text":"<p>Suppose you want to deploy a chatbot that creates quizzes from your notes, you will require a connection to the knowledge base. This is where RAG comes to the rescue. RAGs operate as follows:</p> <ul> <li> <p>Knowledge base: Before retrieval, these documents need to be ingested and preprocessed, typically breaking down large documents into smaller chunks, transforming them to text embedding and storing them in a database.</p> </li> <li> <p>User Query: the user asks a question</p> </li> <li> <p>Retrieval: When a user asks a question, the embedding model retrieves relevant information from our knowledge base to provide more context that will be incorporated into the prompt.</p> </li> <li> <p>Augmented Generation: the LLM enhances its response based on the data retrieved. It allows the response generated to be not only based on pre-trained data but also relevant information from the added context. The retrieved data is used to augment the LLM's responses. The LLM then returns an answer to the user's question.</p> </li> </ul> <p></p> <p>The architecture for RAGs is implemented using transformers consisting of two parts: an encoder and a decoder. For example, when a user asks a question, the input text 'encoded' into vectors capturing the meaning of words and the vectors are 'decoded' into our document index and generates new text based on the user query. The LLM uses both an encoder-decoder model to generate the output.</p> <p>Two approaches when implementing RAG according to the proposed paper: Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks are:</p> <ul> <li> <p>RAG-Sequence using retrieved documents to predict the best possible answer to a user query</p> </li> <li> <p>RAG-Token using documents to generate the next token, then retrieve them to answer the user's query</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#why-would-you-use-rags","title":"Why would you use RAGs?","text":"<ul> <li> <p>Information richness: ensures text responses are up to date and current. It, therefore, enhances performance on domain specific tasks by accessing the internal knowledge base.</p> </li> <li> <p>Reduces fabrication by utilizing verifiable data in the knowledge base to provide context to the user queries.</p> </li> <li> <p>It is cost effective as they are more economical compared to fine-tuning an LLM</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#creating-a-knowledge-base","title":"Creating a knowledge base","text":"<p>Our application is based on our personal data i.e., the Neural Network lesson on AI For Beginners curriculum.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#vector-databases","title":"Vector Databases","text":"<p>A vector database, unlike traditional databases, is a specialized database designed to store, manage and search embedded vectors. It stores numerical representations of documents. Breaking down data to numerical embeddings makes it easier for our AI system to understand and process the data.</p> <p>We store our embeddings in vector databases as LLMs have a limit of the number of tokens they accept as input. As you cannot pass the entire embeddings to an LLM, we will need to break them down into chunks and when a user asks a question, the embeddings most like the question will be returned together with the prompt. Chunking also reduces costs on the number of tokens passed through an LLM.</p> <p>Some popular vector databases include Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant and DeepLake. You can create an Azure Cosmos DB model using Azure CLI with the following command:</p> <pre><code>az login\naz group create -n &lt;resource-group-name&gt; -l &lt;location&gt;\naz cosmosdb create -n &lt;cosmos-db-name&gt; -r &lt;resource-group-name&gt;\naz cosmosdb list-keys -n &lt;cosmos-db-name&gt; -g &lt;resource-group-name&gt;\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#from-text-to-embeddings","title":"From text to embeddings","text":"<p>Before we store our data, we will need to convert it to vector embeddings before it is stored in the database. If you are working with large documents or long texts, you can chunk them based on queries you expect. Chunking can be done at sentence level, or at a paragraph level. As chunking derives meanings from the words around them, you can add some other context to a chunk, for example, by adding the document title or including some text before or after the chunk. You can chunk the data as follows:</p> <pre><code>def split_text(text, max_length, min_length):\n    words = text.split()\n    chunks = []\n    current_chunk = []\n\n    for word in words:\n        current_chunk.append(word)\n        if len(' '.join(current_chunk)) &lt; max_length and len(' '.join(current_chunk)) &gt; min_length:\n            chunks.append(' '.join(current_chunk))\n            current_chunk = []\n\n    # If the last chunk didn't reach the minimum length, add it anyway\n    if current_chunk:\n        chunks.append(' '.join(current_chunk))\n\n    return chunks\n</code></pre> <p>Once chunked, we can then embed our text using different embedding models. Some models you can use include: word2vec, ada-002 by OpenAI, Azure Computer Vision and many more. Selecting a model to use will depend on the languages you're using, the type of content encoded (text/images/audio), the size of input it can encode and length of the embedding output.</p> <p>An example of embedded text using OpenAI's <code>text-embedding-ada-002</code> model is: </p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#retrieval-and-vector-search","title":"Retrieval and Vector Search","text":"<p>When a user asks a question, the retriever transforms it into a vector using the query encoder, it then searches through our document search index for relevant vectors in the document that are related to the input. Once done, it converts both the input vector and document vectors into text and passes it through the LLM.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#retrieval","title":"Retrieval","text":"<p>Retrieval happens when the system tries to quickly find the documents from the index that satisfy the search criteria. The goal of the retriever is to get documents that will be used to provide context and ground the LLM on your data.</p> <p>There are several ways to perform search within our database such as:</p> <ul> <li> <p>Keyword search - used for text searches</p> </li> <li> <p>Semantic search - uses the semantic meaning of words</p> </li> <li> <p>Vector search - converts documents from text to vector representations using embedding models. Retrieval will be done by querying the documents whose vector representations are closest to the user question.</p> </li> <li> <p>Hybrid - a combination of both keyword and vector search.</p> </li> </ul> <p>A challenge with retrieval comes in when there is no similar response to the query in the database, the system will then return the best information they can get, however, you can use tactics like set up the maximum distance for relevance or use hybrid search that combines both keywords and vector search. In this lesson we will use hybrid search, a combination of both vector and keyword search. We will store our data into a dataframe with columns containing the chunks as well as embeddings.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#vector-similarity","title":"Vector Similarity","text":"<p>The retriever will search through the knowledge database for embeddings that are close together, the closest neighbour, as they are texts that are similar. In the scenario a user asks a query, it is first embedded then matched with similar embeddings. The common measurement that is used to find how similar different vectors are is cosine similarity which is based on the angle between two vectors.</p> <p>We can measure similarity using other alternatives we can use are Euclidean distance which is the straight line between vector endpoints and dot product which measures the sum of the products of corresponding elements of two vectors.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#search-index","title":"Search index","text":"<p>When doing retrieval, we will need to build a search index for our knowledge base before we perform search. An index will store our embeddings and can quickly retrieve the most similar chunks even in a large database. We can create our index locally using:</p> <pre><code>from sklearn.neighbors import NearestNeighbors\n\nembeddings = flattened_df['embeddings'].to_list()\n\n# Create the search index\nnbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\n\n# To query the index, you can use the kneighbors method\ndistances, indices = nbrs.kneighbors(embeddings)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#re-ranking","title":"Re-ranking","text":"<p>Once you have queried the database, you might need to sort the results from the most relevant. A reranking LLM utilizes Machine Learning to improve the relevance of search results by ordering them from the most relevant. Using Azure AI Search, reranking is done automatically for you using a semantic reranker. An example of how reranking works using nearest neighbours:</p> <pre><code># Find the most similar documents\ndistances, indices = nbrs.kneighbors([query_vector])\n\nindex = []\n# Print the most similar documents\nfor i in range(3):\n    index = indices[0][i]\n    for index in indices[0]:\n        print(flattened_df['chunks'].iloc[index])\n        print(flattened_df['path'].iloc[index])\n        print(flattened_df['distances'].iloc[index])\n    else:\n        print(f\"Index {index} not found in DataFrame\")\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#bringing-it-all-together","title":"Bringing it all together","text":"<p>The last step is adding our LLM into the mix to be able to get responses that are grounded on our data. We can implement it as follows:</p> <pre><code>user_input = \"what is a perceptron?\"\n\ndef chatbot(user_input):\n    # Convert the question to a query vector\n    query_vector = create_embeddings(user_input)\n\n    # Find the most similar documents\n    distances, indices = nbrs.kneighbors([query_vector])\n\n    # add documents to query  to provide context\n    history = []\n    for index in indices[0]:\n        history.append(flattened_df['chunks'].iloc[index])\n\n    # combine the history and the user input\n    history.append(user_input)\n\n    # create a message object\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an AI assistant that helps with AI questions.\"},\n        {\"role\": \"user\", \"content\": history[-1]}\n    ]\n\n    # use chat completion to generate a response\n    response = openai.chat.completions.create(\n        model=\"gpt-4\",\n        temperature=0.7,\n        max_tokens=800,\n        messages=messages\n    )\n\n    return response.choices[0].message\n\nchatbot(user_input)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#evaluating-our-application","title":"Evaluating our application","text":""},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#evaluation-metrics","title":"Evaluation Metrics","text":"<ul> <li> <p>Quality of responses supplied ensuring it sounds natural, fluent and human-like</p> </li> <li> <p>Groundedness of the data: evaluating whether the response that came from supplied docs</p> </li> <li> <p>Relevance: evaluating the response matches and is related to the question asked</p> </li> <li> <p>Fluency - whether the response makes sense grammatically</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#use-cases-for-using-rag-retervival-augmented-generation-and-vector-databases","title":"Use Cases for using RAG (Retervival Augmented Generation) and vector databases","text":"<p>There are many different use cases where function calls can improve your app like:</p> <ul> <li> <p>Question and Answering: grounding your company data to a chat that can be used by employees to ask questions.</p> </li> <li> <p>Recommendation Systems: where you can create a system that matches the most similar values e.g. movies, restaurants and many more.</p> </li> <li> <p>Chatbot services: you can store chat history and personalize the conversation based on the user data.</p> </li> <li> <p>Image search based on vector embeddings, useful when doing image recognition and anomaly detection.</p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#summary","title":"Summary","text":"<p>We have covered the fundamental areas of RAG from adding our data to the application, the user query and output. To simplify creation of RAG, you can use frameworks such as Semanti Kernel, Langchain or Autogen.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#assignment","title":"Assignment","text":"<p>To continue your learning of Retrieval Augmented Generation (RAG) you can build:</p> <ul> <li> <p>Build a front-end for the application using the framework of your choice</p> </li> <li> <p>Utilize a framework, either LangChain or Semantic Kernel, and recreate your application.</p> </li> </ul> <p>Congratulations for completing the lesson \ud83d\udc4f.</p>"},{"location":"curricula/generative-ai-for-beginners/15-rag-and-vector-databases/#learning-does-not-stop-here-continue-the-journey","title":"Learning does not stop here, continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/","title":"Lesson 16","text":""},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#introduction","title":"Introduction","text":"<p>The world of open-source LLMs is exciting and constantly evolving. This lesson aims to provide an in-depth look at open source models. If you are looking for information on how proprietary models compare to open source models, go to the \"Exploring and Comparing Different LLMs\" lesson. This lesson will also cover the topic of fine-tuning but a more detailed explanation can be found in the \"Fine-Tuning LLMs\" lesson.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#learning-goals","title":"Learning goals","text":"<ul> <li>Gain an understanding of open source Models</li> <li>Understanding the benefits of working with open source Models</li> <li>Exploring the open models available on Hugging Face and the Azure AI Studio</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#what-are-open-source-models","title":"What are Open Source Models?","text":"<p>Open source software has played a crucial role in the growth of technology across various fields. The Open Source Initiative (OSI) has defined 10 criteria for software to be classified as open source. The source code must be openly shared under a license approved by the OSI.</p> <p>While the development of LLMs has similar elements to developing software, the process is not exactly the same. This has brought much discussion in the community on the definition of open source in the context of LLMs. For a model to be aligned with the traditional definition of open source the following information should be publicly available:</p> <ul> <li>Datasets used to train the model.</li> <li>Full model weights as a part of the training.</li> <li>The evaluation code.</li> <li>The fine-tuning code.</li> <li>Full model weights and training metrics.</li> </ul> <p>There are currently only a few models that match this criteria. The OLMo model created by Allen Institute for\u00a0Artificial\u00a0Intelligence\u00a0(AllenAI)\u00a0is one that fits this category.</p> <p>For this lesson, we will refer to the models as \"open models\" going forward as they may not match the criteria above at the time of writing.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#benefits-of-open-models","title":"Benefits of Open Models","text":"<p>Highly Customizable - Since open models are released with detailed training information, researchers and developers can modify the model's internals. This enables the creation of highly specialized models that are fine-tuned for a specific task or area of study. Some examples of this are code generation, mathematical operations and biology.</p> <p>Cost - The cost per token for using and deploying these models is lower than that of proprietary models. When building Generative AI applications, looking at performance vs price when working with these models on your use case should be done.</p> <p> Source: Artificial Analysis</p> <p>Flexibility - Working with open models enables you to be flexible in terms of using different models or combining them. An example of this is the HuggingChat Assistants  where a user can select the model being used directly in the user interface:</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#exploring-different-open-models","title":"Exploring Different Open Models","text":""},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#llama-2","title":"Llama 2","text":"<p>LLama2, developed by Meta is an open model that is optimized for chat based applications. This is due to its fine-tuning method, which included a large amount of dialogue and human feedback. With this method, the model produces more results that are aligned to human expectation which provides a better user experience.</p> <p>Some examples of fine-tuned versions of Llama include Japanese Llama, which specializes in Japanese and Llama Pro, which is an enhanced version of the base model.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#mistral","title":"Mistral","text":"<p>Mistral is an open model with a strong focus of high performance and efficiency. It uses the Mixture-of-Experts approach which combines a group of specialized expert models into one system where depending on the input, certain models are selected to be used. This makes the computation more effective as models are only addressing the inputs they are specialized in.</p> <p>Some examples of fine-tuned versions of Mistral include BioMistral, which is focused on the medical domain and OpenMath Mistral, which performs mathematical computation.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#falcon","title":"Falcon","text":"<p>Falcon is an LLM created by the Technology Innovation Institute (TII). The Falcon-40B was trained on 40 billion parameters which has been shown to perform better than GPT-3 with less compute budget. This is due to its use of the FlashAttention algorithm and multiquery attention that enables it to cut down on the memory requirements at inference time. With this reduced inference time, the Falcon-40B is suitable for chat applications.</p> <p>Some examples of fine-tuned versions of Falcon are the OpenAssistant, an assistant built on open models and GPT4ALL, which delivers higher performance than the base model.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#how-to-choose","title":"How to Choose","text":"<p>There is no one answer for choosing an open model. A good place to start is by using the Azure AI Studio's filter by task feature. This will help you understand what types of tasks the model has been trained for. Hugging Face also maintains an LLM Leaderboard which shows you the best performing models based on certain metrics.</p> <p>When looking to compare LLMs across the different types, Artificial Analysis is another great resource:</p> <p> Source: Artifical Analysis</p> <p>If working on a specific use case, searching for fine-tuned versions that are focused on the same area can be effective. Experimenting with multiple open models to see how they perform according to your and your users' expectations is another good practice</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#next-steps","title":"Next Steps","text":"<p>The best part about open models is that you can get started working with them pretty quickly. Check out the Azure AI Studio Model Catalog, which features a specific Hugging Face collection with these models we discussed here.</p>"},{"location":"curricula/generative-ai-for-beginners/16-open-source-models/#learning-does-not-stop-here-continue-the-journey","title":"Learning does not stop here, continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/","title":"Lesson 17","text":""},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#introduction","title":"Introduction","text":"<p>AI Agents represent an exciting development in Generative AI, enabling Large Language Models (LLMs) to evolve from assistants into agents capable of taking actions. AI Agent frameworks enable developers to create applications that give LLMs access to tools and state management. These frameworks also enhance visibility, allowing users and developers to monitor the actions planned by LLMs, thereby improving experience management.</p> <p>The lesson will cover the following areas:</p> <ul> <li>Understanding what an AI Agent is - What exactly is an AI Agent?</li> <li>Exploring four different AI Agent Frameworks - What makes them unique?</li> <li>Applying these AI Agents to different use cases - When should we use AI Agents?</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#learning-goals","title":"Learning goals","text":"<p>After taking this lesson, you'll be able to:</p> <ul> <li>Explain what AI Agents are and how they can be used.</li> <li>Have an understanding of the differences between some of the popular AI Agent Frameworks, and how they differ.</li> <li>Understand how AI Agents function in order to build applications with them.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#what-are-ai-agents","title":"What Are AI Agents?","text":"<p>AI Agents are a very exciting field in the world of Generative AI. With this excitement comes sometimes a confusion of terms and their application. To keep things simple and inclusive of most of the tools that refer to AI Agents, we are going to use this definition:</p> <p>AI Agents allow Large Language Models (LLMs) to perform tasks by giving them access to a state and tools.</p> <p></p> <p>Let's define these terms:</p> <p>Large Language Models - These are the models referred throughout this course such as GPT-3.5, GPT-4, Llama-2, etc.</p> <p>State - This refers to the context that the LLM is working in. The LLM uses the context of its past actions and the current context, guiding its decision-making for subsequent actions. AI Agent Frameworks allow developers to maintain this context easier.</p> <p>Tools - To complete the task that the user has requested and that the LLM has planned out, the LLM needs access to tools. Some examples of tools can be a database, an API, an external application or even another LLM!</p> <p>These definitions will hopefully give you a good grounding going forward as we look at how they are implemented. Let's explore a few different AI Agent frameworks:</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#langchain-agents","title":"LangChain Agents","text":"<p>LangChain Agents is an implementation of the definitions we provided above.</p> <p>To manage the state , it uses a built-in function called the <code>AgentExecutor</code>. This accepts the defined <code>agent</code> and the <code>tools</code> that are available to it.</p> <p>The <code>Agent Executor</code> also stores the chat history to provide the context of the chat.</p> <p></p> <p>LangChain offers a catalog of tools that can be imported into your application in which the LLM can get access to. These are made by the community and by the LangChain team.</p> <p>You can then define these tools and pass them to the <code>Agent Executor</code>.</p> <p>Visibility is another important aspect when talking about AI Agents. It is important for application developers to understand which tool the LLM is using and why.. For that, the team at LangChain have developed LangSmith.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#autogen","title":"AutoGen","text":"<p>The next AI Agent framework we will discuss is AutoGen. The main focus of AutoGen is conversations. Agents are both conversable and customizable.</p> <p>Conversable - LLMs can start and continue a conversation with another LLM in order to complete a task. This is done by creating <code>AssistantAgents</code> and giving them a specific system message.</p> <pre><code>autogen.AssistantAgent( name=\"Coder\", llm_config=llm_config, ) pm = autogen.AssistantAgent( name=\"Product_manager\", system_message=\"Creative in software product ideas.\", llm_config=llm_config, )\n</code></pre> <p>Customizable - Agents can be defined not only as LLMs but be a user or a tool. As a developer, you can define a <code>UserProxyAgent</code> which is responsible for interacting with the user for feedback in completing a task. This feedback can either continue the execution of the task or stop it.</p> <pre><code>user_proxy = UserProxyAgent(name=\"user_proxy\")\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#state-and-tools","title":"State and Tools","text":"<p>To change and manage state, an assistant Agent generates Python code to complete the task.</p> <p>Here is an example of the process:</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#llm-defined-with-a-system-message","title":"LLM Defined with a System Message","text":"<pre><code>system_message=\"For weather related tasks, only use the functions you have been provided with. Reply TERMINATE when the task is done.\"\n</code></pre> <p>This system messages directs this specific LLM to which functions are relevant for its task. Remember, with AutoGen you can have multiple defined AssistantAgents with different system messages.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#chat-is-initiated-by-user","title":"Chat is Initiated by User","text":"<pre><code>user_proxy.initiate_chat( chatbot, message=\"I am planning a trip to NYC next week, can you help me pick out what to wear? \", )\n</code></pre> <p>This message from the user_proxy (Human) is what will start the process of the Agent to explore the possible functions that it should execute.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#function-is-executed","title":"Function is Executed","text":"<pre><code>chatbot (to user_proxy):\n\n***** Suggested tool Call: get_weather ***** Arguments: {\"location\":\"New York City, NY\",\"time_periond:\"7\",\"temperature_unit\":\"Celsius\"} ******************************************************** --------------------------------------------------------------------------------\n\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING FUNCTION get_weather... user_proxy (to chatbot): ***** Response from calling function \"get_weather\" ***** 112.22727272727272 EUR ****************************************************************\n</code></pre> <p>Once the initial chat is processed, the Agent will send the suggest tool to call. In this case, it is a function called <code>get_weather</code>. Depending on your configuration, this function can be automatically executed and read by the Agent or can be executed based on user input.</p> <p>You can find a list of AutoGen code samples to further explore how to get started building.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#taskweaver","title":"Taskweaver","text":"<p>The next agent framework we will explore is Taskweaver. It is known as a \"code-first\" agent because instead of working strictly with <code>strings</code> , it can work with DataFrames in Python. This becomes extremely useful for data analysis and generation tasks. This can be things like creating graphs and charts or generating random numbers.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#state-and-tools_1","title":"State and Tools","text":"<p>To manage the state of the conversation, TaskWeaver uses the concept of a <code>Planner</code>. The <code>Planner</code> is a LLM that takes the request from the users and maps out the tasks that need to be completed to fulfill this request.</p> <p>To complete the tasks the <code>Planner</code> is exposed to the collection of tools called <code>Plugins</code>. This can be Python classes or a general code interpreter. This plugins are stored as embeddings so that the LLM can better search for the correct plugin.</p> <p></p> <p>Here is an example of a plugin to handle anomaly detection:</p> <pre><code>class AnomalyDetectionPlugin(Plugin): def __call__(self, df: pd.DataFrame, time_col_name: str, value_col_name: str):\n</code></pre> <p>The code is verified before executing. Another feature to manage context in Taskweaver is <code>experience</code>. Experience allows for the context of a conversation to be stored over to the long term in a YAML file. This can be configured so that the LLM improves over time on certain tasks given that it is exposed to prior conversations.</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#jarvis","title":"JARVIS","text":"<p>The last agent framework we will explore is JARVIS. What makes JARVIS unique is that it uses an LLM to manage the <code>state</code> of the conversation and the <code>tools</code>are other AI models. Each of the AI models are specialized models that perform certain tasks such as object detection, transcription or image captioning.</p> <p></p> <p>The LLM, being a general purpose model, receives the request from the user and identifies the specific task and any arguments/data that is needed to complete the task.</p> <pre><code>[{\"task\": \"object-detection\", \"id\": 0, \"dep\": [-1], \"args\": {\"image\": \"e1.jpg\" }}]\n</code></pre> <p>The LLM then formats the request in a manner that the specialized AI model can interpret, such as JSON. Once the AI model has returned its prediction based on the task, the LLM receives the response.</p> <p>If multiple models are required to complete the task, it will also interpret the response from those models before bringing them together to generate to the response to the user.</p> <p>The example below shows how this would work when a user is requesting a description and count of the objects in a picture:</p>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#assignment","title":"Assignment","text":"<p>To continue your learning of AI Agents you can build with AutoGen:</p> <ul> <li>An application that simulates a business meeting with different departments of an education startup.</li> <li>Create system messages that guide LLMs in understanding different personas and priorities, and enable the user to pitch a new product idea.</li> <li>The LLM should then generate follow-up questions from each department to refine and improve the pitch and the product idea</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/17-ai-agents/#learning-does-not-stop-here-continue-the-journey","title":"Learning does not stop here, continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/","title":"Lesson 18","text":""},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#fine-tuning-your-llm","title":"Fine-Tuning Your LLM","text":"<p>Using large language models to build generative AI applications comes with new challenges. A key issue is ensuring response quality (accuracy and relevance) in content generated by the model for a given user request. In previous lessons, we discussed techniques like prompt engineering and retrieval-augmented generation that try to solve the problem by modifying the prompt input to the existing model.</p> <p>In today's lesson, we discuss a third technique, fine-tuning, which tries to address the challenge by retraining the model itself with additional data. Let's dive into the details.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#learning-objectives","title":"Learning Objectives","text":"<p>This lesson introduces the concept of fine-tuning for pre-trained language models, explores the benefits and challenges of this approach, and provides guidance on when and how to use fine tuning to improve the performance of your generative AI models.</p> <p>By the end of this lesson, you should be able to answer the following questions:</p> <ul> <li>What is fine tuning for language models?</li> <li>When, and why, is fine tuning useful?</li> <li>How can I fine-tune a pre-trained model?</li> <li>What are the limitations of fine-tuning?</li> </ul> <p>Ready? Let's get started.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#illustrated-guide","title":"Illustrated Guide","text":"<p>Want to get the big picture of what we'll cover before we dive in? Check out this illustrated guide that describes the learning journey for this lesson - from learning the core concepts and motivation for fine-tuning, to understanding the process and best practices for executing the fine-tuning task. This is a fascinating topic for exploration, so don't forget to check out the Resources page for additional links to support your self-guided learning journey!</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#what-is-fine-tuning-for-language-models","title":"What is fine-tuning for language models?","text":"<p>By definition, large language models are pre-trained on large quantities of text sourced from diverse sources including the internet. As we've learned in previous lessons, we need techniques like prompt engineering and retrieval-augmented generation to improve the quality of the model's responses to the user's questions (\"prompts\").</p> <p>A popular prompt-engineering technique involves giving the model more guidance on what is expected in the response either by providing instructions (explicit guidance) or giving it a few examples (implicit guidance). This is referred to as few-shot learning but it has two limitations:</p> <ul> <li>Model token limits can restrict the number of examples you can give, and limit the effectiveness.</li> <li>Model token costs can make it expensive to add examples to every prompt, and limit flexibility.</li> </ul> <p>Fine-tuning is a common practice in machine learning systems where we take a pre-trained model and retrain it with new data to improve its performance on a specific task. In the context of language models, we can fine-tune the pre-trained model with a curated set of examples for a given task or application domain to create a custom model that may be more accurate and relevant for that specific task or domain. A side-benefit of fine-tuning is that it can also reduce the number of examples needed for few-shot learning - reducing token usage and related costs.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#when-and-why-should-we-fine-tune-models","title":"When and why should we fine-tune models?","text":"<p>In this context, when we talk about fine-tuning, we are referring to supervised fine-tuning where the retraining is done by adding new data that was not part of the original training dataset. This is different from an unsupervised fine-tuning approach where the model is retrained on the original data, but with different hyperparameters.</p> <p>The key thing to remember is that fine-tuning is an advanced technique that requires a certain level of expertise to get the desired results. If done incorrectly, it may not provide the expected improvements, and may even degrade the performance of the model for your targeted domain.</p> <p>So, before you learn \"how\" to fine-tune language models, you need to know \"why\" you should take this route, and \"when\" to start the process of fine-tuning. Start by asking yourself these questions:</p> <ul> <li>Use Case: What is your use case for fine-tuning? What aspect of the current pre-trained model do you want to improve upon?</li> <li>Alternatives: Have you tried other techniques to achieve the desired outcomes? Use them to create a baseline for comparison.</li> <li>Prompt engineering: Try techniques like few-shot prompting with examples of relevant prompt responses. Evaluate the quality of responses.</li> <li>Retrieval Augmented Generation: Try augmenting prompts with query results retrieved by searching your data. Evaluate the quality of responses.</li> <li>Costs: Have you identified the costs for fine-tuning?</li> <li>Tunability - is the pre-trained model available for fine-tuning?</li> <li>Effort - for preparing training data, evaluating &amp; refining model.</li> <li>Compute - for running fine-tuning jobs, and deploying fine-tuned model</li> <li>Data - access to sufficient quality examples for fine-tuning impact</li> <li>Benefits: Have you confirmed the benefits for fine-tuning?</li> <li>Quality - did fine-tuned model outperform baseline?</li> <li>Cost - does it reduce token usage by simplifying prompts?</li> <li>Extensibility - can you repurpose base model for new domains?</li> </ul> <p>By answering these questions, you should be able to decide if fine-tuning is the right approach for your use case. Ideally, the approach is valid only if the benefits outweigh the costs. Once you decide to proceed, it's time to think about how you can fine tune the pre-trained model.</p> <p>Want to get more insights on the decision-making process? Watch To fine-tune or not to fine-tune</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#how-can-we-fine-tune-a-pre-trained-model","title":"How can we fine-tune a pre-trained model?","text":"<p>To fine-tune a pre-trained model, you need to have:</p> <ul> <li>a pre-trained model to fine-tune</li> <li>a dataset to use for fine-tuning</li> <li>a training environment to run the fine-tuning job</li> <li>a hosting environment to deploy fine-tuned model</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#fine-tuning-in-action","title":"Fine-Tuning In Action","text":"<p>The following resources provide step-by-step tutorials to walk you through a real example using a selected model with a curated dataset. To work through these tutorials, you need an account on the specific provider, along with access to the relevant model and datasets.</p> Provider Tutorial Description OpenAI How to fine-tune chat models Learn to fine-tune a <code>gpt-35-turbo</code> for a specific domain (\"recipe assistant\") by preparing training data, running the fine-tuning job, and using the fine-tuned model for inference. Azure OpenAI GPT 3.5 Turbo fine-tuning tutorial Learn to fine-tune a <code>gpt-35-turbo-0613</code> model on Azure by taking steps to create &amp; upload training data, run the fine-tuning job. Deploy &amp; use the new model. Hugging Face Fine-tuning LLMs with Hugging Face This blog post walks you fine-tuning an open LLM (ex: <code>CodeLlama 7B</code>) using the transformers library &amp; Transformer Reinforcement Learning (TRL) with open datasets on Hugging Face. \ud83e\udd17 AutoTrain Fine-tuning LLMs with AutoTrain AutoTrain (or AutoTrain Advanced) is a python library developed by Hugging Face that allows finetuning for many different tasks including LLM finetuning. AutoTrain is a no-code solution and finetuning can be done in your own cloud, on Hugging Face Spaces or locally. It supports both a web-based GUI, CLI and training via yaml config files."},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#assignment","title":"Assignment","text":"<p>Select one of the tutorials above and walk through them. We may replicate a version of these tutorials in Jupyter Notebooks in this repo for reference only. Please use the original sources directly to get the latest versions.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#great-work-continue-your-learning","title":"Great Work! Continue Your Learning.","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p> <p>Congratulations!! You have completed the final lesson from the v2 series for this course! Don't stop learning and building. **Check out the RESOURCES page for a list of additional suggestions for just this topic.</p> <p>Our v1 series of lessons have also been updated with more assignments and concepts. So take a minute to refresh your knowledge - and please share your questions and feedback to help us improve these lessons for the community.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#resources-for-self-guided-learning","title":"Resources For Self-Guided Learning","text":"<p>The lesson was built using a number of core resources from OpenAI and Azure OpenAI as references for the terminology and tutorials. Here is a non-comprehensive list, for your own self-guided learning journeys.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#1-primary-resources","title":"1. Primary Resources","text":"Title/Link Description Fine-tuning with OpenAI Models Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt, saving you costs, improving response quality, and enabling lower-latency requests. Get an overview of fine-tuning from OpenAI. What is Fine-Tuning with Azure OpenAI? Understand what fine-tuning is (concept), why you should look at it (motivating problem), what data to use (training) and measuring the quality Customize a model with fine-tuning Azure OpenAI Service lets you tailor our models to your personal datasets using fine-tuning. Learn how to fine-tune (process) select models using Azure AI Studio, Python SDK or REST API. Recommendations for LLM fine-tuning LLMs may not perform well on specific domains, tasks, or datasets, or may produce inaccurate or misleading outputs. When should you consider fine-tuning as a possible solution to this? Continuous Fine Tuning Continuous fine-tuning is the iterative process of selecting an already fine-tuned model as a base model and fine-tuning it further on new sets of training examples. Fine-tuning and function calling Fine-tuning your model with function calling examples can improve model output by getting more accurate and consistent outputs - with similarly-formatted responses &amp; cost-savings Fine-tuning Models: Azure OpenAI Guidance Look up this table to understand what models can be fine-tuned in Azure OpenAI, and which regions these are available in. Look up their token limits and training data expiry dates if needed. To Fine Tune or Not To Fine Tune? That is the Question This 30-min Oct 2023 episode of the AI Show discusses benefits, drawbacks and practical insights that help you make this decision. Getting Started With LLM Fine-Tuning This AI Playbook resource walks you through data requirements, formatting, hyperparameter fine-tuning and challenges/limitations you should know. Tutorial: Azure OpenAI GPT3.5 Turbo Fine-Tuning Learn to create a sample fine-tuning dataset, prepare for fine-tuning, create a fine-tuning job, and deploy the fine-tuned model on Azure. Tutorial: Fine-tune a Llama 2 model in Azure AI Studio Azure AI Studio lets you tailor large language models to your personal datasets using a UI-based workflow suitable for low-code developers. See this example. Tutorial:Fine-tune Hugging Face models for a single GPU on Azure This article describes how to fine-tune a Hugging Face model with the Hugging Face transformers library on a single GPU with Azure DataBricks + Hugging Face Trainer libraries Training: Fine-tune a foundation model with Azure Machine Learning The model catalog in Azure Machine Learning offers many open source models you can fine-tune for your specific task. Try this module is from the AzureML Generative AI Learning Path Tutorial: Azure OpenAI Fine-Tuning Fine-tuning GPT-3.5 or GPT-4 models on Microsoft Azure using W&amp;B allows for detailed tracking and analysis of model performance. This guide extends the concepts from the OpenAI Fine-Tuning guide with specific steps and features for Azure OpenAI."},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/#2-secondary-resources","title":"2. Secondary Resources","text":"<p>This section captures additional resources that are worth exploring, but that we did not have time to cover in this lesson. They may be covered in a future lesson, or as a secondary assignment option, at a later date. For now, use them to build your own expertise and knowledge around this topic.</p> Title/Link Description OpenAI Cookbook: Data preparation and analysis for chat model fine-tuning This notebook serves as a tool to preprocess and analyze the chat dataset used for fine-tuning a chat model. It checks for format errors, provides basic statistics, and estimates token counts for fine-tuning costs. See: Fine-tuning method for gpt-3.5-turbo. OpenAI Cookbook: Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant The aim of this notebook is to walk through a comprehensive example of how to fine-tune OpenAI models for Retrieval Augmented Generation (RAG). We will also be integrating Qdrant and Few-Shot Learning to boost model performance and reduce fabrications. OpenAI Cookbook: Fine-tuning GPT with Weights &amp; Biases Weights &amp; Biases (W&amp;B) is the AI developer platform, with tools for training models, fine-tuning models, and leveraging foundation models. Read their OpenAI Fine-Tuning guide first, then try the Cookbook exercise. Community Tutorial Phinetuning 2.0 - fine-tuning for Small Language Models Meet Phi-2, Microsoft\u2019s new small model, remarkably powerful yet compact. This tutorial will guide you through fine-tuning Phi-2, demonstrating how to build a unique dataset and fine-tune model using QLoRA. Hugging Face Tutorial How to Fine-Tune LLMs in 2024 with Hugging Face This blog post walks you thorugh how to fine-tune open LLMs using Hugging Face TRL, Transformers &amp; datasets in 2024. You define a use case, setup a dev environment, prepare a dataset, fine tune the model, test-evaluate it, then deploy it to production. Hugging Face: AutoTrain Advanced Brings faster and easier training and deployments of state-of-the-art machine learning models. Repo has Colab-friendly tutorials with YouTube video guidance, for fine-tuning. Reflects recent local-first update . Read the AutoTrain documentation"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/RESOURCES/","title":"RESOURCES","text":""},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/RESOURCES/#resources-for-self-guided-learning","title":"Resources For Self-Guided Learning","text":"<p>The lesson was built using a number of core resources from OpenAI and Azure OpenAI as references for the terminology and tutorials. Here is a non-comprehensive list, for your own self-guided learning journeys.</p>"},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/RESOURCES/#1-primary-resources","title":"1. Primary Resources","text":"Title/Link Description Fine-tuning with OpenAI Models Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt, saving you costs, improving response quality, and enabling lower-latency requests. Get an overview of fine-tuning from OpenAI. What is Fine-Tuning with Azure OpenAI? Understand what fine-tuning is (concept), why you should look at it (motivating problem), what data to use (training) and measuring the quality Customize a model with fine-tuning Azure OpenAI Service lets you tailor our models to your personal datasets using fine-tuning. Learn how to fine-tune (process) select models using Azure AI Studio, Python SDK or REST API. Recommendations for LLM fine-tuning LLMs may not perform well on specific domains, tasks, or datasets, or may produce inaccurate or misleading outputs. When should you consider fine-tuning as a possible solution to this? Continuous Fine Tuning Continuous fine-tuning is the iterative process of selecting an already fine-tuned model as a base model and fine-tuning it further on new sets of training examples. Fine-tuning and function calling Fine-tuning your model with function calling examples can improve model output by getting more accurate and consistent outputs - with similarly-formatted responses &amp; cost-savings Fine-tuning Models: Azure OpenAI Guidance Look up this table to understand what models can be fine-tuned in Azure OpenAI, and which regions these are available in. Look up their token limits and training data expiry dates if needed. To Fine Tune or Not To Fine Tune? That is the Question This 30-min Oct 2023 episode of the AI Show discusses benefits, drawbacks and practical insights that help you make this decision. Getting Started With LLM Fine-Tuning This AI Playbook resource walks you through data requirements, formatting, hyperparameter fine-tuning and challenges/limitations you should know. Tutorial: Azure OpenAI GPT3.5 Turbo Fine-Tuning Learn to create a sample fine-tuning dataset, prepare for fine-tuning, create a fine-tuning job, and deploy the fine-tuned model on Azure. Tutorial: Fine-tune a Llama 2 model in Azure AI Studio Azure AI Studio lets you tailor large language models to your personal datasets using a UI-based workflow suitable for low-code developers. See this example. Tutorial:Fine-tune Hugging Face models for a single GPU on Azure This article describes how to fine-tune a Hugging Face model with the Hugging Face transformers library on a single GPU with Azure DataBricks + Hugging Face Trainer libraries Training: Fine-tune a foundation model with Azure Machine Learning The model catalog in Azure Machine Learning offers many open source models you can fine-tune for your specific task. Try this module is from the AzureML Generative AI Learning Path Tutorial: Azure OpenAI Fine-Tuning Fine-tuning GPT-3.5 or GPT-4 models on Microsoft Azure using W&amp;B allows for detailed tracking and analysis of model performance. This guide extends the concepts from the OpenAI Fine-Tuning guide with specific steps and features for Azure OpenAI."},{"location":"curricula/generative-ai-for-beginners/18-fine-tuning/RESOURCES/#2-secondary-resources","title":"2. Secondary Resources","text":"<p>This section captures additional resources that are worth exploring, but that we did not have time to cover in this lesson. They may be covered in a future lesson, or as a secondary assignment option, at a later date. For now, use them to build your own expertise and knowledge around this topic.</p> Title/Link Description OpenAI Cookbook: Data preparation and analysis for chat model fine-tuning This notebook serves as a tool to preprocess and analyze the chat dataset used for fine-tuning a chat model. It checks for format errors, provides basic statistics, and estimates token counts for fine-tuning costs. See: Fine-tuning method for gpt-3.5-turbo. OpenAI Cookbook: Fine-Tuning for Retrieval Augmented Generation (RAG) with Qdrant The aim of this notebook is to walk through a comprehensive example of how to fine-tune OpenAI models for Retrieval Augmented Generation (RAG). We will also be integrating Qdrant and Few-Shot Learning to boost model performance and reduce fabrications. OpenAI Cookbook: Fine-tuning GPT with Weights &amp; Biases Weights &amp; Biases (W&amp;B) is the AI developer platform, with tools for training models, fine-tuning models, and leveraging foundation models. Read their OpenAI Fine-Tuning guide first, then try the Cookbook exercise. Community Tutorial Phinetuning 2.0 - fine-tuning for Small Language Models Meet Phi-2, Microsoft\u2019s new small model, remarkably powerful yet compact. This tutorial will guide you through fine-tuning Phi-2, demonstrating how to build a unique dataset and fine-tune model using QLoRA. Hugging Face Tutorial How to Fine-Tune LLMs in 2024 with Hugging Face This blog post walks you thorugh how to fine-tune open LLMs using Hugging Face TRL, Transformers &amp; datasets in 2024. You define a use case, setup a dev environment, prepare a dataset, fine tune the model, test-evaluate it, then deploy it to production. Hugging Face: AutoTrain Advanced Brings faster and easier training and deployments of state-of-the-art machine learning models. Repo has Colab-friendly tutorials with YouTube video guidance, for fine-tuning. Reflects recent local-first update . Read the AutoTrain documentation"},{"location":"curricula/generative-ai-for-beginners/19-slm/","title":"Lesson 19","text":""},{"location":"curricula/generative-ai-for-beginners/19-slm/#introduction-to-small-language-models-for-generative-ai-for-beginners","title":"Introduction to Small Language Models for Generative AI for Beginners","text":"<p>Generative AI is a fascinating field of artificial intelligence that focuses on creating systems capable of generating new content. This content can range from text and images to music and even entire virtual environments. One of the most exciting applications of generative AI is in the realm of language models.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#what-are-small-language-models","title":"What Are Small Language Models?","text":"<p>A Small Language Model (SLM) represents a scaled-down variant of a large language model (LLM), leveraging many of the architectural principles and techniques of LLMs, while exhibiting a significantly reduced computational footprint. </p> <p>SLMs are a subset of language models designed to generate human-like text. Unlike their larger counterparts, such as GPT-4, SLMs are more compact and efficient, making them ideal for applications where computational resources are limited. Despite their smaller size, they can still perform a variety of tasks. Typically, SLMs are constructed by compressing or distilling LLMs, aiming to retain a substantial portion of the original model's functionality and linguistic capabilities. This reduction in model size decreases the overall complexity, making SLMs more efficient in terms of both memory usage and computational requirements. Despite these optimizations, SLMs can still perform a wide range of natural language processing (NLP) tasks:</p> <ul> <li>Text Generation: Creating coherent and contextually relevant sentences or paragraphs.</li> <li>Text Completion: Predicting and completing sentences based on a given prompt.</li> <li>Translation: Converting text from one language to another.</li> <li>Summarization: Condensing long pieces of text into shorter, more digestible summaries.</li> </ul> <p>Albeit with some trade-offs in performance or depth of understanding compared to their larger counterparts. </p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#how-do-small-language-models-work","title":"How Do Small Language Models Work?","text":"<p>SLMs are trained on vast amounts of text data. During training, they learn the patterns and structures of language, enabling them to generate text that is both grammatically correct and contextually appropriate. The training process involves:</p> <ul> <li>Data Collection: Gathering large datasets of text from various sources.</li> <li>Preprocessing: Cleaning and organizing the data to make it suitable for training.</li> <li>Training: Using machine learning algorithms to teach the model how to understand and generate text.</li> <li>Fine-Tuning: Adjusting the model to improve its performance on specific tasks.</li> </ul> <p>The development of SLMs aligns with the increasing need for models that can be deployed in resource-constrained environments, such as mobile devices or edge computing platforms, where full-scale LLMs may be impractical due to their heavy resource demands. By focusing on efficiency, SLMs balance performance with accessibility, enabling broader application across various domains.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#learning-objectives","title":"Learning Objectives","text":"<p>In this lesson, we hope to introduce the knowledge of SLM and combine it with Microsoft Phi-3 to learn different scenarios in text content, vision and MoE.</p> <p>By the end of this lesson, you should be able to answer the following questions:</p> <ul> <li>What is SLM</li> <li>What is the difference about SLM and LLM</li> <li>What is Microsoft Phi-3/3.5 Family</li> <li>How to inference Microsoft Phi-3/3.5 Family</li> </ul> <p>Ready? Let's get started.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#the-distinctions-between-large-language-models-llms-and-small-language-models-slms","title":"The Distinctions between Large Language Models (LLMs) and Small Language Models (SLMs)","text":"<p>Both LLMs and SLMs are built upon foundational principles of probabilistic machine learning, following similar approaches in their architectural design, training methodologies, data generation processes, and model evaluation techniques. However, several key factors differentiate these two types of models.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#applications-of-small-language-models","title":"Applications of Small Language Models","text":"<p>SLMs have a wide range of applications, including:</p> <ul> <li>Chatbots: Providing customer support and engaging with users in a conversational manner.</li> <li>Content Creation: Assisting writers by generating ideas or even drafting entire articles.</li> <li>Education: Helping students with writing assignments or learning new languages.</li> <li>Accessibility: Creating tools for individuals with disabilities, such as text-to-speech systems.</li> </ul> <p>Size</p> <p>A primary distinction between LLMs and SLMs lies in the scale of the models. LLMs, such as ChatGPT (GPT-4), can comprise an estimated 1.76 trillion parameters, while open-source SLMs like Mistral 7B are designed with significantly fewer parameters\u2014approximately 7 billion. This disparity is primarily due to differences in model architecture and training processes. For instance, ChatGPT employs a self-attention mechanism within an encoder-decoder framework, whereas Mistral 7B uses sliding window attention, which enables more efficient training within a decoder-only model. This architectural variance has profound implications for the complexity and performance of these models.</p> <p>Comprehension</p> <p>SLMs are typically optimized for performance within specific domains, making them highly specialized but potentially limited in their ability to provide broad contextual understanding across multiple fields of knowledge. In contrast, LLMs aim to simulate human-like intelligence on a more comprehensive level. Trained on vast, diverse datasets, LLMs are designed to perform well across a variety of domains, offering greater versatility and adaptability. Consequently, LLMs are more suitable for a wider range of downstream tasks, such as natural language processing and programming.</p> <p>Computing</p> <p>The training and deployment of LLMs are resource-intensive processes, often requiring significant computational infrastructure, including large-scale GPU clusters. For example, training a model like ChatGPT from scratch may necessitate thousands of GPUs over extended periods. In contrast, SLMs, with their smaller parameter counts, are more accessible in terms of computational resources. Models like Mistral 7B can be trained and run on local machines equipped with moderate GPU capabilities, although training still demands several hours across multiple GPUs.</p> <p>Bias</p> <p>Bias is a known issue in LLMs, primarily due to the nature of the training data. These models often rely on raw, openly available data from the internet, which may underrepresent or misrepresent certain groups, introduce erroneous labeling, or reflect linguistic biases influenced by dialect, geographic variations, and grammatical rules. Additionally, the complexity of LLM architectures can inadvertently exacerbate bias, which may go unnoticed without careful fine-tuning. On the other hand, SLMs, being trained on more constrained, domain-specific datasets, are inherently less susceptible to such biases, though they are not immune to them.</p> <p>Inference</p> <p>The reduced size of SLMs affords them a significant advantage in terms of inference speed, allowing them to generate outputs efficiently on local hardware without the need for extensive parallel processing. In contrast, LLMs, due to their size and complexity, often require substantial parallel computational resources to achieve acceptable inference times. The presence of multiple concurrent users further slows down LLMs' response times, especially when deployed at scale.</p> <p>In summary, while both LLMs and SLMs share a foundational basis in machine learning, they differ significantly in terms of model size, resource requirements, contextual understanding, susceptibility to bias, and inference speed. These distinctions reflect their respective suitability for different use cases, with LLMs being more versatile but resource-heavy, and SLMs offering more domain-specific efficiency with reduced computational demands.</p> <p>Note\uff1aIn this chapter, we will introduce SLM using Microsoft Phi-3 / 3.5 as an example.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#introduce-phi-3-phi-35-family","title":"Introduce Phi-3 / Phi-3.5 Family","text":"<p>Phi-3 / 3.5 Family mainly targets text, vision, and Agent (MoE) application scenarios:</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#phi-3-35-instruct","title":"Phi-3 / 3.5 Instruct","text":"<p>Mainly for text generation, chat completion, and content information extraction, etc.</p> <p>Phi-3-mini</p> <p>The 3.8B language model is available on Microsoft Azure AI Studio, Hugging Face, and Ollama. Phi-3 models significantly outperform language models of equal and larger sizes on key benchmarks (see benchmark numbers below, higher numbers are better). Phi-3-mini outperforms models twice its size, while Phi-3-small and Phi-3-medium outperform larger models, including GPT-3.5</p> <p>Phi-3-small &amp; medium</p> <p>With just 7B parameters, Phi-3-small beats GPT-3.5T on a variety of language, reasoning, coding, and math benchmarks.</p> <p>The Phi-3-medium with 14B parameters continues this trend and outperforms the Gemini 1.0 Pro.</p> <p>Phi-3.5-mini</p> <p>We can think of it as an upgrade of Phi-3-mini. While the parameters remain unchanged, it improves the ability to support multiple languages( Support 20+ languages:Arabic, Chinese, Czech, Danish, Dutch, English, Finnish, French, German, Hebrew, Hungarian, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Russian, Spanish, Swedish, Thai, Turkish, Ukrainian) \u200b\u200band adds stronger support for long context.</p> <p>Phi-3.5-mini with 3.8B parameters outperforms language models of the same size and on par with models twice its size.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#phi-3-35-vision","title":"Phi-3 / 3.5 Vision","text":"<p>We can think of the Instruct model of Phi-3/3.5 as Phi's ability to understand, and Vision is what gives Phi eyes to understand the world.</p> <p>Phi-3-Vision</p> <p>Phi-3-vision, with only 4.2B parameters, continues this trend and outperforms larger models such as Claude-3 Haiku and Gemini 1.0 Pro V on general visual reasoning tasks, OCR, and table and diagram comprehension tasks.</p> <p>Phi-3.5-Vision</p> <p>Phi-3.5-Vision is also an upgrade of Phi-3-Vision, adding support for multiple images. You can think of it as an improvement in vision, not only can you see pictures, but also videos.</p> <p>Phi-3.5-vision outperforms larger models such as Claude-3.5 Sonnet and Gemini 1.5 Flash across OCR, table and chart understanding tasks and on par on general visual knowledge reasoning tasks.Support multi-frame input, i.e., perform reasoning on multiple input images</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#phi-35-moe","title":"Phi-3.5-MoE","text":"<p>Mixture of Experts(MoE) enable models to be pretrained with far less compute, which means you can dramatically scale up the model or dataset size with the same compute budget as a dense model. In particular, a MoE model should achieve the same quality as its dense counterpart much faster during pretraining.</p> <p>Phi-3.5-MoE comprises 16x3.8B expert modules.Phi-3.5-MoE with only 6.6B active parameters achieves a similar level of reasoning, language understanding, and math as much larger models</p> <p>We can use the Phi-3/3.5 Family model based on different scenarios. Unlike LLM, you can deploy Phi-3/3.5-mini or Phi-3/3.5-Vision on edge devices.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#how-to-use-phi-335-family-models","title":"How to use Phi-3/3.5 Family models","text":"<p>We hope to use Phi-3/3.5 in different scenarios. Next, we will use Phi-3/3.5 based on different scenarios.</p> <p></p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#inference-difference-clouds-api","title":"Inference difference Cloud's API","text":"<p>GitHub Models</p> <p>GitHub Models is the most direct way. You can quickly access the Phi-3/3.5-Instruct model through GitHub Models. Combined with the Azure AI Inference SDK / OpenAI SDK, you can access the API through code to complete the Phi-3/3.5-Instruct call. You can also test different effects through Playground.</p> <ul> <li>Demo:Comparison of the effects of Phi-3-mini and Phi-3.5-mini in Chinese scenarios</li> </ul> <p></p> <p></p> <p>Azure AI Studio</p> <p>Or if we want to use the vision and MoE models, you can use Azure AI Studio to complete the call. If you are interested, you can read the Phi-3 Cookbook to learn how to call Phi-3/3.5 Instruct, Vision, MoE through Azure AI Studio Click this link</p> <p>NVIDIA NIM</p> <p>In addition to the cloud-based Model Catalog solutions provided by Azure and GitHub, you can also use Nivida NIM to complete related calls. You can visit NIVIDA NIM to complete the API calls of Phi-3/3.5 Family. NVIDIA NIM (NVIDIA Inference Microservices) is a set of accelerated inference microservices designed to help developers deploy AI models efficiently across various environments, including clouds, data centers, and workstations.</p> <p>Here are some key features of NVIDIA NIM:</p> <ul> <li>Ease of Deployment: NIM allows for the deployment of AI models with a single command, making it straightforward to integrate into existing workflows.</li> <li>Optimized Performance: It leverages NVIDIA\u2019s pre-optimized inference engines, such as TensorRT and TensorRT-LLM, to ensure low latency and high throughput.</li> <li>Scalability: NIM supports autoscaling on Kubernetes, enabling it to handle varying workloads effectively.</li> <li>Security and Control: Organizations can maintain control over their data and applications by self-hosting NIM microservices on their own managed infrastructure.</li> <li>Standard APIs: NIM provides industry-standard APIs, making it easy to build and integrate AI applications like chatbots, AI assistants, and more.</li> </ul> <p>NIM is part of NVIDIA AI Enterprise, which aims to simplify the deployment and operationalization of AI models, ensuring they run efficiently on NVIDIA GPUs.</p> <ul> <li>Demo: Using Nividia NIM to call Phi-3.5-Vision-API  [Click this link]</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#inference-phi-335-in-local-env","title":"Inference Phi-3/3.5 in local env","text":"<p>Inference in relation to Phi-3, or any language model like GPT-3, refers to the process of generating responses or predictions based on the input it receives. When you provide a prompt or question to Phi-3, it uses its trained neural network to infer the most likely and relevant response by analyzing patterns and relationships in the data it was trained on.</p> <p>Hugging face Transformer Hugging Face Transformers is a powerful library designed for natural language processing (NLP) and other machine learning tasks. Here are some key points about it:</p> <ol> <li> <p>Pretrained Models: It provides thousands of pretrained models that can be used for various tasks such as text classification, named entity recognition, question answering, summarization, translation, and text generation.</p> </li> <li> <p>Framework Interoperability: The library supports multiple deep learning frameworks, including PyTorch, TensorFlow, and JAX. This allows you to train a model in one framework and use it in another.</p> </li> <li> <p>Multimodal Capabilities: Besides NLP, Hugging Face Transformers also supports tasks in computer vision (e.g., image classification, object detection) and audio processing (e.g., speech recognition, audio classification).</p> </li> <li> <p>Ease of Use: The library offers APIs and tools to easily download and fine-tune models, making it accessible for both beginners and experts.</p> </li> <li> <p>Community and Resources: Hugging Face has a vibrant community and extensive documentation, tutorials, and guides to help users get started and make the most of the library. official documentation or their GitHub repository.</p> </li> </ol> <p>This is the most commonly used method, but it also requires GPU acceleration. After all, scenes such as Vision and MoE require a lot of calculations, which will be very limited in the CPU if they are not quantized.</p> <ul> <li> <p>Demo:Using Transformer to call Phi-3.5-Instuct Click this link</p> </li> <li> <p>Demo:Using Transformer to call Phi-3.5-VisionClick this link</p> </li> <li> <p>Demo:Using Transformer to call Phi-3.5-MoEClick this link</p> </li> </ul> <p>Ollama Ollama is a platform designed to make it easier to run large language models (LLMs) locally on your machine. It supports various models like Llama 3.1, Phi 3, Mistral, and Gemma 2, among others. The platform simplifies the process by bundling model weights, configuration, and data into a single package, making it more accessible for users to customize and create their own models. Ollama is available for macOS, Linux, and Windows. It\u2019s a great tool if you\u2019re looking to experiment with or deploy LLMs without relying on cloud services. Ollama is the most direct way, you just need to execute the following statement.</p> <pre><code>ollama run phi3.5\n</code></pre> <p>ONNX Runtime for GenAI</p> <p>ONNX Runtime is a cross-platform inference and training machine-learning accelerator. ONNX Runtime for Generative AI (GENAI) is a powerful tool that helps you run generative AI models efficiently across various platforms. </p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#what-is-onnx-runtime","title":"What is ONNX Runtime?","text":"<p>ONNX Runtime is an open-source project that enables high-performance inference of machine learning models. It supports models in the Open Neural Network Exchange (ONNX) format, which is a standard for representing machine learning models.ONNX Runtime inference can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#what-is-generative-ai","title":"What is Generative AI?","text":"<p>Generative AI refers to AI systems that can generate new content, such as text, images, or music, based on the data they have been trained on. Examples include language models like GPT-3 and image generation models like Stable Diffusion. ONNX Runtime for GenAI library provides the generative AI loop for ONNX models, including inference with ONNX Runtime, logits processing, search and sampling, and KV cache management.</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#onnx-runtime-for-genai","title":"ONNX Runtime for GENAI","text":"<p>ONNX Runtime for GENAI extends the capabilities of ONNX Runtime to support generative AI models. Here are some key features:</p> <ul> <li>Broad Platform Support: It works on various platforms, including Windows, Linux, macOS, Android, and iOS.</li> <li>Model Support: It supports many popular generative AI models, such as LLaMA, GPT-Neo, BLOOM, and more.</li> <li>Performance Optimization: It includes optimizations for different hardware accelerators like NVIDIA GPUs, AMD GPUs, and more2.</li> <li>Ease of Use: It provides APIs for easy integration into applications, allowing you to generate text, images, and other content with minimal code</li> <li>Users can call a high level generate() method, or run each iteration of the model in a loop, generating one token at a time, and optionally updating generation parameters inside the loop.</li> <li>ONNX runtume also has support for greedy/beam search and TopP, TopK sampling to generate token sequences and built-in logits processing like repetition penalties. You can also easily add custom scoring.</li> </ul>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#getting-started","title":"Getting Started","text":"<p>To get started with ONNX Runtime for GENAI, you can follow these steps:</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#install-onnx-runtime","title":"Install ONNX Runtime:","text":"<pre><code>pip install onnxruntime\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#install-the-generative-ai-extensions","title":"Install the Generative AI Extensions:","text":"<pre><code>pip install onnxruntime-genai\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#run-a-model-heres-a-simple-example-in-python","title":"Run a Model: Here\u2019s a simple example in Python:","text":"<pre><code>import onnxruntime_genai as og\n\nmodel = og.Model('path_to_your_model.onnx')\n\ntokenizer = og.Tokenizer(model)\n\ninput_text = \"Hello, how are you?\"\n\ninput_tokens = tokenizer.encode(input_text)\n\noutput_tokens = model.generate(input_tokens)\n\noutput_text = tokenizer.decode(output_tokens)\n\nprint(output_text) \n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#demousing-onnx-runtime-genai-to-call-phi-35-vision","title":"Demo:Using ONNX Runtime GenAI to call Phi-3.5-Vision","text":"<pre><code>import onnxruntime_genai as og\n\nmodel_path = './Your Phi-3.5-vision-instruct ONNX Path'\n\nimg_path = './Your Image Path'\n\nmodel = og.Model(model_path)\n\nprocessor = model.create_multimodal_processor()\n\ntokenizer_stream = processor.create_stream()\n\ntext = \"Your Prompt\"\n\nprompt = \"&lt;|user|&gt;\\n\"\n\nprompt += \"&lt;|image_1|&gt;\\n\"\n\nprompt += f\"{text}&lt;|end|&gt;\\n\"\n\nprompt += \"&lt;|assistant|&gt;\\n\"\n\nimage = og.Images.open(img_path)\n\ninputs = processor(prompt, images=image)\n\nparams = og.GeneratorParams(model)\n\nparams.set_inputs(inputs)\n\nparams.set_search_options(max_length=3072)\n\ngenerator = og.Generator(model, params)\n\nwhile not generator.is_done():\n\n    generator.compute_logits()\n\n    generator.generate_next_token()\n\n    new_token = generator.get_next_tokens()[0]\n\n    code += tokenizer_stream.decode(new_token)\n\n    print(tokenizer_stream.decode(new_token), end='', flush=True)\n</code></pre> <p>Others</p> <p>In addition to ONNX Runtime and Ollama reference methods, we can also complete the reference of quantitative models based on the model reference methods provided by different manufacturers. Such as Apple MLX framework with Apple Metal, Qualcomm QNN with NPU, Intel OpenVINO with CPU/GPU, etc. You can also get more content from Phi-3 Cookbook</p>"},{"location":"curricula/generative-ai-for-beginners/19-slm/#more","title":"More","text":"<p>We have learned the basics of Phi-3/3.5 Family, but to learn more about SLM we need more knowledge. You can find the answers in the Phi-3 Cookbook. If you want to learn more, please visit the Phi-3 Cookbook.</p>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/","title":"Lesson 20","text":""},{"location":"curricula/generative-ai-for-beginners/20-mistral/#building-with-mistral-models","title":"Building with Mistral Models","text":""},{"location":"curricula/generative-ai-for-beginners/20-mistral/#introduction","title":"Introduction","text":"<p>This lesson will cover:  - Exploring the different Mistral Models  - Understanding the use-cases and scenarios for each model  - Code samples show the unique features of each model. </p>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#the-mistral-models","title":"The Mistral Models","text":"<p>In this lesson, we will explore 3 different Mistral models:  Mistral Large, Mistral Small and Mistral Nemo. </p> <p>Each of these models are available free on the Github Model marketplace. The code in this notebook will be using this models to run the code. Here are more details on using Github Models to prototype with AI models. </p>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#mistral-large-2-2407","title":"Mistral Large 2 (2407)","text":"<p>Mistral Large 2 is currently the flagship model from Mistral and is designed for enterprise use. </p> <p>The model is an  upgrade to the original Mistral Large by offering  -  Larger Context Window - 128k vs 32k  -  Better performance on Math and Coding Tasks - 76.9% average accuracy vs 60.4%  -  Increased multilingual performance - languages include: English, French, German, Spanish, Italian, Portuguese, Dutch, Russian, Chinese, Japanese, Korean, Arabic, and Hindi.</p> <p>With these features, Mistral Large excels at  - Retrieval Augmented Generation (RAG) - due to the larger context window - Function Calling - this model has native function calling which allows integration with external tools and APIs. These calls can be made both in parallel or one after another in a sequential order.  - Code Generation - this model excels on Python, Java, TypeScript and C++ generation. </p>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#rag-example-using-mistral-large-2","title":"RAG Example using Mistral Large 2","text":"<p>In this example, we are using Mistral Large 2 to run a RAG pattern over a text document. The question is written in Korean and asks about the author's activities before college. </p> <p>It uses Cohere Embeddings Model to create embeddings of the text document as well as the question. For this sample, it uses the faiss Python package as a vector store. </p> <p>The prompt sent to the Mistral model includes both the questions and the retrieved chunks that are similar to the question. The Model then provides a natural language response. </p> <pre><code>pip install faiss-cpu\n</code></pre> <pre><code>import requests\nimport numpy as np\nimport faiss\nimport os\n\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import SystemMessage, UserMessage\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.ai.inference import EmbeddingsClient\n\nendpoint = \"https://models.inference.ai.azure.com\"\nmodel_name = \"Mistral-large\"\ntoken = os.environ[\"GITHUB_TOKEN\"]\n\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(token),\n)\n\nresponse = requests.get('https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt')\ntext = response.text\n\nchunk_size = 2048\nchunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\nlen(chunks)\n\nembed_model_name = \"cohere-embed-v3-multilingual\" \n\nembed_client = EmbeddingsClient(\n        endpoint=endpoint,\n        credential=AzureKeyCredential(token)\n)\n\nembed_response = embed_client.embed(\n    input=chunks,\n    model=embed_model_name\n)\n\n\n\ntext_embeddings = []\nfor item in embed_response.data:\n    length = len(item.embedding)\n    text_embeddings.append(item.embedding)\ntext_embeddings = np.array(text_embeddings)\n\n\nd = text_embeddings.shape[1]\nindex = faiss.IndexFlatL2(d)\nindex.add(text_embeddings)\n\nquestion = \"\uc800\uc790\uac00 \ub300\ud559\uc5d0 \uc624\uae30 \uc804\uc5d0 \uc8fc\ub85c \ud588\ub358 \ub450 \uac00\uc9c0 \uc77c\uc740 \ubb34\uc5c7\uc774\uc5c8\ub098\uc694?\uff1f\"\n\nquestion_embedding = embed_client.embed(\n    input=[question],\n    model=embed_model_name\n)\n\nquestion_embeddings = np.array(question_embedding.data[0].embedding)\n\n\nD, I = index.search(question_embeddings.reshape(1, -1), k=2) # distance, index\nretrieved_chunks = [chunks[i] for i in I.tolist()[0]]\n\nprompt = f\"\"\"\nContext information is below.\n---------------------\n{retrieved_chunks}\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: {question}\nAnswer:\n\"\"\"\n\n\nchat_response = client.complete(\n    messages=[\n        SystemMessage(content=\"You are a helpful assistant.\"),\n        UserMessage(content=prompt),\n    ],\n    temperature=1.0,\n    top_p=1.0,\n    max_tokens=1000,\n    model=model_name\n)\n\nprint(chat_response.choices[0].message.content)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#mistral-small","title":"Mistral Small","text":"<p>Mistral Small is another model in the Mistral family of models under the premier/enterprise category. As the name implies, this model is a Small Language Model (SLM). The advantages of using Mistral Small are that it is:  - Cost Saving compared to Mistral LLMs like Mistral Large and NeMo - 80% price drop - Low latency - faster response compared to Mistral's LLMs - Flexible - can be deployed across different environments with less restrictions on required resources. </p> <p>Mistral Small is great for:  - Text based tasks such as summarization, sentiment analysis and translation.  - Applications where frequent requests are made due to its cost effectiveness  - Low latency code tasks like review and code suggestions </p>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#comparing-mistral-small-and-mistral-large","title":"Comparing Mistral Small and Mistral Large","text":"<p>To show differences in latency between Mistral Small and Large, run the below cells. </p> <p>You should see a difference in response times between 3-5 seconds. Also note the response lengths and style over the same prompt.  </p> <pre><code>import os \nendpoint = \"https://models.inference.ai.azure.com\"\nmodel_name = \"Mistral-small\"\ntoken = os.environ[\"GITHUB_TOKEN\"]\n\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(token),\n)\n\nresponse = client.complete(\n    messages=[\n        SystemMessage(content=\"You are a helpful coding assistant.\"),\n        UserMessage(content=\"Can you write a Python function to the fizz buzz test?\"),\n    ],\n    temperature=1.0,\n    top_p=1.0,\n    max_tokens=1000,\n    model=model_name\n)\n\nprint(response.choices[0].message.content)\n</code></pre> <pre><code>import os\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import SystemMessage, UserMessage\nfrom azure.core.credentials import AzureKeyCredential\n\nendpoint = \"https://models.inference.ai.azure.com\"\nmodel_name = \"Mistral-large\"\ntoken = os.environ[\"GITHUB_TOKEN\"]\n\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(token),\n)\n\nresponse = client.complete(\n    messages=[\n        SystemMessage(content=\"You are a helpful coding assistant.\"),\n        UserMessage(content=\"Can you write a Python function to the fizz buzz test?\"),\n    ],\n    temperature=1.0,\n    top_p=1.0,\n    max_tokens=1000,\n    model=model_name\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#mistral-nemo","title":"Mistral NeMo","text":"<p>Compared to the other two models discussed in this lesson, Mistral NeMo is the only free model with an Apache2 License. </p> <p>It is viewed as an upgrade to the earlier open source LLM from Mistral, Mistral 7B. </p> <p>Some other feature of the NeMo model are: </p> <ul> <li> <p>More efficient tokenization: This model using the Tekken tokenizer over the more commonly used tiktoken. This allows for better performance over more languages and code. </p> </li> <li> <p>Finetuning: The base model is available for finetuning. This allows for more flexibility for use-cases where finetuning may be needed. </p> </li> <li> <p>Native Function Calling - Like Mistral Large, this model has been trained on function calling. This makes it unique as being one of the first open source models to do so. </p> </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#comparing-tokenizers","title":"Comparing Tokenizers","text":"<p>In this sample, we will look at how Mistral NeMo handles tokenization compared to Mistral Large. </p> <p>Both samples take the same prompt but you should see that NeMo returns back less tokens vs Mistral Large. </p> <pre><code>pip install mistral-common\n</code></pre> <pre><code># Import needed packages:\nfrom mistral_common.protocol.instruct.messages import (\n    UserMessage,\n)\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\nfrom mistral_common.protocol.instruct.tool_calls import (\n    Function,\n    Tool,\n)\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n\n# Load Mistral tokenizer\n\nmodel_name = \"open-mistral-nemo \"\n\ntokenizer = MistralTokenizer.from_model(model_name)\n\n# Tokenize a list of messages\ntokenized = tokenizer.encode_chat_completion(\n    ChatCompletionRequest(\n        tools=[\n            Tool(\n                function=Function(\n                    name=\"get_current_weather\",\n                    description=\"Get the current weather\",\n                    parameters={\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"location\": {\n                                \"type\": \"string\",\n                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n                            },\n                            \"format\": {\n                                \"type\": \"string\",\n                                \"enum\": [\"celsius\", \"fahrenheit\"],\n                                \"description\": \"The temperature unit to use. Infer this from the users location.\",\n                            },\n                        },\n                        \"required\": [\"location\", \"format\"],\n                    },\n                )\n            )\n        ],\n        messages=[\n            UserMessage(content=\"What's the weather like today in Paris\"),\n        ],\n        model=model_name,\n    )\n)\ntokens, text = tokenized.tokens, tokenized.text\n\n# Count the number of tokens\nprint(len(tokens))\n</code></pre> <pre><code># Import needed packages:\nfrom mistral_common.protocol.instruct.messages import (\n    UserMessage,\n)\nfrom mistral_common.protocol.instruct.request import ChatCompletionRequest\nfrom mistral_common.protocol.instruct.tool_calls import (\n    Function,\n    Tool,\n)\nfrom mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n\n# Load Mistral tokenizer\n\nmodel_name = \"mistral-large-latest\"\n\ntokenizer = MistralTokenizer.from_model(model_name)\n\n# Tokenize a list of messages\ntokenized = tokenizer.encode_chat_completion(\n    ChatCompletionRequest(\n        tools=[\n            Tool(\n                function=Function(\n                    name=\"get_current_weather\",\n                    description=\"Get the current weather\",\n                    parameters={\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"location\": {\n                                \"type\": \"string\",\n                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n                            },\n                            \"format\": {\n                                \"type\": \"string\",\n                                \"enum\": [\"celsius\", \"fahrenheit\"],\n                                \"description\": \"The temperature unit to use. Infer this from the users location.\",\n                            },\n                        },\n                        \"required\": [\"location\", \"format\"],\n                    },\n                )\n            )\n        ],\n        messages=[\n            UserMessage(content=\"What's the weather like today in Paris\"),\n        ],\n        model=model_name,\n    )\n)\ntokens, text = tokenized.tokens, tokenized.text\n\n# Count the number of tokens\nprint(len(tokens))\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/20-mistral/#learning-does-not-stop-here-continue-the-journey","title":"Learning does not stop here, continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p>"},{"location":"curricula/generative-ai-for-beginners/21-meta/","title":"Lesson 21","text":""},{"location":"curricula/generative-ai-for-beginners/21-meta/#building-with-the-meta-family-models","title":"Building With the Meta Family Models","text":""},{"location":"curricula/generative-ai-for-beginners/21-meta/#introduction","title":"Introduction","text":"<p>This lesson will cover: </p> <ul> <li>Exploring the two main Meta family models - Llama 3.1 and Llama 3.2 </li> <li>Understanding the use-cases and scenarios for each model </li> <li>Code sample to show the unique features of each model </li> </ul>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#the-meta-family-of-models","title":"The Meta Family of Models","text":"<p>In this lesson, we will explore 2 models from the Meta family or \"Llama Herd\" - Llama 3.1 and Llama 3.2 </p> <p>These models come in different variants and are available on the Github Model marketplace. Here are more details on using Github Models to prototype with AI models.</p> <p>Model Variants:  - Llama 3.1 - 70B Instruct  - Llama 3.1 - 405B Instruct  - Llama 3.2 - 11B Vision Instruct  - Llama 3.2 - 90B Vision Instruct </p> <p>Note: Llama 3 is also available on Github Models but won't be covered in this lesson</p>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#llama-31","title":"Llama 3.1","text":"<p>At 405 Billion Parameters, Llama 3.1 fits into the open source LLM category. </p> <p>The mode is an upgrade to the earlier release Llama 3 by offering: </p> <ul> <li>Larger context window - 128k tokens vs 8k tokens </li> <li>Larger Max Output Tokens - 4096 vs 2048 </li> <li>Better Multilingual Support - due to increase in training tokens </li> </ul> <p>These enables Llama 3.1 to handle more complex use cases  when building GenAI applications including:  - Native Function Calling - the ability to call external tools and functions outside of the LLM workflow - Better RAG Performance - due to the higher context window  - Synthetic Data Generation - the ability to create effective data for tasks such as fine-tuning </p>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#native-function-calling","title":"Native Function Calling","text":"<p>Llama 3.1 has been fine-tuned to be more effective at making function or tool calls. It also has two built-in tools that the model can identify as needing to be used based on the prompt from the user. These tools are: </p> <ul> <li>Brave Search - Can be used to get up-to-date information like the weather by performing a web search </li> <li>Wolfram Alpha - Can be used for more complex mathematical calculations so writing your own functions is not required. </li> </ul> <p>You can also create your own custom tools that LLM can call. </p> <p>In the code example below: </p> <ul> <li>We define the available tools (brave_search, wolfram_alpha) in the system prompt. </li> <li>Send a user prompt that asks about the weather in a certain city. </li> <li>The LLM will respond with a tool call to the Brave Search tool which will look like this <code>&lt;|python_tag|&gt;brave_search.call(query=\"Stockholm weather\")</code> </li> </ul> <p>*Note: This example only make the tool call, if you would like to get the results, you will need to create a free account on the Brave API page and define the function itself` </p> <pre><code>import os\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\nfrom azure.core.credentials import AzureKeyCredential\n\ntoken = os.environ[\"GITHUB_TOKEN\"]\nendpoint = \"https://models.inference.ai.azure.com\"\nmodel_name = \"meta-llama-3.1-405b-instruct\"\n\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(token),\n)\n\n\ntool_prompt=f\"\"\"\n&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\nEnvironment: ipython\nTools: brave_search, wolfram_alpha\nCutting Knowledge Date: December 2023\nToday Date: 23 July 2024\n\nYou are a helpful assistant&lt;|eot_id|&gt;\n\"\"\"\n\nmessages = [\n    SystemMessage(content=tool_prompt),\n    UserMessage(content=\"What is the weather in Stockholm?\"),\n\n]\n\nresponse = client.complete(messages=messages, model=model_name)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#llama-32","title":"Llama 3.2","text":"<p>Despite being a LLM, one limitation that Llama 3.1 has is multimodality. That is, being able to use different types of input such as images as prompts and providing responses. This ability is one of the main features of Llama 3.2. These features also include: </p> <ul> <li>Multimodality -  has the ability to evaluate both text and image prompts </li> <li>Small to Medium size variations (11B and 90B) - this provides flexible deployment options, </li> <li>Text-only variations (1B and 3B) - this allows the model to be deployed on edge / mobile devices and provides low latency </li> </ul> <p>The multimodal support represents a big step in the world of open source models. The code example below takes both an image and text prompt to get an analysis of the image from Llama 3.2 90B. </p>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#multimodal-support-with-llama-32","title":"Multimodal Support with Llama 3.2","text":"<pre><code>import os\nfrom azure.ai.inference import ChatCompletionsClient\nfrom azure.ai.inference.models import (\n    SystemMessage,\n    UserMessage,\n    TextContentItem,\n    ImageContentItem,\n    ImageUrl,\n    ImageDetailLevel,\n)\nfrom azure.core.credentials import AzureKeyCredential\n\ntoken = os.environ[\"GITHUB_TOKEN\"]\nendpoint = \"https://models.inference.ai.azure.com\"\nmodel_name = \"Llama-3.2-90B-Vision-Instruct\"\n\nclient = ChatCompletionsClient(\n    endpoint=endpoint,\n    credential=AzureKeyCredential(token),\n)\n\nresponse = client.complete(\n    messages=[\n        SystemMessage(\n            content=\"You are a helpful assistant that describes images in details.\"\n        ),\n        UserMessage(\n            content=[\n                TextContentItem(text=\"What's in this image?\"),\n                ImageContentItem(\n                    image_url=ImageUrl.load(\n                        image_file=\"sample.jpg\",\n                        image_format=\"jpg\",\n                        detail=ImageDetailLevel.LOW)\n                ),\n            ],\n        ),\n    ],\n    model=model_name,\n)\n\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"curricula/generative-ai-for-beginners/21-meta/#learning-does-not-stop-here-continue-the-journey","title":"Learning does not stop here, continue the Journey","text":"<p>After completing this lesson, check out our Generative AI Learning collection to continue leveling up your Generative AI knowledge!</p>"},{"location":"curricula/ml-for-beginners/","title":"Overview","text":"<p>This curriculum is forked from Machine Learning for Beginners from Microsoft under MIT license.</p> <p> </p> <p> </p> <p></p>"},{"location":"curricula/ml-for-beginners/#machine-learning-for-beginners-a-curriculum","title":"Machine Learning for Beginners - A Curriculum","text":"<p>\ud83c\udf0d Travel around the world as we explore Machine Learning by means of world cultures \ud83c\udf0d</p> <p>Cloud Advocates at Microsoft are pleased to offer a 12-week, 26-lesson curriculum all about Machine Learning. In this curriculum, you will learn about what is sometimes called classic machine learning, using primarily Scikit-learn as a library and avoiding deep learning, which is covered in our AI for Beginners' curriculum. Pair these lessons with our 'Data Science for Beginners' curriculum, as well!</p> <p>Travel with us around the world as we apply these classic techniques to data from many areas of the world. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment, and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.</p> <p>\u270d\ufe0f Hearty thanks to our authors Jen Looper, Stephen Howell, Francesca Lazzeri, Tomomi Imura, Cassie Breviu, Dmitry Soshnikov, Chris Noring, Anirban Mukherjee, Ornella Altunyan, Ruth Yakubu and Amy Boyd</p> <p>\ud83c\udfa8 Thanks as well to our illustrators Tomomi Imura, Dasani Madipalli, and Jen Looper</p> <p>\ud83d\ude4f Special thanks \ud83d\ude4f to our Microsoft Student Ambassador authors, reviewers, and content contributors, notably Rishit Dagli, Muhammad Sakib Khan Inan, Rohan Raj, Alexandru Petrescu, Abhishek Jaiswal, Nawrin Tabassum, Ioan Samuila, and Snigdha Agarwal</p> <p>\ud83e\udd29 Extra gratitude to Microsoft Student Ambassadors Eric Wanjau, Jasleen Sondhi, and Vidushi Gupta for our R lessons!</p>"},{"location":"curricula/ml-for-beginners/#getting-started","title":"Getting Started","text":"<p>Follow these steps: 1. Fork the Repository: Click on the \"Fork\" button at the top-right corner of this page. 2. Clone the Repository:   <code>git clone https://github.com/microsoft/ML-For-Beginners.git</code></p> <p>find all additional resources for this course in our Microsoft Learn collection</p> <p>Students, to use this curriculum, fork the entire repo to your own GitHub account and complete the exercises on your own or with a group:</p> <ul> <li>Start with a pre-lecture quiz.</li> <li>Read the lecture and complete the activities, pausing and reflecting at each knowledge check.</li> <li>Try to create the projects by comprehending the lessons rather than running the solution code; however that code is available in the <code>/solution</code> folders in each project-oriented lesson.</li> <li>Take the post-lecture quiz.</li> <li>Complete the challenge.</li> <li>Complete the assignment.</li> <li>After completing a lesson group, visit the Discussion Board and \"learn out loud\" by filling out the appropriate PAT rubric. A 'PAT' is a Progress Assessment Tool that is a rubric you fill out to further your learning. You can also react to other PATs so we can learn together.</li> </ul> <p>For further study, we recommend following these Microsoft Learn modules and learning paths.</p> <p>Teachers, we have included some suggestions on how to use this curriculum.</p>"},{"location":"curricula/ml-for-beginners/#video-walkthroughs","title":"Video walkthroughs","text":"<p>Some of the lessons are available as short form video. You can find all these in-line in the lessons, or on the ML for Beginners playlist on the Microsoft Developer YouTube channel by clicking the image below.</p> <p></p>"},{"location":"curricula/ml-for-beginners/#meet-the-team","title":"Meet the Team","text":"<p>Gif by Mohit Jaisal</p> <p>\ud83c\udfa5 Click the image above for a video about the project and the folks who created it!</p>"},{"location":"curricula/ml-for-beginners/#pedagogy","title":"Pedagogy","text":"<p>We have chosen two pedagogical tenets while building this curriculum: ensuring that it is hands-on project-based and that it includes frequent quizzes. In addition, this curriculum has a common theme to give it cohesion.</p> <p>By ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. In addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12-week cycle. This curriculum also includes a postscript on real-world applications of ML, which can be used as extra credit or as a basis for discussion.</p> <p>Find our Code of Conduct, Contributing, and Translation guidelines. We welcome your constructive feedback!</p>"},{"location":"curricula/ml-for-beginners/#each-lesson-includes","title":"Each lesson includes","text":"<ul> <li>optional sketchnote</li> <li>optional supplemental video</li> <li>video walkthrough (some lessons only)</li> <li>pre-lecture warmup quiz</li> <li>written lesson</li> <li>for project-based lessons, step-by-step guides on how to build the project</li> <li>knowledge checks</li> <li>a challenge</li> <li>supplemental reading</li> <li>assignment</li> <li>post-lecture quiz</li> </ul> <p>A note about languages: These lessons are primarily written in Python, but many are also available in R. To complete an R lesson, go to the <code>/solution</code> folder and look for R lessons. They include an .rmd extension that represents an R Markdown file which can be simply defined as an embedding of <code>code chunks</code> (of R or other languages) and a <code>YAML header</code> (that guides how to format outputs such as PDF) in a <code>Markdown document</code>. As such, it serves as an exemplary authoring framework for data science since it allows you to combine your code, its output, and your thoughts by allowing you to write them down in Markdown. Moreover, R Markdown documents can be rendered to output formats such as PDF, HTML, or Word.</p> <p>A note about quizzes: All quizzes are contained Quiz App folder, for 52 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the <code>quiz-app</code> folder to locally host or deploy to Azure.</p> Lesson Number Topic Lesson Grouping Learning Objectives Linked Lesson Author 01 Introduction to machine learning Introduction Learn the basic concepts behind machine learning Lesson Muhammad 02 The History of machine learning Introduction Learn the history underlying this field Lesson Jen and Amy 03 Fairness and machine learning Introduction What are the important philosophical issues around fairness that students should consider when building and applying ML models? Lesson Tomomi 04 Techniques for machine learning Introduction What techniques do ML researchers use to build ML models? Lesson Chris and Jen 05 Introduction to regression Regression Get started with Python and Scikit-learn for regression models <ul><li>Python</li><li>R</li></ul> <ul><li>Jen</li><li>Eric Wanjau</li></ul> 06 North American pumpkin prices \ud83c\udf83 Regression Visualize and clean data in preparation for ML <ul><li>Python</li><li>R</li></ul> <ul><li>Jen</li><li>Eric Wanjau</li></ul> 07 North American pumpkin prices \ud83c\udf83 Regression Build linear and polynomial regression models <ul><li>Python</li><li>R</li></ul> <ul><li>Jen and Dmitry</li><li>Eric Wanjau</li></ul> 08 North American pumpkin prices \ud83c\udf83 Regression Build a logistic regression model <ul><li>Python </li><li>R</li></ul> <ul><li>Jen</li><li>Eric Wanjau</li></ul> 09 A Web App \ud83d\udd0c Web App Build a web app to use your trained model Python Jen 10 Introduction to classification Classification Clean, prep, and visualize your data; introduction to classification <ul><li> Python </li><li>R</li></ul> <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> 11 Delicious Asian and Indian cuisines \ud83c\udf5c Classification Introduction to classifiers <ul><li> Python</li><li>R</li></ul> <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> 12 Delicious Asian and Indian cuisines \ud83c\udf5c Classification More classifiers <ul><li> Python</li><li>R</li></ul> <ul><li>Jen and Cassie</li><li>Eric Wanjau</li></ul> 13 Delicious Asian and Indian cuisines \ud83c\udf5c Classification Build a recommender web app using your model Python Jen 14 Introduction to clustering Clustering Clean, prep, and visualize your data; Introduction to clustering <ul><li> Python</li><li>R</li></ul> <ul><li>Jen</li><li>Eric Wanjau</li></ul> 15 Exploring Nigerian Musical Tastes \ud83c\udfa7 Clustering Explore the K-Means clustering method <ul><li> Python</li><li>R</li></ul> <ul><li>Jen</li><li>Eric Wanjau</li></ul> 16 Introduction to natural language processing \u2615\ufe0f Natural language processing Learn the basics about NLP by building a simple bot Python Stephen 17 Common NLP Tasks \u2615\ufe0f Natural language processing Deepen your NLP knowledge by understanding common tasks required when dealing with language structures Python Stephen 18 Translation and sentiment analysis \u2665\ufe0f Natural language processing Translation and sentiment analysis with Jane Austen Python Stephen 19 Romantic hotels of Europe \u2665\ufe0f Natural language processing Sentiment analysis with hotel reviews 1 Python Stephen 20 Romantic hotels of Europe \u2665\ufe0f Natural language processing Sentiment analysis with hotel reviews 2 Python Stephen 21 Introduction to time series forecasting Time series Introduction to time series forecasting Python Francesca 22 \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with ARIMA Time series Time series forecasting with ARIMA Python Francesca 23 \u26a1\ufe0f World Power Usage \u26a1\ufe0f - time series forecasting with SVR Time series Time series forecasting with Support Vector Regressor Python Anirban 24 Introduction to reinforcement learning Reinforcement learning Introduction to reinforcement learning with Q-Learning Python Dmitry 25 Help Peter avoid the wolf! \ud83d\udc3a Reinforcement learning Reinforcement learning Gym Python Dmitry Postscript Real-World ML scenarios and applications ML in the Wild Interesting and revealing real-world applications of classical ML Lesson Team Postscript Model Debugging in ML using RAI dashboard ML in the Wild Model Debugging in Machine Learning using Responsible AI dashboard components Lesson Ruth Yakubu <p>find all additional resources for this course in our Microsoft Learn collection</p>"},{"location":"curricula/ml-for-beginners/#offline-access","title":"Offline access","text":"<p>You can run this documentation offline by using Docsify. Fork this repo, install Docsify on your local machine, and then in the root folder of this repo, type <code>docsify serve</code>. The website will be served on port 3000 on your localhost: <code>localhost:3000</code>.</p>"},{"location":"curricula/ml-for-beginners/#pdfs","title":"PDFs","text":"<p>Find a pdf of the curriculum with links here.</p>"},{"location":"curricula/ml-for-beginners/#help-wanted","title":"Help Wanted","text":"<p>Would you like to contribute a translation? Please read our translation guidelines and add a templated issue to manage the workload here.</p>"},{"location":"curricula/ml-for-beginners/#other-curricula","title":"Other Curricula","text":"<p>Our team produces other curricula! Check out:</p> <ul> <li>AI for Beginners</li> <li>Data Science for Beginners</li> <li>New Version 2.0 - Generative AI for Beginners</li> <li>NEW Cybersecurity for Beginners</li> <li>Web Dev for Beginners</li> <li>IoT for Beginners</li> <li>Machine Learning for Beginners</li> <li>XR Development for Beginners</li> <li>Mastering GitHub Copilot for AI Paired Programming</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/","title":"Introduction","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/#introduction-to-machine-learning","title":"Introduction to machine learning","text":"<p>In this section of the curriculum, you will be introduced to the base concepts underlying the field of machine learning, what it is, and learn about its history and the techniques researchers use to work with it.  Let's explore this new world of ML together!</p> <p></p> <p>Photo by Bill Oxford on Unsplash</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/#lessons","title":"Lessons","text":"<ol> <li>Introduction to machine learning</li> <li>The History of machine learning and AI</li> <li>Fairness and machine learning</li> <li>Techniques of machine learning</li> </ol>"},{"location":"curricula/ml-for-beginners/1-Introduction/#credits","title":"Credits","text":"<p>\"Introduction to Machine Learning\" was written with \u2665\ufe0f by a team of folks including Muhammad Sakib Khan Inan, Ornella Altunyan and Jen Looper</p> <p>\"The History of Machine Learning\" was written with \u2665\ufe0f by Jen Looper and Amy Boyd</p> <p>\"Fairness and Machine Learning\" was written with \u2665\ufe0f by Tomomi Imura </p> <p>\"Techniques of Machine Learning\" was written with \u2665\ufe0f by Jen Looper and Chris Noring </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/","title":"Intro to ML","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#introduction-to-machine-learning","title":"Introduction to machine learning","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>\ud83c\udfa5 Click the image above for a short video working through this lesson.</p> <p>Welcome to this course on classical machine learning for beginners! Whether you're completely new to this topic, or an experienced ML practitioner looking to brush up on an area, we're happy to have you join us! We want to create a friendly launching spot for your ML study and would be happy to evaluate, respond to, and incorporate your feedback.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: MIT's John Guttag introduces machine learning</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#getting-started-with-machine-learning","title":"Getting started with machine learning","text":"<p>Before starting with this curriculum, you need to have your computer set up and ready to run notebooks locally.</p> <ul> <li>Configure your machine with these videos. Use the following links to learn how to install Python in your system and setup a text editor for development.</li> <li>Learn Python. It's also recommended to have a basic understanding of Python, a programming language useful for data scientists that we use in this course.</li> <li>Learn Node.js and JavaScript. We also use JavaScript a few times in this course when building web apps, so you will need to have node and npm installed, as well as Visual Studio Code available for both Python and JavaScript development.</li> <li>Create a GitHub account. Since you found us here on GitHub, you might already have an account, but if not, create one and then fork this curriculum to use on your own. (Feel free to give us a star, too \ud83d\ude0a)</li> <li>Explore Scikit-learn. Familiarize yourself with Scikit-learn, a set of ML libraries that we reference in these lessons.</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#what-is-machine-learning","title":"What is machine learning?","text":"<p>The term 'machine learning' is one of the most popular and frequently used terms of today. There is a nontrivial possibility that you have heard this term at least once if you have some sort of familiarity with technology, no matter what domain you work in. The mechanics of machine learning, however, are a mystery to most people. For a machine learning beginner, the subject can sometimes feel overwhelming. Therefore, it is important to understand what machine learning actually is, and to learn about it step by step, through practical examples.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#the-hype-curve","title":"The hype curve","text":"<p>Google Trends shows the recent 'hype curve' of the term 'machine learning'</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#a-mysterious-universe","title":"A mysterious universe","text":"<p>We live in a universe full of fascinating mysteries. Great scientists such as Stephen Hawking, Albert Einstein, and many more have devoted their lives to searching for meaningful information that uncovers the mysteries of the world around us. This is the human condition of learning: a human child learns new things and uncovers the structure of their world year by year as they grow to adulthood.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#the-childs-brain","title":"The child's brain","text":"<p>A child's brain and senses perceive the facts of their surroundings and gradually learn the hidden patterns of life which help the child to craft logical rules to identify learned patterns. The learning process of the human brain makes humans the most sophisticated living creature of this world. Learning continuously by discovering hidden patterns and then innovating on those patterns enables us to make ourselves better and better throughout our lifetime. This learning capacity and evolving capability is related to a concept called brain plasticity. Superficially, we can draw some motivational similarities between the learning process of the human brain and the concepts of machine learning.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#the-human-brain","title":"The human brain","text":"<p>The human brain perceives things from the real world, processes the perceived information, makes rational decisions, and performs certain actions based on circumstances. This is what we called behaving intelligently. When we program a facsimile of the intelligent behavioral process to a machine, it is called artificial intelligence (AI).</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#some-terminology","title":"Some terminology","text":"<p>Although the terms can be confused, machine learning (ML) is an important subset of artificial intelligence. ML is concerned with using specialized algorithms to uncover meaningful information and find hidden patterns from perceived data to corroborate the rational decision-making process.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#ai-ml-deep-learning","title":"AI, ML, Deep Learning","text":"<p>A diagram showing the relationships between AI, ML, deep learning, and data science. Infographic by Jen Looper inspired by this graphic</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#concepts-to-cover","title":"Concepts to cover","text":"<p>In this curriculum, we are going to cover only the core concepts of machine learning that a beginner must know. We cover what we call 'classical machine learning' primarily using Scikit-learn, an excellent library many students use to learn the basics.  To understand broader concepts of artificial intelligence or deep learning, a strong fundamental knowledge of machine learning is indispensable, and so we would like to offer it here.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#in-this-course-you-will-learn","title":"In this course you will learn:","text":"<ul> <li>core concepts of machine learning</li> <li>the history of ML</li> <li>ML and fairness</li> <li>regression ML techniques</li> <li>classification ML techniques</li> <li>clustering ML techniques</li> <li>natural language processing ML techniques</li> <li>time series forecasting ML techniques</li> <li>reinforcement learning</li> <li>real-world applications for ML</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#what-we-will-not-cover","title":"What we will not cover","text":"<ul> <li>deep learning</li> <li>neural networks</li> <li>AI</li> </ul> <p>To make for a better learning experience, we will avoid the complexities of neural networks, 'deep learning' - many-layered model-building using neural networks - and AI, which we will discuss in a different curriculum. We also will offer a forthcoming data science curriculum to focus on that aspect of this larger field.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#why-study-machine-learning","title":"Why study machine learning?","text":"<p>Machine learning, from a systems perspective, is defined as the creation of automated systems that can learn hidden patterns from data to aid in making intelligent decisions.</p> <p>This motivation is loosely inspired by how the human brain learns certain things based on the data it perceives from the outside world.</p> <p>\u2705 Think for a minute why a business would want to try to use machine learning strategies vs. creating a hard-coded rules-based engine.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#applications-of-machine-learning","title":"Applications of machine learning","text":"<p>Applications of machine learning are now almost everywhere, and are as ubiquitous as the data that is flowing around our societies, generated by our smart phones, connected devices, and other systems. Considering the immense potential of state-of-the-art machine learning algorithms, researchers have been exploring their capability to solve multi-dimensional and multi-disciplinary real-life problems with great positive outcomes.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#examples-of-applied-ml","title":"Examples of applied ML","text":"<p>You can use machine learning in many ways:</p> <ul> <li>To predict the likelihood of disease from a patient's medical history or reports.</li> <li>To leverage weather data to predict weather events.</li> <li>To understand the sentiment of a text.</li> <li>To detect fake news to stop the spread of propaganda.</li> </ul> <p>Finance, economics, earth science, space exploration, biomedical engineering, cognitive science, and even fields in the humanities have adapted machine learning to solve the arduous, data-processing heavy problems of their domain.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#conclusion","title":"Conclusion","text":"<p>Machine learning automates the process of pattern-discovery by finding meaningful insights from real-world or generated data. It has proven itself to be highly valuable in business, health, and financial applications, among others.</p> <p>In the near future, understanding the basics of machine learning is going to be a must for people from any domain due to its widespread adoption.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Sketch, on paper or using an online app like Excalidraw, your understanding of the differences between AI, ML, deep learning, and data science. Add some ideas of problems that each of these techniques are good at solving.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#review-self-study","title":"Review &amp; Self Study","text":"<p>To learn more about how you can work with ML algorithms in the cloud, follow this Learning Path.</p> <p>Take a Learning Path about the basics of ML.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/1-intro-to-ML/#assignment","title":"Assignment","text":"<p>Get up and running</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/","title":"History of ML","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#history-of-machine-learning","title":"History of machine learning","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>\ud83c\udfa5 Click the image above for a short video working through this lesson.</p> <p>In this lesson, we will walk through the major milestones in the history of machine learning and artificial intelligence.</p> <p>The history of artificial intelligence (AI) as a field is intertwined with the history of machine learning, as the algorithms and computational advances that underpin ML fed into the development of AI. It is useful to remember that, while these fields as distinct areas of inquiry began to crystallize in the 1950s, important algorithmic, statistical, mathematical, computational and technical discoveries predated and overlapped this era. In fact, people have been thinking about these questions for hundreds of years: this article discusses the historical intellectual underpinnings of the idea of a 'thinking machine.'</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#notable-discoveries","title":"Notable discoveries","text":"<ul> <li>1763, 1812 Bayes Theorem and its predecessors. This theorem and its applications underlie inference, describing the probability of an event occurring based on prior knowledge.</li> <li>1805 Least Square Theory by French mathematician Adrien-Marie Legendre. This theory, which you will learn about  in our Regression unit, helps in data fitting.</li> <li>1913 Markov Chains, named after Russian mathematician Andrey Markov, is used to describe a sequence of possible events based on a previous state.</li> <li>1957 Perceptron is a type of linear classifier invented by American psychologist Frank Rosenblatt that underlies advances in deep learning.</li> </ul> <ul> <li>1967 Nearest Neighbor is an algorithm originally designed to map routes. In an ML context it is used to  detect patterns.</li> <li>1970 Backpropagation is used to train feedforward neural networks.</li> <li>1982 Recurrent Neural Networks are artificial neural networks derived from feedforward neural networks that create temporal graphs.</li> </ul> <p>\u2705 Do a little research. What other dates stand out as pivotal in the history of ML and AI?</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1950-machines-that-think","title":"1950: Machines that think","text":"<p>Alan Turing, a truly remarkable person who was voted by the public in 2019 as the greatest scientist of the 20th century, is credited as helping to lay the foundation for the concept of a 'machine that can think.' He grappled with naysayers and his own need for empirical evidence of this concept in part by creating the Turing Test, which you will explore in our NLP lessons.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1956-dartmouth-summer-research-project","title":"1956: Dartmouth Summer Research Project","text":"<p>\"The Dartmouth Summer Research Project on artificial intelligence was a seminal event for artificial intelligence as a field,\" and it was here that the term 'artificial intelligence' was coined (source).</p> <p>Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.</p> <p>The lead researcher, mathematics professor John McCarthy, hoped \"to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.\" The participants included another luminary in the field, Marvin Minsky.</p> <p>The workshop is credited with having initiated and encouraged several discussions including \"the rise of symbolic methods, systems focussed on limited domains (early expert systems), and deductive systems versus inductive systems.\" (source).</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1956-1974-the-golden-years","title":"1956 - 1974: \"The golden years\"","text":"<p>From the 1950s through the mid '70s, optimism ran high in the hope that AI could solve many problems. In 1967, Marvin Minsky stated confidently that \"Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved.\" (Minsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall)</p> <p>natural language processing research flourished, search was refined and made more powerful, and the concept of 'micro-worlds' was created, where simple tasks were completed using plain language instructions.</p> <p>Research was well funded by government agencies, advances were made in computation and algorithms, and prototypes of intelligent machines were built. Some of these machines include:</p> <ul> <li> <p>Shakey the robot, who could maneuver and decide how to perform tasks 'intelligently'.</p> <p></p> <p>Shakey in 1972</p> </li> </ul> <ul> <li> <p>Eliza, an early 'chatterbot', could converse with people and act as a primitive 'therapist'. You'll learn more about Eliza in the NLP lessons.</p> <p></p> <p>A version of Eliza, a chatbot</p> </li> </ul> <ul> <li> <p>\"Blocks world\" was an example of a micro-world where blocks could be stacked and sorted, and experiments in teaching machines to make decisions could be tested. Advances built with libraries such as SHRDLU helped propel language processing forward.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Blocks world with SHRDLU</p> </li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1974-1980-ai-winter","title":"1974 - 1980: \"AI Winter\"","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#by-the-mid-1970s-it-had-become-apparent-that-the-complexity-of-making-intelligent-machines-had-been-understated-and-that-its-promise-given-the-available-compute-power-had-been-overblown-funding-dried-up-and-confidence-in-the-field-slowed-some-issues-that-impacted-confidence-included","title":"By the mid 1970s, it had become apparent that the complexity of making 'intelligent machines' had been understated and that its promise, given the available compute power, had been overblown. Funding dried up and confidence in the field slowed. Some issues that impacted confidence included:","text":"<ul> <li>Limitations. Compute power was too limited.</li> <li>Combinatorial explosion. The amount of parameters needed to be trained grew exponentially as more was asked of computers, without a parallel evolution of compute power and capability.</li> <li>Paucity of data. There was a paucity of data that hindered the process of testing, developing, and refining algorithms.</li> <li>Are we asking the right questions?. The very questions that were being asked began to be questioned. Researchers began to field criticism about their approaches:</li> <li>Turing tests came into question by means, among other ideas, of the 'chinese room theory' which posited that, \"programming a digital computer may make it appear to understand language but could not produce real understanding.\" (source)</li> <li>The ethics of introducing artificial intelligences such as the \"therapist\" ELIZA into society was challenged.</li> </ul> <p>At the same time, various AI schools of thought began to form. A dichotomy was established between \"scruffy\" vs. \"neat AI\" practices. Scruffy labs tweaked programs for hours until they had the desired results. Neat labs \"focused on logic and formal problem solving\". ELIZA and SHRDLU were well-known scruffy systems. In the 1980s, as demand emerged to make ML systems reproducible, the neat approach gradually took the forefront as its results are more explainable.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1980s-expert-systems","title":"1980s Expert systems","text":"<p>As the field grew, its benefit to business became clearer, and in the 1980s so did the proliferation of 'expert systems'. \"Expert systems were among the first truly successful forms of artificial intelligence (AI) software.\" (source).</p> <p>This type of system is actually hybrid, consisting partially of a rules engine defining business requirements, and an inference engine that leveraged the rules system to deduce new facts.</p> <p>This era also saw increasing attention paid to neural networks.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1987-1993-ai-chill","title":"1987 - 1993: AI 'Chill'","text":"<p>The proliferation of specialized expert systems hardware had the unfortunate effect of becoming too specialized. The rise of personal computers also competed with these large, specialized, centralized systems. The democratization of computing had begun, and it eventually paved the way for the modern explosion of big data.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#1993-2011","title":"1993 - 2011","text":"<p>This epoch saw a new era for ML and AI to be able to solve some of the problems that had been caused earlier by the lack of data and compute power. The amount of data began to rapidly increase and become more widely available, for better and for worse, especially with the advent of the smartphone around 2007. Compute power expanded exponentially, and algorithms evolved alongside. The field began to gain maturity as the freewheeling days of the past began to crystallize into a true discipline.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#now","title":"Now","text":"<p>Today machine learning and AI touch almost every part of our lives. This era calls for careful understanding of the risks and potentials effects of these algorithms on human lives. As Microsoft's Brad Smith has stated, \"Information technology raises issues that go to the heart of fundamental human-rights protections like privacy and freedom of expression. These issues heighten responsibility for tech companies that create these products. In our view, they also call for thoughtful government regulation and for the development of norms around acceptable uses\" (source).</p> <p>It remains to be seen what the future holds, but it is important to understand these computer systems and the software and algorithms that they run. We hope that this curriculum will help you to gain a better understanding so that you can decide for yourself.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Yann LeCun discusses the history of deep learning in this lecture</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Dig into one of these historical moments and learn more about the people behind them. There are fascinating characters, and no scientific discovery was ever created in a cultural vacuum. What do you discover?</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#review-self-study","title":"Review &amp; Self Study","text":"<p>Here are items to watch and listen to:</p> <p>This podcast where Amy Boyd discusses the evolution of AI</p> <p></p>"},{"location":"curricula/ml-for-beginners/1-Introduction/2-history-of-ML/#assignment","title":"Assignment","text":"<p>Create a timeline</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/","title":"Fairness","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#building-machine-learning-solutions-with-responsible-ai","title":"Building Machine Learning solutions with responsible AI","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#introduction","title":"Introduction","text":"<p>In this curriculum, you will start to discover how machine learning can and is impacting our everyday lives. Even now, systems and models are involved in daily decision-making tasks, such as health care diagnoses, loan approvals or detecting fraud. So, it is important that these models work well to provide outcomes that are trustworthy. Just as any software application, AI systems are going to miss expectations or have an undesirable outcome. That is why it is essential to be about to understand and explain the behavior of an AI model. </p> <p>Imagine what can happen when the data you are using to build these models lacks certain demographics, such as race, gender, political view, religion, or disproportionally represents such demographics. What about when the model\u2019s output is interpreted to favor some demographic? What is the consequence for the application? In addition, what happens when the model has an adverse outcome and is harmful to people? Who is accountable for the AI systems behavior? These are some questions we will explore in this curriculum. </p> <p>In this lesson, you will: </p> <ul> <li>Raise your awareness of the importance of fairness in machine learning and fairness-related harms.</li> <li>Become familiar with the practice of exploring outliers and unusual scenarios to ensure reliability and safety</li> <li>Gain understanding on the need to empower everyone by designing inclusive systems</li> <li>Explore how vital it is to protect privacy and security of data and people</li> <li>See the importance of having a glass box approach to explain the behavior of AI models</li> <li>Be mindful of how accountability is essential to build trust in AI systems</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#prerequisite","title":"Prerequisite","text":"<p>As a prerequisite, please take the \"Responsible AI Principles\" Learn Path and watch the video below on the topic:</p> <p>Learn more about Responsible AI by following this Learning Path</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Microsoft's Approach to Responsible AI</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#fairness","title":"Fairness","text":"<p>AI systems should treat everyone fairly and avoid affecting similar groups of people in different ways. For example, when AI systems provide guidance on medical treatment, loan applications, or employment, they should make the same recommendations to everyone with similar symptoms, financial circumstances, or professional qualifications. Each of us as humans carries around inherited biases that affect our decisions and actions. These biases can be evident in the data that we use to train AI systems. Such manipulation can sometimes happen unintentionally. It is often difficult to consciously know when you are introducing bias in data. </p> <p>\u201cUnfairness\u201d encompasses negative impacts, or \u201charms\u201d, for a group of people, such as those defined in terms of race, gender, age, or disability status. The main fairness-related harms can be classified as: </p> <ul> <li>Allocation, if a gender or ethnicity for example is favored over another.</li> <li>Quality of service. If you train the data for one specific scenario but reality is much more complex, it leads to a poor performing service.  For instance, a hand soap dispenser that could not seem to be able to sense people with dark skin. Reference</li> <li>Denigration. To unfairly criticize and label something or someone. For example, an image labeling technology infamously mislabeled images of dark-skinned people as gorillas.</li> <li>Over- or under- representation. The idea is that a certain group is not seen in a certain profession, and any service or function that keeps promoting that is contributing to harm.</li> <li>Stereotyping. Associating a given group with pre-assigned attributes.  For example, a language translation system betweem English and Turkish may have inaccuraces due to words with stereotypical associations to gender.</li> </ul> <p></p> <p>translation to Turkish</p> <p></p> <p>translation back to English</p> <p>When designing and testing AI systems, we need to ensure that AI is fair and not programmed to make biased or discriminatory decisions, which human beings are also prohibited from making. Guaranteeing fairness in AI and machine learning remains a complex sociotechnical challenge. </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#reliability-and-safety","title":"Reliability and safety","text":"<p>To build trust, AI systems need to be reliable, safe, and consistent under normal and unexpected conditions. It is important to know how AI systems will behavior in a variety of situations, especially when they are outliers. When building AI solutions, there needs to be a substantial amount of focus on how to handle a wide variety of circumstances that the AI solutions would encounter. For example, a self-driving car needs to put people's safety as a top priority. As a result, the AI powering the car need to consider all the possible scenarios that the car could come across such as night, thunderstorms or blizzards, kids running across the street, pets, road constructions etc. How well an AI system can handle a wild range of conditions reliably and safely reflects the level of anticipation the data scientist or AI developer considered during the design or testing of the system.  </p> <p>\ud83c\udfa5 Click the here for a video: </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#inclusiveness","title":"Inclusiveness","text":"<p>AI systems should be designed to engage and empower everyone. When designing and implementing AI systems data scientists and AI developers identify and address potential barriers in the system that could unintentionally exclude people. For example, there are 1 billion people with disabilities around the world. With the advancement of AI, they can access a wide range of information and opportunities more easily in their daily lives. By addressing the barriers, it creates opportunities to innovate and develop AI products with better experiences that benefit everyone. </p> <p>\ud83c\udfa5 Click the here for a video: inclusiveness in AI</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#security-and-privacy","title":"Security and privacy","text":"<p>AI systems should be safe and respect people\u2019s privacy. People have less trust in systems that put their privacy, information, or lives at risk. When training machine learning models, we rely on data to produce the best results. In doing so, the origin of the data and integrity must be considered. For example, was the data user submitted or publicly available? Next, while working with the data, it is crucial to develop AI systems that can protect confidential information and resist attacks. As AI becomes more prevalent, protecting privacy and securing important personal and business information is becoming more critical and complex. Privacy and data security issues require especially close attention for AI because access to data is essential for AI systems to make accurate and informed predictions and decisions about people. </p> <p>\ud83c\udfa5 Click the here for a video: security in AI</p> <ul> <li>As an industry we have made significant advancements in Privacy &amp; security, fueled significantly by regulations like the GDPR (General Data Protection Regulation). </li> <li>Yet with AI systems we must acknowledge the tension between the need for more personal data to make systems more personal and effective \u2013 and privacy. </li> <li>Just like with the birth of connected computers with the internet, we are also seeing a huge uptick in the number of security issues related to AI. </li> <li>At the same time, we have seen AI being used to improve security. As an example, most modern anti-virus scanners are driven by AI heuristics today. </li> <li>We need to ensure that our Data Science processes blend harmoniously with the latest privacy and security practices. </li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#transparency","title":"Transparency","text":"<p>AI systems should be understandable. A crucial part of transparency is explaining the behavior of AI systems and their components. Improving the understanding of AI systems requires that stakeholders comprehend how and why they function so that they can identify potential performance issues, safety and privacy concerns, biases, exclusionary practices, or unintended outcomes. We also believe that those who use AI systems should be honest and forthcoming about when, why, and how they choose to deploy them. As well as the limitations of the systems they use. For example, if a bank uses an AI system to support its consumer lending decisions, it is important to examine the outcomes and understand which data influences the system\u2019s recommendations. Governments are starting to regulate AI across industries, so data scientists and organizations must explain if an AI system meets regulatory requirements, especially when there is an undesirable outcome. </p> <p>\ud83c\udfa5 Click the here for a video: transparency in AI</p> <ul> <li>Because AI systems are so complex, it is hard to understand how they work and interpret the results. </li> <li>This lack of understanding affects the way these systems are managed, operationalized, and documented. </li> <li>This lack of understanding more importantly affects the decisions made using the results these systems produce. </li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#accountability","title":"Accountability","text":"<p>The people who design and deploy AI systems must be accountable for how their systems operate. The need for accountability is particularly crucial with sensitive use technologies like facial recognition. Recently, there has been a growing demand for facial recognition technology, especially from law enforcement organizations who see the potential of the technology in uses like finding missing children. However, these technologies could potentially be used by a government to put their citizens\u2019 fundamental freedoms at risk by, for example, enabling continuous surveillance of specific individuals. Hence, data scientists and organizations need to be responsible for how their AI system impacts individuals or society.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Warnings of Mass Surveillance Through Facial Recognition </p> <p>Ultimately one of the biggest questions for our generation, as the first generation that is bringing AI to society, is how to ensure that computers will remain accountable to people and how to ensure that the people that design computers remain accountable to everyone else.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#impact-assessment","title":"Impact assessment","text":"<p>Before training a machine learning model, it is important to conduct an impact assessmet to understand the purpose of the AI system; what the intended use is; where it will be deployed; and who will be interacting with the system.  These are helpful for reviewer(s) or testers evaluating the system to know what factors to take into consideration when identifying potential risks and expected consequences.</p> <p>The following are areas of focus when conducting an impact assessment:</p> <ul> <li>Adverse impact on individuals.  Being aware of any restriction or requirements, unsupported use or any known limitations hindering the system's performance is vital to ensure that the system is not used in a way that could cause harm to individuals.</li> <li>Data requirements.  Gaining an understanding of how and where the system will use data enables reviewers to explore any data requirements you would need to be mindful of (e.g., GDPR or HIPPA data regulations).  In addition, examine whether the source or quantity of data is substantial for training.</li> <li>Summary of impact.  Gather a list of potential harms that could  arise from using the system.  Throughout the ML lifecycle, review if the issues identified are mitigated or addressed.</li> <li>Applicable goals for each of the six core principles.  Assess if the goals from each of the principles are met and if there are any gaps.</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#debugging-with-responsible-ai","title":"Debugging with responsible AI","text":"<p>Similar to debugging a software application, debugging an AI system is a necessary process of identifying and resolving issues in the system.  There are many factors that would affect a model not performing as expected or responsibly.  Most traditional model performance metrics are quantitative aggregates of a model's performance, which are not sufficient to analyze how a model violates the responsible AI principles. Furthermore, a machine learning model is a black box that makes it difficult to understand what drives its outcome or provide explanation when it makes a mistake.  Later in this course, we will learn how to use the Responsible AI dashboard to help debug AI systems.  The dashboard provides a holistic tool for data scientists and AI developers to perform:</p> <ul> <li>Error analysis.  To identify the error distribution of the model that can affect the system's fairness or reliability.</li> <li>Model overview. To discover where there are disparities in the model's performance across data cohorts.</li> <li>Data analysis.  To understand the data distribution and identify any potential bias in the data that could lead to fairness, inclusiveness, and reliability issues.</li> <li>Model interpretability. To understand what affects or influences the model's predictions. This helps in explaining the model's behavior, which is important for transparency and accountability.</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>To prevent harms from being introduced in the first place, we should: </p> <ul> <li>have a diversity of backgrounds and perspectives among the people working on systems </li> <li>invest in datasets that reflect the diversity of our society </li> <li>develop better methods throughout the machine learning lifecycle for detecting and correcting responible AI when it occurs </li> </ul> <p>Think about real-life scenarios where a model's untrustworthiness is evident in model-building and usage. What else should we consider? </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#review-self-study","title":"Review &amp; Self Study","text":"<p>In this lesson, you have learned some basics of the concepts of fairness and unfairness in machine learning.  </p> <p>Watch this workshop to dive deeper into the topics: </p> <ul> <li>In pursuit of responsible AI: Bringing principles to practice by Besmira Nushi, Mehrnoosh Sameki and Amit Sharma</li> </ul> <p></p> <p>\ud83c\udfa5 Click the image above for a video: RAI Toolbox: An open-source framework for building responsible AI by Besmira Nushi, Mehrnoosh Sameki, and Amit Sharma</p> <p>Also, read: </p> <ul> <li> <p>Microsoft\u2019s RAI resource center: Responsible AI Resources \u2013 Microsoft AI </p> </li> <li> <p>Microsoft\u2019s FATE research group: FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research </p> </li> </ul> <p>RAI Toolbox: </p> <ul> <li>Responsible AI Toolbox GitHub repository</li> </ul> <p>Read about Azure Machine Learning's tools to ensure fairness:</p> <ul> <li>Azure Machine Learning </li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/3-fairness/#assignment","title":"Assignment","text":"<p>Explore RAI Toolbox </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/","title":"Techniques of ML","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#techniques-of-machine-learning","title":"Techniques of Machine Learning","text":"<p>The process of building, using, and maintaining machine learning models and the data they use is a very different process from many other development workflows. In this lesson, we will demystify the process, and outline the main techniques you need to know. You will:</p> <ul> <li>Understand the processes underpinning machine learning at a high level.</li> <li>Explore base concepts such as 'models', 'predictions', and 'training data'.</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>\ud83c\udfa5 Click the image above for a short video working through this lesson.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#introduction","title":"Introduction","text":"<p>On a high level, the craft of creating machine learning (ML) processes is comprised of a number of steps:</p> <ol> <li>Decide on the question. Most ML processes start by asking a question that cannot be answered by a simple conditional program or rules-based engine. These questions often revolve around predictions based on a collection of data.</li> <li>Collect and prepare data. To be able to answer your question, you need data. The quality and, sometimes, quantity of your data will determine how well you can answer your initial question. Visualizing data is an important aspect of this phase. This phase also includes splitting the data into a training and testing group to build a model.</li> <li>Choose a training method. Depending on your question and the nature of your data, you need to choose how you want to train a model to best reflect your data and make accurate predictions against it. This is the part of your ML process that requires specific expertise and, often, a considerable amount of experimentation.</li> <li>Train the model. Using your training data, you'll use various algorithms to train a model to recognize patterns in the data. The model might leverage internal weights that can be adjusted to privilege certain parts of the data over others to build a better model.</li> <li>Evaluate the model. You use never before seen data (your testing data) from your collected set to see how the model is performing.</li> <li>Parameter tuning. Based on the performance of your model, you can redo the process using different parameters, or variables, that control the behavior of the algorithms used to train the model.</li> <li>Predict. Use new inputs to test the accuracy of your model.</li> </ol>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#what-question-to-ask","title":"What question to ask","text":"<p>Computers are particularly skilled at discovering hidden patterns in data. This utility is very helpful for researchers who have questions about a given domain that cannot be easily answered by creating a conditionally-based rules engine. Given an actuarial task, for example, a data scientist might be able to construct handcrafted rules around the mortality of smokers vs non-smokers.</p> <p>When many other variables are brought into the equation, however, a ML model might prove more efficient to predict future mortality rates based on past health history. A more cheerful example might be making weather predictions for the month of April in a given location based on data that includes latitude, longitude, climate change, proximity to the ocean, patterns of the jet stream, and more.</p> <p>\u2705 This slide deck on weather models offers a historical perspective for using ML in weather analysis.  </p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#pre-building-tasks","title":"Pre-building tasks","text":"<p>Before starting to build your model, there are several tasks you need to complete. To test your question and form a hypothesis based on a model's predictions, you need to identify and configure several elements.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#data","title":"Data","text":"<p>To be able to answer your question with any kind of certainty, you need a good amount of data of the right type. There are two things you need to do at this point:</p> <ul> <li>Collect data. Keeping in mind the previous lesson on fairness in data analysis, collect your data with care. Be aware of the sources of this data, any inherent biases it might have, and document its origin.</li> <li>Prepare data. There are several steps in the data preparation process. You might need to collate data and normalize it if it comes from diverse sources. You can improve the data's quality and quantity through various methods such as converting strings to numbers (as we do in Clustering). You might also generate new data, based on the original (as we do in Classification). You can clean and edit the data (as we will prior to the Web App lesson). Finally, you might also need to randomize it and shuffle it, depending on your training techniques.</li> </ul> <p>\u2705 After collecting and processing your data, take a moment to see if its shape will allow you to address your intended question. It may be that the data will not perform well in your given task, as we discover in our Clustering lessons!</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#features-and-target","title":"Features and Target","text":"<p>A feature is a measurable property of your data. In many datasets it is expressed as a column heading like 'date' 'size' or 'color'. Your feature variable, usually represented as <code>X</code> in code, represent the input variable which will be used to train model.</p> <p>A target is a thing you are trying to predict. Target usually represented as <code>y</code> in code, represents the answer to the question you are trying to ask of your data: in December, what color pumpkins will be cheapest? in San Francisco, what neighborhoods will have the best real estate price? Sometimes target is also referred as label attribute.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#selecting-your-feature-variable","title":"Selecting your feature variable","text":"<p>\ud83c\udf93 Feature Selection and Feature Extraction How do you know which variable to choose when building a model? You'll probably go through a process of feature selection or feature extraction to choose the right variables for the most performant model. They're not the same thing, however: \"Feature extraction creates new features from functions of the original features, whereas feature selection returns a subset of the features.\" (source)</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#visualize-your-data","title":"Visualize your data","text":"<p>An important aspect of the data scientist's toolkit is the power to visualize data using several excellent libraries such as Seaborn or MatPlotLib. Representing your data visually might allow you to uncover hidden correlations that you can leverage. Your visualizations might also help you to uncover bias or unbalanced data (as we discover in Classification).</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#split-your-dataset","title":"Split your dataset","text":"<p>Prior to training, you need to split your dataset into two or more parts of unequal size that still represent the data well.</p> <ul> <li>Training. This part of the dataset is fit to your model to train it. This set constitutes the majority of the original dataset.</li> <li>Testing. A test dataset is an independent group of data, often gathered from the original data, that you use to confirm the performance of the built model.</li> <li>Validating. A validation set is a smaller independent group of examples that you use to tune the model's hyperparameters, or architecture, to improve the model. Depending on your data's size and the question you are asking, you might not need to build this third set (as we note in Time Series Forecasting).</li> </ul>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#building-a-model","title":"Building a model","text":"<p>Using your training data, your goal is to build a model, or a statistical representation of your data, using various algorithms to train it. Training a model exposes it to data and allows it to make assumptions about perceived patterns it discovers, validates, and accepts or rejects.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#decide-on-a-training-method","title":"Decide on a training method","text":"<p>Depending on your question and the nature of your data, you will choose a method to train it. Stepping through Scikit-learn's documentation - which we use in this course - you can explore many ways to train a model. Depending on your experience, you might have to try several different methods to build the best model. You are likely to go through a process whereby data scientists evaluate the performance of a model by feeding it unseen data, checking for accuracy, bias, and other quality-degrading issues, and selecting the most appropriate training method for the task at hand.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#train-a-model","title":"Train a model","text":"<p>Armed with your training data, you are ready to 'fit' it to create a model. You will notice that in many ML libraries you will find the code 'model.fit' - it is at this time that you send in your feature variable as an array of values (usually 'X') and a target variable (usually 'y').</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#evaluate-the-model","title":"Evaluate the model","text":"<p>Once the training process is complete (it can take many iterations, or 'epochs', to train a large model), you will be able to evaluate the model's quality by using test data to gauge its performance. This data is a subset of the original data that the model has not previously analyzed. You can print out a table of metrics about your model's quality.</p> <p>\ud83c\udf93 Model fitting</p> <p>In the context of machine learning, model fitting refers to the accuracy of the model's underlying function as it attempts to analyze data with which it is not familiar.</p> <p>\ud83c\udf93 Underfitting and overfitting are common problems that degrade the quality of the model, as the model fits either not well enough or too well. This causes the model to make predictions either too closely aligned or too loosely aligned with its training data. An overfit model predicts training data too well because it has learned the data's details and noise too well. An underfit model is not accurate as it can neither accurately analyze its training data nor data it has not yet 'seen'.</p> <p></p> <p>Infographic by Jen Looper</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#parameter-tuning","title":"Parameter tuning","text":"<p>Once your initial training is complete, observe the quality of the model and consider improving it by tweaking its 'hyperparameters'. Read more about the process in the documentation.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#prediction","title":"Prediction","text":"<p>This is the moment where you can use completely new data to test your model's accuracy. In an 'applied' ML setting, where you are building web assets to use the model in production, this process might involve gathering user input (a button press, for example) to set a variable and send it to the model for inference, or evaluation.</p> <p>In these lessons, you will discover how to use these steps to prepare, build, test, evaluate, and predict - all the gestures of a data scientist and more, as you progress in your journey to become a 'full stack' ML engineer.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Draw a flow chart reflecting the steps of a ML practitioner. Where do you see yourself right now in the process? Where do you predict you will find difficulty? What seems easy to you?</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#review-self-study","title":"Review &amp; Self Study","text":"<p>Search online for interviews with data scientists who discuss their daily work. Here is one.</p>"},{"location":"curricula/ml-for-beginners/1-Introduction/4-techniques-of-ML/#assignment","title":"Assignment","text":"<p>Interview a data scientist</p>"},{"location":"curricula/ml-for-beginners/2-Regression/","title":"Regression","text":""},{"location":"curricula/ml-for-beginners/2-Regression/#regression-models-for-machine-learning","title":"Regression models for machine learning","text":""},{"location":"curricula/ml-for-beginners/2-Regression/#regional-topic-regression-models-for-pumpkin-prices-in-north-america","title":"Regional topic: Regression models for pumpkin prices in North America \ud83c\udf83","text":"<p>In North America, pumpkins are often carved into scary faces for Halloween. Let's discover more about these fascinating vegetables!</p> <p></p> <p>Photo by Beth Teutschmann on Unsplash</p>"},{"location":"curricula/ml-for-beginners/2-Regression/#what-you-will-learn","title":"What you will learn","text":"<p>\ud83c\udfa5 Click the image above for a quick introduction video to this lesson</p> <p>The lessons in this section cover types of regression in the context of machine learning. Regression models can help determine the relationship between variables. This type of model can predict values such as length, temperature, or age, thus uncovering relationships between variables as it analyzes data points.</p> <p>In this series of lessons, you'll discover the differences between linear and logistic regression, and when you should prefer one over the other.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video introducing regression models.</p> <p>In this group of lessons, you will get set up to begin machine learning tasks, including configuring Visual Studio Code to manage notebooks, the common environment for data scientists. You will discover Scikit-learn, a library for machine learning, and you will build your first models, focusing on Regression models in this chapter.</p> <p>There are useful low-code tools that can help you learn about working with regression models. Try Azure ML for this task</p>"},{"location":"curricula/ml-for-beginners/2-Regression/#lessons","title":"Lessons","text":"<ol> <li>Tools of the trade</li> <li>Managing data</li> <li>Linear and polynomial regression</li> <li>Logistic regression</li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/#credits","title":"Credits","text":"<p>\"ML with regression\" was written with \u2665\ufe0f by Jen Looper</p> <p>\u2665\ufe0f Quiz contributors include: Muhammad Sakib Khan Inan and Ornella Altunyan</p> <p>The pumpkin dataset is suggested by this project on Kaggle and its data is sourced from the Specialty Crops Terminal Markets Standard Reports distributed by the United States Department of Agriculture. We have added some points around color based on variety to normalize the distribution. This data is in the public domain.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/","title":"Tools","text":""},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#get-started-with-python-and-scikit-learn-for-regression-models","title":"Get started with Python and Scikit-learn for regression models","text":"<p>Sketchnote by Tomomi Imura</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#this-lesson-is-available-in-r","title":"This lesson is available in R!","text":""},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#introduction","title":"Introduction","text":"<p>In these four lessons, you will discover how to build regression models. We will discuss what these are for shortly. But before you do anything, make sure you have the right tools in place to start the process!</p> <p>In this lesson, you will learn how to:</p> <ul> <li>Configure your computer for local machine learning tasks.</li> <li>Work with Jupyter notebooks.</li> <li>Use Scikit-learn, including installation.</li> <li>Explore linear regression with a hands-on exercise.</li> </ul>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#installations-and-configurations","title":"Installations and configurations","text":"<p>\ud83c\udfa5 Click the image above for a short video working through configuring your computer for ML.</p> <ol> <li>Install Python. Ensure that Python is installed on your computer. You will use Python for many data science and machine learning tasks. Most computer systems already include a Python installation. There are useful Python Coding Packs available as well, to ease the setup for some users.</li> </ol> <p>Some usages of Python, however, require one version of the software, whereas others require a different version. For this reason, it's useful to work within a virtual environment.</p> <ol> <li>Install Visual Studio Code. Make sure you have Visual Studio Code installed on your computer. Follow these instructions to install Visual Studio Code for the basic installation. You are going to use Python in Visual Studio Code in this course, so you might want to brush up on how to configure Visual Studio Code for Python development.</li> </ol> <p>Get comfortable with Python by working through this collection of Learn modules</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: using Python within VS Code.</p> <ol> <li> <p>Install Scikit-learn, by following these instructions. Since you need to ensure that you use Python 3, it's recommended that you use a virtual environment. Note, if you are installing this library on a M1 Mac, there are special instructions on the page linked above.</p> </li> <li> <p>Install Jupyter Notebook. You will need to install the Jupyter package.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#your-ml-authoring-environment","title":"Your ML authoring environment","text":"<p>You are going to use notebooks to develop your Python code and create machine learning models. This type of file is a common tool for data scientists, and they can be identified by their suffix or extension <code>.ipynb</code>.</p> <p>Notebooks are an interactive environment that allow the developer to both code and add notes and write documentation around the code which is quite helpful for experimental or research-oriented projects.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video working through this exercise.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#exercise-work-with-a-notebook","title":"Exercise - work with a notebook","text":"<p>In this folder, you will find the file notebook.ipynb.</p> <ol> <li>Open notebook.ipynb in Visual Studio Code.</li> </ol> <p>A Jupyter server will start with Python 3+ started. You will find areas of the notebook that can be <code>run</code>, pieces of code. You can run a code block, by selecting the icon that looks like a play button.</p> <ol> <li>Select the <code>md</code> icon and add a bit of markdown, and the following text # Welcome to your notebook.</li> </ol> <p>Next, add some Python code.</p> <ol> <li>Type print('hello notebook') in the code block.</li> <li>Select the arrow to run the code.</li> </ol> <p>You should see the printed statement:</p> <pre><code>```output\nhello notebook\n```\n</code></pre> <p></p> <p>You can interleaf your code with comments to self-document the notebook.</p> <p>\u2705 Think for a minute how different a web developer's working environment is versus that of a data scientist.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#up-and-running-with-scikit-learn","title":"Up and running with Scikit-learn","text":"<p>Now that Python is set up in your local environment, and you are comfortable with Jupyter notebooks, let's get equally comfortable with Scikit-learn (pronounce it <code>sci</code> as in <code>science</code>). Scikit-learn provides an extensive API to help you perform ML tasks.</p> <p>According to their website, \"Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\"</p> <p>In this course, you will use Scikit-learn and other tools to build machine learning models to perform what we call 'traditional machine learning' tasks. We have deliberately avoided neural networks and deep learning, as they are better covered in our forthcoming 'AI for Beginners' curriculum.</p> <p>Scikit-learn makes it straightforward to build models and evaluate them for use. It is primarily focused on using numeric data and contains several ready-made datasets for use as learning tools. It also includes pre-built models for students to try. Let's explore the process of loading prepackaged data and using a built in estimator  first ML model with Scikit-learn with some basic data.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#exercise-your-first-scikit-learn-notebook","title":"Exercise - your first Scikit-learn notebook","text":"<p>This tutorial was inspired by the linear regression example on Scikit-learn's web site.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video working through this exercise.</p> <p>In the notebook.ipynb file associated to this lesson, clear out all the cells by pressing the 'trash can' icon.</p> <p>In this section, you will work with a small dataset about diabetes that is built into Scikit-learn for learning purposes. Imagine that you wanted to test a treatment for diabetic patients. Machine Learning models might help you determine which patients would respond better to the treatment, based on combinations of variables. Even a very basic regression model, when visualized, might show information about variables that would help you organize your theoretical clinical trials.</p> <p>\u2705 There are many types of regression methods, and which one you pick depends on the answer you're looking for. If you want to predict the probable height for a person of a given age, you'd use linear regression, as you're seeking a numeric value. If you're interested in discovering whether a type of cuisine should be considered vegan or not, you're looking for a category assignment so you would use logistic regression. You'll learn more about logistic regression later. Think a bit about some questions you can ask of data, and which of these methods would be more appropriate.</p> <p>Let's get started on this task.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#import-libraries","title":"Import libraries","text":"<p>For this task we will import some libraries:</p> <ul> <li>matplotlib. It's a useful graphing tool and we will use it to create a line plot.</li> <li>numpy. numpy is a useful library for handling numeric data in Python.</li> <li>sklearn. This is the Scikit-learn library.</li> </ul> <p>Import some libraries to help with your tasks.</p> <ol> <li>Add imports by typing the following code:</li> </ol> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import datasets, linear_model, model_selection\n</code></pre> <p>Above you are importing <code>matplotlib</code>, <code>numpy</code> and you are importing <code>datasets</code>, <code>linear_model</code> and <code>model_selection</code> from <code>sklearn</code>. <code>model_selection</code> is used for splitting data into training and test sets.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#the-diabetes-dataset","title":"The diabetes dataset","text":"<p>The built-in diabetes dataset includes 442 samples of data around diabetes, with 10 feature variables, some of which include:</p> <ul> <li>age: age in years</li> <li>bmi: body mass index</li> <li>bp: average blood pressure</li> <li>s1 tc: T-Cells (a type of white blood cells)</li> </ul> <p>\u2705 This dataset includes the concept of 'sex' as a feature variable important to research around diabetes. Many medical datasets include this type of binary classification. Think a bit about how categorizations such as this might exclude certain parts of a population from treatments.</p> <p>Now, load up the X and y data.</p> <p>\ud83c\udf93 Remember, this is supervised learning, and we need a named 'y' target.</p> <p>In a new code cell, load the diabetes dataset by calling <code>load_diabetes()</code>. The input <code>return_X_y=True</code> signals that <code>X</code> will be a data matrix, and <code>y</code> will be the regression target.</p> <ol> <li> <p>Add some print commands to show the shape of the data matrix and its first element:</p> <pre><code>X, y = datasets.load_diabetes(return_X_y=True)\nprint(X.shape)\nprint(X[0])\n</code></pre> <p>What you are getting back as a response, is a tuple. What you are doing is to assign the two first values of the tuple to <code>X</code> and <code>y</code> respectively. Learn more about tuples.</p> <p>You can see that this data has 442 items shaped in arrays of 10 elements:</p> <pre><code>(442, 10)\n[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n-0.04340085 -0.00259226  0.01990842 -0.01764613]\n</code></pre> <p>\u2705 Think a bit about the relationship between the data and the regression target. Linear regression predicts relationships between feature X and target variable y. Can you find the target for the diabetes dataset in the documentation? What is this dataset demonstrating, given that target?</p> </li> <li> <p>Next, select a portion of this dataset to plot by selecting the 3rd column of the dataset. You can do this by using the <code>:</code> operator to select all rows, and then selecting the 3rd column using the index (2). You can also reshape the data to be a 2D array - as required for plotting - by using <code>reshape(n_rows, n_columns)</code>. If one of the parameter is -1, the corresponding dimension is calculated automatically.</p> </li> </ol> <pre><code>X = X[:, 2]\nX = X.reshape((-1,1))\n</code></pre> <p>\u2705 At any time, print out the data to check its shape.</p> <ol> <li>Now that you have data ready to be plotted, you can see if a machine can help determine a logical split between the numbers in this dataset. To do this, you need to split both the data (X) and the target (y) into test and training sets. Scikit-learn has a straightforward way to do this; you can split your test data at a given point.</li> </ol> <pre><code>X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33)\n</code></pre> <ol> <li> <p>Now you are ready to train your model! Load up the linear regression model and train it with your X and y training sets using <code>model.fit()</code>:</p> <pre><code>model = linear_model.LinearRegression()\nmodel.fit(X_train, y_train)\n</code></pre> <p>\u2705 <code>model.fit()</code> is a function you'll see in many ML libraries such as TensorFlow</p> </li> <li> <p>Then, create a prediction using test data, using the function <code>predict()</code>. This will be used to draw the line between data groups</p> <pre><code>y_pred = model.predict(X_test)\n</code></pre> </li> <li> <p>Now it's time to show the data in a plot. Matplotlib is a very useful tool for this task. Create a scatterplot of all the X and y test data, and use the prediction to draw a line in the most appropriate place, between the model's data groupings.</p> <pre><code>plt.scatter(X_test, y_test,  color='black')\nplt.plot(X_test, y_pred, color='blue', linewidth=3)\nplt.xlabel('Scaled BMIs')\nplt.ylabel('Disease Progression')\nplt.title('A Graph Plot Showing Diabetes Progression Against BMI')\nplt.show()\n</code></pre> </li> </ol> <p></p> <p>\u2705 Think a bit about what's going on here. A straight line is running through many small dots of data, but what is it doing exactly? Can you see how you should be able to use this line to predict where a new, unseen data point should fit in relationship to the plot's y axis? Try to put into words the practical use of this model.</p> <p>Congratulations, you built your first linear regression model, created a prediction with it, and displayed it in a plot!</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Plot a different variable from this dataset. Hint: edit this line: <code>X = X[:,2]</code>. Given this dataset's target, what are you able to discover about the progression of diabetes as a disease?</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#review-self-study","title":"Review &amp; Self Study","text":"<p>In this tutorial, you worked with simple linear regression, rather than univariate or multiple linear regression. Read a little about the differences between these methods, or take a look at this video</p> <p>Read more about the concept of regression and think about what kinds of questions can be answered by this technique. Take this tutorial to deepen your understanding.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/1-Tools/#assignment","title":"Assignment","text":"<p>A different dataset</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/","title":"Data","text":""},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#build-a-regression-model-using-scikit-learn-prepare-and-visualize-data","title":"Build a regression model using Scikit-learn: prepare and visualize data","text":"<p>Infographic by Dasani Madipalli</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#this-lesson-is-available-in-r","title":"This lesson is available in R!","text":""},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#introduction","title":"Introduction","text":"<p>Now that you are set up with the tools you need to start tackling machine learning model building with Scikit-learn, you are ready to start asking questions of your data. As you work with data and apply ML solutions, it's very important to understand how to ask the right question to properly unlock the potentials of your dataset.</p> <p>In this lesson, you will learn:</p> <ul> <li>How to prepare your data for model-building.</li> <li>How to use Matplotlib for data visualization.</li> </ul>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#asking-the-right-question-of-your-data","title":"Asking the right question of your data","text":"<p>The question you need answered will determine what type of ML algorithms you will leverage. And the quality of the answer you get back will be heavily dependent on the nature of your data.</p> <p>Take a look at the data provided for this lesson. You can open this .csv file in VS Code. A quick skim immediately shows that there are blanks and a mix of strings and numeric data. There's also a strange column called 'Package' where the data is a mix between 'sacks', 'bins' and other values. The data, in fact, is a bit of a mess.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video working through preparing the data for this lesson.</p> <p>In fact, it is not very common to be gifted a dataset that is completely ready to use to create a ML model out of the box. In this lesson, you will learn how to prepare a raw dataset using standard Python libraries. You will also learn various techniques to visualize the data.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#case-study-the-pumpkin-market","title":"Case study: 'the pumpkin market'","text":"<p>In this folder you will find a .csv file in the root <code>data</code> folder called US-pumpkins.csv which includes 1757 lines of data about the market for pumpkins, sorted into groupings by city. This is raw data extracted from the Specialty Crops Terminal Markets Standard Reports distributed by the United States Department of Agriculture.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#preparing-data","title":"Preparing data","text":"<p>This data is in the public domain. It can be downloaded in many separate files, per city, from the USDA web site. To avoid too many separate files, we have concatenated all the city data into one spreadsheet, thus we have already prepared the data a bit. Next, let's take a closer look at the data.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#the-pumpkin-data-early-conclusions","title":"The pumpkin data - early conclusions","text":"<p>What do you notice about this data? You already saw that there is a mix of strings, numbers, blanks and strange values that you need to make sense of.</p> <p>What question can you ask of this data, using a Regression technique? What about \"Predict the price of a pumpkin for sale during a given month\". Looking again at the data, there are some changes you need to make to create the data structure necessary for the task.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#exercise-analyze-the-pumpkin-data","title":"Exercise - analyze the pumpkin data","text":"<p>Let's use Pandas, (the name stands for <code>Python Data Analysis</code>) a tool very useful for shaping data, to analyze and prepare this pumpkin data.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#first-check-for-missing-dates","title":"First, check for missing dates","text":"<p>You will first need to take steps to check for missing dates:</p> <ol> <li>Convert the dates to a month format (these are US dates, so the format is <code>MM/DD/YYYY</code>).</li> <li>Extract the month to a new column.</li> </ol> <p>Open the notebook.ipynb file in Visual Studio Code and import the spreadsheet in to a new Pandas dataframe.</p> <ol> <li> <p>Use the <code>head()</code> function to view the first five rows.</p> <pre><code>import pandas as pd\npumpkins = pd.read_csv('../data/US-pumpkins.csv')\npumpkins.head()\n</code></pre> <p>\u2705 What function would you use to view the last five rows?</p> </li> <li> <p>Check if there is missing data in the current dataframe:</p> <pre><code>pumpkins.isnull().sum()\n</code></pre> <p>There is missing data, but maybe it won't matter for the task at hand.</p> </li> <li> <p>To make your dataframe easier to work with, select only the columns you need, using the <code>loc</code> function which extracts from the original dataframe a group of rows (passed as first parameter) and columns (passed as second parameter). The expression <code>:</code> in the case below means \"all rows\".</p> <pre><code>columns_to_select = ['Package', 'Low Price', 'High Price', 'Date']\npumpkins = pumpkins.loc[:, columns_to_select]\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#second-determine-average-price-of-pumpkin","title":"Second, determine average price of pumpkin","text":"<p>Think about how to determine the average price of a pumpkin in a given month. What columns would you pick for this task? Hint: you'll need 3 columns.</p> <p>Solution: take the average of the <code>Low Price</code> and <code>High Price</code> columns to populate the new Price column, and convert the Date column to only show the month. Fortunately, according to the check above, there is no missing data for dates or prices.</p> <ol> <li> <p>To calculate the average, add the following code:</p> <pre><code>price = (pumpkins['Low Price'] + pumpkins['High Price']) / 2\n\nmonth = pd.DatetimeIndex(pumpkins['Date']).month\n</code></pre> </li> </ol> <p>\u2705 Feel free to print any data you'd like to check using <code>print(month)</code>.</p> <ol> <li> <p>Now, copy your converted data into a fresh Pandas dataframe:</p> <pre><code>new_pumpkins = pd.DataFrame({'Month': month, 'Package': pumpkins['Package'], 'Low Price': pumpkins['Low Price'],'High Price': pumpkins['High Price'], 'Price': price})\n</code></pre> <p>Printing out your dataframe will show you a clean, tidy dataset on which you can build your new regression model.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#but-wait-theres-something-odd-here","title":"But wait! There's something odd here","text":"<p>If you look at the <code>Package</code> column, pumpkins are sold in many different configurations. Some are sold in '1 1/9 bushel' measures, and some in '1/2 bushel' measures, some per pumpkin, some per pound, and some in big boxes with varying widths.</p> <p>Pumpkins seem very hard to weigh consistently</p> <p>Digging into the original data, it's interesting that anything with <code>Unit of Sale</code> equalling 'EACH' or 'PER BIN' also have the <code>Package</code> type per inch, per bin, or 'each'. Pumpkins seem to be very hard to weigh consistently, so let's filter them by selecting only pumpkins with the string 'bushel' in their <code>Package</code> column.</p> <ol> <li> <p>Add a filter at the top of the file, under the initial .csv import:</p> <pre><code>pumpkins = pumpkins[pumpkins['Package'].str.contains('bushel', case=True, regex=True)]\n</code></pre> <p>If you print the data now, you can see that you are only getting the 415 or so rows of data containing pumpkins by the bushel.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#but-wait-theres-one-more-thing-to-do","title":"But wait! There's one more thing to do","text":"<p>Did you notice that the bushel amount varies per row? You need to normalize the pricing so that you show the pricing per bushel, so do some math to standardize it.</p> <ol> <li> <p>Add these lines after the block creating the new_pumpkins dataframe:</p> <pre><code>new_pumpkins.loc[new_pumpkins['Package'].str.contains('1 1/9'), 'Price'] = price/(1 + 1/9)\n\nnew_pumpkins.loc[new_pumpkins['Package'].str.contains('1/2'), 'Price'] = price/(1/2)\n</code></pre> </li> </ol> <p>\u2705 According to The Spruce Eats, a bushel's weight depends on the type of produce, as it's a volume measurement. \"A bushel of tomatoes, for example, is supposed to weigh 56 pounds... Leaves and greens take up more space with less weight, so a bushel of spinach is only 20 pounds.\" It's all pretty complicated! Let's not bother with making a bushel-to-pound conversion, and instead price by the bushel. All this study of bushels of pumpkins, however, goes to show how very important it is to understand the nature of your data!</p> <p>Now, you can analyze the pricing per unit based on their bushel measurement. If you print out the data one more time, you can see how it's standardized.</p> <p>\u2705 Did you notice that pumpkins sold by the half-bushel are very expensive? Can you figure out why? Hint: little pumpkins are way pricier than big ones, probably because there are so many more of them per bushel, given the unused space taken by one big hollow pie pumpkin.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#visualization-strategies","title":"Visualization Strategies","text":"<p>Part of the data scientist's role is to demonstrate the quality and nature of the data they are working with. To do this, they often create interesting visualizations, or plots, graphs, and charts, showing different aspects of data. In this way, they are able to visually show relationships and gaps that are otherwise hard to uncover.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video working through visualizing the data for this lesson.</p> <p>Visualizations can also help determine the machine learning technique most appropriate for the data. A scatterplot that seems to follow a line, for example, indicates that the data is a good candidate for a linear regression exercise.</p> <p>One data visualization library that works well in Jupyter notebooks is Matplotlib (which you also saw in the previous lesson).</p> <p>Get more experience with data visualization in these tutorials.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#exercise-experiment-with-matplotlib","title":"Exercise - experiment with Matplotlib","text":"<p>Try to create some basic plots to display the new dataframe you just created. What would a basic line plot show?</p> <ol> <li> <p>Import Matplotlib at the top of the file, under the Pandas import:</p> <pre><code>import matplotlib.pyplot as plt\n</code></pre> </li> <li> <p>Rerun the entire notebook to refresh.</p> </li> <li> <p>At the bottom of the notebook, add a cell to plot the data as a box:</p> <pre><code>price = new_pumpkins.Price\nmonth = new_pumpkins.Month\nplt.scatter(price, month)\nplt.show()\n</code></pre> <p></p> <p>Is this a useful plot? Does anything about it surprise you?</p> <p>It's not particularly useful as all it does is display in your data as a spread of points in a given month.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#make-it-useful","title":"Make it useful","text":"<p>To get charts to display useful data, you usually need to group the data somehow. Let's try creating a plot where the y axis shows the months and the data demonstrates the distribution of data.</p> <ol> <li> <p>Add a cell to create a grouped bar chart:</p> <pre><code>new_pumpkins.groupby(['Month'])['Price'].mean().plot(kind='bar')\nplt.ylabel(\"Pumpkin Price\")\n</code></pre> <p></p> <p>This is a more useful data visualization! It seems to indicate that the highest price for pumpkins occurs in September and October. Does that meet your expectation? Why or why not?</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Explore the different types of visualization that Matplotlib offers. Which types are most appropriate for regression problems?</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take a look at the many ways to visualize data. Make a list of the various libraries available and note which are best for given types of tasks, for example 2D visualizations vs. 3D visualizations. What do you discover?</p>"},{"location":"curricula/ml-for-beginners/2-Regression/2-Data/#assignment","title":"Assignment","text":"<p>Exploring visualization</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/","title":"Linear","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#build-a-regression-model-using-scikit-learn-regression-four-ways","title":"Build a regression model using Scikit-learn: regression four ways","text":"<p>Infographic by Dasani Madipalli</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#this-lesson-is-available-in-r","title":"This lesson is available in R!","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#introduction","title":"Introduction","text":"<p>So far you have explored what regression is with sample data gathered from the pumpkin pricing dataset that we will use throughout this lesson. You have also visualized it using Matplotlib.</p> <p>Now you are ready to dive deeper into regression for ML. While visualization allows you to make sense of data, the real power of Machine Learning comes from training models. Models are trained on historic data to automatically capture data dependencies, and they allow you to predict outcomes for new data, which the model has not seem before.</p> <p>In this lesson, you will learn more about two types of regression: basic linear regression and polynomial regression, along with some of the math underlying these techniques. Those models will allow us to predict pumpkin prices depending on different input data. </p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video overview of linear regression.</p> <p>Throughout this curriculum, we assume minimal knowledge of math, and seek to make it accessible for students coming from other fields, so watch for notes, \ud83e\uddee callouts, diagrams, and other learning tools to aid in comprehension.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#prerequisite","title":"Prerequisite","text":"<p>You should be familiar by now with the structure of the pumpkin data that we are examining. You can find it preloaded and pre-cleaned in this lesson's notebook.ipynb file. In the file, the pumpkin price is displayed per bushel in a new data frame.  Make sure you can run these notebooks in kernels in Visual Studio Code.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#preparation","title":"Preparation","text":"<p>As a reminder, you are loading this data so as to ask questions of it. </p> <ul> <li>When is the best time to buy pumpkins? </li> <li>What price can I expect of a case of miniature pumpkins?</li> <li>Should I buy them in half-bushel baskets or by the 1 1/9 bushel box? Let's keep digging into this data.</li> </ul> <p>In the previous lesson, you created a Pandas data frame and populated it with part of the original dataset, standardizing the pricing by the bushel. By doing that, however, you were only able to gather about 400 datapoints and only for the fall months. </p> <p>Take a look at the data that we preloaded in this lesson's accompanying notebook. The data is preloaded and an initial scatterplot is charted to show month data. Maybe we can get a little more detail about the nature of the data by cleaning it more.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#a-linear-regression-line","title":"A linear regression line","text":"<p>As you learned in Lesson 1, the goal of a linear regression exercise is to be able to plot a line to:</p> <ul> <li>Show variable relationships. Show the relationship between variables</li> <li>Make predictions. Make accurate predictions on where a new datapoint would fall in relationship to that line. </li> </ul> <p>It is typical of Least-Squares Regression to draw this type of line. The term 'least-squares' means that all the datapoints surrounding the regression line are squared and then added up. Ideally, that final sum is as small as possible, because we want a low number of errors, or <code>least-squares</code>. </p> <p>We do so since we want to model a line that has the least cumulative distance from all of our data points. We also square the terms before adding them since we are concerned with its magnitude rather than its direction.</p> <p>\ud83e\uddee Show me the math </p> <p>This line, called the line of best fit can be expressed by an equation: </p> <pre><code>Y = a + bX\n</code></pre> <p><code>X</code> is the 'explanatory variable'. <code>Y</code> is the 'dependent variable'. The slope of the line is <code>b</code> and <code>a</code> is the y-intercept, which refers to the value of <code>Y</code> when <code>X = 0</code>. </p> <p></p> <p>First, calculate the slope <code>b</code>. Infographic by Jen Looper</p> <p>In other words, and referring to our pumpkin data's original question: \"predict the price of a pumpkin per bushel by month\", <code>X</code> would refer to the price and <code>Y</code> would refer to the month of sale. </p> <p></p> <p>Calculate the value of Y. If you're paying around $4, it must be April! Infographic by Jen Looper</p> <p>The math that calculates the line must demonstrate the slope of the line, which is also dependent on the intercept, or where <code>Y</code> is situated when <code>X = 0</code>.</p> <p>You can observe the method of calculation for these values on the Math is Fun web site. Also visit this Least-squares calculator to watch how the numbers' values impact the line.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#correlation","title":"Correlation","text":"<p>One more term to understand is the Correlation Coefficient between given X and Y variables. Using a scatterplot, you can quickly visualize this coefficient. A plot with datapoints scattered in a neat line have high correlation, but a plot with datapoints scattered everywhere between X and Y have a low correlation.</p> <p>A good linear regression model will be one that has a high (nearer to 1 than 0) Correlation Coefficient using the Least-Squares Regression method with a line of regression.</p> <p>\u2705 Run the notebook accompanying this lesson and look at the Month to Price scatterplot. Does the data associating Month to Price for pumpkin sales seem to have high or low correlation, according to your visual interpretation of the scatterplot? Does that change if you use more fine-grained measure instead of <code>Month</code>, eg. day of the year (i.e. number of days since the beginning of the year)?</p> <p>In the code below, we will assume that we have cleaned up the data, and obtained a data frame called <code>new_pumpkins</code>, similar to the following:</p> ID Month DayOfYear Variety City Package Low Price High Price Price 70 9 267 PIE TYPE BALTIMORE 1 1/9 bushel cartons 15.0 15.0 13.636364 71 9 267 PIE TYPE BALTIMORE 1 1/9 bushel cartons 18.0 18.0 16.363636 72 10 274 PIE TYPE BALTIMORE 1 1/9 bushel cartons 18.0 18.0 16.363636 73 10 274 PIE TYPE BALTIMORE 1 1/9 bushel cartons 17.0 17.0 15.454545 74 10 281 PIE TYPE BALTIMORE 1 1/9 bushel cartons 15.0 15.0 13.636364 <p>The code to clean the data is available in <code>notebook.ipynb</code>. We have performed the same cleaning steps as in the previous lesson, and have calculated <code>DayOfYear</code> column using the following expression: </p> <pre><code>day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)\n</code></pre> <p>Now that you have an understanding of the math behind linear regression, let's create a Regression model to see if we can predict which package of pumpkins will have the best pumpkin prices. Someone buying pumpkins for a holiday pumpkin patch might want this information to be able to optimize their purchases of pumpkin packages for the patch.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#looking-for-correlation","title":"Looking for Correlation","text":"<p>\ud83c\udfa5 Click the image above for a short video overview of correlation.</p> <p>From the previous lesson you have probably seen that the average price for different months looks like this:</p> <p></p> <p>This suggests that there should be some correlation, and we can try training linear regression model to predict the relationship between <code>Month</code> and <code>Price</code>, or between <code>DayOfYear</code> and <code>Price</code>. Here is the scatter plot that shows the latter relationship:</p> <p> </p> <p>Let's see if there is a correlation using the <code>corr</code> function:</p> <pre><code>print(new_pumpkins['Month'].corr(new_pumpkins['Price']))\nprint(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))\n</code></pre> <p>It looks like the correlation is pretty small, -0.15 by <code>Month</code> and -0.17 by the <code>DayOfMonth</code>, but there could be another important relationship. It looks like there are different clusters of prices corresponding to different pumpkin varieties. To confirm this hypothesis, let's plot each pumpkin category using a different color. By passing an <code>ax</code> parameter to the <code>scatter</code> plotting function we can plot all points on the same graph:</p> <pre><code>ax=None\ncolors = ['red','blue','green','yellow']\nfor i,var in enumerate(new_pumpkins['Variety'].unique()):\n    df = new_pumpkins[new_pumpkins['Variety']==var]\n    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)\n</code></pre> <p> </p> <p>Our investigation suggests that variety has more effect on the overall price than the actual selling date. We can see this with a bar graph:</p> <pre><code>new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')\n</code></pre> <p> </p> <p>Let us focus for the moment only on one pumpkin variety, the 'pie type', and see what effect the date has on the price:</p> <p></p><pre><code>pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']\npie_pumpkins.plot.scatter('DayOfYear','Price') \n</code></pre> <p>If we now calculate the correlation between <code>Price</code> and <code>DayOfYear</code> using <code>corr</code> function, we will get something like <code>-0.27</code> - which means that training a predictive model makes sense.</p> <p>Before training a linear regression model, it is important to make sure that our data is clean. Linear regression does not work well with missing values, thus it makes sense to get rid of all empty cells:</p> <pre><code>pie_pumpkins.dropna(inplace=True)\npie_pumpkins.info()\n</code></pre> <p>Another approach would be to fill those empty values with mean values from the corresponding column.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#simple-linear-regression","title":"Simple Linear Regression","text":"<p>\ud83c\udfa5 Click the image above for a short video overview of linear and polynomial regression.</p> <p>To train our Linear Regression model, we will use the Scikit-learn library.</p> <pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n</code></pre> <p>We start by separating input values (features) and the expected output (label) into separate numpy arrays:</p> <pre><code>X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)\ny = pie_pumpkins['Price']\n</code></pre> <p>Note that we had to perform <code>reshape</code> on the input data in order for the Linear Regression package to understand it correctly. Linear Regression expects a 2D-array as an input, where each row of the array corresponds to a vector of input features. In our case, since we have only one input - we need an array with shape N\u00d71, where N is the dataset size.</p> <p>Then, we need to split the data into train and test datasets, so that we can validate our model after training:</p> <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n</code></pre> <p>Finally, training the actual Linear Regression model takes only two lines of code. We define the <code>LinearRegression</code> object, and fit it to our data using the <code>fit</code> method:</p> <pre><code>lin_reg = LinearRegression()\nlin_reg.fit(X_train,y_train)\n</code></pre> <p>The <code>LinearRegression</code> object after <code>fit</code>-ting contains all the coefficients of the regression, which can be accessed using <code>.coef_</code> property. In our case, there is just one coefficient, which should be around <code>-0.017</code>. It means that prices seem to drop a bit with time, but not too much, around 2 cents per day. We can also access the intersection point of the regression with Y-axis using <code>lin_reg.intercept_</code> - it will be around <code>21</code> in our case, indicating the price at the beginning of the year.</p> <p>To see how accurate our model is, we can predict prices on a test dataset, and then measure how close our predictions are to the expected values. This can be done using mean square error (MSE) metrics, which is the mean of all squared differences between expected and predicted value.</p> <pre><code>pred = lin_reg.predict(X_test)\n\nmse = np.sqrt(mean_squared_error(y_test,pred))\nprint(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')\n</code></pre> <p>Our error seems to be around 2 points, which is ~17%. Not too good. Another indicator of model quality is the coefficient of determination, which can be obtained like this:</p> <p></p><pre><code>score = lin_reg.score(X_train,y_train)\nprint('Model determination: ', score)\n</code></pre> If the value is 0, it means that the model does not take input data into account, and acts as the worst linear predictor, which is simply a mean value of the result. The value of 1 means that we can perfectly predict all expected outputs. In our case, the coefficient is around 0.06, which is quite low. <p>We can also plot the test data together with the regression line to better see how regression works in our case:</p> <pre><code>plt.scatter(X_test,y_test)\nplt.plot(X_test,pred)\n</code></pre> <p></p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#polynomial-regression","title":"Polynomial Regression","text":"<p>Another type of Linear Regression is Polynomial Regression. While sometimes there's a linear relationship between variables - the bigger the pumpkin in volume, the higher the price - sometimes these relationships can't be plotted as a plane or straight line. </p> <p>\u2705 Here are some more examples of data that could use Polynomial Regression</p> <p>Take another look at the relationship between Date and Price. Does this scatterplot seem like it should necessarily be analyzed by a straight line? Can't prices fluctuate? In this case, you can try polynomial regression.</p> <p>\u2705 Polynomials are mathematical expressions that might consist of one or more variables and coefficients</p> <p>Polynomial regression creates a curved line to better fit nonlinear data. In our case, if we include a squared <code>DayOfYear</code> variable into input data, we should be able to fit our data with a parabolic curve, which will have a minimum at a certain point within the year.</p> <p>Scikit-learn includes a helpful pipeline API to combine different steps of data processing together. A pipeline is a chain of estimators. In our case, we will create a pipeline that first adds polynomial features to our model, and then trains the regression:</p> <pre><code>from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\npipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())\n\npipeline.fit(X_train,y_train)\n</code></pre> <p>Using <code>PolynomialFeatures(2)</code> means that we will include all second-degree polynomials from the input data. In our case it will just mean <code>DayOfYear</code><sup>2</sup>, but given two input variables X and Y, this will add X<sup>2</sup>, XY and Y<sup>2</sup>. We may also use higher degree polynomials if we want.</p> <p>Pipelines can be used in the same manner as the original <code>LinearRegression</code> object, i.e. we can <code>fit</code> the pipeline, and then use <code>predict</code> to get the prediction results. Here is the graph showing test data, and the approximation curve:</p> <p></p> <p>Using Polynomial Regression, we can get slightly lower MSE and higher determination, but not significantly. We need to take into account other features!</p> <p>You can see that the minimal pumpkin prices are observed somewhere around Halloween. How can you explain this? </p> <p>\ud83c\udf83 Congratulations, you just created a model that can help predict the price of pie pumpkins. You can probably repeat the same procedure for all pumpkin types, but that would be tedious. Let's learn now how to take pumpkin variety into account in our model!</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#categorical-features","title":"Categorical Features","text":"<p>In the ideal world, we want to be able to predict prices for different pumpkin varieties using the same model. However, the <code>Variety</code> column is somewhat different from columns like <code>Month</code>, because it contains non-numeric values. Such columns are called categorical.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video overview of using categorical features.</p> <p>Here you can see how average price depends on variety:</p> <p></p> <p>To take variety into account, we first need to convert it to numeric form, or encode it. There are several way we can do it:</p> <ul> <li>Simple numeric encoding will build a table of different varieties, and then replace the variety name by an index in that table. This is not the best idea for linear regression, because linear regression takes the actual numeric value of the index, and adds it to the result, multiplying by some coefficient. In our case, the relationship between the index number and the price is clearly non-linear, even if we make sure that indices are ordered in some specific way.</li> <li>One-hot encoding will replace the <code>Variety</code> column by 4 different columns, one for each variety. Each column will contain <code>1</code> if the corresponding row is of a given variety, and <code>0</code> otherwise. This means that there will be four coefficients in linear regression, one for each pumpkin variety, responsible for \"starting price\" (or rather \"additional price\") for that particular variety.</li> </ul> <p>The code below shows how we can one-hot encode a variety:</p> <pre><code>pd.get_dummies(new_pumpkins['Variety'])\n</code></pre> ID FAIRYTALE MINIATURE MIXED HEIRLOOM VARIETIES PIE TYPE 70 0 0 0 1 71 0 0 0 1 ... ... ... ... ... 1738 0 1 0 0 1739 0 1 0 0 1740 0 1 0 0 1741 0 1 0 0 1742 0 1 0 0 <p>To train linear regression using one-hot encoded variety as input, we just need to initialize <code>X</code> and <code>y</code> data correctly:</p> <pre><code>X = pd.get_dummies(new_pumpkins['Variety'])\ny = new_pumpkins['Price']\n</code></pre> <p>The rest of the code is the same as what we used above to train Linear Regression. If you try it, you will see that the mean squared error is about the same, but we get much higher coefficient of determination (~77%). To get even more accurate predictions, we can take more categorical features into account, as well as numeric features, such as <code>Month</code> or <code>DayOfYear</code>. To get one large array of features, we can use <code>join</code>:</p> <pre><code>X = pd.get_dummies(new_pumpkins['Variety']) \\\n        .join(new_pumpkins['Month']) \\\n        .join(pd.get_dummies(new_pumpkins['City'])) \\\n        .join(pd.get_dummies(new_pumpkins['Package']))\ny = new_pumpkins['Price']\n</code></pre> <p>Here we also take into account <code>City</code> and <code>Package</code> type, which gives us MSE 2.84 (10%), and determination 0.94!</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#putting-it-all-together","title":"Putting it all together","text":"<p>To make the best model, we can use combined (one-hot encoded categorical + numeric) data from the above example together with Polynomial Regression. Here is the complete code for your convenience:</p> <pre><code># set up training data\nX = pd.get_dummies(new_pumpkins['Variety']) \\\n        .join(new_pumpkins['Month']) \\\n        .join(pd.get_dummies(new_pumpkins['City'])) \\\n        .join(pd.get_dummies(new_pumpkins['Package']))\ny = new_pumpkins['Price']\n\n# make train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# setup and train the pipeline\npipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())\npipeline.fit(X_train,y_train)\n\n# predict results for test data\npred = pipeline.predict(X_test)\n\n# calculate MSE and determination\nmse = np.sqrt(mean_squared_error(y_test,pred))\nprint(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')\n\nscore = pipeline.score(X_train,y_train)\nprint('Model determination: ', score)\n</code></pre> <p>This should give us the best determination coefficient of almost 97%, and MSE=2.23 (~8% prediction error).</p> Model MSE Determination <code>DayOfYear</code> Linear 2.77 (17.2%) 0.07 <code>DayOfYear</code> Polynomial 2.73 (17.0%) 0.08 <code>Variety</code> Linear 5.24 (19.7%) 0.77 All features Linear 2.84 (10.5%) 0.94 All features Polynomial 2.23 (8.25%) 0.97 <p>\ud83c\udfc6 Well done! You created four Regression models in one lesson, and improved the model quality to 97%. In the final section on Regression, you will learn about Logistic Regression to determine categories. </p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Test several different variables in this notebook to see how correlation corresponds to model accuracy.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#review-self-study","title":"Review &amp; Self Study","text":"<p>In this lesson we learned about Linear Regression. There are other important types of Regression. Read about Stepwise, Ridge, Lasso and Elasticnet techniques. A good course to study to learn more is the Stanford Statistical Learning course</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/#assignment","title":"Assignment","text":"<p>Build a Model</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/assignment/#create-a-regression-model","title":"Create a Regression Model","text":""},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/assignment/#instructions","title":"Instructions","text":"<p>In this lesson you were shown how to build a model using both Linear and Polynomial Regression. Using this knowledge, find a dataset or use one of Scikit-learn's built-in sets to build a fresh model. Explain in your notebook why you chose the technique you did, and demonstrate your model's accuracy. If it is not accurate, explain why.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement presents a complete notebook with a well-documented solution the solution is incomplete the solution is flawed or buggy"},{"location":"curricula/ml-for-beginners/2-Regression/3-Linear/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/","title":"Logistic","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#logistic-regression-to-predict-categories","title":"Logistic regression to predict categories","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#this-lesson-is-available-in-r","title":"This lesson is available in R!","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#introduction","title":"Introduction","text":"<p>In this final lesson on Regression, one of the basic classic ML techniques, we will take a look at Logistic Regression. You would use this technique to discover patterns to predict binary categories. Is this candy chocolate or not? Is this disease contagious or not? Will this customer choose this product or not? </p> <p>In this lesson, you will learn:</p> <ul> <li>A new library for data visualization</li> <li>Techniques for logistic regression</li> </ul> <p>\u2705 Deepen your understanding of working with this type of regression in this Learn module</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#prerequisite","title":"Prerequisite","text":"<p>Having worked with the pumpkin data, we are now familiar enough with it to realize that there's one binary category that we can work with: <code>Color</code>.</p> <p>Let's build a logistic regression model to predict that, given some variables, what color a given pumpkin is likely to be (orange \ud83c\udf83 or white \ud83d\udc7b).</p> <p>Why are we talking about binary classification in a lesson grouping about regression? Only for linguistic convenience, as logistic regression is really a classification method, albeit a linear-based one. Learn about other ways to classify data in the next lesson group.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#define-the-question","title":"Define the question","text":"<p>For our purposes, we will express this as a binary: 'White' or 'Not White'. There is also a 'striped' category in our dataset but there are few instances of it, so we will not use it. It disappears once we remove null values from the dataset, anyway.</p> <p>\ud83c\udf83 Fun fact, we sometimes call white pumpkins 'ghost' pumpkins. They aren't very easy to carve, so they aren't as popular as the orange ones but they are cool looking! So we could also reformulate our question as: 'Ghost' or 'Not Ghost'. \ud83d\udc7b</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#about-logistic-regression","title":"About logistic regression","text":"<p>Logistic regression differs from linear regression, which you learned about previously, in a few important ways.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video overview of logistic regression.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#binary-classification","title":"Binary classification","text":"<p>Logistic regression does not offer the same features as linear regression. The former offers a prediction about a binary category (\"white or not white\") whereas the latter is capable of predicting continual values, for example given the origin of a pumpkin and the time of harvest, how much its price will rise.</p> <p></p> <p>Infographic by Dasani Madipalli</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#other-classifications","title":"Other classifications","text":"<p>There are other types of logistic regression, including multinomial and ordinal:</p> <ul> <li>Multinomial, which involves having more than one category - \"Orange, White, and Striped\".</li> <li>Ordinal, which involves ordered categories, useful if we wanted to order our outcomes logically, like our pumpkins that are ordered by a finite number of sizes (mini,sm,med,lg,xl,xxl).</li> </ul> <p></p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#variables-do-not-have-to-correlate","title":"Variables DO NOT have to correlate","text":"<p>Remember how linear regression worked better with more correlated variables? Logistic regression is the opposite - the variables don't have to align. That works for this data which has somewhat weak correlations.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#you-need-a-lot-of-clean-data","title":"You need a lot of clean data","text":"<p>Logistic regression will give more accurate results if you use more data; our small dataset is not optimal for this task, so keep that in mind.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video overview of preparing data for linear regression</p> <p>\u2705 Think about the types of data that would lend themselves well to logistic regression</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#exercise-tidy-the-data","title":"Exercise - tidy the data","text":"<p>First, clean the data a bit, dropping null values and selecting only some of the columns:</p> <ol> <li> <p>Add the following code:</p> <pre><code>columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']\npumpkins = full_pumpkins.loc[:, columns_to_select]\n\npumpkins.dropna(inplace=True)\n</code></pre> <p>You can always take a peek at your new dataframe:</p> <pre><code>pumpkins.info\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#visualization-categorical-plot","title":"Visualization - categorical plot","text":"<p>By now you have loaded up the starter notebook with pumpkin data once again and cleaned it so as to preserve a dataset containing a few variables, including <code>Color</code>. Let's visualize the dataframe in the notebook using a different library: Seaborn, which is built on Matplotlib which we used earlier. </p> <p>Seaborn offers some neat ways to visualize your data. For example, you can compare distributions of the data for each <code>Variety</code> and <code>Color</code> in a categorical plot.</p> <ol> <li> <p>Create such a plot by using the <code>catplot</code> function, using our pumpkin data <code>pumpkins</code>, and specifying a color mapping for each pumpkin category (orange or white):</p> <pre><code>import seaborn as sns\n\npalette = {\n'ORANGE': 'orange',\n'WHITE': 'wheat',\n}\n\nsns.catplot(\ndata=pumpkins, y=\"Variety\", hue=\"Color\", kind=\"count\",\npalette=palette, \n)\n</code></pre> <p></p> <p>By observing the data, you can see how the Color data relates to Variety.</p> <p>\u2705 Given this categorical plot, what are some interesting explorations you can envision?</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#data-pre-processing-feature-and-label-encoding","title":"Data pre-processing: feature and label encoding","text":"<p>Our pumpkins dataset contains string values for all its columns. Working with categorical data is intuitive for humans but not for machines. Machine learning algorithms work well with numbers. That's why encoding is a very important step in the data pre-processing phase, since it enables us to turn categorical data into numerical data, without losing any information. Good encoding leads to building a good model.</p> <p>For feature encoding there are two main types of encoders:</p> <ol> <li> <p>Ordinal encoder: it suits well for ordinal variables, which are categorical variables where their data follows a logical ordering, like the <code>Item Size</code> column in our dataset. It creates a mapping such that each category is represented by a number, which is the order of the category in the column.</p> <pre><code>from sklearn.preprocessing import OrdinalEncoder\n\nitem_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]\nordinal_features = ['Item Size']\nordinal_encoder = OrdinalEncoder(categories=item_size_categories)\n</code></pre> </li> <li> <p>Categorical encoder: it suits well for nominal variables, which are categorical variables where their data does not follow a logical ordering, like all the features different from <code>Item Size</code> in our dataset. It is a one-hot encoding, which means that each category is represented by a binary column: the encoded variable is equal to 1 if the pumpkin belongs to that Variety and 0 otherwise.</p> <p></p><pre><code>from sklearn.preprocessing import OneHotEncoder\n\ncategorical_features = ['City Name', 'Package', 'Variety', 'Origin']\ncategorical_encoder = OneHotEncoder(sparse_output=False)\n</code></pre> Then, <code>ColumnTransformer</code> is used to combine multiple encoders into a single step and apply them to the appropriate columns. </li> </ol> <p></p><pre><code>    from sklearn.compose import ColumnTransformer\n\n    ct = ColumnTransformer(transformers=[\n        ('ord', ordinal_encoder, ordinal_features),\n        ('cat', categorical_encoder, categorical_features)\n        ])\n\n    ct.set_output(transform='pandas')\n    encoded_features = ct.fit_transform(pumpkins)\n</code></pre> On the other hand, to encode the label, we use the scikit-learn <code>LabelEncoder</code> class, which is a utility class to help normalize labels such that they contain only values between 0 and n_classes-1 (here, 0 and 1). <p></p><pre><code>    from sklearn.preprocessing import LabelEncoder\n\n    label_encoder = LabelEncoder()\n    encoded_label = label_encoder.fit_transform(pumpkins['Color'])\n</code></pre> Once we have encoded the features and the label, we can merge them into a new dataframe <code>encoded_pumpkins</code>. <p></p><pre><code>    encoded_pumpkins = encoded_features.assign(Color=encoded_label)\n</code></pre> \u2705 What are the advantages of using an ordinal encoder for the <code>Item Size</code> column?"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#analyse-relationships-between-variables","title":"Analyse relationships between variables","text":"<p>Now that we have pre-processed our data, we can analyse the relationships between the features and the label to grasp an idea of how well the model will be able to predict the label given the features. The best way to perform this kind of analysis is plotting the data. We'll be using again the Seaborn <code>catplot</code> function, to visualize the relationships between <code>Item Size</code>,  <code>Variety</code> and <code>Color</code> in a categorical plot. To better plot the data we'll be using the encoded <code>Item Size</code> column and the unencoded <code>Variety</code> column.</p> <p></p><pre><code>    palette = {\n    'ORANGE': 'orange',\n    'WHITE': 'wheat',\n    }\n    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']\n\n    g = sns.catplot(\n        data=pumpkins,\n        x=\"Item Size\", y=\"Color\", row='Variety',\n        kind=\"box\", orient=\"h\",\n        sharex=False, margin_titles=True,\n        height=1.8, aspect=4, palette=palette,\n    )\n    g.set(xlabel=\"Item Size\", ylabel=\"\").set(xlim=(0,6))\n    g.set_titles(row_template=\"{row_name}\")\n</code></pre>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#use-a-swarm-plot","title":"Use a swarm plot","text":"<p>Since Color is a binary category (White or Not), it needs 'a specialized approach to visualization'. There are other ways to visualize the relationship of this category with other variables. </p> <p>You can visualize variables side-by-side with Seaborn plots.</p> <ol> <li> <p>Try a 'swarm' plot to show the distribution of values:</p> <pre><code>palette = {\n0: 'orange',\n1: 'wheat'\n}\nsns.swarmplot(x=\"Color\", y=\"ord__Item Size\", data=encoded_pumpkins, palette=palette)\n</code></pre> <p></p> </li> </ol> <p>Watch Out: the code above might generate a warning, since seaborn fails to represent such amount of datapoints into a swam plot. A possible solution is decreasing the size of the marker, by using the 'size' parameter. However, be aware that this affects the readability of the plot.</p> <p>\ud83e\uddee Show Me The Math</p> <p>Logistic regression relies on the concept of 'maximum likelihood' using sigmoid functions. A 'Sigmoid Function' on a plot looks like an 'S' shape. It takes a value and maps it to somewhere between 0 and 1. Its curve is also called a 'logistic curve'. Its formula looks like this:</p> <p></p> <p>where the sigmoid's midpoint finds itself at x's 0 point, L is the curve's maximum value, and k is the curve's steepness. If the outcome of the function is more than 0.5, the label in question will be given the class '1' of the binary choice. If not, it will be classified as '0'.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#build-your-model","title":"Build your model","text":"<p>Building a model to find these binary classification is surprisingly straightforward in Scikit-learn.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a short video overview of building a linear regression model</p> <ol> <li> <p>Select the variables you want to use in your classification model and split the training and test sets calling <code>train_test_split()</code>:</p> <pre><code>from sklearn.model_selection import train_test_split\n\nX = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]\ny = encoded_pumpkins['Color']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n</code></pre> </li> <li> <p>Now you can train your model, by calling <code>fit()</code> with your training data, and print out its result:</p> <pre><code>from sklearn.metrics import f1_score, classification_report \nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\nprint(classification_report(y_test, predictions))\nprint('Predicted labels: ', predictions)\nprint('F1-score: ', f1_score(y_test, predictions))\n</code></pre> <p>Take a look at your model's scoreboard. It's not bad, considering you have only about 1000 rows of data:</p> <pre><code>                   precision    recall  f1-score   support\n\n                0       0.94      0.98      0.96       166\n                1       0.85      0.67      0.75        33\n\n    accuracy                                0.92       199\n    macro avg           0.89      0.82      0.85       199\n    weighted avg        0.92      0.92      0.92       199\n\n    Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n    0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n    1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0\n    0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n    0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n    0 0 0 1 0 0 0 0 0 0 0 0 1 1]\n    F1-score:  0.7457627118644068\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#better-comprehension-via-a-confusion-matrix","title":"Better comprehension via a confusion matrix","text":"<p>While you can get a scoreboard report terms by printing out the items above, you might be able to understand your model more easily by using a confusion matrix to help us understand how the model is performing.</p> <p>\ud83c\udf93 A 'confusion matrix' (or 'error matrix') is a table that expresses your model's true vs. false positives and negatives, thus gauging the accuracy of predictions.</p> <ol> <li> <p>To use a confusion metrics, call <code>confusion_matrix()</code>:</p> <pre><code>from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, predictions)\n</code></pre> <p>Take a look at your model's confusion matrix:</p> <pre><code>array([[162,   4],\n       [ 11,  22]])\n</code></pre> </li> </ol> <p>In Scikit-learn, confusion matrices Rows (axis 0) are actual labels and columns (axis 1) are predicted labels.</p> 0 1 0 TN FP 1 FN TP <p>What's going on here? Let's say our model is asked to classify pumpkins between two binary categories, category 'white' and category 'not-white'.</p> <ul> <li>If your model predicts a pumpkin as not white and it belongs to category 'not-white' in reality we call it a true negative, shown by the top left number.</li> <li>If your model predicts a pumpkin as white and it belongs to category 'not-white' in reality we call it a false negative, shown by the bottom left number. </li> <li>If your model predicts a pumpkin as not white and it belongs to category 'white' in reality we call it a false positive, shown by the top right number. </li> <li>If your model predicts a pumpkin as white and it belongs to category 'white' in reality we call it a true positive, shown by the bottom right number.</li> </ul> <p>As you might have guessed it's preferable to have a larger number of true positives and true negatives and a lower number of false positives and false negatives, which implies that the model performs better.</p> <p>How does the confusion matrix relate to precision and recall? Remember, the classification report printed above showed precision (0.85) and recall (0.67).</p> <p>Precision = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461</p> <p>Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666</p> <p>\u2705 Q: According to the confusion matrix, how did the model do? A: Not bad; there are a good number of true negatives but also a few false negatives. </p> <p>Let's revisit the terms we saw earlier with the help of the confusion matrix's mapping of TP/TN and FP/FN:</p> <p>\ud83c\udf93 Precision: TP/(TP + FP) The fraction of relevant instances among the retrieved instances (e.g. which labels were well-labeled)</p> <p>\ud83c\udf93 Recall: TP/(TP + FN) The fraction of relevant instances that were retrieved, whether well-labeled or not</p> <p>\ud83c\udf93 f1-score: (2 * precision * recall)/(precision + recall) A weighted average of the precision and recall, with best being 1 and worst being 0</p> <p>\ud83c\udf93 Support: The number of occurrences of each label retrieved</p> <p>\ud83c\udf93 Accuracy: (TP + TN)/(TP + TN + FP + FN) The percentage of labels predicted accurately for a sample.</p> <p>\ud83c\udf93 Macro Avg: The calculation of the unweighted mean metrics for each label, not taking label imbalance into account.</p> <p>\ud83c\udf93 Weighted Avg: The calculation of the mean metrics for each label, taking label imbalance into account by weighting them by their support (the number of true instances for each label).</p> <p>\u2705 Can you think which metric you should watch if you want your model to reduce the number of false negatives?</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#visualize-the-roc-curve-of-this-model","title":"Visualize the ROC curve of this model","text":"<p>\ud83c\udfa5 Click the image above for a short video overview of ROC curves</p> <p>Let's do one more visualization to see the so-called 'ROC' curve:</p> <pre><code>from sklearn.metrics import roc_curve, roc_auc_score\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ny_scores = model.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n\nfig = plt.figure(figsize=(6, 6))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()\n</code></pre> <p>Using Matplotlib, plot the model's Receiving Operating Characteristic or ROC. ROC curves are often used to get a view of the output of a classifier in terms of its true vs. false positives. \"ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis.\" Thus, the steepness of the curve and the space between the midpoint line and the curve matter: you want a curve that quickly heads up and over the line. In our case, there are false positives to start with, and then the line heads up and over properly:</p> <p></p> <p>Finally, use Scikit-learn's <code>roc_auc_score</code> API to compute the actual 'Area Under the Curve' (AUC):</p> <p></p><pre><code>auc = roc_auc_score(y_test,y_scores[:,1])\nprint(auc)\n</code></pre> The result is <code>0.9749908725812341</code>. Given that the AUC ranges from 0 to 1, you want a big score, since a model that is 100% correct in its predictions will have an AUC of 1; in this case, the model is pretty good.  <p>In future lessons on classifications, you will learn how to iterate to improve your model's scores. But for now, congratulations! You've completed these regression lessons!</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#challenge","title":"\ud83d\ude80Challenge","text":"<p>There's a lot more to unpack regarding logistic regression! But the best way to learn is to experiment. Find a dataset that lends itself to this type of analysis and build a model with it. What do you learn? tip: try Kaggle for interesting datasets.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#review-self-study","title":"Review &amp; Self Study","text":"<p>Read the first few pages of this paper from Stanford on some practical uses for logistic regression. Think about tasks that are better suited for one or the other type of regression tasks that we have studied up to this point. What would work best?</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/#assignment","title":"Assignment","text":"<p>Retrying this regression</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/assignment/#retrying-some-regression","title":"Retrying some Regression","text":""},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/assignment/#instructions","title":"Instructions","text":"<p>In the lesson, you used a subset of the pumpkin data. Now, go back to the original data and try to use all of it, cleaned and standardized, to build a Logistic Regression model.</p>"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with a well-explained and well-performing model A notebook is presented with a model that performs minimally A notebook is presented with a sub-performing model or none"},{"location":"curricula/ml-for-beginners/2-Regression/4-Logistic/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/","title":"Lesson 3","text":""},{"location":"curricula/ml-for-beginners/3-Web-App/#build-a-web-app-to-use-a-ml-model","title":"Build a Web App to use a ML Model","text":"<p>In this lesson, you will train an ML model on a data set that's out of this world: UFO sightings over the past century, sourced from NUFORC's database.</p> <p>You will learn:</p> <ul> <li>How to 'pickle' a trained model</li> <li>How to use that model in a Flask app</li> </ul> <p>We will continue our use of notebooks to clean data and train our model, but you can take the process one step further by exploring using a model 'in the wild', so to speak: in a web app.</p> <p>To do this, you need to build a web app using Flask.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/3-Web-App/#building-an-app","title":"Building an app","text":"<p>There are several ways to build web apps to consume machine learning models. Your web architecture may influence the way your model is trained. Imagine that you are working in a business where the data science group has trained a model that they want you to use in an app.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#considerations","title":"Considerations","text":"<p>There are many questions you need to ask:</p> <ul> <li>Is it a web app or a mobile app? If you are building a mobile app or need to use the model in an IoT context, you could use TensorFlow Lite and use the model in an Android or iOS app.</li> <li>Where will the model reside? In the cloud or locally?</li> <li>Offline support. Does the app have to work offline?</li> <li>What technology was used to train the model? The chosen technology may influence the tooling you need to use.<ul> <li>Using TensorFlow. If you are training a model using TensorFlow, for example, that ecosystem provides the ability to convert a TensorFlow model for use in a web app by using TensorFlow.js.</li> <li>Using PyTorch. If you are building a model using a library such as PyTorch, you have the option to export it in ONNX (Open Neural Network Exchange) format for use in JavaScript web apps that can use the Onnx Runtime. This option will be explored in a future lesson for a Scikit-learn-trained model.</li> <li>Using Lobe.ai or Azure Custom Vision. If you are using an ML SaaS (Software as a Service) system such as Lobe.ai or Azure Custom Vision to train a model, this type of software provides ways to export the model for many platforms, including building a bespoke API to be queried in the cloud by your online application.</li> </ul> </li> </ul> <p>You also have the opportunity to build an entire Flask web app that would be able to train the model itself in a web browser. This can also be done using TensorFlow.js in a JavaScript context.</p> <p>For our purposes, since we have been working with Python-based notebooks, let's explore the steps you need to take to export a trained model from such a notebook to a format readable by a Python-built web app.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#tool","title":"Tool","text":"<p>For this task, you need two tools: Flask and Pickle, both of which run on Python.</p> <p>\u2705 What's Flask? Defined as a 'micro-framework' by its creators, Flask provides the basic features of web frameworks using Python and a templating engine to build web pages. Take a look at this Learn module to practice building with Flask.</p> <p>\u2705 What's Pickle? Pickle \ud83e\udd52 is a Python module that serializes and de-serializes a Python object structure. When you 'pickle' a model, you serialize or flatten its structure for use on the web. Be careful: pickle is not intrinsically secure, so be careful if prompted to 'un-pickle' a file. A pickled file has the suffix <code>.pkl</code>.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#exercise-clean-your-data","title":"Exercise - clean your data","text":"<p>In this lesson you'll use data from 80,000 UFO sightings, gathered by NUFORC (The National UFO Reporting Center). This data has some interesting descriptions of UFO sightings, for example:</p> <ul> <li>Long example description. \"A man emerges from a beam of light that shines on a grassy field at night and he runs towards the Texas Instruments parking lot\".</li> <li>Short example description. \"the lights chased us\".</li> </ul> <p>The ufos.csv spreadsheet includes columns about the <code>city</code>, <code>state</code> and <code>country</code> where the sighting occurred, the object's <code>shape</code> and its <code>latitude</code> and <code>longitude</code>.</p> <p>In the blank notebook included in this lesson:</p> <ol> <li> <p>import <code>pandas</code>, <code>matplotlib</code>, and <code>numpy</code> as you did in previous lessons and import the ufos spreadsheet. You can take a look at a sample data set:</p> <pre><code>import pandas as pd\nimport numpy as np\n\nufos = pd.read_csv('./data/ufos.csv')\nufos.head()\n</code></pre> </li> <li> <p>Convert the ufos data to a small dataframe with fresh titles. Check the unique values in the <code>Country</code> field.</p> <pre><code>ufos = pd.DataFrame({'Seconds': ufos['duration (seconds)'], 'Country': ufos['country'],'Latitude': ufos['latitude'],'Longitude': ufos['longitude']})\n\nufos.Country.unique()\n</code></pre> </li> <li> <p>Now, you can reduce the amount of data we need to deal with by dropping any null values and only importing sightings between 1-60 seconds:</p> <pre><code>ufos.dropna(inplace=True)\n\nufos = ufos[(ufos['Seconds'] &gt;= 1) &amp; (ufos['Seconds'] &lt;= 60)]\n\nufos.info()\n</code></pre> </li> <li> <p>Import Scikit-learn's <code>LabelEncoder</code> library to convert the text values for countries to a number:</p> <p>\u2705 LabelEncoder encodes data alphabetically</p> <pre><code>from sklearn.preprocessing import LabelEncoder\n\nufos['Country'] = LabelEncoder().fit_transform(ufos['Country'])\n\nufos.head()\n</code></pre> <p>Your data should look like this:</p> <pre><code>    Seconds Country Latitude    Longitude\n2   20.0    3       53.200000   -2.916667\n3   20.0    4       28.978333   -96.645833\n14  30.0    4       35.823889   -80.253611\n23  60.0    4       45.582778   -122.352222\n24  3.0     3       51.783333   -0.783333\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/3-Web-App/#exercise-build-your-model","title":"Exercise - build your model","text":"<p>Now you can get ready to train a model by dividing the data into the training and testing group.</p> <ol> <li> <p>Select the three features you want to train on as your X vector, and the y vector will be the <code>Country</code>. You want to be able to input <code>Seconds</code>, <code>Latitude</code> and <code>Longitude</code> and get a country id to return.</p> <pre><code>from sklearn.model_selection import train_test_split\n\nSelected_features = ['Seconds','Latitude','Longitude']\n\nX = ufos[Selected_features]\ny = ufos['Country']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n</code></pre> </li> <li> <p>Train your model using logistic regression:</p> <pre><code>from sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\n\nprint(classification_report(y_test, predictions))\nprint('Predicted labels: ', predictions)\nprint('Accuracy: ', accuracy_score(y_test, predictions))\n</code></pre> </li> </ol> <p>The accuracy isn't bad (around 95%), unsurprisingly, as <code>Country</code> and <code>Latitude/Longitude</code> correlate.</p> <p>The model you created isn't very revolutionary as you should be able to infer a <code>Country</code> from its <code>Latitude</code> and <code>Longitude</code>, but it's a good exercise to try to train from raw data that you cleaned, exported, and then use this model in a web app.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#exercise-pickle-your-model","title":"Exercise - 'pickle' your model","text":"<p>Now, it's time to pickle your model! You can do that in a few lines of code. Once it's pickled, load your pickled model and test it against a sample data array containing values for seconds, latitude and longitude,</p> <pre><code>import pickle\nmodel_filename = 'ufo-model.pkl'\npickle.dump(model, open(model_filename,'wb'))\n\nmodel = pickle.load(open('ufo-model.pkl','rb'))\nprint(model.predict([[50,44,-12]]))\n</code></pre> <p>The model returns '3', which is the country code for the UK. Wild! \ud83d\udc7d</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#exercise-build-a-flask-app","title":"Exercise - build a Flask app","text":"<p>Now you can build a Flask app to call your model and return similar results, but in a more visually pleasing way.</p> <ol> <li> <p>Start by creating a folder called web-app next to the notebook.ipynb file where your ufo-model.pkl file resides.</p> </li> <li> <p>In that folder create three more folders: static, with a folder css inside it, and templates. You should now have the following files and directories:</p> <pre><code>web-app/\n  static/\n    css/\n  templates/\nnotebook.ipynb\nufo-model.pkl\n</code></pre> <p>\u2705 Refer to the solution folder for a view of the finished app</p> </li> <li> <p>The first file to create in web-app folder is requirements.txt file. Like package.json in a JavaScript app, this file lists dependencies required by the app. In requirements.txt add the lines:</p> <pre><code>scikit-learn\npandas\nnumpy\nflask\n</code></pre> </li> <li> <p>Now, run this file by navigating to web-app:</p> <pre><code>cd web-app\n</code></pre> </li> <li> <p>In your terminal type <code>pip install</code>, to install the libraries listed in requirements.txt:</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Now, you're ready to create three more files to finish the app:</p> <ol> <li>Create app.py in the root.</li> <li>Create index.html in templates directory.</li> <li>Create styles.css in static/css directory.</li> </ol> </li> <li> <p>Build out the styles.css file with a few styles:</p> <pre><code>body {\n    width: 100%;\n    height: 100%;\n    font-family: 'Helvetica';\n    background: black;\n    color: #fff;\n    text-align: center;\n    letter-spacing: 1.4px;\n    font-size: 30px;\n}\n\ninput {\n    min-width: 150px;\n}\n\n.grid {\n    width: 300px;\n    border: 1px solid #2d2d2d;\n    display: grid;\n    justify-content: center;\n    margin: 20px auto;\n}\n\n.box {\n    color: #fff;\n    background: #2d2d2d;\n    padding: 12px;\n    display: inline-block;\n}\n</code></pre> </li> <li> <p>Next, build out the index.html file:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;\ud83d\udef8 UFO Appearance Prediction! \ud83d\udc7d&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/styles.css') }}\"&gt;\n  &lt;/head&gt;\n\n  &lt;body&gt;\n    &lt;div class=\"grid\"&gt;\n\n      &lt;div class=\"box\"&gt;\n\n        &lt;p&gt;According to the number of seconds, latitude and longitude, which country is likely to have reported seeing a UFO?&lt;/p&gt;\n\n        &lt;form action=\"{{ url_for('predict')}}\" method=\"post\"&gt;\n          &lt;input type=\"number\" name=\"seconds\" placeholder=\"Seconds\" required=\"required\" min=\"0\" max=\"60\" /&gt;\n          &lt;input type=\"text\" name=\"latitude\" placeholder=\"Latitude\" required=\"required\" /&gt;\n          &lt;input type=\"text\" name=\"longitude\" placeholder=\"Longitude\" required=\"required\" /&gt;\n          &lt;button type=\"submit\" class=\"btn\"&gt;Predict country where the UFO is seen&lt;/button&gt;\n        &lt;/form&gt;\n\n        &lt;p&gt;{{ prediction_text }}&lt;/p&gt;\n\n      &lt;/div&gt;\n\n    &lt;/div&gt;\n\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Take a look at the templating in this file. Notice the 'mustache' syntax around variables that will be provided by the app, like the prediction text: <code>{{}}</code>. There's also a form that posts a prediction to the <code>/predict</code> route.</p> <p>Finally, you're ready to build the python file that drives the consumption of the model and the display of predictions:</p> </li> <li> <p>In <code>app.py</code> add:</p> <pre><code>import numpy as np\nfrom flask import Flask, request, render_template\nimport pickle\n\napp = Flask(__name__)\n\nmodel = pickle.load(open(\"./ufo-model.pkl\", \"rb\"))\n\n\n@app.route(\"/\")\ndef home():\n    return render_template(\"index.html\")\n\n\n@app.route(\"/predict\", methods=[\"POST\"])\ndef predict():\n\n    int_features = [int(x) for x in request.form.values()]\n    final_features = [np.array(int_features)]\n    prediction = model.predict(final_features)\n\n    output = prediction[0]\n\n    countries = [\"Australia\", \"Canada\", \"Germany\", \"UK\", \"US\"]\n\n    return render_template(\n        \"index.html\", prediction_text=\"Likely country: {}\".format(countries[output])\n    )\n\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n</code></pre> <p>\ud83d\udca1 Tip: when you add <code>debug=True</code> while running the web app using Flask, any changes you make to your application will be reflected immediately without the need to restart the server. Beware! Don't enable this mode in a production app.</p> </li> </ol> <p>If you run <code>python app.py</code> or <code>python3 app.py</code> - your web server starts up, locally, and you can fill out a short form to get an answer to your burning question about where UFOs have been sighted!</p> <p>Before doing that, take a look at the parts of <code>app.py</code>:</p> <ol> <li>First, dependencies are loaded and the app starts.</li> <li>Then, the model is imported.</li> <li>Then, index.html is rendered on the home route.</li> </ol> <p>On the <code>/predict</code> route, several things happen when the form is posted:</p> <ol> <li>The form variables are gathered and converted to a numpy array. They are then sent to the model and a prediction is returned.</li> <li>The Countries that we want displayed are re-rendered as readable text from their predicted country code, and that value is sent back to index.html to be rendered in the template.</li> </ol> <p>Using a model this way, with Flask and a pickled model, is relatively straightforward. The hardest thing is to understand what shape the data is that must be sent to the model to get a prediction. That all depends on how the model was trained. This one has three data points to be input in order to get a prediction.</p> <p>In a professional setting, you can see how good communication is necessary between the folks who train the model and those who consume it in a web or mobile app. In our case, it's only one person, you!</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Instead of working in a notebook and importing the model to the Flask app, you could train the model right within the Flask app! Try converting your Python code in the notebook, perhaps after your data is cleaned, to train the model from within the app on a route called <code>train</code>. What are the pros and cons of pursuing this method?</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/3-Web-App/#review-self-study","title":"Review &amp; Self Study","text":"<p>There are many ways to build a web app to consume ML models. Make a list of the ways you could use JavaScript or Python to build a web app to leverage machine learning. Consider architecture: should the model stay in the app or live in the cloud? If the latter, how would you access it? Draw out an architectural model for an applied ML web solution.</p>"},{"location":"curricula/ml-for-beginners/3-Web-App/#assignment","title":"Assignment","text":"<p>Try a different model</p>"},{"location":"curricula/ml-for-beginners/4-Classification/","title":"Classification","text":""},{"location":"curricula/ml-for-beginners/4-Classification/#getting-started-with-classification","title":"Getting started with classification","text":""},{"location":"curricula/ml-for-beginners/4-Classification/#regional-topic-delicious-asian-and-indian-cuisines","title":"Regional topic: Delicious Asian and Indian Cuisines \ud83c\udf5c","text":"<p>In Asia and India, food traditions are extremely diverse, and very delicious! Let's look at data about regional cuisines to try to understand their ingredients.</p> <p></p> <p>Photo by Lisheng Chang on Unsplash</p>"},{"location":"curricula/ml-for-beginners/4-Classification/#what-you-will-learn","title":"What you will learn","text":"<p>In this section, you will build on your earlier study of Regression and learn about other classifiers that you can use to better understand the data.</p> <p>There are useful low-code tools that can help you learn about working with classification models. Try Azure ML for this task</p>"},{"location":"curricula/ml-for-beginners/4-Classification/#lessons","title":"Lessons","text":"<ol> <li>Introduction to classification</li> <li>More classifiers</li> <li>Yet other classifiers</li> <li>Applied ML: build a web app</li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/#credits","title":"Credits","text":"<p>\"Getting started with classification\" was written with \u2665\ufe0f by Cassie Breviu and Jen Looper</p> <p>The delicious cuisines dataset was sourced from Kaggle.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/","title":"Introduction","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#introduction-to-classification","title":"Introduction to classification","text":"<p>In these four lessons, you will explore a fundamental focus of classic machine learning - classification. We will walk through using various classification algorithms with a dataset about all the brilliant cuisines of Asia and India. Hope you're hungry!</p> <p></p> <p>Celebrate pan-Asian cuisines in these lessons! Image by Jen Looper</p> <p>Classification is a form of supervised learning that bears a lot in common with regression techniques. If machine learning is all about predicting values or names to things by using datasets, then classification generally falls into two groups: binary classification and multiclass classification.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: MIT's John Guttag introduces classification</p> <p>Remember:</p> <ul> <li>Linear regression helped you predict relationships between variables and make accurate predictions on where a new datapoint would fall in relationship to that line. So, you could predict what price a pumpkin would be in September vs. December, for example.</li> <li>Logistic regression helped you discover \"binary categories\": at this price point, is this pumpkin orange or not-orange?</li> </ul> <p>Classification uses various algorithms to determine other ways of determining a data point's label or class. Let's work with this cuisine data to see whether, by observing a group of ingredients, we can determine its cuisine of origin.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#this-lesson-is-available-in-r","title":"This lesson is available in R!","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#introduction","title":"Introduction","text":"<p>Classification is one of the fundamental activities of the machine learning researcher and data scientist. From basic classification of a binary value (\"is this email spam or not?\"), to complex image classification and segmentation using computer vision, it's always useful to be able to sort data into classes and ask questions of it.</p> <p>To state the process in a more scientific way, your classification method creates a predictive model that enables you to map the relationship between input variables to output variables.</p> <p></p> <p>Binary vs. multiclass problems for classification algorithms to handle. Infographic by Jen Looper</p> <p>Before starting the process of cleaning our data, visualizing it, and prepping it for our ML tasks, let's learn a bit about the various ways machine learning can be leveraged to classify data.</p> <p>Derived from statistics, classification using classic machine learning uses features, such as <code>smoker</code>, <code>weight</code>, and <code>age</code> to determine likelihood of developing X disease. As a supervised learning technique similar to the regression exercises you performed earlier, your data is labeled and the ML algorithms use those labels to classify and predict classes (or 'features') of a dataset and assign them to a group or outcome.</p> <p>\u2705 Take a moment to imagine a dataset about cuisines. What would a multiclass model be able to answer? What would a binary model be able to answer? What if you wanted to determine whether a given cuisine was likely to use fenugreek? What if you wanted to see if, given a present of a grocery bag full of star anise, artichokes, cauliflower, and horseradish, you could create a typical Indian dish?</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video.The whole premise of the show 'Chopped' is the 'mystery basket' where chefs have to make some dish out of a random choice of ingredients. Surely a ML model would have helped!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#hello-classifier","title":"Hello 'classifier'","text":"<p>The question we want to ask of this cuisine dataset is actually a multiclass question, as we have several potential national cuisines to work with. Given a batch of ingredients, which of these many classes will the data fit?</p> <p>Scikit-learn offers several different algorithms to use to classify data, depending on the kind of problem you want to solve. In the next two lessons, you'll learn about several of these algorithms.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#exercise-clean-and-balance-your-data","title":"Exercise - clean and balance your data","text":"<p>The first task at hand, before starting this project, is to clean and balance your data to get better results. Start with the blank notebook.ipynb file in the root of this folder.</p> <p>The first thing to install is imblearn. This is a Scikit-learn package that will allow you to better balance the data (you will learn more about this task in a minute).</p> <ol> <li> <p>To install <code>imblearn</code>, run <code>pip install</code>, like so:</p> <pre><code>pip install imblearn\n</code></pre> </li> <li> <p>Import the packages you need to import your data and visualize it, also import <code>SMOTE</code> from <code>imblearn</code>.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\n</code></pre> <p>Now you are set up to read import the data next.</p> </li> <li> <p>The next task will be to import the data:</p> <pre><code>df  = pd.read_csv('../data/cuisines.csv')\n</code></pre> </li> </ol> <p>Using <code>read_csv()</code> will read the content of the csv file cusines.csv and place it in the variable <code>df</code>.</p> <ol> <li> <p>Check the data's shape:</p> <pre><code>df.head()\n</code></pre> </li> </ol> <p>The first five rows look like this:</p> <pre><code>```output\n|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |\n| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |\n| 0   | 65         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |\n| 1   | 66         | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |\n| 2   | 67         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |\n| 3   | 68         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |\n| 4   | 69         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |\n```\n</code></pre> <ol> <li> <p>Get info about this data by calling <code>info()</code>:</p> <pre><code>df.info()\n</code></pre> <p>Your out resembles:</p> <pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2448 entries, 0 to 2447\nColumns: 385 entries, Unnamed: 0 to zucchini\ndtypes: int64(384), object(1)\nmemory usage: 7.2+ MB\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#exercise-learning-about-cuisines","title":"Exercise - learning about cuisines","text":"<p>Now the work starts to become more interesting. Let's discover the distribution of data, per cuisine </p> <ol> <li> <p>Plot the data as bars by calling <code>barh()</code>:</p> <pre><code>df.cuisine.value_counts().plot.barh()\n</code></pre> <p></p> <p>There are a finite number of cuisines, but the distribution of data is uneven. You can fix that! Before doing so, explore a little more. </p> </li> <li> <p>Find out how much data is available per cuisine and print it out:</p> <pre><code>thai_df = df[(df.cuisine == \"thai\")]\njapanese_df = df[(df.cuisine == \"japanese\")]\nchinese_df = df[(df.cuisine == \"chinese\")]\nindian_df = df[(df.cuisine == \"indian\")]\nkorean_df = df[(df.cuisine == \"korean\")]\n\nprint(f'thai df: {thai_df.shape}')\nprint(f'japanese df: {japanese_df.shape}')\nprint(f'chinese df: {chinese_df.shape}')\nprint(f'indian df: {indian_df.shape}')\nprint(f'korean df: {korean_df.shape}')\n</code></pre> <p>the output looks like so:</p> <pre><code>thai df: (289, 385)\njapanese df: (320, 385)\nchinese df: (442, 385)\nindian df: (598, 385)\nkorean df: (799, 385)\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#discovering-ingredients","title":"Discovering ingredients","text":"<p>Now you can dig deeper into the data and learn what are the typical ingredients per cuisine. You should clean out recurrent data that creates confusion between cuisines, so let's learn about this problem.</p> <ol> <li> <p>Create a function <code>create_ingredient()</code> in Python to create an ingredient dataframe. This function will start by dropping an unhelpful column and sort through ingredients by their count:</p> <pre><code>def create_ingredient_df(df):\n    ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')\n    ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]\n    ingredient_df = ingredient_df.sort_values(by='value', ascending=False,\n    inplace=False)\n    return ingredient_df\n</code></pre> </li> </ol> <p>Now you can use that function to get an idea of top ten most popular ingredients by cuisine.</p> <ol> <li> <p>Call <code>create_ingredient()</code> and plot it calling <code>barh()</code>:</p> <pre><code>thai_ingredient_df = create_ingredient_df(thai_df)\nthai_ingredient_df.head(10).plot.barh()\n</code></pre> <p></p> </li> <li> <p>Do the same for the japanese data:</p> <pre><code>japanese_ingredient_df = create_ingredient_df(japanese_df)\njapanese_ingredient_df.head(10).plot.barh()\n</code></pre> <p></p> </li> <li> <p>Now for the chinese ingredients:</p> <pre><code>chinese_ingredient_df = create_ingredient_df(chinese_df)\nchinese_ingredient_df.head(10).plot.barh()\n</code></pre> <p></p> </li> <li> <p>Plot the indian ingredients:</p> <pre><code>indian_ingredient_df = create_ingredient_df(indian_df)\nindian_ingredient_df.head(10).plot.barh()\n</code></pre> <p></p> </li> <li> <p>Finally, plot the korean ingredients:</p> <pre><code>korean_ingredient_df = create_ingredient_df(korean_df)\nkorean_ingredient_df.head(10).plot.barh()\n</code></pre> <p></p> </li> <li> <p>Now, drop the most common ingredients that create confusion between distinct cuisines, by calling <code>drop()</code>: </p> </li> </ol> <p>Everyone loves rice, garlic and ginger!</p> <pre><code>```python\nfeature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)\nlabels_df = df.cuisine #.unique()\nfeature_df.head()\n```\n</code></pre>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#balance-the-dataset","title":"Balance the dataset","text":"<p>Now that you have cleaned the data, use SMOTE - \"Synthetic Minority Over-sampling Technique\" - to balance it.</p> <ol> <li> <p>Call <code>fit_resample()</code>, this strategy generates new samples by interpolation.</p> <pre><code>oversample = SMOTE()\ntransformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)\n</code></pre> <p>By balancing your data, you'll have better results when classifying it. Think about a binary classification. If most of your data is one class, a ML model is going to predict that class more frequently, just because there is more data for it. Balancing the data takes any skewed data and helps remove this imbalance. </p> </li> <li> <p>Now you can check the numbers of labels per ingredient:</p> <pre><code>print(f'new label count: {transformed_label_df.value_counts()}')\nprint(f'old label count: {df.cuisine.value_counts()}')\n</code></pre> <p>Your output looks like so:</p> <pre><code>new label count: korean      799\nchinese     799\nindian      799\njapanese    799\nthai        799\nName: cuisine, dtype: int64\nold label count: korean      799\nindian      598\nchinese     442\njapanese    320\nthai        289\nName: cuisine, dtype: int64\n</code></pre> <p>The data is nice and clean, balanced, and very delicious! </p> </li> <li> <p>The last step is to save your balanced data, including labels and features, into a new dataframe that can be exported into a file:</p> <pre><code>transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')\n</code></pre> </li> <li> <p>You can take one more look at the data using <code>transformed_df.head()</code> and <code>transformed_df.info()</code>. Save a copy of this data for use in future lessons:</p> <pre><code>transformed_df.head()\ntransformed_df.info()\ntransformed_df.to_csv(\"../data/cleaned_cuisines.csv\")\n</code></pre> <p>This fresh CSV can now be found in the root data folder.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#challenge","title":"\ud83d\ude80Challenge","text":"<p>This curriculum contains several interesting datasets. Dig through the <code>data</code> folders and see if any contain datasets that would be appropriate for binary or multi-class classification? What questions would you ask of this dataset?</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#review-self-study","title":"Review &amp; Self Study","text":"<p>Explore SMOTE's API. What use cases is it best used for? What problems does it solve?</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/#assignment","title":"Assignment","text":"<p>Explore classification methods</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/assignment/#explore-classification-methods","title":"Explore classification methods","text":""},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/assignment/#instructions","title":"Instructions","text":"<p>In Scikit-learn documentation you'll find a large list of ways to classify data. Do a little scavenger hunt in these docs: your goals is to look for classification methods and match a dataset in this curriculum, a question you can ask of it, and a technique of classification. Create a spreadsheet or table in a .doc file and explain how the dataset would work with the classification algorithm.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement a document is presented overviewing 5 algorithms alongside a classification technique. The overview is well-explained and detailed. a document is presented overviewing 3 algorithms alongside a classification technique. The overview is well-explained and detailed. a document is presented overviewing fewer than three algorithms alongside a classification technique and the overview is neither well-explained nor detailed."},{"location":"curricula/ml-for-beginners/4-Classification/1-Introduction/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/","title":"Classifiers 1","text":""},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#cuisine-classifiers-1","title":"Cuisine classifiers 1","text":"<p>In this lesson, you will use the dataset you saved from the last lesson full of balanced, clean data all about cuisines.</p> <p>You will use this dataset with a variety of classifiers to predict a given national cuisine based on a group of ingredients. While doing so, you'll learn more about some of the ways that algorithms can be leveraged for classification tasks.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#preparation","title":"Preparation","text":"<p>Assuming you completed Lesson 1, make sure that a cleaned_cuisines.csv file exists in the root <code>/data</code> folder for these four lessons.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#exercise-predict-a-national-cuisine","title":"Exercise - predict a national cuisine","text":"<ol> <li> <p>Working in this lesson's notebook.ipynb folder, import that file along with the Pandas library:</p> <pre><code>import pandas as pd\ncuisines_df = pd.read_csv(\"../data/cleaned_cuisines.csv\")\ncuisines_df.head()\n</code></pre> <p>The data looks like this:</p> </li> </ol> Unnamed: 0 cuisine almond angelica anise anise_seed apple apple_brandy apricot armagnac ... whiskey white_bread white_wine whole_grain_wheat_flour wine wood yam yeast yogurt zucchini 0 0 indian 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 1 1 indian 1 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 2 indian 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 3 3 indian 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 4 indian 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 1 0 <ol> <li> <p>Now, import several more libraries:</p> <pre><code>from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\nfrom sklearn.svm import SVC\nimport numpy as np\n</code></pre> </li> <li> <p>Divide the X and y coordinates into two dataframes for training. <code>cuisine</code> can be the labels dataframe:</p> <pre><code>cuisines_label_df = cuisines_df['cuisine']\ncuisines_label_df.head()\n</code></pre> <p>It will look like this:</p> <pre><code>0    indian\n1    indian\n2    indian\n3    indian\n4    indian\nName: cuisine, dtype: object\n</code></pre> </li> <li> <p>Drop that <code>Unnamed: 0</code> column and the <code>cuisine</code> column, calling <code>drop()</code>. Save the rest of the data as trainable features:</p> <pre><code>cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)\ncuisines_feature_df.head()\n</code></pre> <p>Your features look like this:</p> </li> </ol> almond angelica anise anise_seed apple apple_brandy apricot armagnac artemisia artichoke ... whiskey white_bread white_wine whole_grain_wheat_flour wine wood yam yeast yogurt zucchini 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 1 0 <p>Now you are ready to train your model!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#choosing-your-classifier","title":"Choosing your classifier","text":"<p>Now that your data is clean and ready for training, you have to decide which algorithm to use for the job. </p> <p>Scikit-learn groups classification under Supervised Learning, and in that category you will find many ways to classify. The variety is quite bewildering at first sight. The following methods all include classification techniques:</p> <ul> <li>Linear Models</li> <li>Support Vector Machines</li> <li>Stochastic Gradient Descent</li> <li>Nearest Neighbors</li> <li>Gaussian Processes</li> <li>Decision Trees</li> <li>Ensemble methods (voting Classifier)</li> <li>Multiclass and multioutput algorithms (multiclass and multilabel classification, multiclass-multioutput classification)</li> </ul> <p>You can also use neural networks to classify data, but that is outside the scope of this lesson.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#what-classifier-to-go-with","title":"What classifier to go with?","text":"<p>So, which classifier should you choose? Often, running through several and looking for a good result is a way to test. Scikit-learn offers a side-by-side comparison on a created dataset, comparing KNeighbors, SVC two ways, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB and QuadraticDiscrinationAnalysis, showing the results visualized: </p> <p></p> <p>Plots generated on Scikit-learn's documentation</p> <p>AutoML solves this problem neatly by running these comparisons in the cloud, allowing you to choose the best algorithm for your data. Try it here</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#a-better-approach","title":"A better approach","text":"<p>A better way than wildly guessing, however, is to follow the ideas on this downloadable ML Cheat sheet. Here, we discover that, for our multiclass problem, we have some choices:</p> <p></p> <p>A section of Microsoft's Algorithm Cheat Sheet, detailing multiclass classification options</p> <p>\u2705 Download this cheat sheet, print it out, and hang it on your wall!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#reasoning","title":"Reasoning","text":"<p>Let's see if we can reason our way through different approaches given the constraints we have:</p> <ul> <li>Neural networks are too heavy. Given our clean, but minimal dataset, and the fact that we are running training locally via notebooks, neural networks are too heavyweight for this task.</li> <li>No two-class classifier. We do not use a two-class classifier, so that rules out one-vs-all. </li> <li>Decision tree or logistic regression could work. A decision tree might work, or logistic regression for multiclass data. </li> <li>Multiclass Boosted Decision Trees solve a different problem. The multiclass boosted decision tree is most suitable for nonparametric tasks, e.g. tasks designed to build rankings, so it is not useful for us.</li> </ul>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#using-scikit-learn","title":"Using Scikit-learn","text":"<p>We will be using Scikit-learn to analyze our data. However, there are many ways to use logistic regression in Scikit-learn. Take a look at the parameters to pass.  </p> <p>Essentially there are two important parameters - <code>multi_class</code> and <code>solver</code> - that we need to specify, when we ask Scikit-learn to perform a logistic regression. The <code>multi_class</code> value applies a certain behavior. The value of the solver is what algorithm to use. Not all solvers can be paired with all <code>multi_class</code> values.</p> <p>According to the docs, in the multiclass case, the training algorithm:</p> <ul> <li>Uses the one-vs-rest (OvR) scheme, if the <code>multi_class</code> option is set to <code>ovr</code></li> <li>Uses the cross-entropy loss, if the <code>multi_class</code> option is set to <code>multinomial</code>. (Currently the <code>multinomial</code> option is supported only by the \u2018lbfgs\u2019, \u2018sag\u2019, \u2018saga\u2019 and \u2018newton-cg\u2019 solvers.)\"</li> </ul> <p>\ud83c\udf93 The 'scheme' here can either be 'ovr' (one-vs-rest) or 'multinomial'. Since logistic regression is really designed to support binary classification, these schemes allow it to better handle multiclass classification tasks. source</p> <p>\ud83c\udf93 The 'solver' is defined as \"the algorithm to use in the optimization problem\". source.</p> <p>Scikit-learn offers this table to explain how solvers handle different challenges presented by different kinds of data structures:</p> <p></p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#exercise-split-the-data","title":"Exercise - split the data","text":"<p>We can focus on logistic regression for our first training trial since you recently learned about the latter in a previous lesson. Split your data into training and testing groups by calling <code>train_test_split()</code>:</p> <pre><code>X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)\n</code></pre>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#exercise-apply-logistic-regression","title":"Exercise - apply logistic regression","text":"<p>Since you are using the multiclass case, you need to choose what scheme to use and what solver to set. Use LogisticRegression with a multiclass setting and the liblinear solver to train.</p> <ol> <li> <p>Create a logistic regression with multi_class set to <code>ovr</code> and the solver set to <code>liblinear</code>:</p> <pre><code>lr = LogisticRegression(multi_class='ovr',solver='liblinear')\nmodel = lr.fit(X_train, np.ravel(y_train))\n\naccuracy = model.score(X_test, y_test)\nprint (\"Accuracy is {}\".format(accuracy))\n</code></pre> <p>\u2705 Try a different solver like <code>lbfgs</code>, which is often set as default</p> <p>Note, use Pandas <code>ravel</code> function to flatten your data when needed.</p> <p>The accuracy is good at over 80%!</p> </li> <li> <p>You can see this model in action by testing one row of data (#50):</p> <pre><code>print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')\nprint(f'cuisine: {y_test.iloc[50]}')\n</code></pre> <p>The result is printed:</p> </li> </ol> <pre><code>ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')\ncuisine: indian\n</code></pre> <p>\u2705 Try a different row number and check the results</p> <ol> <li> <p>Digging deeper, you can check for the accuracy of this prediction:</p> <pre><code>test= X_test.iloc[50].values.reshape(-1, 1).T\nproba = model.predict_proba(test)\nclasses = model.classes_\nresultdf = pd.DataFrame(data=proba, columns=classes)\n\ntopPrediction = resultdf.T.sort_values(by=[0], ascending = [False])\ntopPrediction.head()\n</code></pre> <p>The result is printed - Indian cuisine is its best guess, with good probability:</p> 0 indian 0.715851 chinese 0.229475 japanese 0.029763 korean 0.017277 thai 0.007634 <p>\u2705 Can you explain why the model is pretty sure this is an Indian cuisine?</p> </li> <li> <p>Get more detail by printing a classification report, as you did in the regression lessons:</p> <pre><code>y_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred))\n</code></pre> precision recall f1-score support chinese 0.73 0.71 0.72 229 indian 0.91 0.93 0.92 254 japanese 0.70 0.75 0.72 220 korean 0.86 0.76 0.81 242 thai 0.79 0.85 0.82 254 accuracy 0.80 1199 macro avg 0.80 0.80 0.80 1199 weighted avg 0.80 0.80 0.80 1199 </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#challenge","title":"\ud83d\ude80Challenge","text":"<p>In this lesson, you used your cleaned data to build a machine learning model that can predict a national cuisine based on a series of ingredients. Take some time to read through the many options Scikit-learn provides to classify data. Dig deeper into the concept of 'solver' to understand what goes on behind the scenes.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#review-self-study","title":"Review &amp; Self Study","text":"<p>Dig a little more into the math behind logistic regression in this lesson</p>"},{"location":"curricula/ml-for-beginners/4-Classification/2-Classifiers-1/#assignment","title":"Assignment","text":"<p>Study the solvers</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/","title":"Classifiers 2","text":""},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#cuisine-classifiers-2","title":"Cuisine classifiers 2","text":"<p>In this second classification lesson, you will explore more ways to classify numeric data. You will also learn about the ramifications for choosing one classifier over the other.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#prerequisite","title":"Prerequisite","text":"<p>We assume that you have completed the previous lessons and have a cleaned dataset in your <code>data</code> folder called cleaned_cuisines.csv in the root of this 4-lesson folder.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#preparation","title":"Preparation","text":"<p>We have loaded your notebook.ipynb file with the cleaned dataset and have divided it into X and y dataframes, ready for the model building process.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#a-classification-map","title":"A classification map","text":"<p>Previously, you learned about the various options you have when classifying data using Microsoft's cheat sheet. Scikit-learn offers a similar, but more granular cheat sheet that can further help narrow down your estimators (another term for classifiers):</p> <p></p> <p>Tip: visit this map online and click along the path to read documentation.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#the-plan","title":"The plan","text":"<p>This map is very helpful once you have a clear grasp of your data, as you can 'walk' along its paths to a decision:</p> <ul> <li>We have &gt;50 samples</li> <li>We want to predict a category</li> <li>We have labeled data</li> <li>We have fewer than 100K samples</li> <li>\u2728 We can choose a Linear SVC</li> <li>If that doesn't work, since we have numeric data<ul> <li>We can try a \u2728 KNeighbors Classifier </li> <li>If that doesn't work, try \u2728 SVC and \u2728 Ensemble Classifiers</li> </ul> </li> </ul> <p>This is a very helpful trail to follow.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#exercise-split-the-data","title":"Exercise - split the data","text":"<p>Following this path, we should start by importing some libraries to use.</p> <ol> <li> <p>Import the needed libraries:</p> <pre><code>from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\nimport numpy as np\n</code></pre> </li> <li> <p>Split your training and test data:</p> <pre><code>X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#linear-svc-classifier","title":"Linear SVC classifier","text":"<p>Support-Vector clustering (SVC) is a child of the Support-Vector machines family of ML techniques (learn more about these below). In this method, you can choose a 'kernel' to decide how to cluster the labels. The 'C' parameter refers to 'regularization' which regulates the influence of parameters. The kernel can be one of several; here we set it to 'linear' to ensure that we leverage linear SVC. Probability defaults to 'false'; here we set it to 'true' to gather probability estimates. We set the random state to '0' to shuffle the data to get probabilities.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#exercise-apply-a-linear-svc","title":"Exercise - apply a linear SVC","text":"<p>Start by creating an array of classifiers. You will add progressively to this array as we test. </p> <ol> <li> <p>Start with a Linear SVC:</p> <pre><code>C = 10\n# Create different classifiers.\nclassifiers = {\n    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)\n}\n</code></pre> </li> <li> <p>Train your model using the Linear SVC and print out a report:</p> <pre><code>n_classifiers = len(classifiers)\n\nfor index, (name, classifier) in enumerate(classifiers.items()):\n    classifier.fit(X_train, np.ravel(y_train))\n\n    y_pred = classifier.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n    print(classification_report(y_test,y_pred))\n</code></pre> <p>The result is pretty good:</p> <pre><code>Accuracy (train) for Linear SVC: 78.6% \n              precision    recall  f1-score   support\n\n     chinese       0.71      0.67      0.69       242\n      indian       0.88      0.86      0.87       234\n    japanese       0.79      0.74      0.76       254\n      korean       0.85      0.81      0.83       242\n        thai       0.71      0.86      0.78       227\n\n    accuracy                           0.79      1199\n   macro avg       0.79      0.79      0.79      1199\nweighted avg       0.79      0.79      0.79      1199\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#k-neighbors-classifier","title":"K-Neighbors classifier","text":"<p>K-Neighbors is part of the \"neighbors\" family of ML methods, which can be used for both supervised and unsupervised learning. In this method, a predefined number of points is created and data are gathered around these points such that generalized labels can be predicted for the data.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#exercise-apply-the-k-neighbors-classifier","title":"Exercise - apply the K-Neighbors classifier","text":"<p>The previous classifier was good, and worked well with the data, but maybe we can get better accuracy. Try a K-Neighbors classifier.</p> <ol> <li> <p>Add a line to your classifier array (add a comma after the Linear SVC item):</p> <pre><code>'KNN classifier': KNeighborsClassifier(C),\n</code></pre> <p>The result is a little worse:</p> <pre><code>Accuracy (train) for KNN classifier: 73.8% \n              precision    recall  f1-score   support\n\n     chinese       0.64      0.67      0.66       242\n      indian       0.86      0.78      0.82       234\n    japanese       0.66      0.83      0.74       254\n      korean       0.94      0.58      0.72       242\n        thai       0.71      0.82      0.76       227\n\n    accuracy                           0.74      1199\n   macro avg       0.76      0.74      0.74      1199\nweighted avg       0.76      0.74      0.74      1199\n</code></pre> <p>\u2705 Learn about K-Neighbors</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#support-vector-classifier","title":"Support Vector Classifier","text":"<p>Support-Vector classifiers are part of the Support-Vector Machine family of ML methods that are used for classification and regression tasks. SVMs \"map training examples to points in space\" to maximize the distance between two categories. Subsequent data is mapped into this space so their category can be predicted.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#exercise-apply-a-support-vector-classifier","title":"Exercise - apply a Support Vector Classifier","text":"<p>Let's try for a little better accuracy with a Support Vector Classifier.</p> <ol> <li> <p>Add a comma after the K-Neighbors item, and then add this line:</p> <pre><code>'SVC': SVC(),\n</code></pre> <p>The result is quite good!</p> <pre><code>Accuracy (train) for SVC: 83.2% \n              precision    recall  f1-score   support\n\n     chinese       0.79      0.74      0.76       242\n      indian       0.88      0.90      0.89       234\n    japanese       0.87      0.81      0.84       254\n      korean       0.91      0.82      0.86       242\n        thai       0.74      0.90      0.81       227\n\n    accuracy                           0.83      1199\n   macro avg       0.84      0.83      0.83      1199\nweighted avg       0.84      0.83      0.83      1199\n</code></pre> <p>\u2705 Learn about Support-Vectors</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#ensemble-classifiers","title":"Ensemble Classifiers","text":"<p>Let's follow the path to the very end, even though the previous test was quite good. Let's try some 'Ensemble Classifiers, specifically Random Forest and AdaBoost:</p> <pre><code>  'RFST': RandomForestClassifier(n_estimators=100),\n  'ADA': AdaBoostClassifier(n_estimators=100)\n</code></pre> <p>The result is very good, especially for Random Forest:</p> <pre><code>Accuracy (train) for RFST: 84.5% \n              precision    recall  f1-score   support\n\n     chinese       0.80      0.77      0.78       242\n      indian       0.89      0.92      0.90       234\n    japanese       0.86      0.84      0.85       254\n      korean       0.88      0.83      0.85       242\n        thai       0.80      0.87      0.83       227\n\n    accuracy                           0.84      1199\n   macro avg       0.85      0.85      0.84      1199\nweighted avg       0.85      0.84      0.84      1199\n\nAccuracy (train) for ADA: 72.4% \n              precision    recall  f1-score   support\n\n     chinese       0.64      0.49      0.56       242\n      indian       0.91      0.83      0.87       234\n    japanese       0.68      0.69      0.69       254\n      korean       0.73      0.79      0.76       242\n        thai       0.67      0.83      0.74       227\n\n    accuracy                           0.72      1199\n   macro avg       0.73      0.73      0.72      1199\nweighted avg       0.73      0.72      0.72      1199\n</code></pre> <p>\u2705 Learn about Ensemble Classifiers</p> <p>This method of Machine Learning \"combines the predictions of several base estimators\" to improve the model's quality. In our example, we used Random Trees and AdaBoost. </p> <ul> <li> <p>Random Forest, an averaging method, builds a 'forest' of 'decision trees' infused with randomness to avoid overfitting. The n_estimators parameter is set to the number of trees.</p> </li> <li> <p>AdaBoost fits a classifier to a dataset and then fits copies of that classifier to the same dataset. It focuses on the weights of incorrectly classified items and adjusts the fit for the next classifier to correct.</p> </li> </ul>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Each of these techniques has a large number of parameters that you can tweak. Research each one's default parameters and think about what tweaking these parameters would mean for the model's quality.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#review-self-study","title":"Review &amp; Self Study","text":"<p>There's a lot of jargon in these lessons, so take a minute to review this list of useful terminology!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/3-Classifiers-2/#assignment","title":"Assignment","text":"<p>Parameter play</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/","title":"Applied","text":""},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#build-a-cuisine-recommender-web-app","title":"Build a Cuisine Recommender Web App","text":"<p>In this lesson, you will build a classification model using some of the techniques you have learned in previous lessons and with the delicious cuisine dataset used throughout this series. In addition, you will build a small web app to use a saved model, leveraging Onnx's web runtime.</p> <p>One of the most useful practical uses of machine learning is building recommendation systems, and you can take the first step in that direction today!</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Jen Looper builds a web app using classified cuisine data</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In this lesson you will learn:</p> <ul> <li>How to build a model and save it as an Onnx model</li> <li>How to use Netron to inspect the model</li> <li>How to use your model in a web app for inference</li> </ul>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#build-your-model","title":"Build your model","text":"<p>Building applied ML systems is an important part of leveraging these technologies for your business systems. You can use models within your web applications (and thus use them in an offline context if needed) by using Onnx.</p> <p>In a previous lesson, you built a Regression model about UFO sightings, \"pickled\" it, and used it in a Flask app. While this architecture is very useful to know, it is a full-stack Python app, and your requirements may include the use of a JavaScript application. </p> <p>In this lesson, you can build a basic JavaScript-based system for inference. First, however, you need to train a model and convert it for use with Onnx.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#exercise-train-classification-model","title":"Exercise - train classification model","text":"<p>First, train a classification model using the cleaned cuisines dataset we used. </p> <ol> <li> <p>Start by importing useful libraries:</p> <pre><code>!pip install skl2onnx\nimport pandas as pd \n</code></pre> <p>You need 'skl2onnx' to help convert your Scikit-learn model to Onnx format.</p> </li> <li> <p>Then, work with your data in the same way you did in previous lessons, by reading a CSV file using <code>read_csv()</code>:</p> <pre><code>data = pd.read_csv('../data/cleaned_cuisines.csv')\ndata.head()\n</code></pre> </li> <li> <p>Remove the first two unnecessary columns and save the remaining data as 'X':</p> <pre><code>X = data.iloc[:,2:]\nX.head()\n</code></pre> </li> <li> <p>Save the labels as 'y':</p> <pre><code>y = data[['cuisine']]\ny.head()\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#commence-the-training-routine","title":"Commence the training routine","text":"<p>We will use the 'SVC' library which has good accuracy.</p> <ol> <li> <p>Import the appropriate libraries from Scikit-learn:</p> <pre><code>from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report\n</code></pre> </li> <li> <p>Separate training and test sets:</p> <pre><code>X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n</code></pre> </li> <li> <p>Build an SVC Classification model as you did in the previous lesson:</p> <pre><code>model = SVC(kernel='linear', C=10, probability=True,random_state=0)\nmodel.fit(X_train,y_train.values.ravel())\n</code></pre> </li> <li> <p>Now, test your model, calling <code>predict()</code>:</p> <pre><code>y_pred = model.predict(X_test)\n</code></pre> </li> <li> <p>Print out a classification report to check the model's quality:</p> <pre><code>print(classification_report(y_test,y_pred))\n</code></pre> <p>As we saw before, the accuracy is good:</p> <pre><code>                precision    recall  f1-score   support\n\n     chinese       0.72      0.69      0.70       257\n      indian       0.91      0.87      0.89       243\n    japanese       0.79      0.77      0.78       239\n      korean       0.83      0.79      0.81       236\n        thai       0.72      0.84      0.78       224\n\n    accuracy                           0.79      1199\n   macro avg       0.79      0.79      0.79      1199\nweighted avg       0.79      0.79      0.79      1199\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#convert-your-model-to-onnx","title":"Convert your model to Onnx","text":"<p>Make sure to do the conversion with the proper Tensor number. This dataset has 380 ingredients listed, so you need to notate that number in <code>FloatTensorType</code>:</p> <ol> <li> <p>Convert using a tensor number of 380.</p> <pre><code>from skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\n\ninitial_type = [('float_input', FloatTensorType([None, 380]))]\noptions = {id(model): {'nocl': True, 'zipmap': False}}\n</code></pre> </li> <li> <p>Create the onx and store as a file model.onnx:</p> <pre><code>onx = convert_sklearn(model, initial_types=initial_type, options=options)\nwith open(\"./model.onnx\", \"wb\") as f:\n    f.write(onx.SerializeToString())\n</code></pre> <p>Note, you can pass in options in your conversion script. In this case, we passed in 'nocl' to be True and 'zipmap' to be False. Since this is a classification model, you have the option to remove ZipMap which produces a list of dictionaries (not necessary). <code>nocl</code> refers to class information being included in the model. Reduce your model's size by setting <code>nocl</code> to 'True'. </p> </li> </ol> <p>Running the entire notebook will now build an Onnx model and save it to this folder.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#view-your-model","title":"View your model","text":"<p>Onnx models are not very visible in Visual Studio code, but there's a very good free software that many researchers use to visualize the model to ensure that it is properly built. Download Netron and  open your model.onnx file. You can see your simple model visualized, with its 380 inputs and classifier listed:</p> <p></p> <p>Netron is a helpful tool to view your models.</p> <p>Now you are ready to use this neat model in a web app. Let's build an app that will come in handy when you look in your refrigerator and try to figure out which combination of your leftover ingredients you can use to cook a given cuisine, as determined by your model.</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#build-a-recommender-web-application","title":"Build a recommender web application","text":"<p>You can use your model directly in a web app. This architecture also allows you to run it locally and even offline if needed. Start by creating an <code>index.html</code> file in the same folder where you stored your <code>model.onnx</code> file.</p> <ol> <li> <p>In this file index.html, add the following markup:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n    &lt;header&gt;\n        &lt;title&gt;Cuisine Matcher&lt;/title&gt;\n    &lt;/header&gt;\n    &lt;body&gt;\n        ...\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> </li> <li> <p>Now, working within the <code>body</code> tags, add a little markup to show a list of checkboxes reflecting some ingredients:</p> <pre><code>&lt;h1&gt;Check your refrigerator. What can you create?&lt;/h1&gt;\n        &lt;div id=\"wrapper\"&gt;\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"4\" class=\"checkbox\"&gt;\n                &lt;label&gt;apple&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"247\" class=\"checkbox\"&gt;\n                &lt;label&gt;pear&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"77\" class=\"checkbox\"&gt;\n                &lt;label&gt;cherry&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"126\" class=\"checkbox\"&gt;\n                &lt;label&gt;fenugreek&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"302\" class=\"checkbox\"&gt;\n                &lt;label&gt;sake&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"327\" class=\"checkbox\"&gt;\n                &lt;label&gt;soy sauce&lt;/label&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"boxCont\"&gt;\n                &lt;input type=\"checkbox\" value=\"112\" class=\"checkbox\"&gt;\n                &lt;label&gt;cumin&lt;/label&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div style=\"padding-top:10px\"&gt;\n            &lt;button onClick=\"startInference()\"&gt;What kind of cuisine can you make?&lt;/button&gt;\n        &lt;/div&gt; \n</code></pre> <p>Notice that each checkbox is given a value.  This reflects the index where the ingredient is found according to the dataset. Apple, for example, in this alphabetic list, occupies the fifth column, so its value is '4' since we start counting at 0. You can consult the ingredients spreadsheet to discover a given ingredient's index.</p> <p>Continuing your work in the index.html file, add a script block where the model is called after the final closing <code>&lt;/div&gt;</code>. </p> </li> <li> <p>First, import the Onnx Runtime:</p> <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.9.0/dist/ort.min.js\"&gt;&lt;/script&gt; \n</code></pre> <p>Onnx Runtime is used to enable running your Onnx models across a wide range of hardware platforms, including optimizations and an API to use.</p> </li> <li> <p>Once the Runtime is in place, you can call it:</p> <pre><code>&lt;script&gt;\n    const ingredients = Array(380).fill(0);\n\n    const checks = [...document.querySelectorAll('.checkbox')];\n\n    checks.forEach(check =&gt; {\n        check.addEventListener('change', function() {\n            // toggle the state of the ingredient\n            // based on the checkbox's value (1 or 0)\n            ingredients[check.value] = check.checked ? 1 : 0;\n        });\n    });\n\n    function testCheckboxes() {\n        // validate if at least one checkbox is checked\n        return checks.some(check =&gt; check.checked);\n    }\n\n    async function startInference() {\n\n        let atLeastOneChecked = testCheckboxes()\n\n        if (!atLeastOneChecked) {\n            alert('Please select at least one ingredient.');\n            return;\n        }\n        try {\n            // create a new session and load the model.\n\n            const session = await ort.InferenceSession.create('./model.onnx');\n\n            const input = new ort.Tensor(new Float32Array(ingredients), [1, 380]);\n            const feeds = { float_input: input };\n\n            // feed inputs and run\n            const results = await session.run(feeds);\n\n            // read from results\n            alert('You can enjoy ' + results.label.data[0] + ' cuisine today!')\n\n        } catch (e) {\n            console.log(`failed to inference ONNX model`);\n            console.error(e);\n        }\n    }\n\n&lt;/script&gt;\n</code></pre> </li> </ol> <p>In this code, there are several things happening:</p> <ol> <li>You created an array of 380 possible values (1 or 0) to be set and sent to the model for inference, depending on whether an ingredient checkbox is checked.</li> <li>You created an array of checkboxes and a way to determine whether they were checked in an <code>init</code> function that is called when the application starts. When a checkbox is checked, the <code>ingredients</code> array is altered to reflect the chosen ingredient.</li> <li>You created a <code>testCheckboxes</code> function that checks whether any checkbox was checked.</li> <li>You use <code>startInference</code> function when the button is pressed and, if any checkbox is checked, you start inference.</li> <li>The inference routine includes:</li> <li>Setting up an asynchronous load of the model</li> <li>Creating a Tensor structure to send to the model</li> <li>Creating 'feeds' that reflects the <code>float_input</code> input that you created when training your model (you can use Netron to verify that name)</li> <li>Sending these 'feeds' to the model and waiting for a response</li> </ol>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#test-your-application","title":"Test your application","text":"<p>Open a terminal session in Visual Studio Code in the folder where your index.html file resides. Ensure that you have http-server installed globally, and type <code>http-server</code> at the prompt. A localhost should open and you can view your web app. Check what cuisine is recommended based on various ingredients:</p> <p></p> <p>Congratulations, you have created a 'recommendation' web app  with a few fields. Take some time to build out this system!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Your web app is very minimal, so continue to build it out using ingredients and their indexes from the ingredient_indexes data. What flavor combinations work to create a given national dish?</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#review-self-study","title":"Review &amp; Self Study","text":"<p>While this lesson just touched on the utility of creating a recommendation system for food ingredients, this area of ML applications is very rich in examples. Read some more about how these systems are built:</p> <ul> <li>https://www.sciencedirect.com/topics/computer-science/recommendation-engine</li> <li>https://www.technologyreview.com/2014/08/25/171547/the-ultimate-challenge-for-recommendation-engines/</li> <li>https://www.technologyreview.com/2015/03/23/168831/everything-is-a-recommendation/</li> </ul>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/#assignment","title":"Assignment","text":"<p>Build a new recommender</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/assignment/#build-a-recommender","title":"Build a recommender","text":""},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/assignment/#instructions","title":"Instructions","text":"<p>Given your exercises in this lesson, you now know how to build JavaScript-based web app using Onnx Runtime and a converted Onnx model. Experiment with building a new recommender using data from these lessons or sourced elsewhere (give credit, please). You might create a pet recommender given various personality attributes, or a music genre recommender based on a person's mood. Be creative!</p>"},{"location":"curricula/ml-for-beginners/4-Classification/4-Applied/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A web app and notebook are presented, both well documented and running One of those two is missing or flawed Both are either missing or flawed"},{"location":"curricula/ml-for-beginners/5-Clustering/","title":"Clustering","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/#clustering-models-for-machine-learning","title":"Clustering models for machine learning","text":"<p>Clustering is a machine learning task where it looks to find objects that resemble one another and group these into groups called clusters.  What differs clustering from other approaches in machine learning, is that things happen automatically, in fact, it's fair to say it's the opposite of supervised learning. </p>"},{"location":"curricula/ml-for-beginners/5-Clustering/#regional-topic-clustering-models-for-a-nigerian-audiences-musical-taste","title":"Regional topic: clustering models for a Nigerian audience's musical taste \ud83c\udfa7","text":"<p>Nigeria's diverse audience has diverse musical tastes. Using data scraped from Spotify (inspired by this article, let's look at some music popular in Nigeria. This dataset includes data about various songs' 'danceability' score, 'acousticness', loudness, 'speechiness', popularity and energy. It will be interesting to discover patterns in this data!</p> <p></p> <p>Photo by Marcela Laskoski on Unsplash</p> <p>In this series of lessons, you will discover new ways to analyze data using clustering techniques. Clustering is particularly useful when your dataset lacks labels. If it does have labels, then classification techniques such as those you learned in previous lessons might be more useful. But in cases where you are looking to group unlabelled data, clustering is a great way to discover patterns.</p> <p>There are useful low-code tools that can help you learn about working with clustering models. Try Azure ML for this task</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/#lessons","title":"Lessons","text":"<ol> <li>Introduction to clustering</li> <li>K-Means clustering</li> </ol>"},{"location":"curricula/ml-for-beginners/5-Clustering/#credits","title":"Credits","text":"<p>These lessons were written with \ud83c\udfb6 by Jen Looper with helpful reviews by Rishit Dagli and Muhammad Sakib Khan Inan.</p> <p>The Nigerian Songs dataset was sourced from Kaggle as scraped from Spotify.</p> <p>Useful K-Means examples that aided in creating this lesson include this iris exploration, this introductory notebook, and this hypothetical NGO example.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/","title":"Visualize","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#introduction-to-clustering","title":"Introduction to clustering","text":"<p>Clustering is a type of Unsupervised Learning that presumes that a dataset is unlabelled or that its inputs are not matched with predefined outputs. It uses various algorithms to sort through unlabeled data and provide groupings according to patterns it discerns in the data. </p> <p></p> <p>\ud83c\udfa5 Click the image above for a video. While you're studying machine learning with clustering, enjoy some Nigerian Dance Hall tracks - this is a highly rated song from 2014 by PSquare.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#introduction","title":"Introduction","text":"<p>Clustering is very useful for data exploration. Let's see if it can help discover trends and patterns in the way Nigerian audiences consume music.</p> <p>\u2705 Take a minute to think about the uses of clustering. In real life, clustering happens whenever you have a pile of laundry and need to sort out your family members' clothes \ud83e\udde6\ud83d\udc55\ud83d\udc56\ud83e\ude72. In data science, clustering happens when trying to analyze a user's preferences, or determine the characteristics of any unlabeled dataset. Clustering, in a way, helps make sense of chaos, like a sock drawer.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: MIT's John Guttag introduces clustering</p> <p>In a professional setting, clustering can be used to determine things like market segmentation, determining what age groups buy what items, for example. Another use would be anomaly detection, perhaps to detect fraud from a dataset of credit card transactions. Or you might use clustering to determine tumors in a batch of medical scans. </p> <p>\u2705 Think a minute about how you might have encountered clustering 'in the wild', in a banking, e-commerce, or business setting.</p> <p>\ud83c\udf93 Interestingly, cluster analysis originated in the fields of Anthropology and Psychology in the 1930s. Can you imagine how it might have been used?</p> <p>Alternately, you could use it for grouping search results - by shopping links, images, or reviews, for example. Clustering is useful when you have a large dataset that you want to reduce and on which you want to perform more granular analysis, so the technique can be used to learn about data before other models are constructed.</p> <p>\u2705 Once your data is organized in clusters, you assign it a cluster Id, and this technique can be useful when preserving a dataset's privacy; you can instead refer to a data point by its cluster id, rather than by more revealing identifiable data. Can you think of other reasons why you'd refer to a cluster Id rather than other elements of the cluster to identify it?</p> <p>Deepen your understanding of clustering techniques in this Learn module</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#getting-started-with-clustering","title":"Getting started with clustering","text":"<p>Scikit-learn offers a large array of methods to perform clustering. The type you choose will depend on your use case. According to the documentation, each method has various benefits. Here is a simplified table of the methods supported by Scikit-learn and their appropriate use cases:</p> Method name Use case K-Means general purpose, inductive Affinity propagation many, uneven clusters, inductive Mean-shift many, uneven clusters, inductive Spectral clustering few, even clusters, transductive Ward hierarchical clustering many, constrained clusters, transductive Agglomerative clustering many, constrained, non Euclidean distances, transductive DBSCAN non-flat geometry, uneven clusters, transductive OPTICS non-flat geometry, uneven clusters with variable density, transductive Gaussian mixtures flat geometry, inductive BIRCH large dataset with outliers, inductive <p>\ud83c\udf93 How we create clusters has a lot to do with how we gather up the data points into groups. Let's unpack some vocabulary:</p> <p>\ud83c\udf93 'Transductive' vs. 'inductive'</p> <p>Transductive inference is derived from observed training cases that map to specific test cases. Inductive inference is derived from training cases that map to general rules which are only then applied to test cases. </p> <p>An example: Imagine you have a dataset that is only partially  labelled. Some things are 'records', some 'cds', and some are blank. Your job is to provide labels for the blanks. If you choose an inductive approach, you'd train a model looking for 'records' and 'cds', and apply those labels to your unlabeled data. This approach will have trouble classifying things that are actually 'cassettes'. A transductive approach, on the other hand, handles this unknown data more effectively as it works to group similar items together and then applies a label to a group. In this case, clusters might reflect 'round musical things' and 'square musical things'. </p> <p>\ud83c\udf93 'Non-flat' vs. 'flat' geometry</p> <p>Derived from mathematical terminology, non-flat vs. flat geometry refers to the measure of distances between points by either 'flat' (Euclidean) or 'non-flat' (non-Euclidean) geometrical methods. </p> <p>'Flat' in this context refers to Euclidean geometry (parts of which are taught as 'plane' geometry), and non-flat refers to non-Euclidean geometry. What does geometry have to do with machine learning? Well, as two fields that are rooted in mathematics, there must be a common way to measure distances between points in clusters, and that can be done in a 'flat' or 'non-flat' way, depending on the nature of the data. Euclidean distances are measured as the length of a line segment between two points. Non-Euclidean distances are measured along a curve. If your data, visualized, seems to not exist on a plane, you might need to use a specialized algorithm to handle it.</p> <p> Infographic by Dasani Madipalli</p> <p>\ud83c\udf93 'Distances'</p> <p>Clusters are defined by their distance matrix, e.g. the distances between points. This distance can be measured in a few ways. Euclidean clusters are defined by the average of the point values, and contain a 'centroid' or center point. Distances are thus measured by the distance to that centroid. Non-Euclidean distances refer to 'clustroids', the point closest to other points. Clustroids in turn can be defined in various ways.</p> <p>\ud83c\udf93 'Constrained'</p> <p>Constrained Clustering introduces 'semi-supervised' learning into this unsupervised method. The relationships between points are flagged as 'cannot link' or 'must-link' so some rules are forced on the dataset.</p> <p>An example: If an algorithm is set free on a batch of unlabelled or semi-labelled data, the clusters it produces may be of poor quality. In the example above, the clusters might group 'round music things' and 'square music things' and 'triangular things' and 'cookies'. If given some constraints, or rules to follow (\"the item must be made of plastic\", \"the item needs to be able to produce music\") this can help 'constrain' the algorithm to make better choices.</p> <p>\ud83c\udf93 'Density'</p> <p>Data that is 'noisy' is considered to be 'dense'. The distances between points in each of its clusters may prove, on examination, to be more or less dense, or 'crowded' and thus this data needs to be analyzed with the appropriate clustering method. This article demonstrates the difference between using K-Means clustering vs. HDBSCAN algorithms to explore a noisy dataset with uneven cluster density.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#clustering-algorithms","title":"Clustering algorithms","text":"<p>There are over 100 clustering algorithms, and their use depends on the nature of the data at hand. Let's discuss some of the major ones:</p> <ul> <li>Hierarchical clustering. If an object is classified by its proximity to a nearby object, rather than to one farther away, clusters are formed based on their members' distance to and from other objects. Scikit-learn's agglomerative clustering is hierarchical.</li> </ul> <p></p> <p>Infographic by Dasani Madipalli</p> <ul> <li>Centroid clustering. This popular algorithm requires the choice of 'k', or the number of clusters to form, after which the algorithm determines the center point of a cluster and gathers data around that point. K-means clustering is a popular version of centroid clustering. The center is determined by the nearest mean, thus the name. The squared distance from the cluster is minimized.</li> </ul> <p></p> <p>Infographic by Dasani Madipalli</p> <ul> <li> <p>Distribution-based clustering. Based in statistical modeling, distribution-based clustering centers on determining the probability that a data point belongs to a cluster, and assigning it accordingly. Gaussian mixture methods belong to this type.</p> </li> <li> <p>Density-based clustering. Data points are assigned to clusters based on their density, or their grouping around each other. Data points far from the group are considered outliers or noise. DBSCAN, Mean-shift and OPTICS belong to this type of clustering.</p> </li> <li> <p>Grid-based clustering. For multi-dimensional datasets, a grid is created and the data is divided amongst the grid's cells, thereby creating clusters.</p> </li> </ul>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#exercise-cluster-your-data","title":"Exercise - cluster your data","text":"<p>Clustering as a technique is greatly aided by proper visualization, so let's get started by visualizing our music data. This exercise will help us decide which of the methods of clustering we should most effectively use for the nature of this data.</p> <ol> <li> <p>Open the notebook.ipynb file in this folder.</p> </li> <li> <p>Import the <code>Seaborn</code> package for good data visualization.</p> <pre><code>!pip install seaborn\n</code></pre> </li> <li> <p>Append the song data from nigerian-songs.csv. Load up a dataframe with some data about the songs. Get ready to explore this data by importing the libraries and dumping out the data:</p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\ndf = pd.read_csv(\"../data/nigerian-songs.csv\")\ndf.head()\n</code></pre> <p>Check the first few lines of data:</p> name album artist artist_top_genre release_date length popularity danceability acousticness energy instrumentalness liveness loudness speechiness tempo time_signature 0 Sparky Mandy &amp; The Jungle Cruel Santino alternative r&amp;b 2019 144000 48 0.666 0.851 0.42 0.534 0.11 -6.699 0.0829 133.015 5 1 shuga rush EVERYTHING YOU HEARD IS TRUE Odunsi (The Engine) afropop 2020 89488 30 0.71 0.0822 0.683 0.000169 0.101 -5.64 0.36 129.993 3 2 LITT! LITT! AYL\u00d8 indie r&amp;b 2018 207758 40 0.836 0.272 0.564 0.000537 0.11 -7.127 0.0424 130.005 4 3 Confident / Feeling Cool Enjoy Your Life Lady Donli nigerian pop 2019 175135 14 0.894 0.798 0.611 0.000187 0.0964 -4.961 0.113 111.087 4 4 wanted you rare. Odunsi (The Engine) afropop 2018 152049 25 0.702 0.116 0.833 0.91 0.348 -6.044 0.0447 105.115 4 </li> <li> <p>Get some information about the dataframe, calling <code>info()</code>:</p> <pre><code>df.info()\n</code></pre> </li> </ol> <p>The output looking like so:</p> <pre><code>```output\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 530 entries, 0 to 529\nData columns (total 16 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   name              530 non-null    object \n 1   album             530 non-null    object \n 2   artist            530 non-null    object \n 3   artist_top_genre  530 non-null    object \n 4   release_date      530 non-null    int64  \n 5   length            530 non-null    int64  \n 6   popularity        530 non-null    int64  \n 7   danceability      530 non-null    float64\n 8   acousticness      530 non-null    float64\n 9   energy            530 non-null    float64\n 10  instrumentalness  530 non-null    float64\n 11  liveness          530 non-null    float64\n 12  loudness          530 non-null    float64\n 13  speechiness       530 non-null    float64\n 14  tempo             530 non-null    float64\n 15  time_signature    530 non-null    int64  \ndtypes: float64(8), int64(4), object(4)\nmemory usage: 66.4+ KB\n```\n</code></pre> <ol> <li> <p>Double-check for null values, by calling <code>isnull()</code> and verifying the sum being 0:</p> <pre><code>df.isnull().sum()\n</code></pre> <p>Looking good:</p> <pre><code>name                0\nalbum               0\nartist              0\nartist_top_genre    0\nrelease_date        0\nlength              0\npopularity          0\ndanceability        0\nacousticness        0\nenergy              0\ninstrumentalness    0\nliveness            0\nloudness            0\nspeechiness         0\ntempo               0\ntime_signature      0\ndtype: int64\n</code></pre> </li> <li> <p>Describe the data:</p> <pre><code>df.describe()\n</code></pre> release_date length popularity danceability acousticness energy instrumentalness liveness loudness speechiness tempo time_signature count 530 530 530 530 530 530 530 530 530 530 530 530 mean 2015.390566 222298.1698 17.507547 0.741619 0.265412 0.760623 0.016305 0.147308 -4.953011 0.130748 116.487864 3.986792 std 3.131688 39696.82226 18.992212 0.117522 0.208342 0.148533 0.090321 0.123588 2.464186 0.092939 23.518601 0.333701 min 1998 89488 0 0.255 0.000665 0.111 0 0.0283 -19.362 0.0278 61.695 3 25% 2014 199305 0 0.681 0.089525 0.669 0 0.07565 -6.29875 0.0591 102.96125 4 50% 2016 218509 13 0.761 0.2205 0.7845 0.000004 0.1035 -4.5585 0.09795 112.7145 4 75% 2017 242098.5 31 0.8295 0.403 0.87575 0.000234 0.164 -3.331 0.177 125.03925 4 max 2020 511738 73 0.966 0.954 0.995 0.91 0.811 0.582 0.514 206.007 5 </li> </ol> <p>\ud83e\udd14 If we are working with clustering, an unsupervised method that does not require labeled data, why are we showing this data with labels? In the data exploration phase, they come in handy, but they are not necessary for the clustering algorithms to work. You could just as well remove the column headers and refer to the data by column number. </p> <p>Look at the general values of the data. Note that popularity can be '0', which show songs that have no ranking. Let's remove those shortly.</p> <ol> <li> <p>Use a barplot to find out the most popular genres:</p> <pre><code>import seaborn as sns\n\ntop = df['artist_top_genre'].value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=top[:5].index,y=top[:5].values)\nplt.xticks(rotation=45)\nplt.title('Top genres',color = 'blue')\n</code></pre> <p></p> </li> </ol> <p>\u2705 If you'd like to see more top values, change the top <code>[:5]</code> to a bigger value, or remove it to see all.</p> <p>Note, when the top genre is described as 'Missing', that means that Spotify did not classify it, so let's get rid of it.</p> <ol> <li> <p>Get rid of missing data by filtering it out</p> <pre><code>df = df[df['artist_top_genre'] != 'Missing']\ntop = df['artist_top_genre'].value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=top.index,y=top.values)\nplt.xticks(rotation=45)\nplt.title('Top genres',color = 'blue')\n</code></pre> <p>Now recheck the genres:</p> <p></p> </li> <li> <p>By far, the top three genres dominate this dataset. Let's concentrate on <code>afro dancehall</code>, <code>afropop</code>, and <code>nigerian pop</code>, additionally filter the dataset to remove anything with a 0 popularity value (meaning it was not classified with a popularity in the dataset and can be considered noise for our purposes):</p> <pre><code>df = df[(df['artist_top_genre'] == 'afro dancehall') | (df['artist_top_genre'] == 'afropop') | (df['artist_top_genre'] == 'nigerian pop')]\ndf = df[(df['popularity'] &gt; 0)]\ntop = df['artist_top_genre'].value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=top.index,y=top.values)\nplt.xticks(rotation=45)\nplt.title('Top genres',color = 'blue')\n</code></pre> </li> <li> <p>Do a quick test to see if the data correlates in any particularly strong way:</p> <pre><code>corrmat = df.corr(numeric_only=True)\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True)\n</code></pre> <p></p> <p>The only strong correlation is between <code>energy</code> and <code>loudness</code>, which is not too surprising, given that loud music is usually pretty energetic. Otherwise, the correlations are relatively weak. It will be interesting to see what a clustering algorithm can make of this data.</p> <p>\ud83c\udf93 Note that correlation does not imply causation! We have proof of correlation but no proof of causation. An amusing web site has some visuals that emphasize this point.</p> </li> </ol> <p>Is there any convergence in this dataset around a song's perceived popularity and danceability? A FacetGrid shows that there are concentric circles that line up, regardless of genre. Could it be that Nigerian tastes converge at a certain level of danceability for this genre?  </p> <p>\u2705 Try different datapoints (energy, loudness, speechiness) and more or different musical genres. What can you discover? Take a look at the <code>df.describe()</code> table to see the general spread of the data points.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#exercise-data-distribution","title":"Exercise - data distribution","text":"<p>Are these three genres significantly different in the perception of their danceability, based on their popularity?</p> <ol> <li> <p>Examine our top three genres data distribution for popularity and danceability along a given x and y axis.</p> <pre><code>sns.set_theme(style=\"ticks\")\n\ng = sns.jointplot(\n    data=df,\n    x=\"popularity\", y=\"danceability\", hue=\"artist_top_genre\",\n    kind=\"kde\",\n)\n</code></pre> <p>You can discover concentric circles around a general point of convergence, showing the distribution of points.</p> <p>\ud83c\udf93 Note that this example uses a KDE (Kernel Density Estimate) graph that represents the data using a continuous probability density curve. This allows us to interpret data when working with multiple distributions.</p> <p>In general, the three genres align loosely in terms of their popularity and danceability. Determining clusters in this loosely-aligned data will be a challenge:</p> <p></p> </li> <li> <p>Create a scatter plot:</p> <pre><code>sns.FacetGrid(df, hue=\"artist_top_genre\", height=5) \\\n   .map(plt.scatter, \"popularity\", \"danceability\") \\\n   .add_legend()\n</code></pre> <p>A scatterplot of the same axes shows a similar pattern of convergence</p> <p></p> </li> </ol> <p>In general, for clustering, you can use scatterplots to show clusters of data, so mastering this type of visualization is very useful. In the next lesson, we will take this filtered data and use k-means clustering to discover groups in this data that see to overlap in interesting ways.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#challenge","title":"\ud83d\ude80Challenge","text":"<p>In preparation for the next lesson, make a chart about the various clustering algorithms you might discover and use in a production environment. What kinds of problems is the clustering trying to address?</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#review-self-study","title":"Review &amp; Self Study","text":"<p>Before you apply clustering algorithms, as we have learned, it's a good idea to understand the nature of your dataset. Read more on this topic here</p> <p>This helpful article walks you through the different ways that various clustering algorithms behave, given different data shapes.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/#assignment","title":"Assignment","text":"<p>Research other visualizations for clustering</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/assignment/#research-other-visualizations-for-clustering","title":"Research other visualizations for clustering","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/assignment/#instructions","title":"Instructions","text":"<p>In this lesson, you have worked with some visualization techniques to get a grasp on plotting your data in preparation for clustering it. Scatterplots, in particular are useful for finding groups of objects. Research different ways and different libraries to create scatterplots and document your work in a notebook. You can use the data from this lesson, other lessons, or data you source yourself (please credit its source, however, in your notebook). Plot some data using scatterplots and explain what you discover.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with five well-documented scatterplots A notebook is presented with fewer than five scatterplots and it is less well documented An incomplete notebook is presented"},{"location":"curricula/ml-for-beginners/5-Clustering/1-Visualize/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/","title":"K Means","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#k-means-clustering","title":"K-Means clustering","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>In this lesson, you will learn how to create clusters using Scikit-learn and the Nigerian music dataset you imported earlier. We will cover the basics of K-Means for Clustering. Keep in mind that, as you learned in the earlier lesson, there are many ways to work with clusters and the method you use depends on your data. We will try K-Means as it's the most common clustering technique. Let's get started!</p> <p>Terms you will learn about:</p> <ul> <li>Silhouette scoring</li> <li>Elbow method</li> <li>Inertia</li> <li>Variance</li> </ul>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#introduction","title":"Introduction","text":"<p>K-Means Clustering is a method derived from the domain of signal processing. It is used to divide and partition groups of data into 'k' clusters using a series of observations. Each observation works to group a given datapoint closest to its nearest 'mean', or the center point of a cluster.</p> <p>The clusters can be visualized as Voronoi diagrams, which include a point (or 'seed') and its corresponding region. </p> <p></p> <p>infographic by Jen Looper</p> <p>The K-Means clustering process executes in a three-step process:</p> <ol> <li>The algorithm selects k-number of center points by sampling from the dataset. After this, it loops:<ol> <li>It assigns each sample to the nearest centroid.</li> <li>It creates new centroids by taking the mean value of all of the samples assigned to the previous centroids.</li> <li>Then, it calculates the difference between the new and old centroids and repeats until the centroids are stabilized.</li> </ol> </li> </ol> <p>One drawback of using K-Means includes the fact that you will need to establish 'k', that is the number of centroids. Fortunately the  'elbow method' helps to estimate a good starting value for 'k'. You'll try it in a minute.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#prerequisite","title":"Prerequisite","text":"<p>You will work in this lesson's notebook.ipynb file that includes the data import and preliminary cleaning you did in the last lesson.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#exercise-preparation","title":"Exercise - preparation","text":"<p>Start by taking another look at the songs data.</p> <ol> <li> <p>Create a boxplot, calling <code>boxplot()</code> for each column:</p> <pre><code>plt.figure(figsize=(20,20), dpi=200)\n\nplt.subplot(4,3,1)\nsns.boxplot(x = 'popularity', data = df)\n\nplt.subplot(4,3,2)\nsns.boxplot(x = 'acousticness', data = df)\n\nplt.subplot(4,3,3)\nsns.boxplot(x = 'energy', data = df)\n\nplt.subplot(4,3,4)\nsns.boxplot(x = 'instrumentalness', data = df)\n\nplt.subplot(4,3,5)\nsns.boxplot(x = 'liveness', data = df)\n\nplt.subplot(4,3,6)\nsns.boxplot(x = 'loudness', data = df)\n\nplt.subplot(4,3,7)\nsns.boxplot(x = 'speechiness', data = df)\n\nplt.subplot(4,3,8)\nsns.boxplot(x = 'tempo', data = df)\n\nplt.subplot(4,3,9)\nsns.boxplot(x = 'time_signature', data = df)\n\nplt.subplot(4,3,10)\nsns.boxplot(x = 'danceability', data = df)\n\nplt.subplot(4,3,11)\nsns.boxplot(x = 'length', data = df)\n\nplt.subplot(4,3,12)\nsns.boxplot(x = 'release_date', data = df)\n</code></pre> <p>This data is a little noisy: by observing each column as a boxplot, you can see outliers.</p> <p></p> </li> </ol> <p>You could go through the dataset and remove these outliers, but that would make the data pretty minimal.</p> <ol> <li> <p>For now, choose which columns you will use for your clustering exercise. Pick ones with similar ranges and encode the <code>artist_top_genre</code> column as numeric data:</p> <pre><code>from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nX = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]\n\ny = df['artist_top_genre']\n\nX['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])\n\ny = le.transform(y)\n</code></pre> </li> <li> <p>Now you need to pick how many clusters to target. You know there are 3 song genres that we carved out of the dataset, so let's try 3:</p> <pre><code>from sklearn.cluster import KMeans\n\nnclusters = 3 \nseed = 0\n\nkm = KMeans(n_clusters=nclusters, random_state=seed)\nkm.fit(X)\n\n# Predict the cluster for each data point\n\ny_cluster_kmeans = km.predict(X)\ny_cluster_kmeans\n</code></pre> </li> </ol> <p>You see an array printed out with predicted clusters (0, 1,or 2) for each row of the dataframe.</p> <ol> <li> <p>Use this array to calculate a 'silhouette score':</p> <pre><code>from sklearn import metrics\nscore = metrics.silhouette_score(X, y_cluster_kmeans)\nscore\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#silhouette-score","title":"Silhouette score","text":"<p>Look for a silhouette score closer to 1. This score varies from -1 to 1, and if the score is 1, the cluster is dense and well-separated from other clusters. A value near 0 represents overlapping clusters with samples very close to the decision boundary of the neighboring clusters. (Source)</p> <p>Our score is .53, so right in the middle. This indicates that our data is not particularly well-suited to this type of clustering, but let's continue.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#exercise-build-a-model","title":"Exercise - build a model","text":"<ol> <li> <p>Import <code>KMeans</code> and start the clustering process.</p> <pre><code>from sklearn.cluster import KMeans\nwcss = []\n\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n</code></pre> <p>There are a few parts here that warrant explaining.</p> <p>\ud83c\udf93 range: These are the iterations of the clustering process</p> <p>\ud83c\udf93 random_state: \"Determines random number generation for centroid initialization.\" Source</p> <p>\ud83c\udf93 WCSS: \"within-cluster sums of squares\" measures the squared average distance of all the points within a cluster to the cluster centroid. Source. </p> <p>\ud83c\udf93 Inertia: K-Means algorithms attempt to choose centroids to minimize 'inertia', \"a measure of how internally coherent clusters are.\" Source. The value is appended to the wcss variable on each iteration.</p> <p>\ud83c\udf93 k-means++: In Scikit-learn you can use the 'k-means++' optimization, which \"initializes the centroids to be (generally) distant from each other, leading to probably better results than random initialization.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#elbow-method","title":"Elbow method","text":"<p>Previously, you surmised that, because you have targeted 3 song genres, you should choose 3 clusters. But is that the case?</p> <ol> <li> <p>Use the 'elbow method' to make sure.</p> <pre><code>plt.figure(figsize=(10,5))\nsns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')\nplt.title('Elbow')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n</code></pre> <p>Use the <code>wcss</code> variable that you built in the previous step to create a chart showing where the 'bend' in the elbow is, which indicates the optimum number of clusters. Maybe it is 3!</p> <p></p> </li> </ol>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#exercise-display-the-clusters","title":"Exercise - display the clusters","text":"<ol> <li> <p>Try the process again, this time setting three clusters, and display the clusters as a scatterplot:</p> <pre><code>from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters = 3)\nkmeans.fit(X)\nlabels = kmeans.predict(X)\nplt.scatter(df['popularity'],df['danceability'],c = labels)\nplt.xlabel('popularity')\nplt.ylabel('danceability')\nplt.show()\n</code></pre> </li> <li> <p>Check the model's accuracy:</p> <pre><code>labels = kmeans.labels_\n\ncorrect_labels = sum(y == labels)\n\nprint(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, y.size))\n\nprint('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))\n</code></pre> <p>This model's accuracy is not very good, and the shape of the clusters gives you a hint why. </p> <p></p> <p>This data is too imbalanced, too little correlated and there is too much variance between the column values to cluster well. In fact, the clusters that form are probably heavily influenced or skewed by the three genre categories we defined above. That was a learning process!</p> <p>In Scikit-learn's documentation, you can see that a model like this one, with clusters not very well demarcated, has a 'variance' problem:</p> <p></p> <p>Infographic from Scikit-learn</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#variance","title":"Variance","text":"<p>Variance is defined as \"the average of the squared differences from the Mean\" (Source). In the context of this clustering problem, it refers to data that the numbers of our dataset tend to diverge a bit too much from the mean. </p> <p>\u2705 This is a great moment to think about all the ways you could correct this issue. Tweak the data a bit more? Use different columns? Use a different algorithm? Hint: Try scaling your data to normalize it and test other columns.</p> <p>Try this 'variance calculator' to understand the concept a bit more.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Spend some time with this notebook, tweaking parameters. Can you improve the accuracy of the model by cleaning  the data more (removing outliers, for example)? You can use weights to give more weight to given data samples. What else can you do to create better clusters?</p> <p>Hint: Try to scale your data. There's commented code in the notebook that adds standard scaling to make the data columns resemble each other more closely in terms of range. You'll find that while the silhouette score goes down, the 'kink' in the elbow graph smooths out. This is because leaving the data unscaled allows data with less variance to carry more weight. Read a bit more on this problem here.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take a look at a K-Means Simulator such as this one. You can use this tool to visualize sample data points and determine its centroids. You can edit the data's randomness, numbers of clusters and numbers of centroids. Does this help you get an idea of how the data can be grouped?</p> <p>Also, take a look at this handout on K-Means from Stanford.</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/#assignment","title":"Assignment","text":"<p>Try different clustering methods</p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/assignment/#try-different-clustering-methods","title":"Try different clustering methods","text":""},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/assignment/#instructions","title":"Instructions","text":"<p>In this lesson you learned about K-Means clustering. Sometimes K-Means is not appropriate for your data. Create a notebook using data either from these lessons or from somewhere else (credit your source) and show a different clustering method NOT using K-Means. What did you learn? </p>"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with a well-documented clustering model A notebook is presented without good documentation and/or incomplete Incomplete work is submitted"},{"location":"curricula/ml-for-beginners/5-Clustering/2-K-Means/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/6-NLP/","title":"NLP","text":""},{"location":"curricula/ml-for-beginners/6-NLP/#getting-started-with-natural-language-processing","title":"Getting started with natural language processing","text":"<p>Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken and written -- referred to as natural language. It is a component of artificial intelligence (AI). NLP has existed for more than 50 years and has roots in the field of linguistics. The whole field is directed at helping machines understand and process the human language. This can then be used to perform tasks like spell check or machine translation. It has a variety of real-world applications in a number of fields, including medical research, search engines and business intelligence.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/#regional-topic-european-languages-and-literature-and-romantic-hotels-of-europe","title":"Regional topic: European languages and literature and romantic hotels of Europe \u2764\ufe0f","text":"<p>In this section of the curriculum, you will be introduced to one of the most widespread uses of machine learning: natural language processing (NLP). Derived from computational linguistics, this category of artificial intelligence is the bridge between humans and machines via voice or textual communication.</p> <p>In these lessons we'll learn the basics of NLP by building small conversational bots to learn how machine learning aids in making these conversations more and more 'smart'. You'll travel back in time, chatting with Elizabeth Bennett and Mr. Darcy from Jane Austen's classic novel, Pride and Prejudice, published in 1813. Then, you'll further your knowledge by learning about sentiment analysis via hotel reviews in Europe.</p> <p></p> <p>Photo by Elaine Howlin on Unsplash</p>"},{"location":"curricula/ml-for-beginners/6-NLP/#lessons","title":"Lessons","text":"<ol> <li>Introduction to natural language processing</li> <li>Common NLP tasks and techniques</li> <li>Translation and sentiment analysis with machine learning</li> <li>Preparing your data</li> <li>NLTK for Sentiment Analysis</li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/#credits","title":"Credits","text":"<p>These natural language processing lessons were written with \u2615 by Stephen Howell</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/","title":"Introduction to NLP","text":""},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#introduction-to-natural-language-processing","title":"Introduction to natural language processing","text":"<p>This lesson covers a brief history and important concepts of natural language processing, a subfield of computational linguistics.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#introduction","title":"Introduction","text":"<p>NLP, as it is commonly known, is one of the best-known areas where machine learning has been applied and used in production software.</p> <p>\u2705 Can you think of software that you use every day that probably has some NLP embedded? What about your word processing programs or mobile apps that you use regularly?</p> <p>You will learn about:</p> <ul> <li>The idea of languages. How languages developed and what the major areas of study have been.</li> <li>Definition and concepts. You will also learn definitions and concepts about how computers process text, including parsing, grammar, and identifying nouns and verbs. There are some coding tasks in this lesson, and several important concepts are introduced that you will learn to code later on in the next lessons.</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#computational-linguistics","title":"Computational linguistics","text":"<p>Computational linguistics is an area of research and development over many decades that studies how computers can work with, and even understand, translate, and communicate with languages. Natural language processing (NLP) is a related field focused on how computers can process 'natural', or human, languages.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#example-phone-dictation","title":"Example - phone dictation","text":"<p>If you have ever dictated to your phone instead of typing or asked a virtual assistant a question, your speech was converted into a text form and then processed or parsed from the language you spoke. The detected keywords were then processed into a format that the phone or assistant could understand and act on.</p> <p></p> <p>Real linguistic comprehension is hard! Image by Jen Looper</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#how-is-this-technology-made-possible","title":"How is this technology made possible?","text":"<p>This is possible because someone wrote a computer program to do this. A few decades ago, some science fiction writers predicted that people would mostly speak to their computers, and the computers would always understand exactly what they meant. Sadly, it turned out to be a harder problem that many imagined, and while it is a much better understood problem today, there are significant challenges in achieving 'perfect' natural language processing when it comes to understanding the meaning of a sentence. This is a particularly hard problem when it comes to understanding humour or detecting emotions such as sarcasm in a sentence.</p> <p>At this point, you may be remembering school classes where the teacher covered the parts of grammar in a sentence. In some countries, students are taught grammar and linguistics as a dedicated subject, but in many, these topics are included as part of learning a language: either your first language in primary school (learning to read and write) and perhaps a second language in post-primary, or high school. Don't  worry if you are not an expert at differentiating nouns from verbs or adverbs from adjectives!</p> <p>If you struggle with the difference between the simple present and present progressive, you are not alone. This is a challenging thing for many people, even native speakers of a language. The good news is that computers are really good at applying formal rules, and you will learn to write code that can parse a sentence as well as a human. The greater challenge you will examine later is understanding the meaning, and sentiment, of a sentence.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#prerequisites","title":"Prerequisites","text":"<p>For this lesson, the main prerequisite is being able to read and understand the language of this lesson. There are no math problems or equations to solve. While the original author wrote this lesson in English, it is also translated into other languages, so you could be reading a translation. There are examples where a number of different languages are used (to compare the different grammar rules of different languages). These are not translated, but the explanatory text is, so the meaning should be clear.</p> <p>For the coding tasks, you will use Python and the examples are using Python 3.8.</p> <p>In this section, you will need, and use:</p> <ul> <li>Python 3 comprehension.  Programming language comprehension in Python 3, this lesson uses input, loops, file reading, arrays.</li> <li>Visual Studio Code + extension. We will use Visual Studio Code and its Python extension. You can also use a Python IDE of your choice.</li> <li>TextBlob. TextBlob is a simplified text processing library for Python. Follow the instructions on the TextBlob site to install it on your system (install the corpora as well, as shown below):</li> </ul> <pre><code>pip install -U textblob\npython -m textblob.download_corpora\n</code></pre> <p>\ud83d\udca1 Tip: You can run Python directly in VS Code environments. Check the docs for more information.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#talking-to-machines","title":"Talking to machines","text":"<p>The history of trying to make computers understand human language goes back decades, and one of the earliest scientists to consider natural language processing was Alan Turing.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#the-turing-test","title":"The 'Turing test'","text":"<p>When Turing was researching artificial intelligence in the 1950's, he considered if a conversational test could be given to a human and computer (via typed correspondence) where the human in the conversation was not sure if they were conversing with another human or a computer.</p> <p>If, after a certain length of conversation, the human could not determine that the answers were from a computer or not, then could the computer be said to be thinking?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#the-inspiration-the-imitation-game","title":"The inspiration - 'the imitation game'","text":"<p>The idea for this came from a party game called The Imitation Game where an interrogator is alone in a room and tasked with determining which of two people (in another room) are male and female respectively. The interrogator can send notes, and must try to think of questions where the written answers reveal the gender of the mystery person. Of course, the players in the other room are trying to trick the interrogator by answering questions in such as way as to mislead or confuse the interrogator, whilst also giving the appearance of answering honestly.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#developing-eliza","title":"Developing Eliza","text":"<p>In the 1960's an MIT scientist called Joseph Weizenbaum developed Eliza, a computer 'therapist' that would ask the human questions and give the appearance of understanding their answers. However, while Eliza could parse a sentence and identify certain grammatical constructs and keywords so as to give a reasonable answer, it could not be said to understand the sentence. If Eliza was presented with a sentence following the format \"I am sad\" it might rearrange and substitute words in the sentence to form the response \"How long have you been sad\". </p> <p>This gave the impression that Eliza understood the statement and was asking a follow-on question, whereas in reality, it was changing the tense and adding some words. If Eliza could not identify a keyword that it had a response for, it would instead give a random response that could be applicable to many different statements. Eliza could be easily tricked, for instance if a user wrote \"You are a bicycle\" it might respond with \"How long have I been a bicycle?\", instead of a more reasoned response.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video about original ELIZA program</p> <p>Note: You can read the original description of Eliza published in 1966 if you have an ACM account. Alternately, read about Eliza on wikipedia</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#exercise-coding-a-basic-conversational-bot","title":"Exercise - coding a basic conversational bot","text":"<p>A conversational bot, like Eliza, is a program that elicits user input and seems to understand and respond intelligently. Unlike Eliza, our bot will not have several rules giving it the appearance of having an intelligent conversation. Instead, our bot will have one ability only, to keep the conversation going with random responses that might work in almost any trivial conversation.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#the-plan","title":"The plan","text":"<p>Your steps when building a conversational bot:</p> <ol> <li>Print instructions advising the user how to interact with the bot</li> <li>Start a loop</li> <li>Accept user input</li> <li>If user has asked to exit, then exit</li> <li>Process user input and determine response (in this case, the response is a random choice from a list of possible generic responses)</li> <li>Print response</li> <li>loop back to step 2</li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#building-the-bot","title":"Building the bot","text":"<p>Let's create the bot next. We'll start by defining some phrases.</p> <ol> <li> <p>Create this bot yourself in Python with the following random responses:</p> <pre><code>random_responses = [\"That is quite interesting, please tell me more.\",\n                    \"I see. Do go on.\",\n                    \"Why do you say that?\",\n                    \"Funny weather we've been having, isn't it?\",\n                    \"Let's change the subject.\",\n                    \"Did you catch the game last night?\"]\n</code></pre> <p>Here is some sample output to guide you (user input is on the lines starting with <code>&gt;</code>):</p> <pre><code>Hello, I am Marvin, the simple robot.\nYou can end this conversation at any time by typing 'bye'\nAfter typing each answer, press 'enter'\nHow are you today?\n&gt; I am good thanks\nThat is quite interesting, please tell me more.\n&gt; today I went for a walk     \nDid you catch the game last night?\n&gt; I did, but my team lost\nFunny weather we've been having, isn't it?\n&gt; yes but I hope next week is better\nLet's change the subject.\n&gt; ok, lets talk about music\nWhy do you say that?\n&gt; because I like music!\nWhy do you say that?\n&gt; bye\nIt was nice talking to you, goodbye!\n</code></pre> <p>One possible solution to the task is here</p> <p>\u2705 Stop and consider</p> <ol> <li>Do you think the random responses would 'trick' someone into thinking that the bot actually understood them?</li> <li>What features would the bot need to be more effective?</li> <li>If a bot could really 'understand' the meaning of a sentence, would it need to 'remember' the meaning of previous sentences in a conversation too?</li> </ol> </li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Choose one of the \"stop and consider\" elements above and either try to implement them in code or write a solution on paper using pseudocode.</p> <p>In the next lesson, you'll learn about a number of other approaches to parsing natural language and machine learning.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take a look at the references below as further reading opportunities.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#references","title":"References","text":"<ol> <li>Schubert, Lenhart, \"Computational Linguistics\", The Stanford Encyclopedia of Philosophy (Spring 2020 Edition), Edward N. Zalta (ed.), URL = https://plato.stanford.edu/archives/spr2020/entries/computational-linguistics/.</li> <li>Princeton University \"About WordNet.\" WordNet. Princeton University. 2010. </li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/1-Introduction-to-NLP/#assignment","title":"Assignment","text":"<p>Search for a bot</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/","title":"Tasks","text":""},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#common-natural-language-processing-tasks-and-techniques","title":"Common natural language processing tasks and techniques","text":"<p>For most natural language processing tasks, the text to be processed, must be broken down, examined, and the results stored or cross referenced with rules and data sets. These tasks, allows the programmer to derive the meaning or intent or only the frequency of terms and words in a text.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Let's discover common techniques used in processing text. Combined with machine learning, these techniques help you to analyse large amounts of text efficiently. Before applying ML to these tasks, however, let's understand the problems encountered by an NLP specialist.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#tasks-common-to-nlp","title":"Tasks common to NLP","text":"<p>There are different ways to analyse a text you are working on. There are tasks you can perform and through these tasks you are able to gauge an understanding of the text and draw conclusions. You usually carry out these tasks in a sequence.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#tokenization","title":"Tokenization","text":"<p>Probably the first thing most NLP algorithms have to do is to split the text into tokens, or words. While this sounds simple, having to account for punctuation and different languages' word and sentence delimiters can make it tricky. You might have to use various methods to determine demarcations.</p> <p></p> <p>Tokenizing a sentence from Pride and Prejudice. Infographic by Jen Looper</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#embeddings","title":"Embeddings","text":"<p>Word embeddings are a way to convert your text data numerically. Embeddings are done in a way so that words with a similar meaning or words used together cluster together.</p> <p></p> <p>\"I have the highest respect for your nerves, they are my old friends.\" - Word embeddings for a sentence in Pride and Prejudice. Infographic by Jen Looper</p> <p>\u2705 Try this interesting tool to experiment with word embeddings. Clicking on one word shows clusters of similar words: 'toy' clusters with 'disney', 'lego', 'playstation', and 'console'.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#parsing-part-of-speech-tagging","title":"Parsing &amp; Part-of-speech Tagging","text":"<p>Every word that has been tokenized can be tagged as a part of speech - a noun, verb, or adjective. The sentence <code>the quick red fox jumped over the lazy brown dog</code> might be POS tagged as fox = noun, jumped = verb.</p> <p></p> <p>Parsing a sentence from Pride and Prejudice. Infographic by Jen Looper</p> <p>Parsing is recognizing what words are related to each other in a sentence - for instance <code>the quick red fox jumped</code> is an adjective-noun-verb sequence that is separate from the <code>lazy brown dog</code> sequence.  </p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#word-and-phrase-frequencies","title":"Word and Phrase Frequencies","text":"<p>A useful procedure when analyzing a large body of text is to build a dictionary of every word or phrase of interest and how often it appears. The phrase <code>the quick red fox jumped over the lazy brown dog</code> has a word frequency of 2 for the.</p> <p>Let's look at an example text where we count the frequency of words. Rudyard Kipling's poem The Winners contains the following verse:</p> <pre><code>What the moral? Who rides may read.\nWhen the night is thick and the tracks are blind\nA friend at a pinch is a friend, indeed,\nBut a fool to wait for the laggard behind.\nDown to Gehenna or up to the Throne,\nHe travels the fastest who travels alone.\n</code></pre> <p>As phrase frequencies can be case insensitive or case sensitive as required, the phrase <code>a friend</code> has a frequency of 2 and <code>the</code> has a frequency of 6, and <code>travels</code> is 2.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#n-grams","title":"N-grams","text":"<p>A text can be split into sequences of words of a set length, a single word (unigram), two words (bigrams), three words (trigrams) or any number of words (n-grams).</p> <p>For instance <code>the quick red fox jumped over the lazy brown dog</code> with a n-gram score of 2 produces the following n-grams:</p> <ol> <li>the quick </li> <li>quick red </li> <li>red fox</li> <li>fox jumped </li> <li>jumped over </li> <li>over the </li> <li>the lazy </li> <li>lazy brown </li> <li>brown dog</li> </ol> <p>It might be easier to visualize it as a sliding box over the sentence. Here it is for n-grams of 3 words, the n-gram is in bold in each sentence:</p> <ol> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> <li>the quick red fox jumped over the lazy brown dog</li> </ol> <p></p> <p>N-gram value of 3: Infographic by Jen Looper</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#noun-phrase-extraction","title":"Noun phrase Extraction","text":"<p>In most sentences, there is a noun that is the subject, or object of the sentence. In English, it is often identifiable as having 'a' or 'an' or 'the' preceding it. Identifying the subject or object of a sentence by 'extracting the noun phrase' is a common task in NLP when attempting to understand the meaning of a sentence.</p> <p>\u2705 In the sentence \"I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.\", can you identify the noun phrases?</p> <p>In the sentence <code>the quick red fox jumped over the lazy brown dog</code> there are 2 noun phrases: quick red fox and lazy brown dog.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#sentiment-analysis","title":"Sentiment analysis","text":"<p>A sentence or text can be analysed for sentiment, or how positive or negative it is. Sentiment is measured in polarity and objectivity/subjectivity. Polarity is measured from -1.0 to 1.0 (negative to positive) and 0.0 to 1.0 (most objective to most subjective).</p> <p>\u2705 Later you'll learn that there are different ways to determine sentiment using machine learning, but one way is to have a list of words and phrases that are categorized as positive or negative by a human expert and apply that model to text to calculate a polarity score. Can you see how this would work in some circumstances and less well in others?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#inflection","title":"Inflection","text":"<p>Inflection enables you to take a word and get the singular or plural of the word.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#lemmatization","title":"Lemmatization","text":"<p>A lemma is the root or headword for a set of words, for instance flew, flies, flying have a lemma of the verb fly.</p> <p>There are also useful databases available for the NLP researcher, notably:</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#wordnet","title":"WordNet","text":"<p>WordNet is a database of words, synonyms, antonyms and many other details for every word in many different languages. It is incredibly useful when attempting to build translations, spell checkers, or language tools of any type.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#nlp-libraries","title":"NLP Libraries","text":"<p>Luckily, you don't have to build all of these techniques yourself, as there are excellent Python libraries available that make it much more accessible to developers who aren't specialized in natural language processing or machine learning. The next lessons include more examples of these, but here you will learn some useful examples to help you with the next task.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#exercise-using-textblob-library","title":"Exercise - using <code>TextBlob</code> library","text":"<p>Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob \"stands on the giant shoulders of NLTK and pattern, and plays nicely with both.\" It has a considerable amount of ML embedded in its API.</p> <p>Note: A useful Quick Start guide is available for TextBlob that is recommended for experienced Python developers </p> <p>When attempting to identify noun phrases, TextBlob offers several options of extractors to find noun phrases. </p> <ol> <li> <p>Take a look at <code>ConllExtractor</code>.</p> <pre><code>from textblob import TextBlob\nfrom textblob.np_extractors import ConllExtractor\n# import and create a Conll extractor to use later \nextractor = ConllExtractor()\n\n# later when you need a noun phrase extractor:\nuser_input = input(\"&gt; \")\nuser_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified\nnp = user_input_blob.noun_phrases                                    \n</code></pre> <p>What's going on here? ConllExtractor is \"A noun phrase extractor that uses chunk parsing trained with the ConLL-2000 training corpus.\" ConLL-2000 refers to the 2000 Conference on Computational Natural Language Learning. Each year the conference hosted a workshop to tackle a thorny NLP problem, and in 2000 it was noun chunking. A model was trained on the Wall Street Journal, with \"sections 15-18 as training data (211727 tokens) and section 20 as test data (47377 tokens)\". You can look at the procedures used here and the results.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#challenge-improving-your-bot-with-nlp","title":"Challenge - improving your bot with NLP","text":"<p>In the previous lesson you built a very simple Q&amp;A bot. Now, you'll make Marvin a bit more sympathetic by analyzing your input for sentiment and printing out a response to match the sentiment. You'll also need to identify a <code>noun_phrase</code> and ask about it.</p> <p>Your steps when building a better conversational bot:</p> <ol> <li>Print instructions advising the user how to interact with the bot</li> <li>Start loop </li> <li>Accept user input</li> <li>If user has asked to exit, then exit</li> <li>Process user input and determine appropriate sentiment response</li> <li>If a noun phrase is detected in the sentiment, pluralize it and ask for more input on that topic</li> <li>Print response</li> <li>loop back to step 2</li> </ol> <p>Here is the code snippet to determine sentiment using TextBlob. Note there are only four gradients of sentiment response (you could have more if you like):</p> <pre><code>if user_input_blob.polarity &lt;= -0.5:\n  response = \"Oh dear, that sounds bad. \"\nelif user_input_blob.polarity &lt;= 0:\n  response = \"Hmm, that's not great. \"\nelif user_input_blob.polarity &lt;= 0.5:\n  response = \"Well, that sounds positive. \"\nelif user_input_blob.polarity &lt;= 1:\n  response = \"Wow, that sounds great. \"\n</code></pre> <p>Here is some sample output to guide you (user input is on the lines with starting with &gt;):</p> <pre><code>Hello, I am Marvin, the friendly robot.\nYou can end this conversation at any time by typing 'bye'\nAfter typing each answer, press 'enter'\nHow are you today?\n&gt; I am ok\nWell, that sounds positive. Can you tell me more?\n&gt; I went for a walk and saw a lovely cat\nWell, that sounds positive. Can you tell me more about lovely cats?\n&gt; cats are the best. But I also have a cool dog\nWow, that sounds great. Can you tell me more about cool dogs?\n&gt; I have an old hounddog but he is sick\nHmm, that's not great. Can you tell me more about old hounddogs?\n&gt; bye\nIt was nice talking to you, goodbye!\n</code></pre> <p>One possible solution to the task is here</p> <p>\u2705 Knowledge Check</p> <ol> <li>Do you think the sympathetic responses would 'trick' someone into thinking that the bot actually understood them?</li> <li>Does identifying the noun phrase make the bot more 'believable'?</li> <li>Why would extracting a 'noun phrase' from a sentence a useful thing to do?</li> </ol> <p>Implement the bot in the prior knowledge check and test it on a friend. Can it trick them? Can you make your bot more 'believable?'</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Take a task in the prior knowledge check and try to implement it. Test the bot on a friend. Can it trick them? Can you make your bot more 'believable?'</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#review-self-study","title":"Review &amp; Self Study","text":"<p>In the next few lessons you will learn more about sentiment analysis. Research this interesting technique in articles such as these on KDNuggets</p>"},{"location":"curricula/ml-for-beginners/6-NLP/2-Tasks/#assignment","title":"Assignment","text":"<p>Make a bot talk back</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/","title":"Translation Sentiment","text":""},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#translation-and-sentiment-analysis-with-ml","title":"Translation and sentiment analysis with ML","text":"<p>In the previous lessons you learned how to build a basic bot using <code>TextBlob</code>, a library that embeds ML behind-the-scenes to perform basic NLP tasks such as noun phrase extraction. Another important challenge in computational linguistics is accurate translation of a sentence from one spoken or written language to another.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>Translation is a very hard problem compounded by the fact that there are thousands of languages and each can have very different grammar rules. One approach is to convert the formal grammar rules for one language, such as English, into a non-language dependent structure, and then translate it by converting back to another language. This approach means that you would take the following steps:</p> <ol> <li>Identification. Identify or tag the words in input language into nouns, verbs etc.</li> <li>Create translation. Produce a direct translation of each word in the target language format.</li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#example-sentence-english-to-irish","title":"Example sentence, English to Irish","text":"<p>In 'English', the sentence I feel happy is three words in the order:</p> <ul> <li>subject (I)</li> <li>verb (feel)</li> <li>adjective (happy)</li> </ul> <p>However, in the 'Irish' language, the same sentence has a very different grammatical structure - emotions like \"happy\" or \"sad\" are expressed as being upon you.</p> <p>The English phrase <code>I feel happy</code> in Irish would be <code>T\u00e1 athas orm</code>. A literal translation would be <code>Happy is upon me</code>.</p> <p>An Irish speaker translating to English would say <code>I feel happy</code>, not <code>Happy is upon me</code>, because they understand the meaning of the sentence, even if the words and sentence structure are different.</p> <p>The formal order for the sentence in Irish are:</p> <ul> <li>verb (T\u00e1 or is)</li> <li>adjective (athas, or happy)</li> <li>subject (orm, or upon me)</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#translation","title":"Translation","text":"<p>A naive translation program might translate words only, ignoring the sentence structure.</p> <p>\u2705 If you've learned a second (or third or more) language as an adult, you might have started by thinking in your native language, translating a concept word by word in your head to the second language, and then speaking out your translation. This is similar to what naive translation computer programs are doing. It's important to get past this phase to attain fluency!</p> <p>Naive translation leads to bad (and sometimes hilarious) mistranslations: <code>I feel happy</code> translates literally to <code>Mise bhraitheann athas</code> in Irish. That means (literally) <code>me feel happy</code> and is not a valid Irish sentence. Even though English and Irish are languages spoken on two closely neighboring islands, they are very different languages with different grammar structures.</p> <p>You can watch some videos about Irish linguistic traditions such as this one</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#machine-learning-approaches","title":"Machine learning approaches","text":"<p>So far, you've learned about the formal rules approach to natural language processing. Another approach is to ignore the meaning of the words, and instead use machine learning to detect patterns. This can work in translation if you have lots of text (a corpus) or texts (corpora) in both the origin and target languages.</p> <p>For instance, consider the case of Pride and Prejudice, a well-known English novel written by Jane Austen in 1813. If you consult the book in English and a human translation of the book in French, you could detect phrases in one that are idiomatically translated into the other. You'll do that in a minute.</p> <p>For instance, when an English phrase such as <code>I have no money</code> is translated literally to French, it might become <code>Je n'ai pas de monnaie</code>. \"Monnaie\" is a tricky french 'false cognate', as 'money' and 'monnaie' are not synonymous. A better translation that a human might make would be <code>Je n'ai pas d'argent</code>, because it better conveys the meaning that you have no money (rather than 'loose change' which is the meaning of 'monnaie').</p> <p></p> <p>Image by Jen Looper</p> <p>If an ML model has enough human translations to build a model on, it can improve the accuracy of translations by identifying common patterns in texts that have been previously translated by expert human speakers of both languages.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#exercise-translation","title":"Exercise - translation","text":"<p>You can use <code>TextBlob</code> to translate sentences. Try the famous first line of Pride and Prejudice:</p> <pre><code>from textblob import TextBlob\n\nblob = TextBlob(\n    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife!\"\n)\nprint(blob.translate(to=\"fr\"))\n</code></pre> <p><code>TextBlob</code> does a pretty good job at the translation: \"C'est une v\u00e9rit\u00e9 universellement reconnue, qu'un homme c\u00e9libataire en possession d'une bonne fortune doit avoir besoin d'une femme!\". </p> <p>It can be argued that TextBlob's translation is far more exact, in fact, than the 1932 French translation of the book by V. Leconte and Ch. Pressoir:</p> <p>\"C'est une v\u00e9rit\u00e9 universelle qu'un c\u00e9libataire pourvu d'une belle fortune doit avoir envie de se marier, et, si peu que l'on sache de son sentiment \u00e0 cet egard, lorsqu'il arrive dans une nouvelle r\u00e9sidence, cette id\u00e9e est si bien fix\u00e9e dans l'esprit de ses voisins qu'ils le consid\u00e8rent sur-le-champ comme la propri\u00e9t\u00e9 l\u00e9gitime de l'une ou l'autre de leurs filles.\"</p> <p>In this case, the translation informed by ML does a better job than the human translator who is unnecessarily putting words in the original author's mouth for 'clarity'.</p> <p>What's going on here? and why is TextBlob so good at translation? Well, behind the scenes, it's using Google translate, a sophisticated AI able to parse millions of phrases to predict the best strings for the task at hand. There's nothing manual going on here and you need an internet connection to use <code>blob.translate</code>.</p> <p>\u2705 Try some more sentences. Which is better, ML or human translation? In which cases?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#sentiment-analysis","title":"Sentiment analysis","text":"<p>Another area where machine learning can work very well is sentiment analysis. A non-ML approach to sentiment is to identify words and phrases which are 'positive' and 'negative'. Then, given a new piece of text, calculate the total value of the positive, negative and neutral words to identify the overall sentiment. </p> <p>This approach is easily tricked as you may have seen in the Marvin task - the sentence <code>Great, that was a wonderful waste of time, I'm glad we are lost on this dark road</code> is a sarcastic, negative sentiment sentence, but the simple algorithm detects 'great', 'wonderful', 'glad' as positive and 'waste', 'lost' and 'dark' as negative. The overall sentiment is swayed by these conflicting words.</p> <p>\u2705 Stop a second and think about how we convey sarcasm as human speakers. Tone inflection plays a large role. Try to say the phrase \"Well, that film was awesome\" in different ways to discover how your voice conveys meaning.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#ml-approaches","title":"ML approaches","text":"<p>The ML approach would be to manually gather negative and positive bodies of text - tweets, or movie reviews, or anything where the human has given a score and a written opinion. Then NLP techniques can be applied to opinions and scores, so that patterns emerge (e.g., positive movie reviews tend to have the phrase 'Oscar worthy' more than negative movie reviews, or positive restaurant reviews say 'gourmet' much more than 'disgusting').</p> <p>\u2696\ufe0f Example: If you worked in a politician's office and there was some new law being debated, constituents might write to the office with emails supporting or emails against the particular new law. Let's say you are tasked with reading the emails and sorting them in 2 piles, for and against. If there were a lot of emails, you might be overwhelmed attempting to read them all. Wouldn't it be nice if a bot could read them all for you, understand them and tell you in which pile each email belonged? </p> <p>One way to achieve that is to use Machine Learning. You would train the model with a portion of the against emails and a portion of the for emails. The model would tend to associate phrases and words with the against side and the for side, but it would not understand any of the content, only that certain words and patterns were more likely to appear in an against or a for email. You could test it with some emails that you had not used to train the model, and see if it came to the same conclusion as you did. Then, once you were happy with the accuracy of the model, you could process future emails without having to read each one.</p> <p>\u2705 Does this process sound like processes you have used in previous lessons?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#exercise-sentimental-sentences","title":"Exercise - sentimental sentences","text":"<p>Sentiment is measured in with a polarity of -1 to 1, meaning -1 is the most negative sentiment, and 1 is the most positive. Sentiment is also measured with an 0 - 1 score for objectivity (0) and subjectivity (1).</p> <p>Take another look at Jane Austen's Pride and Prejudice. The text is available here at Project Gutenberg. The sample below shows a short program which analyses the sentiment of first and last sentences from the book and display its sentiment polarity and subjectivity/objectivity score.</p> <p>You should use the <code>TextBlob</code> library (described above) to determine <code>sentiment</code> (you do not have to write your own sentiment calculator) in the following task.</p> <pre><code>from textblob import TextBlob\n\nquote1 = \"\"\"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\"\"\n\nquote2 = \"\"\"Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them.\"\"\"\n\nsentiment1 = TextBlob(quote1).sentiment\nsentiment2 = TextBlob(quote2).sentiment\n\nprint(quote1 + \" has a sentiment of \" + str(sentiment1))\nprint(quote2 + \" has a sentiment of \" + str(sentiment2))\n</code></pre> <p>You see the following output:</p> <pre><code>It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want # of a wife. has a sentiment of Sentiment(polarity=0.20952380952380953, subjectivity=0.27142857142857146)\n\nDarcy, as well as Elizabeth, really loved them; and they were\n     both ever sensible of the warmest gratitude towards the persons\n      who, by bringing her into Derbyshire, had been the means of\n      uniting them. has a sentiment of Sentiment(polarity=0.7, subjectivity=0.8)\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#challenge-check-sentiment-polarity","title":"Challenge - check sentiment polarity","text":"<p>Your task is to determine, using sentiment polarity, if Pride and Prejudice has more absolutely positive sentences than absolutely negative ones. For this task, you may assume that a polarity score of 1 or -1 is absolutely positive or negative respectively.</p> <p>Steps:</p> <ol> <li>Download a copy of Pride and Prejudice from Project Gutenberg as a .txt file. Remove the metadata at the start and end of the file, leaving only the original text</li> <li>Open the file in Python and extract the contents as a string</li> <li>Create a TextBlob using the book string</li> <li>Analyse each sentence in the book in a loop</li> <li>If the polarity is 1 or -1 store the sentence in an array or list of positive or negative messages</li> <li>At the end, print out all the positive sentences and negative sentences (separately) and the number of each.</li> </ol> <p>Here is a sample solution.</p> <p>\u2705 Knowledge Check</p> <ol> <li>The sentiment is based on words used in the sentence, but does the code understand the words?</li> <li>Do you think the sentiment polarity is accurate, or in other words, do you agree with the scores?</li> <li>In particular, do you agree or disagree with the absolute positive polarity of the following sentences?<ul> <li>\u201cWhat an excellent father you have, girls!\u201d said she, when the door was shut.</li> <li>\u201cYour examination of Mr. Darcy is over, I presume,\u201d said Miss Bingley; \u201cand pray what is the result?\u201d \u201cI am perfectly convinced by it that Mr. Darcy has no defect.</li> <li>How wonderfully these sort of things occur!</li> <li>I have the greatest dislike in the world to that sort of thing.</li> <li>Charlotte is an excellent manager, I dare say.</li> <li>\u201cThis is delightful indeed!</li> <li>I am so happy!</li> <li>Your idea of the ponies is delightful.</li> </ul> </li> <li>The next 3 sentences were scored with an absolute positive sentiment, but on close reading, they are not positive sentences. Why did the sentiment analysis think they were positive sentences?<ul> <li>Happy shall I be, when his stay at Netherfield is over!\u201d \u201cI wish I could say anything to comfort you,\u201d replied Elizabeth; \u201cbut it is wholly out of my power.</li> <li>If I could but see you as happy!</li> <li>Our distress, my dear Lizzy, is very great.</li> </ul> </li> <li>Do you agree or disagree with the absolute negative polarity of the following sentences?<ul> <li>Everybody is disgusted with his pride.</li> <li>\u201cI should like to know how he behaves among strangers.\u201d \u201cYou shall hear then\u2014but prepare yourself for something very dreadful.</li> <li>The pause was to Elizabeth\u2019s feelings dreadful.</li> <li>It would be dreadful!</li> </ul> </li> </ol> <p>\u2705 Any aficionado of Jane Austen will understand that she often uses her books to critique the more ridiculous aspects of English Regency society. Elizabeth Bennett, the main character in Pride and Prejudice, is a keen social observer (like the author) and her language is often heavily nuanced. Even Mr. Darcy (the love interest in the story) notes Elizabeth's playful and teasing use of language: \"I have had the pleasure of your acquaintance long enough to know that you find great enjoyment in occasionally professing opinions which in fact are not your own.\"</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Can you make Marvin even better by extracting other features from the user input?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#review-self-study","title":"Review &amp; Self Study","text":"<p>There are many ways to extract sentiment from text. Think of the business applications that might make use of this technique. Think about how it can go awry. Read more about sophisticated enterprise-ready systems that analyze sentiment such as Azure Text Analysis. Test some of the Pride and Prejudice sentences above and see if it can detect nuance.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/#assignment","title":"Assignment","text":"<p>Poetic license</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/assignment/#poetic-license","title":"Poetic license","text":""},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/assignment/#instructions","title":"Instructions","text":"<p>In this notebook you can find over 500 Emily Dickinson poems previously analyzed for sentiment using Azure text analytics. Using this dataset, analyze it using the techniques described in the lesson. Does the suggested sentiment of a poem match the more sophistic Azure service's decision? Why or why not, in your opinion? Does anything surprise you?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with a solid analysis of an author's sample output The notebook is incomplete or does not perform analysis No notebook is presented"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/6-NLP/3-Translation-Sentiment/solution/R/","title":"Index","text":"<p>this is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/","title":"Hotel Reviews 1","text":""},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#sentiment-analysis-with-hotel-reviews-processing-the-data","title":"Sentiment analysis with hotel reviews - processing the data","text":"<p>In this section you will use the techniques in the previous lessons to do some exploratory data analysis of a large dataset. Once you have a good understanding of the usefulness of the various columns, you will learn: </p> <ul> <li>how to remove the unnecessary columns</li> <li>how to calculate some new data based on the existing columns</li> <li>how to save the resulting dataset for use in the final challenge</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#introduction","title":"Introduction","text":"<p>So far you've learned about how text data is quite unlike numerical types of data. If it's text that was written or spoken by a human, if can be analysed to find patterns and frequencies, sentiment and meaning. This lesson takes you into a real data set with a real challenge: 515K Hotel Reviews Data in Europe and includes a CC0: Public Domain license. It was scraped from Booking.com from public sources. The creator of the dataset was Jiashen Liu.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#preparation","title":"Preparation","text":"<p>You will need:</p> <ul> <li>The ability to run .ipynb notebooks using Python 3</li> <li>pandas</li> <li>NLTK, which you should install locally</li> <li>The data set which is available on Kaggle 515K Hotel Reviews Data in Europe. It is around 230 MB unzipped. Download it to the root <code>/data</code> folder associated with these NLP lessons.</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#exploratory-data-analysis","title":"Exploratory data analysis","text":"<p>This challenge assumes that you are building a hotel recommendation bot using sentiment analysis and guest reviews scores. The dataset you will be using includes reviews of 1493 different hotels in 6 cities. </p> <p>Using Python, a dataset of hotel reviews, and NLTK's sentiment analysis you could find out:</p> <ul> <li>What are the most frequently used words and phrases in reviews?</li> <li>Do the official tags describing a hotel correlate with review scores (e.g. are the more negative reviews for a particular hotel for  Family with young children than by Solo traveller, perhaps indicating it is better for Solo travellers?)</li> <li>Do the NLTK sentiment scores 'agree' with the hotel reviewer's numerical score?</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#dataset","title":"Dataset","text":"<p>Let's explore the dataset that you've downloaded and saved locally. Open the file in an editor like VS Code or even Excel.</p> <p>The headers in the dataset are as follows:</p> <p>Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng</p> <p>Here they are grouped in a way that might be easier to examine: </p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#hotel-columns","title":"Hotel columns","text":"<ul> <li><code>Hotel_Name</code>, <code>Hotel_Address</code>, <code>lat</code> (latitude), <code>lng</code> (longitude)</li> <li>Using lat and lng you could plot a map with Python showing the hotel locations (perhaps color coded for negative and positive reviews)</li> <li>Hotel_Address is not obviously useful to us, and we'll probably replace that with a country for easier sorting &amp; searching</li> </ul> <p>Hotel Meta-review columns</p> <ul> <li><code>Average_Score</code></li> <li>According to the dataset creator, this column is the Average Score of the hotel, calculated based on the latest comment in the last year. This seems like an unusual way to calculate the score, but it is the data scraped so we may take it as face value for now. </li> </ul> <p>\u2705 Based on the other columns in this data, can you think of another way to calculate the average score?</p> <ul> <li><code>Total_Number_of_Reviews</code></li> <li>The total number of reviews this hotel has received - it is not clear (without writing some code) if this refers to the reviews in the dataset.</li> <li><code>Additional_Number_of_Scoring</code></li> <li>This means a review score was given but no positive or negative review was written by the reviewer</li> </ul> <p>Review columns</p> <ul> <li><code>Reviewer_Score</code></li> <li>This is a numerical value with at most 1 decimal place between the min and max values 2.5 and 10</li> <li>It is not explained why 2.5 is the lowest score possible</li> <li><code>Negative_Review</code></li> <li>If a reviewer wrote nothing, this field will have \"No Negative\"</li> <li>Note that a reviewer may write a positive review in the Negative review column (e.g. \"there is nothing bad about this hotel\")</li> <li><code>Review_Total_Negative_Word_Counts</code></li> <li>Higher negative word counts indicate a lower score (without checking the sentimentality)</li> <li><code>Positive_Review</code></li> <li>If a reviewer wrote nothing, this field will have \"No Positive\"</li> <li>Note that a reviewer may write a negative review in the Positive review column (e.g. \"there is nothing good about this hotel at all\")</li> <li><code>Review_Total_Positive_Word_Counts</code></li> <li>Higher positive word counts indicate a higher score (without checking the sentimentality)</li> <li><code>Review_Date</code> and <code>days_since_review</code></li> <li>A freshness or staleness measure might be applied to a review (older reviews might not be as accurate as newer ones because hotel management changed, or renovations have been done, or a pool was added etc.)</li> <li><code>Tags</code></li> <li>These are short descriptors that a reviewer may select to describe the type of guest they were (e.g. solo or family), the type of room they had, the length of stay and how the review was submitted. </li> <li>Unfortunately, using these tags is problematic, check the section below which discusses their usefulness</li> </ul> <p>Reviewer columns</p> <ul> <li><code>Total_Number_of_Reviews_Reviewer_Has_Given</code></li> <li>This might be a factor in a recommendation model, for instance, if you could determine that more prolific reviewers with hundreds of reviews were more likely to be negative rather than positive. However, the reviewer of any particular review is not identified with a unique code, and therefore cannot be linked to a set of reviews. There are 30 reviewers with 100 or more reviews, but it's hard to see how this can aid the recommendation model.</li> <li><code>Reviewer_Nationality</code></li> <li>Some people might think that certain nationalities are more likely to give a positive or negative review because of a national inclination. Be careful building such anecdotal views into your models. These are national (and sometimes racial) stereotypes, and each reviewer was an individual who wrote a review based on their experience. It may have been filtered through many lenses such as their previous hotel stays, the distance travelled, and their personal temperament. Thinking that their nationality was the reason for a review score is hard to justify.</li> </ul>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#examples","title":"Examples","text":"Average  Score Total Number   Reviews Reviewer   Score Negative Review Positive   Review Tags 7.8 1945 2.5 This is  currently not a hotel but a construction site I was terrorized from early  morning and all day with unacceptable building noise while resting after a  long trip and working in the room People were working all day i e with  jackhammers in the adjacent rooms I asked for a room change but no silent  room was available To make things worse I was overcharged I checked out in  the evening since I had to leave very early flight and received an appropriate  bill A day later the hotel made another charge without my consent in excess  of booked price It's a terrible place Don't punish yourself by booking  here Nothing  Terrible place Stay away Business trip                                Couple Standard Double  Room Stayed 2 nights <p>As you can see, this guest did not have a happy stay at this hotel. The hotel has a good average score of 7.8 and 1945 reviews, but this reviewer gave it 2.5 and wrote 115 words about how negative their stay was. If they wrote nothing at all in the Positive_Review column, you might surmise there was nothing positive, but alas they wrote 7 words of warning. If we just counted words instead of the meaning, or sentiment of the words, we might have a skewed view of the reviewer's intent. Strangely, their score of 2.5 is confusing, because if that hotel stay was so bad, why give it any points at all? Investigating the dataset closely, you'll see that the lowest possible score is 2.5, not 0. The highest possible score is 10.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#tags","title":"Tags","text":"<p>As mentioned above, at first glance, the idea to use <code>Tags</code> to categorize the data makes sense. Unfortunately these tags are not standardized, which means that in a given hotel, the options might be Single room, Twin room, and Double room, but in the next hotel, they are Deluxe Single Room, Classic Queen Room, and Executive King Room. These might be the same things, but there are so many variations that the choice becomes:</p> <ol> <li> <p>Attempt to change all terms to a single standard, which is very difficult, because it is not clear what the conversion path would be in each case (e.g. Classic single room maps to Single room but Superior Queen Room with Courtyard Garden or City View is much harder to map)</p> </li> <li> <p>We can take an NLP approach and measure the frequency of certain terms like Solo, Business Traveller, or Family with young kids as they apply to each hotel, and factor that into the recommendation  </p> </li> </ol> <p>Tags are usually (but not always) a single field containing a list of 5 to 6 comma separated values aligning to Type of trip, Type of guests, Type of room, Number of nights, and Type of device review was submitted on. However, because some reviewers don't fill in each field (they might leave one blank), the values are not always in the same order.</p> <p>As an example, take Type of group. There are 1025 unique possibilities in this field in the <code>Tags</code> column, and unfortunately only some of them refer to a group (some are the type of room etc.). If you filter only the ones that mention family, the results contain many Family room type results. If you include the term with, i.e. count the Family with values, the results are better, with over 80,000 of the 515,000 results containing the phrase \"Family with young children\" or \"Family with older children\".</p> <p>This means the tags column is not completely useless to us, but it will take some work to make it useful.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#average-hotel-score","title":"Average hotel score","text":"<p>There are a number of oddities or discrepancies with the data set that I can't figure out, but are illustrated here so you are aware of them when building your models. If you figure it out, please let us know in the discussion section!</p> <p>The dataset has the following columns relating to the average score and number of reviews: </p> <ol> <li>Hotel_Name</li> <li>Additional_Number_of_Scoring</li> <li>Average_Score</li> <li>Total_Number_of_Reviews</li> <li>Reviewer_Score  </li> </ol> <p>The single hotel with the most reviews in this dataset is Britannia International Hotel Canary Wharf with 4789 reviews out of 515,000. But if we look at the <code>Total_Number_of_Reviews</code> value for this hotel, it is 9086. You might surmise that there are many more scores without reviews, so perhaps we should add in the <code>Additional_Number_of_Scoring</code> column value. That value is 2682, and adding it to 4789 gets us 7,471 which is still 1615 short of the <code>Total_Number_of_Reviews</code>. </p> <p>If you take the <code>Average_Score</code> columns, you might surmise it is the average of the reviews in the dataset, but the description from Kaggle is \"Average Score of the hotel, calculated based on the latest comment in the last year\". That doesn't seem that useful, but we can calculate our own average based on the reviews scores in the data set. Using the same hotel as an example, the average hotel score is given as 7.1 but the calculated score (average reviewer score in the dataset) is 6.8. This is close, but not the same value, and we can only guess that the scores given in the <code>Additional_Number_of_Scoring</code> reviews increased the average to 7.1. Unfortunately with no way to test or prove that assertion, it is difficult to use or trust <code>Average_Score</code>, <code>Additional_Number_of_Scoring</code> and <code>Total_Number_of_Reviews</code> when they are based on, or refer to, data we do not have.</p> <p>To complicate things further, the hotel with the second highest number of reviews has a calculated average score of 8.12 and the dataset <code>Average_Score</code> is 8.1. Is this correct score a coincidence or is the first hotel a discrepancy? </p> <p>On the possibility that these hotel might be an outlier, and that maybe most of the values tally up (but some do not for some reason) we will write a short program next to explore the values in the dataset and determine the correct usage (or non-usage) of the values.</p> <p>\ud83d\udea8 A note of caution</p> <p>When working with this dataset you will write code that calculates something from the text without having to read or analyse the text yourself. This is the essence of NLP, interpreting meaning or sentiment without having to have a human do it. However, it is possible that you will read some of the negative reviews. I would urge you not to, because you don't have to. Some of them are silly, or irrelevant negative hotel reviews, such as  \"The weather wasn't great\", something beyond the control of the hotel, or indeed, anyone. But there is a dark side to some reviews too. Sometimes the negative reviews are racist, sexist, or ageist. This is unfortunate but to be expected in a dataset scraped off a public website. Some reviewers leave reviews that you would find distasteful, uncomfortable, or upsetting. Better to let the code measure the sentiment than read them yourself and be upset. That said, it is a minority that write such things, but they exist all the same. </p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#exercise-data-exploration","title":"Exercise -  Data exploration","text":""},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#load-the-data","title":"Load the data","text":"<p>That's enough examining the data visually, now you'll write some code and get some answers! This section uses the pandas library. Your very first task is to ensure you can load and read the CSV data. The pandas library has a fast CSV loader, and the result is placed in a dataframe, as in previous lessons. The CSV we are loading has over half a million rows, but only 17 columns. Pandas gives you lots of powerful ways to interact with a dataframe, including the ability to perform operations on every row. </p> <p>From here on in this lesson, there will be code snippets and some explanations of the code and some discussion about what the results mean. Use the included notebook.ipynb for your code.</p> <p>Let's start with loading the data file you be using:</p> <pre><code># Load the hotel reviews from CSV\nimport pandas as pd\nimport time\n# importing time so the start and end time can be used to calculate file loading time\nprint(\"Loading data file now, this could take a while depending on file size\")\nstart = time.time()\n# df is 'DataFrame' - make sure you downloaded the file to the data folder\ndf = pd.read_csv('../../data/Hotel_Reviews.csv')\nend = time.time()\nprint(\"Loading took \" + str(round(end - start, 2)) + \" seconds\")\n</code></pre> <p>Now that the data is loaded, we can perform some operations on it. Keep this code at the top of your program for the next part.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#explore-the-data","title":"Explore the data","text":"<p>In this case, the data is already clean, that means that it is ready to work with, and does not have characters in other languages that might trip up algorithms expecting only English characters. </p> <p>\u2705 You might have to work with data that required some initial processing to format it before applying NLP techniques, but not this time. If you had to, how would you handle non-English characters?</p> <p>Take a moment to ensure that once the data is loaded, you can explore it with code. It's very easy to want to focus on the <code>Negative_Review</code> and <code>Positive_Review</code> columns. They are filled with natural text for your NLP algorithms to process. But wait! Before you jump into the NLP and sentiment, you should follow the code below to ascertain if the values given in the dataset match the values you calculate with pandas.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#dataframe-operations","title":"Dataframe operations","text":"<p>The first task in this lesson is to check if the following assertions are correct by writing some code that examines the data frame (without changing it).</p> <p>Like many programming tasks, there are several ways to complete this, but good advice is to do it in the simplest, easiest way you can, especially if it will be easier to understand when you come back to this code in the future. With dataframes, there is a comprehensive API that will often have a way to do what you want efficiently.</p> <p>Treat the following questions as coding tasks and attempt to answer them without looking at the solution. </p> <ol> <li>Print out the shape of the data frame you have just loaded (the shape is the number of rows and columns)</li> <li>Calculate the frequency count for reviewer nationalities:</li> <li>How many distinct values are there for the column <code>Reviewer_Nationality</code> and what are they?</li> <li>What reviewer nationality is the most common in the dataset (print country and number of reviews)?</li> <li>What are the next top 10 most frequently found nationalities, and their frequency count?</li> <li>What was the most frequently reviewed hotel for each of the top 10 most reviewer nationalities?</li> <li>How many reviews are there per hotel (frequency count of hotel) in the dataset?</li> <li>While there is an <code>Average_Score</code> column for each hotel in the dataset, you can also calculate an average score (getting the average of all reviewer scores in the dataset for each hotel). Add a new column to your dataframe with the column header <code>Calc_Average_Score</code> that contains that calculated average. </li> <li>Do any hotels have the same (rounded to 1 decimal place) <code>Average_Score</code> and <code>Calc_Average_Score</code>?</li> <li>Try writing a Python function that takes a Series (row) as an argument and compares the values, printing out a message when the values are not equal. Then use the <code>.apply()</code> method to process every row with the function.</li> <li>Calculate and print out how many rows have column <code>Negative_Review</code> values of \"No Negative\" </li> <li>Calculate and print out how many rows have column <code>Positive_Review</code> values of \"No Positive\"</li> <li>Calculate and print out how many rows have column <code>Positive_Review</code> values of \"No Positive\" and <code>Negative_Review</code> values of \"No Negative\"</li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#code-answers","title":"Code answers","text":"<ol> <li>Print out the shape of the data frame you have just loaded (the shape is the number of rows and columns)</li> </ol> <pre><code>print(\"The shape of the data (rows, cols) is \" + str(df.shape))\n&gt; The shape of the data (rows, cols) is (515738, 17)\n</code></pre> <ol> <li> <p>Calculate the frequency count for reviewer nationalities:</p> </li> <li> <p>How many distinct values are there for the column <code>Reviewer_Nationality</code> and what are they?</p> </li> <li>What reviewer nationality is the most common in the dataset (print country and number of reviews)?</li> </ol> <pre><code># value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality\nnationality_freq = df[\"Reviewer_Nationality\"].value_counts()\nprint(\"There are \" + str(nationality_freq.size) + \" different nationalities\")\n# print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data\nprint(nationality_freq) \n\nThere are 227 different nationalities\n United Kingdom               245246\n United States of America      35437\n Australia                     21686\n Ireland                       14827\n United Arab Emirates          10235\n                               ...  \n Comoros                           1\n Palau                             1\n Northern Mariana Islands          1\n Cape Verde                        1\n Guinea                            1\nName: Reviewer_Nationality, Length: 227, dtype: int64\n</code></pre> <ol> <li> <p>What are the next top 10 most frequently found nationalities, and their frequency count?</p> <pre><code>print(\"The highest frequency reviewer nationality is \" + str(nationality_freq.index[0]).strip() + \" with \" + str(nationality_freq[0]) + \" reviews.\")\n# Notice there is a leading space on the values, strip() removes that for printing\n# What is the top 10 most common nationalities and their frequencies?\nprint(\"The next 10 highest frequency reviewer nationalities are:\")\nprint(nationality_freq[1:11].to_string())\n\nThe highest frequency reviewer nationality is United Kingdom with 245246 reviews.\nThe next 10 highest frequency reviewer nationalities are:\n United States of America     35437\n Australia                    21686\n Ireland                      14827\n United Arab Emirates         10235\n Saudi Arabia                  8951\n Netherlands                   8772\n Switzerland                   8678\n Germany                       7941\n Canada                        7894\n France                        7296\n</code></pre> </li> <li> <p>What was the most frequently reviewed hotel for each of the top 10 most reviewer nationalities?</p> </li> </ol> <pre><code># What was the most frequently reviewed hotel for the top 10 nationalities\n# Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)\nfor nat in nationality_freq[:10].index:\n   # First, extract all the rows that match the criteria into a new dataframe\n   nat_df = df[df[\"Reviewer_Nationality\"] == nat]   \n   # Now get the hotel freq\n   freq = nat_df[\"Hotel_Name\"].value_counts()\n   print(\"The most reviewed hotel for \" + str(nat).strip() + \" was \" + str(freq.index[0]) + \" with \" + str(freq[0]) + \" reviews.\") \n\nThe most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.\nThe most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.\nThe most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.\nThe most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.\nThe most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.\nThe most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.\nThe most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.\nThe most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.\nThe most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.\nThe most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.\n</code></pre> <ol> <li>How many reviews are there per hotel (frequency count of hotel) in the dataset?</li> </ol> <p></p><pre><code># First create a new dataframe based on the old one, removing the uneeded columns\nhotel_freq_df = df.drop([\"Hotel_Address\", \"Additional_Number_of_Scoring\", \"Review_Date\", \"Average_Score\", \"Reviewer_Nationality\", \"Negative_Review\", \"Review_Total_Negative_Word_Counts\", \"Positive_Review\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"Tags\", \"days_since_review\", \"lat\", \"lng\"], axis = 1)\n\n# Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found\nhotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')\n\n# Get rid of all the duplicated rows\nhotel_freq_df = hotel_freq_df.drop_duplicates(subset = [\"Hotel_Name\"])\ndisplay(hotel_freq_df) \n</code></pre>    |                 Hotel_Name                 | Total_Number_of_Reviews | Total_Reviews_Found |    | :----------------------------------------: | :---------------------: | :-----------------: |    | Britannia International Hotel Canary Wharf |          9086           |        4789         |    |    Park Plaza Westminster Bridge London    |          12158          |        4169         |    |   Copthorne Tara Hotel London Kensington   |          7105           |        3578         |    |                    ...                     |           ...           |         ...         |    |       Mercure Paris Porte d Orleans        |           110           |         10          |    |                Hotel Wagner                |           135           |         10          |    |            Hotel Gallitzinberg             |           173           |          8          | <p>You may notice that the counted in the dataset results do not match the value in <code>Total_Number_of_Reviews</code>. It is unclear if this value in the dataset represented the total number of reviews the hotel had, but not all were scraped, or some other calculation. <code>Total_Number_of_Reviews</code> is not used in the model because of this unclarity.</p> <ol> <li>While there is an <code>Average_Score</code> column for each hotel in the dataset, you can also calculate an average score (getting the average of all reviewer scores in the dataset for each hotel). Add a new column to your dataframe with the column header <code>Calc_Average_Score</code> that contains that calculated average. Print out the columns <code>Hotel_Name</code>, <code>Average_Score</code>, and <code>Calc_Average_Score</code>.</li> </ol> <pre><code># define a function that takes a row and performs some calculation with it\ndef get_difference_review_avg(row):\n  return row[\"Average_Score\"] - row[\"Calc_Average_Score\"]\n\n# 'mean' is mathematical word for 'average'\ndf['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)\n\n# Add a new column with the difference between the two average scores\ndf[\"Average_Score_Difference\"] = df.apply(get_difference_review_avg, axis = 1)\n\n# Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)\nreview_scores_df = df.drop_duplicates(subset = [\"Hotel_Name\"])\n\n# Sort the dataframe to find the lowest and highest average score difference\nreview_scores_df = review_scores_df.sort_values(by=[\"Average_Score_Difference\"])\n\ndisplay(review_scores_df[[\"Average_Score_Difference\", \"Average_Score\", \"Calc_Average_Score\", \"Hotel_Name\"]])\n</code></pre> <p>You may also wonder about the <code>Average_Score</code> value and why it is sometimes different from the calculated average score. As we can't know why some of the values match, but others have a difference, it's safest in this case to use the review scores that we have to calculate the average ourselves. That said, the differences are usually very small, here are the hotels with the greatest deviation from the dataset average and the calculated average:</p> Average_Score_Difference Average_Score Calc_Average_Score Hotel_Name -0.8 7.7 8.5 Best Western Hotel Astoria -0.7 8.8 9.5 Hotel Stendhal Place Vend me Paris MGallery -0.7 7.5 8.2 Mercure Paris Porte d Orleans -0.7 7.9 8.6 Renaissance Paris Vendome Hotel -0.5 7.0 7.5 Hotel Royal Elys es ... ... ... ... 0.7 7.5 6.8 Mercure Paris Op ra Faubourg Montmartre 0.8 7.1 6.3 Holiday Inn Paris Montparnasse Pasteur 0.9 6.8 5.9 Villa Eugenie 0.9 8.6 7.7 MARQUIS Faubourg St Honor Relais Ch teaux 1.3 7.2 5.9 Kube Hotel Ice Bar <p>With only 1 hotel having a difference of score greater than 1, it means we can probably ignore the difference and use the calculated average score.</p> <ol> <li> <p>Calculate and print out how many rows have column <code>Negative_Review</code> values of \"No Negative\" </p> </li> <li> <p>Calculate and print out how many rows have column <code>Positive_Review</code> values of \"No Positive\"</p> </li> <li> <p>Calculate and print out how many rows have column <code>Positive_Review</code> values of \"No Positive\" and <code>Negative_Review</code> values of \"No Negative\"</p> </li> </ol> <pre><code># with lambdas:\nstart = time.time()\nno_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == \"No Negative\" else False , axis=1)\nprint(\"Number of No Negative reviews: \" + str(len(no_negative_reviews[no_negative_reviews == True].index)))\n\nno_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == \"No Positive\" else False , axis=1)\nprint(\"Number of No Positive reviews: \" + str(len(no_positive_reviews[no_positive_reviews == True].index)))\n\nboth_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == \"No Negative\" and x['Positive_Review'] == \"No Positive\" else False , axis=1)\nprint(\"Number of both No Negative and No Positive reviews: \" + str(len(both_no_reviews[both_no_reviews == True].index)))\nend = time.time()\nprint(\"Lambdas took \" + str(round(end - start, 2)) + \" seconds\")\n\nNumber of No Negative reviews: 127890\nNumber of No Positive reviews: 35946\nNumber of both No Negative and No Positive reviews: 127\nLambdas took 9.64 seconds\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#another-way","title":"Another way","text":"<p>Another way count items without Lambdas, and use sum to count the rows:</p> <pre><code># without lambdas (using a mixture of notations to show you can use both)\nstart = time.time()\nno_negative_reviews = sum(df.Negative_Review == \"No Negative\")\nprint(\"Number of No Negative reviews: \" + str(no_negative_reviews))\n\nno_positive_reviews = sum(df[\"Positive_Review\"] == \"No Positive\")\nprint(\"Number of No Positive reviews: \" + str(no_positive_reviews))\n\nboth_no_reviews = sum((df.Negative_Review == \"No Negative\") &amp; (df.Positive_Review == \"No Positive\"))\nprint(\"Number of both No Negative and No Positive reviews: \" + str(both_no_reviews))\n\nend = time.time()\nprint(\"Sum took \" + str(round(end - start, 2)) + \" seconds\")\n\nNumber of No Negative reviews: 127890\nNumber of No Positive reviews: 35946\nNumber of both No Negative and No Positive reviews: 127\nSum took 0.19 seconds\n</code></pre> <p>You may have noticed that there are 127 rows that have both \"No Negative\" and \"No Positive\" values for the columns <code>Negative_Review</code> and <code>Positive_Review</code> respectively. That means that the reviewer gave the hotel a numerical score, but declined to write either a positive or negative review. Luckily this is a small amount of rows (127 out of 515738, or 0.02%), so it probably won't skew our model or results in any particular direction, but you might not have expected a data set of reviews to have rows with no reviews, so it's worth exploring the data to discover rows like this.</p> <p>Now that you have explored the dataset, in the next lesson you will filter the data and add some sentiment analysis.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#challenge","title":"\ud83d\ude80Challenge","text":"<p>This lesson demonstrates, as we saw in previous lessons, how critically important it is to understand your data and its foibles before performing operations on it. Text-based data, in particular, bears careful scrutiny. Dig through various text-heavy datasets and see if you can discover areas that could introduce bias or skewed sentiment into a model. </p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take this Learning Path on NLP to discover tools to try when building speech and text-heavy models.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/4-Hotel-Reviews-1/#assignment","title":"Assignment","text":"<p>NLTK</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/","title":"Hotel Reviews 2","text":""},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#sentiment-analysis-with-hotel-reviews","title":"Sentiment analysis with hotel reviews","text":"<p>Now that you have explored the dataset in detail, it's time to filter the columns and then use NLP techniques on the dataset to gain new insights about the hotels.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#filtering-sentiment-analysis-operations","title":"Filtering &amp; Sentiment Analysis Operations","text":"<p>As you've probably noticed, the dataset has a few issues. Some columns are filled with useless information, others seem incorrect. If they are correct, it's unclear how they were calculated, and answers cannot be independently verified by your own calculations.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#exercise-a-bit-more-data-processing","title":"Exercise: a bit more data processing","text":"<p>Clean the data just a bit more. Add columns that will be useful later, change the values in other columns, and drop certain columns completely.</p> <ol> <li> <p>Initial column processing</p> </li> <li> <p>Drop <code>lat</code> and <code>lng</code></p> </li> <li> <p>Replace <code>Hotel_Address</code> values with the following values (if the address contains the same of the city and the country, change it to just the city and the country).</p> <p>These are the only cities and countries in the dataset:</p> <p>Amsterdam, Netherlands</p> <p>Barcelona, Spain</p> <p>London, United Kingdom</p> <p>Milan, Italy</p> <p>Paris, France</p> <p>Vienna, Austria </p> <pre><code>def replace_address(row):\n    if \"Netherlands\" in row[\"Hotel_Address\"]:\n        return \"Amsterdam, Netherlands\"\n    elif \"Barcelona\" in row[\"Hotel_Address\"]:\n        return \"Barcelona, Spain\"\n    elif \"United Kingdom\" in row[\"Hotel_Address\"]:\n        return \"London, United Kingdom\"\n    elif \"Milan\" in row[\"Hotel_Address\"]:        \n        return \"Milan, Italy\"\n    elif \"France\" in row[\"Hotel_Address\"]:\n        return \"Paris, France\"\n    elif \"Vienna\" in row[\"Hotel_Address\"]:\n        return \"Vienna, Austria\" \n\n# Replace all the addresses with a shortened, more useful form\ndf[\"Hotel_Address\"] = df.apply(replace_address, axis = 1)\n# The sum of the value_counts() should add up to the total number of reviews\nprint(df[\"Hotel_Address\"].value_counts())\n</code></pre> <p>Now you can query country level data:</p> <pre><code>display(df.groupby(\"Hotel_Address\").agg({\"Hotel_Name\": \"nunique\"}))\n</code></pre> Hotel_Address Hotel_Name Amsterdam, Netherlands 105 Barcelona, Spain 211 London, United Kingdom 400 Milan, Italy 162 Paris, France 458 Vienna, Austria 158 </li> <li> <p>Process Hotel Meta-review columns</p> </li> <li> <p>Drop <code>Additional_Number_of_Scoring</code></p> </li> <li> <p>Replace <code>Total_Number_of_Reviews</code> with the total number of reviews for that hotel that are actually in the dataset </p> </li> <li> <p>Replace <code>Average_Score</code> with our own calculated score</p> </li> </ol> <pre><code># Drop `Additional_Number_of_Scoring`\ndf.drop([\"Additional_Number_of_Scoring\"], axis = 1, inplace=True)\n# Replace `Total_Number_of_Reviews` and `Average_Score` with our own calculated values\ndf.Total_Number_of_Reviews = df.groupby('Hotel_Name').transform('count')\ndf.Average_Score = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)\n</code></pre> <ol> <li> <p>Process review columns</p> </li> <li> <p>Drop <code>Review_Total_Negative_Word_Counts</code>, <code>Review_Total_Positive_Word_Counts</code>, <code>Review_Date</code> and <code>days_since_review</code></p> </li> <li> <p>Keep <code>Reviewer_Score</code>, <code>Negative_Review</code>, and <code>Positive_Review</code> as they are,</p> </li> <li> <p>Keep <code>Tags</code> for now</p> <ul> <li>We'll be doing some additional filtering operations on the tags in the next section and then tags will be dropped</li> </ul> </li> <li> <p>Process reviewer columns</p> </li> <li> <p>Drop <code>Total_Number_of_Reviews_Reviewer_Has_Given</code></p> </li> <li> <p>Keep <code>Reviewer_Nationality</code></p> </li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#tag-columns","title":"Tag columns","text":"<p>The <code>Tag</code> column is problematic as it is a list (in text form) stored in the column. Unfortunately the order and number of sub sections in this column are not always the same. It's hard for a human to identify the correct phrases to be interested in, because there are 515,000 rows, and 1427 hotels, and each has slightly different options a reviewer could choose. This is where NLP shines. You can scan the text and find the most common phrases, and count them.</p> <p>Unfortunately, we are not interested in single words, but multi-word phrases (e.g. Business trip). Running a multi-word frequency distribution algorithm on that much data (6762646 words) could take an extraordinary amount of time, but without looking at the data, it would seem that is a necessary expense. This is where exploratory data analysis comes in useful, because you've seen a sample of the tags such as <code>[' Business trip  ', ' Solo traveler ', ' Single Room ', ' Stayed 5 nights ', ' Submitted from  a mobile device ']</code> , you can begin to ask if it's possible to greatly reduce the processing you have to do. Luckily, it is - but first you need to follow a few steps to ascertain the tags of interest.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#filtering-tags","title":"Filtering tags","text":"<p>Remember that the goal of the dataset is to add sentiment and columns that will help you choose the best hotel (for yourself or maybe a client tasking you to make a hotel recommendation bot). You need to ask yourself if the tags are useful or not in the final dataset. Here is one interpretation (if you needed the dataset for other reasons different tags might stay in/out of the selection):</p> <ol> <li>The type of trip is relevant, and that should stay</li> <li>The type of guest group is important, and that should stay</li> <li>The type of room, suite, or studio that the guest stayed in is irrelevant (all hotels have basically the same rooms)</li> <li>The device the review was submitted on is irrelevant</li> <li>The number of nights reviewer stayed for could be relevant if you attributed longer stays with them liking the hotel more, but it's a stretch, and probably irrelevant</li> </ol> <p>In summary, keep 2 kinds of tags and remove the others.</p> <p>First, you don't want to count the tags until they are in a better format, so that means removing the square brackets and quotes. You can do this several ways, but you want the fastest as it could take a long time to process a lot of data. Luckily, pandas has an easy way to do each of these steps.</p> <pre><code># Remove opening and closing brackets\ndf.Tags = df.Tags.str.strip(\"[']\")\n# remove all quotes too\ndf.Tags = df.Tags.str.replace(\" ', '\", \",\", regex = False)\n</code></pre> <p>Each tag becomes something like: <code>Business trip, Solo traveler, Single Room, Stayed 5 nights, Submitted from a mobile device</code>. </p> <p>Next we find a problem. Some reviews, or rows, have 5 columns, some 3, some 6. This is a result of how the dataset was created, and hard to fix. You want to get a frequency count of each phrase, but they are in different order in each review, so the count might be off, and a hotel might not get a tag assigned to it that it deserved.</p> <p>Instead you will use the different order to our advantage, because each tag is multi-word but also separated by a comma! The simplest way to do this is to create 6 temporary columns with each tag inserted in to the column corresponding to its order in the tag. You can then merge the 6 columns into one big column and run the <code>value_counts()</code> method on the resulting column. Printing that out, you'll see there was 2428 unique tags. Here is a small sample:</p> Tag Count Leisure trip 417778 Submitted from a mobile device 307640 Couple 252294 Stayed 1 night 193645 Stayed 2 nights 133937 Solo traveler 108545 Stayed 3 nights 95821 Business trip 82939 Group 65392 Family with young children 61015 Stayed 4 nights 47817 Double Room 35207 Standard Double Room 32248 Superior Double Room 31393 Family with older children 26349 Deluxe Double Room 24823 Double or Twin Room 22393 Stayed 5 nights 20845 Standard Double or Twin Room 17483 Classic Double Room 16989 Superior Double or Twin Room 13570 2 rooms 12393 <p>Some of the common tags like <code>Submitted from a mobile device</code> are of no use to us, so it might be a smart thing to remove them before counting phrase occurrence, but it is such a fast operation you can leave them in and ignore them.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#removing-the-length-of-stay-tags","title":"Removing the length of stay tags","text":"<p>Removing these tags is step 1, it reduces the total number of tags to be considered slightly. Note you do not remove them from the dataset, just choose to remove them from consideration as values to  count/keep in the reviews dataset.</p> Length of stay Count Stayed 1 night 193645 Stayed  2 nights 133937 Stayed 3 nights 95821 Stayed  4 nights 47817 Stayed 5 nights 20845 Stayed  6 nights 9776 Stayed 7 nights 7399 Stayed  8 nights 2502 Stayed 9 nights 1293 ... ... <p>There are a huge variety of rooms, suites, studios, apartments and so on. They all mean roughly the same thing and not relevant to you, so remove them from consideration.</p> Type of room Count Double Room 35207 Standard  Double Room 32248 Superior Double Room 31393 Deluxe  Double Room 24823 Double or Twin Room 22393 Standard  Double or Twin Room 17483 Classic Double Room 16989 Superior  Double or Twin Room 13570 <p>Finally, and this is delightful (because it didn't take much processing at all), you will be left with the following useful tags:</p> Tag Count Leisure trip 417778 Couple 252294 Solo  traveler 108545 Business trip 82939 Group (combined with Travellers with friends) 67535 Family with young children 61015 Family  with older children 26349 With a  pet 1405 <p>You could argue that <code>Travellers with friends</code> is the same as <code>Group</code> more or less, and that would be fair to combine the two as above. The code for identifying the correct tags is the Tags notebook.</p> <p>The final step is to create new columns for each of these tags. Then, for every review row, if the <code>Tag</code> column matches one of the new columns, add a 1, if not, add a 0. The end result will be a count of how many reviewers chose this hotel (in aggregate) for, say, business vs leisure, or to bring a pet to, and this is useful information when recommending a hotel.</p> <pre><code># Process the Tags into new columns\n# The file Hotel_Reviews_Tags.py, identifies the most important tags\n# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends, \n# Family with young children, Family with older children, With a pet\ndf[\"Leisure_trip\"] = df.Tags.apply(lambda tag: 1 if \"Leisure trip\" in tag else 0)\ndf[\"Couple\"] = df.Tags.apply(lambda tag: 1 if \"Couple\" in tag else 0)\ndf[\"Solo_traveler\"] = df.Tags.apply(lambda tag: 1 if \"Solo traveler\" in tag else 0)\ndf[\"Business_trip\"] = df.Tags.apply(lambda tag: 1 if \"Business trip\" in tag else 0)\ndf[\"Group\"] = df.Tags.apply(lambda tag: 1 if \"Group\" in tag or \"Travelers with friends\" in tag else 0)\ndf[\"Family_with_young_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with young children\" in tag else 0)\ndf[\"Family_with_older_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with older children\" in tag else 0)\ndf[\"With_a_pet\"] = df.Tags.apply(lambda tag: 1 if \"With a pet\" in tag else 0)\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#save-your-file","title":"Save your file","text":"<p>Finally, save the dataset as it is now with a new name.</p> <pre><code>df.drop([\"Review_Total_Negative_Word_Counts\", \"Review_Total_Positive_Word_Counts\", \"days_since_review\", \"Total_Number_of_Reviews_Reviewer_Has_Given\"], axis = 1, inplace=True)\n\n# Saving new data file with calculated columns\nprint(\"Saving results to Hotel_Reviews_Filtered.csv\")\ndf.to_csv(r'../data/Hotel_Reviews_Filtered.csv', index = False)\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#sentiment-analysis-operations","title":"Sentiment Analysis Operations","text":"<p>In this final section, you will apply sentiment analysis to the review columns and save the results in a dataset.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#exercise-load-and-save-the-filtered-data","title":"Exercise: load and save the filtered data","text":"<p>Note that now you are loading the filtered dataset that was saved in the previous section, not the original dataset.</p> <pre><code>import time\nimport pandas as pd\nimport nltk as nltk\nfrom nltk.corpus import stopwords\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n\n# Load the filtered hotel reviews from CSV\ndf = pd.read_csv('../../data/Hotel_Reviews_Filtered.csv')\n\n# You code will be added here\n\n\n# Finally remember to save the hotel reviews with new NLP data added\nprint(\"Saving results to Hotel_Reviews_NLP.csv\")\ndf.to_csv(r'../data/Hotel_Reviews_NLP.csv', index = False)\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#removing-stop-words","title":"Removing stop words","text":"<p>If you were to run Sentiment Analysis on the Negative and Positive review columns, it could take a long time. Tested on a powerful test laptop with fast CPU,it took 12 - 14 minutes depending on which sentiment library was used. That's a (relatively) long time, so worth investigating if that can be speeded up. </p> <p>Removing stop words, or common English words that do not change the sentiment of a sentence, is the first step. By removing them, the sentiment analysis should run faster, but not be less accurate (as the stop words do not affect sentiment, but they do slow down the analysis). </p> <p>The longest negative review was 395 words, but after removing the stop words, it is 195 words.</p> <p>Removing the stop words is also a fast operation, removing the stop words from 2 review columns over 515,000 rows took 3.3 seconds on the test device. It could take slightly more or less time for you depending on your device CPU speed, RAM, whether you have an SSD or not, and some other factors. The relative shortness of the operation means that if it improves the sentiment analysis time, then it is worth doing.</p> <pre><code>from nltk.corpus import stopwords\n\n# Load the hotel reviews from CSV\ndf = pd.read_csv(\"../../data/Hotel_Reviews_Filtered.csv\")\n\n# Remove stop words - can be slow for a lot of text!\n# Ryan Han (ryanxjhan on Kaggle) has a great post measuring performance of different stop words removal approaches\n# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends\nstart = time.time()\ncache = set(stopwords.words(\"english\"))\ndef remove_stopwords(review):\n    text = \" \".join([word for word in review.split() if word not in cache])\n    return text\n\n# Remove the stop words from both columns\ndf.Negative_Review = df.Negative_Review.apply(remove_stopwords)   \ndf.Positive_Review = df.Positive_Review.apply(remove_stopwords)\n</code></pre>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#performing-sentiment-analysis","title":"Performing sentiment analysis","text":"<p>Now you should calculate the sentiment analysis for both negative and positive review columns, and store the result in 2 new columns. The test of the sentiment will be to compare it to the reviewer's score for the same review. For instance, if the sentiment thinks the negative review had a sentiment of 1 (extremely positive sentiment) and a positive review sentiment of 1, but the reviewer gave the hotel the lowest score possible, then either the review text doesn't match the score, or the sentiment analyser could not recognize the sentiment correctly. You should expect some sentiment scores to be completely wrong, and often that will be explainable, e.g. the review could be extremely sarcastic \"Of course I LOVED sleeping in a room with no heating\" and the sentiment analyser thinks that's positive sentiment, even though a human reading it would know it was sarcasm. </p> <p>NLTK supplies different sentiment analyzers to learn with, and you can substitute them and see if the sentiment is more or less accurate. The VADER sentiment analysis is used here.</p> <p>Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.</p> <pre><code>from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# Create the vader sentiment analyser (there are others in NLTK you can try too)\nvader_sentiment = SentimentIntensityAnalyzer()\n# Hutto, C.J. &amp; Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n\n# There are 3 possibilities of input for a review:\n# It could be \"No Negative\", in which case, return 0\n# It could be \"No Positive\", in which case, return 0\n# It could be a review, in which case calculate the sentiment\ndef calc_sentiment(review):    \n    if review == \"No Negative\" or review == \"No Positive\":\n        return 0\n    return vader_sentiment.polarity_scores(review)[\"compound\"]    \n</code></pre> <p>Later in your program when you are ready to calculate sentiment, you can apply it to each review as follows:</p> <pre><code># Add a negative sentiment and positive sentiment column\nprint(\"Calculating sentiment columns for both positive and negative reviews\")\nstart = time.time()\ndf[\"Negative_Sentiment\"] = df.Negative_Review.apply(calc_sentiment)\ndf[\"Positive_Sentiment\"] = df.Positive_Review.apply(calc_sentiment)\nend = time.time()\nprint(\"Calculating sentiment took \" + str(round(end - start, 2)) + \" seconds\")\n</code></pre> <p>This takes approximately 120 seconds on my computer, but it will vary on each computer. If you want to print of the results and see if the sentiment matches the review:</p> <pre><code>df = df.sort_values(by=[\"Negative_Sentiment\"], ascending=True)\nprint(df[[\"Negative_Review\", \"Negative_Sentiment\"]])\ndf = df.sort_values(by=[\"Positive_Sentiment\"], ascending=True)\nprint(df[[\"Positive_Review\", \"Positive_Sentiment\"]])\n</code></pre> <p>The very last thing to do with the file before using it in the challenge, is to save it! You should also consider reordering all your new columns so they are easy to work with (for a human, it's a cosmetic change).</p> <pre><code># Reorder the columns (This is cosmetic, but to make it easier to explore the data later)\ndf = df.reindex([\"Hotel_Name\", \"Hotel_Address\", \"Total_Number_of_Reviews\", \"Average_Score\", \"Reviewer_Score\", \"Negative_Sentiment\", \"Positive_Sentiment\", \"Reviewer_Nationality\", \"Leisure_trip\", \"Couple\", \"Solo_traveler\", \"Business_trip\", \"Group\", \"Family_with_young_children\", \"Family_with_older_children\", \"With_a_pet\", \"Negative_Review\", \"Positive_Review\"], axis=1)\n\nprint(\"Saving results to Hotel_Reviews_NLP.csv\")\ndf.to_csv(r\"../data/Hotel_Reviews_NLP.csv\", index = False)\n</code></pre> <p>You should run the entire code for the analysis notebook (after you've run your filtering notebook to generate the Hotel_Reviews_Filtered.csv file).</p> <p>To review, the steps are:</p> <ol> <li>Original dataset file Hotel_Reviews.csv is explored in the previous lesson with the explorer notebook</li> <li>Hotel_Reviews.csv is filtered by the filtering notebook resulting in Hotel_Reviews_Filtered.csv</li> <li>Hotel_Reviews_Filtered.csv is processed by the sentiment analysis notebook resulting in Hotel_Reviews_NLP.csv</li> <li>Use Hotel_Reviews_NLP.csv in the NLP Challenge below</li> </ol>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#conclusion","title":"Conclusion","text":"<p>When you started, you had a dataset with columns and data but not all of it could be verified or used. You've explored the data, filtered out what you don't need, converted tags into something useful, calculated your own averages, added some sentiment columns and hopefully, learned some interesting things about processing natural text.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#challenge","title":"Challenge","text":"<p>Now that you have your dataset analyzed for sentiment, see if you can use strategies you've learned in this curriculum (clustering, perhaps?) to determine patterns around sentiment. </p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#review-self-study","title":"Review &amp; Self Study","text":"<p>Take this Learn module to learn more and use different tools to explore sentiment in text.</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/#assignment","title":"Assignment","text":"<p>Try a different dataset</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/assignment/#try-a-different-dataset","title":"Try a different dataset","text":""},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/assignment/#instructions","title":"Instructions","text":"<p>Now that you have learned about using NLTK to assign sentiment to text, try a different dataset. You will probably need to do some data processing around it, so create a notebook and document your thought process. What do you discover?</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A complete notebook and dataset are presented with well-documented cells explaining how the sentiment is assigned The notebook is missing good explanations The notebook is flawed"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/6-NLP/5-Hotel-Reviews-2/solution/R/","title":"Index","text":"<p>this is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/","title":"Time Series","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/#introduction-to-time-series-forecasting","title":"Introduction to time series forecasting","text":"<p>What is time series forecasting? It's about predicting future events by analyzing trends of the past.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/#regional-topic-worldwide-electricity-usage","title":"Regional topic: worldwide electricity usage \u2728","text":"<p>In these two lessons, you will be introduced to time series forecasting, a somewhat lesser known area of machine learning that is nevertheless extremely valuable for industry and business applications, among other fields. While neural networks can be used to enhance the utility of these models, we will study them in the context of classical machine learning as models help predict future performance based on the past.</p> <p>Our regional focus is electrical usage in the world, an interesting dataset to learn about forecasting future power usage based on patterns of past load. You can see how this kind of forecasting can be extremely helpful in a business environment.</p> <p></p> <p>Photo by Peddi Sai hrithik of electrical towers on a road in Rajasthan on Unsplash</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/#lessons","title":"Lessons","text":"<ol> <li>Introduction to time series forecasting</li> <li>Building ARIMA time series models</li> <li>Building Support Vector Regressor for time series forcasting</li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/#credits","title":"Credits","text":"<p>\"Introduction to time series forecasting\" was written with \u26a1\ufe0f by Francesca Lazzeri and Jen Looper. The notebooks first appeared online in the Azure \"Deep Learning For Time Series\" repo originally written by Francesca Lazzeri. The SVR lesson was written by Anirban Mukherjee</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/","title":"Introduction","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#introduction-to-time-series-forecasting","title":"Introduction to time series forecasting","text":"<p>Sketchnote by Tomomi Imura</p> <p>In this lesson and the following one, you will learn a bit about time series forecasting, an interesting and valuable part of a ML scientist's repertoire that is a bit less known than other topics. Time series forecasting is a sort of 'crystal ball': based on past performance of a variable such as price, you can predict its future potential value.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video about time series forecasting</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#pre-lecture-quiz","title":"Pre-lecture quiz","text":"<p>It's a useful and interesting field with real value to business, given its direct application to problems of pricing, inventory, and supply chain issues. While deep learning techniques have started to be used to gain more insights to better predict future performance, time series forecasting remains a field greatly informed by classic ML techniques.</p> <p>Penn State's useful time series curriculum can be found here</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#introduction","title":"Introduction","text":"<p>Suppose you maintain an array of smart parking meters that provide data about how often they are used and for how long over time.</p> <p>What if you could predict, based on the meter's past performance, its future value according to the laws of supply and demand?</p> <p>Accurately predicting when to act so as to achieve your goal is a challenge that could be tackled by time series forecasting. It wouldn't make folks happy to be charged more in busy times when they're looking for a parking spot, but it would be a sure way to generate revenue to clean the streets!</p> <p>Let's explore some of the types of time series algorithms and start a notebook to clean and prepare some data. The data you will analyze  is taken from the GEFCom2014 forecasting competition. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014. Given the historical patterns of electricity load and temperature, you can predict future values of electricity load.</p> <p>In this example, you'll learn how to forecast one time step ahead, using historical load data only. Before starting, however, it's useful to understand what's going on behind the scenes.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#some-definitions","title":"Some definitions","text":"<p>When encountering the term 'time series' you need to understand its use in several different contexts.</p> <p>\ud83c\udf93 Time series</p> <p>In mathematics, \"a time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time.\" An example of a time series is the daily closing value of the Dow Jones Industrial Average. The use of time series plots and statistical modeling is frequently encountered in signal processing, weather forecasting, earthquake prediction, and other fields where events occur and data points can be plotted over time.</p> <p>\ud83c\udf93 Time series analysis</p> <p>Time series analysis, is the analysis of the above mentioned time series data. Time series data can take distinct forms, including 'interrupted time series' which detects patterns in a time series' evolution before and after an interrupting event. The type of analysis needed for the time series, depends on the nature of the data. Time series data itself can take the form of series of numbers or characters.</p> <p>The analysis to be performed, uses a variety of methods, including frequency-domain and time-domain, linear and nonlinear, and more. Learn more about the many ways to analyze this type of data.</p> <p>\ud83c\udf93 Time series forecasting</p> <p>Time series forecasting is the use of a model to predict future values based on patterns displayed by previously gathered data as it occurred in the past. While it is possible to use regression models to explore time series data, with time indices as x variables on a plot, such data is best analyzed using special types of models.</p> <p>Time series data is a list of ordered observations, unlike data that can be analyzed by linear regression.   The most common one is ARIMA, an acronym that stands for \"Autoregressive Integrated Moving Average\".</p> <p>ARIMA models \"relate the present value of a series to past values and past prediction errors.\" They are most appropriate for analyzing time-domain data, where data is ordered over time.</p> <p>There are several types of ARIMA models, which you can learn about here and which you will touch on in the next lesson.</p> <p>In the next lesson, you will build an ARIMA model using Univariate Time Series, which focuses on one variable that changes its value over time. An example of this type of data is this dataset that records the monthly C02 concentration at the Mauna Loa Observatory:</p> CO2 YearMonth Year Month 330.62 1975.04 1975 1 331.40 1975.13 1975 2 331.87 1975.21 1975 3 333.18 1975.29 1975 4 333.92 1975.38 1975 5 333.43 1975.46 1975 6 331.85 1975.54 1975 7 330.01 1975.63 1975 8 328.51 1975.71 1975 9 328.41 1975.79 1975 10 329.25 1975.88 1975 11 330.97 1975.96 1975 12 <p>\u2705 Identify the variable that changes over time in this dataset</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#time-series-data-characteristics-to-consider","title":"Time Series data characteristics to consider","text":"<p>When looking at time series data, you might notice that it has certain characteristics that you need to take into account and mitigate to better understand its patterns. If you consider time series data as potentially providing a 'signal' that you want to analyze, these characteristics can be thought of as 'noise'. You often will need to reduce this 'noise' by offsetting some of these characteristics using some statistical techniques.</p> <p>Here are some concepts you should know to be able to work with time series:</p> <p>\ud83c\udf93 Trends</p> <p>Trends are defined as measurable increases and decreases over time. Read more. In the context of time series, it's about how to use and, if necessary, remove trends from your time series.</p> <p>\ud83c\udf93 Seasonality</p> <p>Seasonality is defined as periodic fluctuations, such as holiday rushes that might affect sales, for example. Take a look at how different types of plots display seasonality in data.</p> <p>\ud83c\udf93 Outliers</p> <p>Outliers are far away from the standard data variance.</p> <p>\ud83c\udf93 Long-run cycle</p> <p>Independent of seasonality, data might display a long-run cycle such as an economic down-turn that lasts longer than a year.</p> <p>\ud83c\udf93 Constant variance</p> <p>Over time, some data display constant fluctuations, such as energy usage per day and night.</p> <p>\ud83c\udf93 Abrupt changes</p> <p>The data might display an abrupt change that might need further analysis. The abrupt shuttering of businesses due to COVID, for example, caused changes in data.</p> <p>\u2705 Here is a sample time series plot showing daily in-game currency spent over a few years. Can you identify any of the characteristics listed above in this data?</p> <p></p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#exercise-getting-started-with-power-usage-data","title":"Exercise - getting started with power usage data","text":"<p>Let's get started creating a time series model to predict future power usage given past usage.</p> <p>The data in this example is taken from the GEFCom2014 forecasting competition. It consists of 3 years of hourly electricity load and temperature values between 2012 and 2014.</p> <p>Tao Hong, Pierre Pinson, Shu Fan, Hamidreza Zareipour, Alberto Troccoli and Rob J. Hyndman, \"Probabilistic energy forecasting: Global Energy Forecasting Competition 2014 and beyond\", International Journal of Forecasting, vol.32, no.3, pp 896-913, July-September, 2016.</p> <ol> <li> <p>In the <code>working</code> folder of this lesson, open the notebook.ipynb file. Start by adding libraries that will help you load and visualize data</p> <pre><code>import os\nimport matplotlib.pyplot as plt\nfrom common.utils import load_data\n%matplotlib inline\n</code></pre> <p>Note, you are using the files from the included <code>common</code> folder which set up your environment and handle downloading the data.</p> </li> <li> <p>Next, examine the data as a dataframe calling <code>load_data()</code> and <code>head()</code>:</p> <pre><code>data_dir = './data'\nenergy = load_data(data_dir)[['load']]\nenergy.head()\n</code></pre> <p>You can see that there are two columns representing date and load:</p> load 2012-01-01 00:00:00 2698.0 2012-01-01 01:00:00 2558.0 2012-01-01 02:00:00 2444.0 2012-01-01 03:00:00 2402.0 2012-01-01 04:00:00 2403.0 </li> <li> <p>Now, plot the data calling <code>plot()</code>:</p> <pre><code>energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p> </li> <li> <p>Now, plot the first week of July 2014, by providing it as input to the <code>energy</code> in <code>[from date]: [to date]</code> pattern:</p> <pre><code>energy['2014-07-01':'2014-07-07'].plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p> <p>A beautiful plot! Take a look at these plots and see if you can determine any of the characteristics listed above. What can we surmise by visualizing the data?</p> </li> </ol> <p>In the next lesson, you will create an ARIMA model to create some forecasts.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Make a list of all the industries and areas of inquiry you can think of that would benefit from time series forecasting. Can you think of an application of these techniques in the arts? In Econometrics? Ecology? Retail? Industry? Finance? Where else?</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#review-self-study","title":"Review &amp; Self Study","text":"<p>Although we won't cover them here, neural networks are sometimes used to enhance classic methods of time series forecasting. Read more about them in this article</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/#assignment","title":"Assignment","text":"<p>Visualize some more time series</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/assignment/#visualize-some-more-time-series","title":"Visualize some more Time Series","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/assignment/#instructions","title":"Instructions","text":"<p>You've begun to learn about Time Series Forecasting by looking at the type of data that requires this special modeling. You've visualized some data around energy. Now, look around for some other data that would benefit from Time Series Forecasting. Find three examples (try Kaggle and Azure Open Datasets) and create a notebook to visualize them. Notate any special characteristics they have (seasonality, abrupt changes, or other trends) in the notebook.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement Three datasets are plotted and explained in a notebook Two datasets are plotted and explained in a notebook Few datasets are plotted or explained in a notebook or the data presented is insufficient"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/1-Introduction/solution/R/","title":"Index","text":"<p>this is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/","title":"ARIMA","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#time-series-forecasting-with-arima","title":"Time series forecasting with ARIMA","text":"<p>In the previous lesson, you learned a bit about time series forecasting and loaded a dataset showing the fluctuations of electrical load over a time period.</p> <p></p> <p>\ud83c\udfa5 Click the image above for a video: A brief introduction to ARIMA models. The example is done in R, but the concepts are universal.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#introduction","title":"Introduction","text":"<p>In this lesson, you will discover a specific way to build models with ARIMA: AutoRegressive Integrated Moving Average. ARIMA models are particularly suited to fit data that shows non-stationarity.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#general-concepts","title":"General concepts","text":"<p>To be able to work with ARIMA, there are some concepts you need to know about:</p> <ul> <li> <p>\ud83c\udf93 Stationarity. From a statistical context, stationarity refers to data whose distribution does not change when shifted in time. Non-stationary data, then, shows fluctuations due to trends that must be transformed to be analyzed. Seasonality, for example, can introduce fluctuations in data and can be eliminated by a process of 'seasonal-differencing'.</p> </li> <li> <p>\ud83c\udf93 Differencing. Differencing data, again from a statistical context, refers to the process of transforming non-stationary data to make it stationary by removing its non-constant trend. \"Differencing removes the changes in the level of a time series, eliminating trend and seasonality and consequently stabilizing the mean of the time series.\" Paper by Shixiong et al</p> </li> </ul>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#arima-in-the-context-of-time-series","title":"ARIMA in the context of time series","text":"<p>Let's unpack the parts of ARIMA to better understand how it helps us model time series and help us make predictions against it.</p> <ul> <li> <p>AR - for AutoRegressive. Autoregressive models, as the name implies, look 'back' in time to analyze previous values in your data and make assumptions about them. These previous values are called 'lags'. An example would be data that shows monthly sales of pencils. Each month's sales total would be considered an 'evolving variable' in the dataset. This model is built as the \"evolving variable of interest is regressed on its own lagged (i.e., prior) values.\" wikipedia</p> </li> <li> <p>I - for Integrated. As opposed to the similar 'ARMA' models, the 'I' in ARIMA refers to its integrated aspect. The data is 'integrated' when differencing steps are applied so as to eliminate non-stationarity.</p> </li> <li> <p>MA -  for Moving Average. The moving-average aspect of this model refers to the output variable that is determined by observing the current and past values of lags.</p> </li> </ul> <p>Bottom line: ARIMA is used to make a model fit the special form of time series data as closely as possible.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#exercise-build-an-arima-model","title":"Exercise - build an ARIMA model","text":"<p>Open the /working folder in this lesson and find the notebook.ipynb file.</p> <ol> <li> <p>Run the notebook to load the <code>statsmodels</code> Python library; you will need this for ARIMA models.</p> </li> <li> <p>Load necessary libraries</p> </li> <li> <p>Now, load up several more libraries useful for plotting data:</p> <pre><code>import os\nimport warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport math\n\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.preprocessing import MinMaxScaler\nfrom common.utils import load_data, mape\nfrom IPython.display import Image\n\n%matplotlib inline\npd.options.display.float_format = '{:,.2f}'.format\nnp.set_printoptions(precision=2)\nwarnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n</code></pre> </li> <li> <p>Load the data from the <code>/data/energy.csv</code> file into a Pandas dataframe and take a look:</p> <pre><code>energy = load_data('./data')[['load']]\nenergy.head(10)\n</code></pre> </li> <li> <p>Plot all the available energy data from January 2012 to December 2014. There should be no surprises as we saw this data in the last lesson:</p> <pre><code>energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p>Now, let's build a model!</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#create-training-and-testing-datasets","title":"Create training and testing datasets","text":"<p>Now your data is loaded, so you can separate it into train and test sets. You'll train your model on the train set. As usual, after the model has finished training, you'll evaluate its accuracy using the test set. You need to ensure that the test set covers a later period in time from the training set to ensure that the model does not gain information from future time periods.</p> <ol> <li> <p>Allocate a two-month period from September 1 to October 31, 2014 to the training set. The test set will include the two-month period of November 1 to December 31, 2014:</p> <pre><code>train_start_dt = '2014-11-01 00:00:00'\ntest_start_dt = '2014-12-30 00:00:00'\n</code></pre> <p>Since this data reflects the daily consumption of energy, there is a strong seasonal pattern, but the consumption is most similar to the consumption in more recent days.</p> </li> <li> <p>Visualize the differences:</p> <pre><code>energy[(energy.index &lt; test_start_dt) &amp; (energy.index &gt;= train_start_dt)][['load']].rename(columns={'load':'train'}) \\\n    .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \\\n    .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p> <p>Therefore, using a relatively small window of time for training the data should be sufficient.</p> <p>Note: Since the function we use to fit the ARIMA model uses in-sample validation during fitting, we will omit validation data.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#prepare-the-data-for-training","title":"Prepare the data for training","text":"<p>Now, you need to prepare the data for training by performing filtering and scaling of your data. Filter your dataset to only include the time periods and columns you need, and scaling to ensure the data is projected in the interval 0,1.</p> <ol> <li> <p>Filter the original dataset to include only the aforementioned time periods per set and only including the needed column 'load' plus the date:</p> <pre><code>train = energy.copy()[(energy.index &gt;= train_start_dt) &amp; (energy.index &lt; test_start_dt)][['load']]\ntest = energy.copy()[energy.index &gt;= test_start_dt][['load']]\n\nprint('Training data shape: ', train.shape)\nprint('Test data shape: ', test.shape)\n</code></pre> <p>You can see the shape of the data:</p> <pre><code>Training data shape:  (1416, 1)\nTest data shape:  (48, 1)\n</code></pre> </li> <li> <p>Scale the data to be in the range (0, 1).</p> <pre><code>scaler = MinMaxScaler()\ntrain['load'] = scaler.fit_transform(train)\ntrain.head(10)\n</code></pre> </li> <li> <p>Visualize the original vs. scaled data:</p> <pre><code>energy[(energy.index &gt;= train_start_dt) &amp; (energy.index &lt; test_start_dt)][['load']].rename(columns={'load':'original load'}).plot.hist(bins=100, fontsize=12)\ntrain.rename(columns={'load':'scaled load'}).plot.hist(bins=100, fontsize=12)\nplt.show()\n</code></pre> <p></p> <p>The original data</p> <p></p> <p>The scaled data</p> </li> <li> <p>Now that you have calibrated the scaled data, you can scale the test data:</p> <pre><code>test['load'] = scaler.transform(test)\ntest.head()\n</code></pre> </li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#implement-arima","title":"Implement ARIMA","text":"<p>It's time to implement ARIMA! You'll now use the <code>statsmodels</code> library that you installed earlier.</p> <p>Now you need to follow several steps</p> <ol> <li>Define the model by calling <code>SARIMAX()</code> and passing in the model parameters: p, d, and q parameters, and P, D, and Q parameters.</li> <li>Prepare the model for the training data by calling the fit() function.</li> <li>Make predictions calling the <code>forecast()</code> function and specifying the number of steps (the <code>horizon</code>) to forecast.</li> </ol> <p>\ud83c\udf93 What are all these parameters for? In an ARIMA model there are 3 parameters that are used to help model the major aspects of a time series: seasonality, trend, and noise. These parameters are:</p> <p><code>p</code>: the parameter associated with the auto-regressive aspect of the model, which incorporates past values. <code>d</code>: the parameter associated with the integrated part of the model, which affects the amount of differencing (\ud83c\udf93 remember differencing \ud83d\udc46?) to apply to a time series. <code>q</code>: the parameter associated with the moving-average part of the model.</p> <p>Note: If your data has a seasonal aspect - which this one does - , we use a seasonal ARIMA model (SARIMA). In that case you need to use another set of parameters: <code>P</code>, <code>D</code>, and <code>Q</code> which describe the same associations as <code>p</code>, <code>d</code>, and <code>q</code>, but correspond to the seasonal components of the model.</p> <ol> <li> <p>Start by setting your preferred horizon value. Let's try 3 hours:</p> <pre><code># Specify the number of steps to forecast ahead\nHORIZON = 3\nprint('Forecasting horizon:', HORIZON, 'hours')\n</code></pre> <p>Selecting the best values for an ARIMA model's parameters can be challenging as it's somewhat subjective and time intensive. You might consider using an <code>auto_arima()</code> function from the <code>pyramid</code> library,</p> </li> <li> <p>For now try some manual selections to find a good model.</p> <pre><code>order = (4, 1, 0)\nseasonal_order = (1, 1, 0, 24)\n\nmodel = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)\nresults = model.fit()\n\nprint(results.summary())\n</code></pre> <p>A table of results is printed.</p> </li> </ol> <p>You've built your first model! Now we need to find a way to evaluate it.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#evaluate-your-model","title":"Evaluate your model","text":"<p>To evaluate your model, you can perform the so-called <code>walk forward</code> validation. In practice, time series models are re-trained each time a new data becomes available. This allows the model to make the best forecast at each time step.</p> <p>Starting at the beginning of the time series using this technique, train the model on the train data set. Then make a prediction on the next time step. The prediction is evaluated against the known value. The training set is then expanded to include the known value and the process is repeated.</p> <p>Note: You should keep the training set window fixed for more efficient training so that every time you add a new observation to the training set, you remove the observation from the beginning of the set.</p> <p>This process provides a more robust estimation of how the model will perform in practice. However, it comes at the computation cost of creating so many models. This is acceptable if the data is small or if the model is simple, but could be an issue at scale.</p> <p>Walk-forward validation is the gold standard of time series model evaluation and is recommended for your own projects.</p> <ol> <li> <p>First, create a test data point for each HORIZON step.</p> <pre><code>test_shifted = test.copy()\n\nfor t in range(1, HORIZON+1):\n    test_shifted['load+'+str(t)] = test_shifted['load'].shift(-t, freq='H')\n\ntest_shifted = test_shifted.dropna(how='any')\ntest_shifted.head(5)\n</code></pre> load load+1 load+2 2014-12-30 00:00:00 0.33 0.29 0.27 2014-12-30 01:00:00 0.29 0.27 0.27 2014-12-30 02:00:00 0.27 0.27 0.30 2014-12-30 03:00:00 0.27 0.30 0.41 2014-12-30 04:00:00 0.30 0.41 0.57 <p>The data is shifted horizontally according to its horizon point.</p> </li> <li> <p>Make predictions on your test data using this sliding window approach in a loop the size of the test data length:</p> <pre><code>%%time\ntraining_window = 720 # dedicate 30 days (720 hours) for training\n\ntrain_ts = train['load']\ntest_ts = test_shifted\n\nhistory = [x for x in train_ts]\nhistory = history[(-training_window):]\n\npredictions = list()\n\norder = (2, 1, 0)\nseasonal_order = (1, 1, 0, 24)\n\nfor t in range(test_ts.shape[0]):\n    model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)\n    model_fit = model.fit()\n    yhat = model_fit.forecast(steps = HORIZON)\n    predictions.append(yhat)\n    obs = list(test_ts.iloc[t])\n    # move the training window\n    history.append(obs[0])\n    history.pop(0)\n    print(test_ts.index[t])\n    print(t+1, ': predicted =', yhat, 'expected =', obs)\n</code></pre> <p>You can watch the training occurring:</p> <pre><code>2014-12-30 00:00:00\n1 : predicted = [0.32 0.29 0.28] expected = [0.32945389435989236, 0.2900626678603402, 0.2739480752014323]\n\n2014-12-30 01:00:00\n2 : predicted = [0.3  0.29 0.3 ] expected = [0.2900626678603402, 0.2739480752014323, 0.26812891674127126]\n\n2014-12-30 02:00:00\n3 : predicted = [0.27 0.28 0.32] expected = [0.2739480752014323, 0.26812891674127126, 0.3025962399283795]\n</code></pre> </li> <li> <p>Compare the predictions to the actual load:</p> <pre><code>eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])\neval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]\neval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')\neval_df['actual'] = np.array(np.transpose(test_ts)).ravel()\neval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])\neval_df.head()\n</code></pre> <p>Output |     |            | timestamp | h   | prediction | actual   | | --- | ---------- | --------- | --- | ---------- | -------- | | 0   | 2014-12-30 | 00:00:00  | t+1 | 3,008.74   | 3,023.00 | | 1   | 2014-12-30 | 01:00:00  | t+1 | 2,955.53   | 2,935.00 | | 2   | 2014-12-30 | 02:00:00  | t+1 | 2,900.17   | 2,899.00 | | 3   | 2014-12-30 | 03:00:00  | t+1 | 2,917.69   | 2,886.00 | | 4   | 2014-12-30 | 04:00:00  | t+1 | 2,946.99   | 2,963.00 |</p> <p>Observe the hourly data's prediction, compared to the actual load. How accurate is this?</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#check-model-accuracy","title":"Check model accuracy","text":"<p>Check the accuracy of your model by testing its mean absolute percentage error (MAPE) over all the predictions.</p> <p>\ud83e\uddee Show me the math</p> <p></p> <p>MAPE is used to show prediction accuracy as a ratio defined by the above formula. The difference between actual<sub>t</sub> and predicted<sub>t</sub> is divided by the actual<sub>t</sub>. \"The absolute value in this calculation is summed for every forecasted point in time and divided by the number of fitted points n.\" wikipedia</p> <ol> <li> <p>Express equation in code:</p> <pre><code>if(HORIZON &gt; 1):\n    eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']\n    print(eval_df.groupby('h')['APE'].mean())\n</code></pre> </li> <li> <p>Calculate one step's MAPE:</p> <pre><code>print('One step forecast MAPE: ', (mape(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')\n</code></pre> <p>One step forecast MAPE:  0.5570581332313952 %</p> </li> <li> <p>Print the multi-step forecast MAPE:</p> <pre><code>print('Multi-step forecast MAPE: ', mape(eval_df['prediction'], eval_df['actual'])*100, '%')\n</code></pre> <pre><code>Multi-step forecast MAPE:  1.1460048657704118 %\n</code></pre> <p>A nice low number is best: consider that a forecast that has a MAPE of 10 is off by 10%.</p> </li> <li> <p>But as always, it's easier to see this kind of accuracy measurement visually, so let's plot it:</p> <pre><code> if(HORIZON == 1):\n    ## Plotting single step forecast\n    eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))\n\nelse:\n    ## Plotting multi step forecast\n    plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]\n    for t in range(1, HORIZON+1):\n        plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values\n\n    fig = plt.figure(figsize=(15, 8))\n    ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)\n    ax = fig.add_subplot(111)\n    for t in range(1, HORIZON+1):\n        x = plot_df['timestamp'][(t-1):]\n        y = plot_df['t+'+str(t)][0:len(x)]\n        ax.plot(x, y, color='blue', linewidth=4*math.pow(.9,t), alpha=math.pow(0.8,t))\n\n    ax.legend(loc='best')\n\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p> </li> </ol> <p>\ud83c\udfc6 A very nice plot, showing a model with good accuracy. Well done!</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Dig into the ways to test the accuracy of a Time Series Model. We touch on MAPE in this lesson, but are there other methods you could use? Research them and annotate them. A helpful document can be found here</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#review-self-study","title":"Review &amp; Self Study","text":"<p>This lesson touches on only the basics of Time Series Forecasting with ARIMA. Take some time to deepen your knowledge by digging into this repository and its various model types to learn other ways to build Time Series models.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/#assignment","title":"Assignment","text":"<p>A new ARIMA model</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/assignment/#a-new-arima-model","title":"A new ARIMA model","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/assignment/#instructions","title":"Instructions","text":"<p>Now that you have built an ARIMA model, build a new one with fresh data (try one of these datasets from Duke. Annotate your work in a notebook, visualize the data and your model, and test its accuracy using MAPE.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with a new ARIMA model built, tested and explained with visualizations and accuracy stated. The notebook presented is not annotated or contains bugs An incomplete notebook is presented"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/2-ARIMA/solution/R/","title":"Index","text":"<p>this is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/","title":"SVR","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#time-series-forecasting-with-support-vector-regressor","title":"Time Series Forecasting with Support Vector Regressor","text":"<p>In the previous lesson, you learned how to use ARIMA model to make time series predictions. Now you'll be looking at Support Vector Regressor model which is a regressor model used to predict continuous data.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#introduction","title":"Introduction","text":"<p>In this lesson, you will discover a specific way to build models with SVM: Support Vector Machine for regression, or SVR: Support Vector Regressor. </p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#svr-in-the-context-of-time-series","title":"SVR in the context of time series <sup>1</sup>","text":"<p>Before understanding the importance of SVR in time series prediction, here are some of the important concepts that you need to know:</p> <ul> <li>Regression: Supervised learning technique to predict continuous values from a given set of inputs. The idea is to fit a curve (or line) in the feature space that has the maximum number of data points. Click here for more information.</li> <li>Support Vector Machine (SVM): A type of supervised machine learning model used for classification, regression and outliers detection. The model is a hyperplane in the feature space, which in case of classification acts as a boundary, and in case of regression acts as the best-fit line. In SVM, a Kernel function is generally used to transform the dataset to a space of higher number of dimensions, so that they can be easily separable. Click here for more information on SVMs.</li> <li>Support Vector Regressor (SVR): A type of SVM, to find the best fit line (which in the case of SVM is a hyperplane) that has the maximum number of data points.</li> </ul>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#why-svr","title":"Why SVR? <sup>1</sup>","text":"<p>In the last lesson you learned about ARIMA, which is a very successful statistical linear method to forecast time series data. However, in many cases, time series data have non-linearity, which cannot be mapped by linear models. In such cases, the ability of SVM to consider non-linearity in the data for regression tasks makes SVR successful in time series forecasting.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#exercise-build-an-svr-model","title":"Exercise - build an SVR model","text":"<p>The first few steps for data preparation are the same as that of the previous lesson on ARIMA. </p> <p>Open the /working folder in this lesson and find the notebook.ipynb file.<sup>2</sup></p> <ol> <li>Run the notebook and import the necessary libraries:  <sup>2</sup></li> </ol> <pre><code>import sys\nsys.path.append('../../')\n</code></pre> <pre><code>import os\nimport warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nimport math\n\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import MinMaxScaler\nfrom common.utils import load_data, mape\n</code></pre> <ol> <li>Load the data from the <code>/data/energy.csv</code> file into a Pandas dataframe and take a look:  <sup>2</sup></li> </ol> <pre><code>energy = load_data('../../data')[['load']]\n</code></pre> <ol> <li>Plot all the available energy data from January 2012 to December 2014: <sup>2</sup></li> </ol> <pre><code>energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p> <p>Now, let's build our SVR model.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#create-training-and-testing-datasets","title":"Create training and testing datasets","text":"<p>Now your data is loaded, so you can separate it into train and test sets. Then you'll reshape the data to create a time-step based dataset which will be needed for the SVR. You'll train your model on the train set. After the model has finished training, you'll evaluate its accuracy on the training set, testing set and then the full dataset to see the overall performance. You need to ensure that the test set covers a later period in time from the training set to ensure that the model does not gain information from future time periods <sup>2</sup> (a situation known as Overfitting).</p> <ol> <li>Allocate a two-month period from September 1 to October 31, 2014 to the training set. The test set will include the two-month period of November 1 to December 31, 2014: <sup>2</sup></li> </ol> <pre><code>train_start_dt = '2014-11-01 00:00:00'\ntest_start_dt = '2014-12-30 00:00:00'\n</code></pre> <ol> <li>Visualize the differences: <sup>2</sup></li> </ol> <pre><code>energy[(energy.index &lt; test_start_dt) &amp; (energy.index &gt;= train_start_dt)][['load']].rename(columns={'load':'train'}) \\\n    .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \\\n    .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)\nplt.xlabel('timestamp', fontsize=12)\nplt.ylabel('load', fontsize=12)\nplt.show()\n</code></pre> <p></p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#prepare-the-data-for-training","title":"Prepare the data for training","text":"<p>Now, you need to prepare the data for training by performing filtering and scaling of your data. Filter your dataset to only include the time periods and columns you need, and scaling to ensure the data is projected in the interval 0,1.</p> <ol> <li>Filter the original dataset to include only the aforementioned time periods per set and only including the needed column 'load' plus the date: <sup>2</sup></li> </ol> <pre><code>train = energy.copy()[(energy.index &gt;= train_start_dt) &amp; (energy.index &lt; test_start_dt)][['load']]\ntest = energy.copy()[energy.index &gt;= test_start_dt][['load']]\n\nprint('Training data shape: ', train.shape)\nprint('Test data shape: ', test.shape)\n</code></pre> <pre><code>Training data shape:  (1416, 1)\nTest data shape:  (48, 1)\n</code></pre> <ol> <li>Scale the training data to be in the range (0, 1): <sup>2</sup></li> </ol> <pre><code>scaler = MinMaxScaler()\ntrain['load'] = scaler.fit_transform(train)\n</code></pre> <ol> <li>Now, you scale the testing data: <sup>2</sup></li> </ol> <pre><code>test['load'] = scaler.transform(test)\n</code></pre>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#create-data-with-time-steps","title":"Create data with time-steps <sup>1</sup>","text":"<p>For the SVR, you transform the input data to be of the form <code>[batch, timesteps]</code>. So, you reshape the existing <code>train_data</code> and <code>test_data</code> such that there is a new dimension which refers to the timesteps. </p> <pre><code># Converting to numpy arrays\ntrain_data = train.values\ntest_data = test.values\n</code></pre> <p>For this example, we take <code>timesteps = 5</code>. So, the inputs to the model are the data for the first 4 timesteps, and the output will be the data for the 5th timestep.</p> <pre><code>timesteps=5\n</code></pre> <p>Converting training data to 2D tensor using nested list comprehension:</p> <pre><code>train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]\ntrain_data_timesteps.shape\n</code></pre> <pre><code>(1412, 5)\n</code></pre> <p>Converting testing data to 2D tensor:</p> <pre><code>test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]\ntest_data_timesteps.shape\n</code></pre> <pre><code>(44, 5)\n</code></pre> <p>Selecting inputs and outputs from training and testing data:</p> <pre><code>x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]\nx_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]\n\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)\n</code></pre> <pre><code>(1412, 4) (1412, 1)\n(44, 4) (44, 1)\n</code></pre>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#implement-svr","title":"Implement SVR <sup>1</sup>","text":"<p>Now, it's time to implement SVR. To read more about this implementation, you can refer to this documentation. For our implementation, we follow these steps:</p> <ol> <li>Define the model by calling <code>SVR()</code> and passing in the model hyperparameters: kernel, gamma, c and epsilon</li> <li>Prepare the model for the training data by calling the <code>fit()</code> function</li> <li>Make predictions calling the <code>predict()</code> function</li> </ol> <p>Now we create an SVR model. Here we use the RBF kernel, and set the hyperparameters gamma, C and epsilon as 0.5, 10 and 0.05 respectively.</p> <pre><code>model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)\n</code></pre>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#fit-the-model-on-training-data","title":"Fit the model on training data <sup>1</sup>","text":"<pre><code>model.fit(x_train, y_train[:,0])\n</code></pre> <pre><code>SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n</code></pre>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#make-model-predictions","title":"Make model predictions <sup>1</sup>","text":"<pre><code>y_train_pred = model.predict(x_train).reshape(-1,1)\ny_test_pred = model.predict(x_test).reshape(-1,1)\n\nprint(y_train_pred.shape, y_test_pred.shape)\n</code></pre> <pre><code>(1412, 1) (44, 1)\n</code></pre> <p>You've built your SVR! Now we need to evaluate it.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#evaluate-your-model","title":"Evaluate your model <sup>1</sup>","text":"<p>For evaluation, first we will scale back the data to our original scale. Then, to check the performance, we will plot the original and predicted time series plot, and also print the MAPE result.</p> <p>Scale the predicted and original output:</p> <pre><code># Scaling the predictions\ny_train_pred = scaler.inverse_transform(y_train_pred)\ny_test_pred = scaler.inverse_transform(y_test_pred)\n\nprint(len(y_train_pred), len(y_test_pred))\n</code></pre> <pre><code># Scaling the original values\ny_train = scaler.inverse_transform(y_train)\ny_test = scaler.inverse_transform(y_test)\n\nprint(len(y_train), len(y_test))\n</code></pre>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#check-model-performance-on-training-and-testing-data","title":"Check model performance on training and testing data <sup>1</sup>","text":"<p>We extract the timestamps from the dataset to show in the x-axis of our plot. Note that we are using the first <code>timesteps-1</code> values as out input for the first output, so the timestamps for the output will start after that.</p> <pre><code>train_timestamps = energy[(energy.index &lt; test_start_dt) &amp; (energy.index &gt;= train_start_dt)].index[timesteps-1:]\ntest_timestamps = energy[test_start_dt:].index[timesteps-1:]\n\nprint(len(train_timestamps), len(test_timestamps))\n</code></pre> <pre><code>1412 44\n</code></pre> <p>Plot the predictions for training data:</p> <pre><code>plt.figure(figsize=(25,6))\nplt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)\nplt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)\nplt.legend(['Actual','Predicted'])\nplt.xlabel('Timestamp')\nplt.title(\"Training data prediction\")\nplt.show()\n</code></pre> <p></p> <p>Print MAPE for training data</p> <pre><code>print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')\n</code></pre> <pre><code>MAPE for training data: 1.7195710200875551 %\n</code></pre> <p>Plot the predictions for testing data</p> <pre><code>plt.figure(figsize=(10,3))\nplt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)\nplt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)\nplt.legend(['Actual','Predicted'])\nplt.xlabel('Timestamp')\nplt.show()\n</code></pre> <p></p> <p>Print MAPE for testing data</p> <pre><code>print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')\n</code></pre> <pre><code>MAPE for testing data:  1.2623790187854018 %\n</code></pre> <p>\ud83c\udfc6 You have a very good result on the testing dataset!</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#check-model-performance-on-full-dataset","title":"Check model performance on full dataset <sup>1</sup>","text":"<pre><code># Extracting load values as numpy array\ndata = energy.copy().values\n\n# Scaling\ndata = scaler.transform(data)\n\n# Transforming to 2D tensor as per model input requirement\ndata_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]\nprint(\"Tensor shape: \", data_timesteps.shape)\n\n# Selecting inputs and outputs from data\nX, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]\nprint(\"X shape: \", X.shape,\"\\nY shape: \", Y.shape)\n</code></pre> <pre><code>Tensor shape:  (26300, 5)\nX shape:  (26300, 4) \nY shape:  (26300, 1)\n</code></pre> <pre><code># Make model predictions\nY_pred = model.predict(X).reshape(-1,1)\n\n# Inverse scale and reshape\nY_pred = scaler.inverse_transform(Y_pred)\nY = scaler.inverse_transform(Y)\n</code></pre> <pre><code>plt.figure(figsize=(30,8))\nplt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)\nplt.plot(Y_pred, color = 'blue', linewidth=0.8)\nplt.legend(['Actual','Predicted'])\nplt.xlabel('Timestamp')\nplt.show()\n</code></pre> <pre><code>print('MAPE: ', mape(Y_pred, Y)*100, '%')\n</code></pre> <pre><code>MAPE:  2.0572089029888656 %\n</code></pre> <p>\ud83c\udfc6 Very nice plots, showing a model with good accuracy. Well done!</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#challenge","title":"\ud83d\ude80Challenge","text":"<ul> <li>Try to tweak the hyperparameters (gamma, C, epsilon) while creating the model and evaluate on the data to see which set of hyperparameters give the best results on the testing data. To know more about these hyperparameters, you can refer to the  document here. </li> <li>Try to use different kernel functions for the model and analyze their performances on the dataset. A helpful document can be found here.</li> <li>Try using different values for <code>timesteps</code> for the model to look back to make prediction.</li> </ul>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#review-self-study","title":"Review &amp; Self Study","text":"<p>This lesson was to introduce the application of SVR for Time Series Forecasting. To read more about SVR, you can refer to this blog. This documentation on scikit-learn provides a more comprehensive explanation about SVMs in general, SVRs and also other implementation details such as the different kernel functions that can be used, and their parameters.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#assignment","title":"Assignment","text":"<p>A new SVR model</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/#credits","title":"Credits","text":"<ol> <li> <p>The text, code and output in this section was contributed by @AnirbanMukherjeeXD \u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> <li> <p>The text, code and output in this section was taken from ARIMA \u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9\u21a9</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/assignment/#a-new-svr-model","title":"A new SVR model","text":""},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/assignment/#instructions","title":"Instructions <sup>1</sup>","text":"<p>Now that you have built an SVR model, build a new one with fresh data (try one of these datasets from Duke). Annotate your work in a notebook, visualize the data and your model, and test its accuracy using appropriate plots and MAPE. Also try tweaking the different hyperparameters and also using different values for the timesteps.</p>"},{"location":"curricula/ml-for-beginners/7-TimeSeries/3-SVR/assignment/#rubric","title":"Rubric <sup>1</sup>","text":"Criteria Exemplary Adequate Needs Improvement A notebook is presented with an SVR model built, tested and explained with visualizations and accuracy stated. The notebook presented is not annotated or contains bugs. An incomplete notebook is presented <ol> <li> <p>The text in this section was based on the assignment from ARIMA \u21a9\u21a9</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/","title":"Reinforcement","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/#introduction-to-reinforcement-learning","title":"Introduction to reinforcement learning","text":"<p>Reinforcement learning, RL, is seen as one of the basic machine learning paradigms, next to supervised learning and unsupervised learning. RL is all about decisions: delivering the right decisions or at least learning from them.</p> <p>Imagine you have a simulated environment such as the stock market. What happens if you impose a given regulation? Does it have a positive or negative effect? If something negative happens, you need to take this negative reinforcement, learn from it, and change course. If it's a positive outcome, you need to build on that positive reinforcement.</p> <p></p> <p>Peter and his friends need to escape the hungry wolf! Image by Jen Looper</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/#regional-topic-peter-and-the-wolf-russia","title":"Regional topic: Peter and the Wolf (Russia)","text":"<p>Peter and the Wolf is a musical fairy tale written by a Russian composer Sergei Prokofiev. It is a story about young pioneer Peter, who bravely goes out of his house to the forest clearing to chase the wolf. In this section, we will train machine learning algorithms that will help Peter:</p> <ul> <li>Explore the surrounding area and build an optimal navigation map</li> <li>Learn how to use a skateboard and balance on it, in order to move around faster.</li> </ul> <p></p> <p>\ud83c\udfa5 Click the image above to listen to Peter and the Wolf by Prokofiev</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/#reinforcement-learning","title":"Reinforcement learning","text":"<p>In previous sections, you have seen two examples of machine learning problems:</p> <ul> <li>Supervised, where we have datasets that suggest sample solutions to the problem we want to solve. Classification and regression are supervised learning tasks.</li> <li>Unsupervised, in which we do not have labeled training data. The main example of unsupervised learning is Clustering.</li> </ul> <p>In this section, we will introduce you to a new type of learning problem that does not require labeled training data. There are several types of such problems:</p> <ul> <li>Semi-supervised learning, where we have a lot of unlabeled data that can be used to pre-train the model.</li> <li>Reinforcement learning, in which an agent learns how to behave by performing experiments in some simulated environment.</li> </ul>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/#example-computer-game","title":"Example - computer game","text":"<p>Suppose you want to teach a computer to play a game, such as chess, or Super Mario. For the computer to play a game, we need it to predict which move to make in each of the game states. While this may seem like a classification problem, it is not - because we do not have a dataset with states and corresponding actions. While we may have some data like existing chess matches or recording of players playing Super Mario, it is likely that that data will not sufficiently cover a large enough number of possible states.</p> <p>Instead of looking for existing game data, Reinforcement Learning (RL) is based on the idea of making the computer play many times and observing the result. Thus, to apply Reinforcement Learning, we need two things:</p> <ul> <li> <p>An environment and a simulator which allow us to play a game many times. This simulator would define all the game rules as well as possible states and actions.</p> </li> <li> <p>A reward function, which would tell us how well we did during each move or game.</p> </li> </ul> <p>The main difference between other types of machine learning and RL is that in RL we typically do not know whether we win or lose until we finish the game. Thus, we cannot say whether a certain move alone is good or not - we only receive a reward at the end of the game. And our goal is to design algorithms that will allow us to train a model under  uncertain conditions. We will learn about one RL algorithm called Q-learning.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/#lessons","title":"Lessons","text":"<ol> <li>Introduction to reinforcement learning and Q-Learning</li> <li>Using a gym simulation environment</li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/#credits","title":"Credits","text":"<p>\"Introduction to Reinforcement Learning\" was written with \u2665\ufe0f by Dmitry Soshnikov</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/","title":"Q-Learning","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#introduction-to-reinforcement-learning-and-q-learning","title":"Introduction to Reinforcement Learning and Q-Learning","text":"<p>Sketchnote by Tomomi Imura</p> <p>Reinforcement learning involves three important concepts: the agent, some states, and a set of actions per state. By executing an action in a specified state, the agent is given a reward. Again imagine the computer game Super Mario. You are Mario, you are in a game level, standing next to a cliff edge. Above you is a coin. You being Mario, in a game level, at a specific position ... that's your state. Moving one step to the right (an action) will take you over the edge, and that would give you a low numerical score. However, pressing the jump button would let you score a point and you would stay alive. That's a positive outcome and that should award you a positive numerical score.</p> <p>By using reinforcement learning and a simulator (the game), you can learn how to play the game to maximize the reward which is staying alive and scoring as many points as possible.</p> <p></p> <p>\ud83c\udfa5 Click the image above to hear Dmitry discuss Reinforcement Learning</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#prerequisites-and-setup","title":"Prerequisites and Setup","text":"<p>In this lesson, we will be experimenting with some code in Python. You should be able to run the Jupyter Notebook code from this lesson, either on your computer or somewhere in the cloud.</p> <p>You can open the lesson notebook and walk through this lesson to build.</p> <p>Note: If you are opening this code from the cloud, you also need to fetch the <code>rlboard.py</code> file, which is used in the notebook code. Add it to the same directory as the notebook.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#introduction","title":"Introduction","text":"<p>In this lesson, we will explore the world of Peter and the Wolf, inspired by a musical fairy tale by a Russian composer, Sergei Prokofiev. We will use Reinforcement Learning to let Peter explore his environment, collect tasty apples and avoid meeting the wolf.</p> <p>Reinforcement Learning (RL) is a learning technique that allows us to learn an optimal behavior of an agent in some environment by running many experiments. An agent in this environment should have some goal, defined by a reward function.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#the-environment","title":"The environment","text":"<p>For simplicity, let's consider Peter's world to be a square board of size <code>width</code> x <code>height</code>, like this:</p> <p></p> <p>Each cell in this board can either be:</p> <ul> <li>ground, on which Peter and other creatures can walk.</li> <li>water, on which you obviously cannot walk.</li> <li>a tree or grass, a place where you can rest.</li> <li>an apple, which represents something Peter would be glad to find in order to feed himself.</li> <li>a wolf, which is dangerous and should be avoided.</li> </ul> <p>There is a separate Python module, <code>rlboard.py</code>, which contains the code to work with this environment. Because this code is not important for understanding our concepts, we will import the module and use it to create the sample board (code block 1):</p> <pre><code>from rlboard import *\n\nwidth, height = 8,8\nm = Board(width,height)\nm.randomize(seed=13)\nm.plot()\n</code></pre> <p>This code should print a picture of the environment similar to the one above.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#actions-and-policy","title":"Actions and policy","text":"<p>In our example, Peter's goal would be able to find an apple, while avoiding the wolf and other obstacles. To do this, he can essentially walk around until he finds an apple.</p> <p>Therefore, at any position, he can choose between one of the following actions: up, down, left and right.</p> <p>We will define those actions as a dictionary, and map them to pairs of corresponding coordinate changes. For example, moving right (<code>R</code>) would correspond to a pair <code>(1,0)</code>. (code block 2):</p> <pre><code>actions = { \"U\" : (0,-1), \"D\" : (0,1), \"L\" : (-1,0), \"R\" : (1,0) }\naction_idx = { a : i for i,a in enumerate(actions.keys()) }\n</code></pre> <p>To sum up, the strategy and goal of this scenario are as follows:</p> <ul> <li> <p>The strategy, of our agent (Peter) is defined by a so-called policy. A policy is a function that returns the action at any given state. In our case, the state of the problem is represented by the board, including the current position of the player.</p> </li> <li> <p>The goal, of reinforcement learning is to eventually learn a good policy that will allow us to solve the problem efficiently. However, as a baseline, let's consider the simplest policy called random walk.</p> </li> </ul>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#random-walk","title":"Random walk","text":"<p>Let's first solve our problem by implementing a random walk strategy. With random walk, we will randomly choose the next action from the allowed actions, until we reach the apple (code block 3).</p> <ol> <li> <p>Implement the random walk with the below code:</p> <pre><code>def random_policy(m):\n    return random.choice(list(actions))\n\ndef walk(m,policy,start_position=None):\n    n = 0 # number of steps\n    # set initial position\n    if start_position:\n        m.human = start_position \n    else:\n        m.random_start()\n    while True:\n        if m.at() == Board.Cell.apple:\n            return n # success!\n        if m.at() in [Board.Cell.wolf, Board.Cell.water]:\n            return -1 # eaten by wolf or drowned\n        while True:\n            a = actions[policy(m)]\n            new_pos = m.move_pos(m.human,a)\n            if m.is_valid(new_pos) and m.at(new_pos)!=Board.Cell.water:\n                m.move(a) # do the actual move\n                break\n        n+=1\n\nwalk(m,random_policy)\n</code></pre> <p>The call to <code>walk</code> should return the length of the corresponding path, which can vary from one run to another. </p> </li> <li> <p>Run the walk experiment a number of times (say, 100), and print the resulting statistics (code block 4):</p> <pre><code>def print_statistics(policy):\n    s,w,n = 0,0,0\n    for _ in range(100):\n        z = walk(m,policy)\n        if z&lt;0:\n            w+=1\n        else:\n            s += z\n            n += 1\n    print(f\"Average path length = {s/n}, eaten by wolf: {w} times\")\n\nprint_statistics(random_policy)\n</code></pre> <p>Note that the average length of a path is around 30-40 steps, which is quite a lot, given the fact that the average distance to the nearest apple is around 5-6 steps.</p> <p>You can also see what Peter's movement looks like during the random walk:</p> <p></p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#reward-function","title":"Reward function","text":"<p>To make our policy more intelligent, we need to understand which moves are \"better\" than others. To do this, we need to define our goal.</p> <p>The goal can be defined in terms of a reward function, which will return some score value for each state. The higher the number, the better the reward function. (code block 5)</p> <pre><code>move_reward = -0.1\ngoal_reward = 10\nend_reward = -10\n\ndef reward(m,pos=None):\n    pos = pos or m.human\n    if not m.is_valid(pos):\n        return end_reward\n    x = m.at(pos)\n    if x==Board.Cell.water or x == Board.Cell.wolf:\n        return end_reward\n    if x==Board.Cell.apple:\n        return goal_reward\n    return move_reward\n</code></pre> <p>An interesting thing about reward functions is that in most cases, we are only given a substantial reward at the end of the game. This means that our algorithm should somehow remember \"good\" steps that lead to a positive reward at the end, and increase their importance. Similarly, all moves that lead to bad results should be discouraged.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#q-learning","title":"Q-Learning","text":"<p>An algorithm that we will discuss here is called Q-Learning. In this algorithm, the policy is defined by a function (or a data structure) called a Q-Table. It records the \"goodness\" of each of the actions in a given state.</p> <p>It is called a Q-Table because it is often convenient to represent it as a table, or multi-dimensional array. Since our board has dimensions <code>width</code> x <code>height</code>, we can represent the Q-Table using a numpy array with shape <code>width</code> x <code>height</code> x <code>len(actions)</code>: (code block 6)</p> <pre><code>Q = np.ones((width,height,len(actions)),dtype=np.float)*1.0/len(actions)\n</code></pre> <p>Notice that we initialize all the values of the Q-Table with an equal value, in our case - 0.25. This corresponds to the \"random walk\" policy, because all moves in each state are equally good. We can pass the Q-Table to the <code>plot</code> function in order to visualize the table on the board: <code>m.plot(Q)</code>.</p> <p></p> <p>In the center of each cell there is an \"arrow\" that indicates the preferred direction of movement. Since all directions are equal, a dot is displayed.</p> <p>Now we need to run the simulation, explore our environment, and learn a better distribution of Q-Table values, which will allow us to find the path to the apple much faster.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#essence-of-q-learning-bellman-equation","title":"Essence of Q-Learning: Bellman Equation","text":"<p>Once we start moving, each action will have a corresponding reward, i.e. we can theoretically select the next action based on the highest immediate reward. However, in most states, the move will not achieve our goal of reaching the apple, and thus we cannot immediately decide which direction is better.</p> <p>Remember that it is not the immediate result that matters, but rather the final result, which we will obtain at the end of the simulation.</p> <p>In order to account for this delayed reward, we need to use the principles of dynamic programming, which allow us to think about out problem recursively.</p> <p>Suppose we are now at the state s, and we want to move to the next state s'. By doing so, we will receive the immediate reward r(s,a), defined by the reward function, plus some future reward. If we suppose that our Q-Table correctly reflects the \"attractiveness\" of each action, then at state s' we will chose an action a that corresponds to maximum value of Q(s',a'). Thus, the best possible future reward we could get at state s will be defined as <code>max</code><sub>a'</sub>Q(s',a') (maximum here is computed over all possible actions a' at state s').</p> <p>This gives the Bellman formula for calculating the value of the Q-Table at state s, given action a:</p> <p></p> <p>Here \u03b3 is the so-called discount factor that determines to which extent you should prefer the current reward over the future reward and vice versa.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#learning-algorithm","title":"Learning Algorithm","text":"<p>Given the equation above, we can now write pseudo-code for our learning algorithm:</p> <ul> <li>Initialize Q-Table Q with equal numbers for all states and actions</li> <li>Set learning rate \u03b1 \u2190 1</li> <li>Repeat simulation many times</li> <li>Start at random position</li> <li>Repeat         1. Select an action a at state s         2. Execute action by moving to a new state s'         3. If we encounter end-of-game condition, or total reward is too small - exit simulation         4. Compute reward r at the new state         5. Update Q-Function according to Bellman equation: Q(s,a) \u2190 (1-\u03b1)Q(s,a)+\u03b1(r+\u03b3 max<sub>a'</sub>Q(s',a'))         6. s \u2190 s'         7. Update the total reward and decrease \u03b1.</li> </ul>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#exploit-vs-explore","title":"Exploit vs. explore","text":"<p>In the algorithm above, we did not specify how exactly we should choose an action at step 2.1. If we are choosing the action randomly, we will randomly explore the environment, and we are quite likely to die often as well as explore areas where we would not normally go. An alternative approach would be to exploit the Q-Table values that we already know, and thus to choose the best action (with higher Q-Table value) at state s. This, however, will prevent us from exploring other states, and it's likely we might not find the optimal solution.</p> <p>Thus, the best approach is to strike a balance between exploration and exploitation. This can be done by choosing the action at state s with probabilities proportional to values in the Q-Table. In the beginning, when Q-Table values are all the same, it would correspond to a random selection, but as we learn more about our environment, we would be more likely to follow the optimal route while allowing the agent to choose the unexplored path once in a while.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#python-implementation","title":"Python implementation","text":"<p>We are now ready to implement the learning algorithm. Before we do that, we also need some function that will convert arbitrary numbers in the Q-Table into a vector of probabilities for corresponding actions.</p> <ol> <li> <p>Create a function <code>probs()</code>:</p> <pre><code>def probs(v,eps=1e-4):\n    v = v-v.min()+eps\n    v = v/v.sum()\n    return v\n</code></pre> <p>We add a few <code>eps</code> to the original vector in order to avoid division by 0 in the initial case, when all components of the vector are identical.</p> </li> </ol> <p>Run them learning algorithm through 5000 experiments, also called epochs: (code block 8) </p><pre><code>    for epoch in range(5000):\n\n        # Pick initial point\n        m.random_start()\n\n        # Start travelling\n        n=0\n        cum_reward = 0\n        while True:\n            x,y = m.human\n            v = probs(Q[x,y])\n            a = random.choices(list(actions),weights=v)[0]\n            dpos = actions[a]\n            m.move(dpos,check_correctness=False) # we allow player to move outside the board, which terminates episode\n            r = reward(m)\n            cum_reward += r\n            if r==end_reward or cum_reward &lt; -1000:\n                lpath.append(n)\n                break\n            alpha = np.exp(-n / 10e5)\n            gamma = 0.5\n            ai = action_idx[a]\n            Q[x,y,ai] = (1 - alpha) * Q[x,y,ai] + alpha * (r + gamma * Q[x+dpos[0], y+dpos[1]].max())\n            n+=1\n</code></pre> <p>After executing this algorithm, the Q-Table should be updated with values that define the attractiveness of different actions at each step. We can try to visualize the Q-Table by plotting a vector at each cell that will point in the desired direction of movement. For simplicity, we draw a small circle instead of an arrow head.</p> <p></p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#checking-the-policy","title":"Checking the policy","text":"<p>Since the Q-Table lists the \"attractiveness\" of each action at each state, it is quite easy to use it to define the efficient navigation in our world. In the simplest case, we can select the action corresponding to the highest Q-Table value: (code block 9)</p> <pre><code>def qpolicy_strict(m):\n        x,y = m.human\n        v = probs(Q[x,y])\n        a = list(actions)[np.argmax(v)]\n        return a\n\nwalk(m,qpolicy_strict)\n</code></pre> <p>If you try the code above several times, you may notice that sometimes it \"hangs\", and you need to press the STOP button in the notebook to interrupt it. This happens because there could be situations when two states \"point\" to each other in terms of optimal Q-Value, in which case the agents ends up moving between those states indefinitely.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Task 1: Modify the <code>walk</code> function to limit the maximum length of path by a certain number of steps (say, 100), and watch the code above return this value from time to time.</p> <p>Task 2: Modify the <code>walk</code> function so that it does not go back to the places where it has already been previously. This will prevent <code>walk</code> from looping, however, the agent can still end up being \"trapped\" in a location from which it is unable to escape.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#navigation","title":"Navigation","text":"<p>A better navigation policy would be the one that we used during training, which combines exploitation and exploration. In this policy, we will select each action with a certain probability, proportional to the values in the Q-Table. This strategy may still result in the agent returning back to a position it has already explored, but, as you can see from the code below, it results in a very short average path to the desired location (remember that <code>print_statistics</code> runs the simulation 100 times): (code block 10)</p> <pre><code>def qpolicy(m):\n        x,y = m.human\n        v = probs(Q[x,y])\n        a = random.choices(list(actions),weights=v)[0]\n        return a\n\nprint_statistics(qpolicy)\n</code></pre> <p>After running this code, you should get a much smaller average path length than before, in the range of 3-6.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#investigating-the-learning-process","title":"Investigating the learning process","text":"<p>As we have mentioned, the learning process is a balance between exploration and exploration of gained knowledge about the structure of problem space. We have seen that the results of learning (the ability to help an agent to find a short path to the goal) has improved, but it is also interesting to observe how the average path length behaves during the learning process:</p> <p></p> <p>The learnings can be summarized as:</p> <ul> <li> <p>Average path length increases. What we see here is that at first, the average path length increases. This is probably due to the fact that when we know nothing about the environment, we are likely to get trapped in bad states, water or wolf. As we learn more and start using this knowledge, we can explore the environment for longer, but we still do not know where the apples are very well.</p> </li> <li> <p>Path length decrease, as we learn more. Once we learn enough, it becomes easier for the agent to achieve the goal, and the path length starts to decrease. However, we are still open to exploration, so we often diverge away from the best path, and explore new options, making the path longer than optimal.</p> </li> <li> <p>Length increase abruptly. What we also observe on this graph is that at some point, the length increased abruptly. This indicates the stochastic nature of the process, and that we can at some point \"spoil\" the Q-Table coefficients by overwriting them with new values. This ideally should be minimized by decreasing learning rate (for example, towards the end of training, we only adjust Q-Table values by a small value).</p> </li> </ul> <p>Overall, it is important to remember that the success and quality of the learning process significantly depends on parameters, such as learning rate, learning rate decay, and discount factor. Those are often called hyperparameters, to distinguish them from parameters, which we optimize during training (for example, Q-Table coefficients). The process of finding the best hyperparameter values is called hyperparameter optimization, and it deserves a separate topic.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/1-QLearning/#assignment","title":"Assignment","text":"<p>A More Realistic World</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/","title":"Gym","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#cartpole-skating","title":"CartPole Skating","text":"<p>The problem we have been solving in the previous lesson might seem like a toy problem, not really applicable for real life scenarios. This is not the case, because many real world problems also share this scenario - including playing Chess or Go. They are similar, because we also have a board with given rules and a discrete state.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#introduction","title":"Introduction","text":"<p>In this lesson we will apply the same principles of Q-Learning to a problem with continuous state, i.e. a state that is given by one or more real numbers. We will deal with the following problem:</p> <p>Problem: If Peter wants to escape from the wolf, he needs to be able to move faster. We will see how Peter can learn to skate, in particular, to keep balance, using Q-Learning.</p> <p></p> <p>Peter and his friends get creative to escape the wolf! Image by Jen Looper</p> <p>We will use a simplified version of balancing known as a CartPole problem. In the cartpole world, we have a horizontal slider that can move left or right, and the goal is to balance a vertical pole on top of the slider.</p> <p></p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#prerequisites","title":"Prerequisites","text":"<p>In this lesson, we will be using a library called OpenAI Gym to simulate different environments. You can run this lesson's code locally (eg. from Visual Studio Code), in which case the simulation will open in a new window. When running the code online, you may need to make some tweaks to the code, as described here.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#openai-gym","title":"OpenAI Gym","text":"<p>In the previous lesson, the rules of the game and the state were given by the <code>Board</code> class which we defined ourselves. Here we will use a special simulation environment, which will simulate the physics behind the balancing pole. One of the most popular simulation environments for training reinforcement learning algorithms is called a Gym, which is maintained by OpenAI. By using this gym we can create difference environments from a cartpole simulation to Atari games.</p> <p>Note: You can see other environments available from OpenAI Gym here. </p> <p>First, let's install the gym and import required libraries (code block 1):</p> <pre><code>import sys\n!{sys.executable} -m pip install gym \n\nimport gym\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random\n</code></pre>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#exercise-initialize-a-cartpole-environment","title":"Exercise - initialize a cartpole environment","text":"<p>To work with a cartpole balancing problem, we need to initialize corresponding environment. Each environment is associated with an:</p> <ul> <li> <p>Observation space that defines the structure of information that we receive from the environment. For cartpole problem, we receive position of the pole, velocity and some other values.</p> </li> <li> <p>Action space that defines possible actions. In our case the action space is discrete, and consists of two actions - left and right. (code block 2)</p> </li> <li> <p>To initialize, type the following code:</p> <pre><code>env = gym.make(\"CartPole-v1\")\nprint(env.action_space)\nprint(env.observation_space)\nprint(env.action_space.sample())\n</code></pre> </li> </ul> <p>To see how the environment works, let's run a short simulation for 100 steps. At each step, we provide one of the actions to be taken - in this simulation we just randomly select an action from <code>action_space</code>. </p> <ol> <li> <p>Run the code below and see what it leads to.</p> <p>\u2705 Remember that it is preferred to run this code on local Python installation! (code block 3)</p> <pre><code>env.reset()\n\nfor i in range(100):\n   env.render()\n   env.step(env.action_space.sample())\nenv.close()\n</code></pre> <p>You should be seeing something similar to this image:</p> <p></p> </li> <li> <p>During simulation, we need to get observations in order to decide how to act. In fact, the step function returns current observations, a reward function, and the done flag that indicates whether it makes sense to continue the simulation or not: (code block 4)</p> <pre><code>env.reset()\n\ndone = False\nwhile not done:\n   env.render()\n   obs, rew, done, info = env.step(env.action_space.sample())\n   print(f\"{obs} -&gt; {rew}\")\nenv.close()\n</code></pre> <p>You will end up seeing something like this in the notebook output:</p> <pre><code>[ 0.03403272 -0.24301182  0.02669811  0.2895829 ] -&gt; 1.0\n[ 0.02917248 -0.04828055  0.03248977  0.00543839] -&gt; 1.0\n[ 0.02820687  0.14636075  0.03259854 -0.27681916] -&gt; 1.0\n[ 0.03113408  0.34100283  0.02706215 -0.55904489] -&gt; 1.0\n[ 0.03795414  0.53573468  0.01588125 -0.84308041] -&gt; 1.0\n...\n[ 0.17299878  0.15868546 -0.20754175 -0.55975453] -&gt; 1.0\n[ 0.17617249  0.35602306 -0.21873684 -0.90998894] -&gt; 1.0\n</code></pre> <p>The observation vector that is returned at each step of the simulation contains the following values: - Position of cart - Velocity of cart - Angle of pole - Rotation rate of pole</p> </li> <li> <p>Get min and max value of those numbers: (code block 5)</p> <pre><code>print(env.observation_space.low)\nprint(env.observation_space.high)\n</code></pre> <p>You may also notice that reward value on each simulation step is always 1. This is because our goal is to survive as long as possible, i.e. keep the pole to a reasonably vertical position for the longest period of time.</p> <p>\u2705 In fact, the CartPole simulation is considered solved if we manage to get the average reward of 195 over 100 consecutive trials.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#state-discretization","title":"State discretization","text":"<p>In Q-Learning, we need to build Q-Table that defines what to do at each state. To be able to do this, we need state to be discreet, more precisely, it should contain finite number of discrete values. Thus, we need somehow to discretize our observations, mapping them to  a finite set of states.</p> <p>There are a few ways we can do this:</p> <ul> <li>Divide into bins. If we know the interval of a certain value, we can divide this interval into a number of bins, and then replace the value by the bin number that it belongs to. This can be done using the numpy <code>digitize</code> method. In this case, we will precisely know the state size, because it will depend on the number of bins we select for digitalization.</li> </ul> <p>\u2705 We can use linear interpolation to bring values to some finite interval (say, from -20 to 20), and then convert numbers to integers by rounding them. This gives us a bit less control on the size of the state, especially if we do not know the exact ranges of input values. For example, in our case 2 out of 4 values do not have upper/lower bounds on their values, which may result in the infinite number of states.</p> <p>In our example, we will go with the second approach. As you may notice later, despite undefined upper/lower bounds, those value rarely take values outside of certain finite intervals, thus those states with extreme values will be very rare.</p> <ol> <li> <p>Here is the function that will take the observation from our model and produce a tuple of 4 integer values: (code block 6)</p> <pre><code>def discretize(x):\n    return tuple((x/np.array([0.25, 0.25, 0.01, 0.1])).astype(np.int))\n</code></pre> </li> <li> <p>Let's also explore another discretization method using bins: (code block 7)</p> <pre><code>def create_bins(i,num):\n    return np.arange(num+1)*(i[1]-i[0])/num+i[0]\n\nprint(\"Sample bins for interval (-5,5) with 10 bins\\n\",create_bins((-5,5),10))\n\nints = [(-5,5),(-2,2),(-0.5,0.5),(-2,2)] # intervals of values for each parameter\nnbins = [20,20,10,10] # number of bins for each parameter\nbins = [create_bins(ints[i],nbins[i]) for i in range(4)]\n\ndef discretize_bins(x):\n    return tuple(np.digitize(x[i],bins[i]) for i in range(4))\n</code></pre> </li> <li> <p>Let's now run a short simulation and observe those discrete environment values. Feel free to try both <code>discretize</code> and <code>discretize_bins</code> and see if there is a difference.</p> <p>\u2705 discretize_bins returns the bin number, which is 0-based. Thus for values of input variable around 0 it returns the number from the middle of the interval (10). In discretize, we did not care about the range of output values, allowing them to be negative, thus the state values are not shifted, and 0 corresponds to 0. (code block 8)</p> <pre><code>env.reset()\n\ndone = False\nwhile not done:\n   #env.render()\n   obs, rew, done, info = env.step(env.action_space.sample())\n   #print(discretize_bins(obs))\n   print(discretize(obs))\nenv.close()\n</code></pre> <p>\u2705 Uncomment the line starting with env.render if you want to see how the environment executes. Otherwise you can execute it in the background, which is faster. We will use this \"invisible\" execution during our Q-Learning process.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#the-q-table-structure","title":"The Q-Table structure","text":"<p>In our previous lesson, the state was a simple pair of numbers from 0 to 8, and thus it was convenient to represent Q-Table by a numpy tensor with a shape of 8x8x2. If we use bins discretization, the size of our state vector is also known, so we can use the same approach and represent state by an array of shape 20x20x10x10x2 (here 2 is the dimension of action space, and first dimensions correspond to the number of bins we have selected to use for each of the parameters in observation space).</p> <p>However, sometimes precise dimensions of the observation space are not known. In case of the <code>discretize</code> function, we may never be sure that our state stays within certain limits, because some of the original values are not bound. Thus, we will use a slightly different approach and represent Q-Table by a dictionary. </p> <ol> <li> <p>Use the pair (state,action) as the dictionary key, and the value would correspond to Q-Table entry value. (code block 9)</p> <pre><code>Q = {}\nactions = (0,1)\n\ndef qvalues(state):\n    return [Q.get((state,a),0) for a in actions]\n</code></pre> <p>Here we also define a function <code>qvalues()</code>, which returns a list of Q-Table values for a given state that corresponds to all possible actions. If the entry is not present in the Q-Table, we will return 0 as the default.</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#lets-start-q-learning","title":"Let's start Q-Learning","text":"<p>Now we are ready to teach Peter to balance!</p> <ol> <li> <p>First, let's set some hyperparameters: (code block 10)</p> <pre><code># hyperparameters\nalpha = 0.3\ngamma = 0.9\nepsilon = 0.90\n</code></pre> <p>Here, <code>alpha</code> is the learning rate that defines to which extent we should adjust the current values of Q-Table at each step. In the previous lesson we started with 1, and then decreased <code>alpha</code> to lower values during training. In this example we will keep it constant just for simplicity, and you can experiment with adjusting <code>alpha</code> values later.</p> <p><code>gamma</code> is the discount factor that shows to which extent we should prioritize future reward over current reward.</p> <p><code>epsilon</code> is the exploration/exploitation factor that determines whether we should prefer exploration to exploitation or vice versa. In our algorithm, we will in <code>epsilon</code> percent of the cases select the next action according to Q-Table values, and in the remaining number of cases we will execute a random action. This will allow us to explore areas of the search space that we have never seen before. </p> <p>\u2705 In terms of balancing - choosing random action (exploration) would act as a random punch in the wrong direction, and the pole would have to learn how to recover the balance from those \"mistakes\"</p> </li> </ol>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#improve-the-algorithm","title":"Improve the algorithm","text":"<p>We can also make two improvements to our algorithm from the previous lesson:</p> <ul> <li> <p>Calculate average cumulative reward, over a number of simulations. We will print the progress each 5000 iterations, and we will average out our cumulative reward over that period of time. It means that if we get more than 195 point - we can consider the problem solved, with even higher quality than required.</p> </li> <li> <p>Calculate maximum average cumulative result, <code>Qmax</code>, and we will store the Q-Table corresponding to that result. When you run the training you will notice that sometimes the average cumulative result starts to drop, and we want to keep the values of Q-Table that correspond to the best model observed during training.</p> </li> <li> <p>Collect all cumulative rewards at each simulation at <code>rewards</code> vector for further plotting. (code block  11)</p> <pre><code>def probs(v,eps=1e-4):\n    v = v-v.min()+eps\n    v = v/v.sum()\n    return v\n\nQmax = 0\ncum_rewards = []\nrewards = []\nfor epoch in range(100000):\n    obs = env.reset()\n    done = False\n    cum_reward=0\n    # == do the simulation ==\n    while not done:\n        s = discretize(obs)\n        if random.random()&lt;epsilon:\n            # exploitation - chose the action according to Q-Table probabilities\n            v = probs(np.array(qvalues(s)))\n            a = random.choices(actions,weights=v)[0]\n        else:\n            # exploration - randomly chose the action\n            a = np.random.randint(env.action_space.n)\n\n        obs, rew, done, info = env.step(a)\n        cum_reward+=rew\n        ns = discretize(obs)\n        Q[(s,a)] = (1 - alpha) * Q.get((s,a),0) + alpha * (rew + gamma * max(qvalues(ns)))\n    cum_rewards.append(cum_reward)\n    rewards.append(cum_reward)\n    # == Periodically print results and calculate average reward ==\n    if epoch%5000==0:\n        print(f\"{epoch}: {np.average(cum_rewards)}, alpha={alpha}, epsilon={epsilon}\")\n        if np.average(cum_rewards) &gt; Qmax:\n            Qmax = np.average(cum_rewards)\n            Qbest = Q\n        cum_rewards=[]\n</code></pre> </li> </ul> <p>What you may notice from those results:</p> <ul> <li> <p>Close to our goal. We are very close to achieving the goal of getting 195 cumulative rewards over 100+ consecutive runs of the simulation, or we may have actually achieved it! Even if we get smaller numbers, we still do not know, because we average over 5000 runs, and only 100 runs is required in the formal criteria.</p> </li> <li> <p>Reward starts to drop. Sometimes the reward start to drop, which means that we can \"destroy\" already learnt values in the Q-Table with the ones that make the situation worse.</p> </li> </ul> <p>This observation is more clearly visible if we plot training progress.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#plotting-training-progress","title":"Plotting Training Progress","text":"<p>During training, we have collected the cumulative reward value at each of the iterations into <code>rewards</code> vector. Here is how it looks when we plot it against the iteration number:</p> <pre><code>plt.plot(rewards)\n</code></pre> <p></p> <p>From this graph, it is not possible to tell anything, because due to the nature of stochastic training process the length of training sessions varies greatly. To make more sense of this graph, we can calculate the running average over a series of experiments, let's say 100. This can be done conveniently using <code>np.convolve</code>: (code block 12)</p> <pre><code>def running_average(x,window):\n    return np.convolve(x,np.ones(window)/window,mode='valid')\n\nplt.plot(running_average(rewards,100))\n</code></pre> <p></p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#varying-hyperparameters","title":"Varying hyperparameters","text":"<p>To make learning more stable, it makes sense to adjust some of our hyperparameters during training. In particular:</p> <ul> <li> <p>For learning rate, <code>alpha</code>, we may start with values close to 1, and then keep decreasing the parameter. With time, we will be getting good probability values in the Q-Table, and thus we should be adjusting them slightly, and not overwriting completely with new values.</p> </li> <li> <p>Increase epsilon. We may want to increase the <code>epsilon</code> slowly, in order to explore less and exploit more. It probably makes sense to start with lower value of <code>epsilon</code>, and move up to almost 1.</p> </li> </ul> <p>Task 1: Play with hyperparameter values and see if you can achieve higher cumulative reward. Are you getting above 195?</p> <p>Task 2: To formally solve the problem, you need to get 195 average reward across 100 consecutive runs. Measure that during training and make sure that you have formally solved the problem!</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#seeing-the-result-in-action","title":"Seeing the result in action","text":"<p>It would be interesting to actually see how the trained model behaves. Let's run the simulation and follow the same action selection strategy as during training, sampling according to the probability distribution in Q-Table: (code block 13)</p> <pre><code>obs = env.reset()\ndone = False\nwhile not done:\n   s = discretize(obs)\n   env.render()\n   v = probs(np.array(qvalues(s)))\n   a = random.choices(actions,weights=v)[0]\n   obs,_,done,_ = env.step(a)\nenv.close()\n</code></pre> <p>You should see something like this:</p> <p></p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#challenge","title":"\ud83d\ude80Challenge","text":"<p>Task 3: Here, we were using the final copy of Q-Table, which may not be the best one. Remember that we have stored the best-performing Q-Table into <code>Qbest</code> variable! Try the same example with the best-performing Q-Table by copying <code>Qbest</code> over to <code>Q</code> and see if you notice the difference.</p> <p>Task 4: Here we were not selecting the best action on each step, but rather sampling with corresponding probability distribution. Would it make more sense to always select the best action, with the highest Q-Table value? This can be done by using <code>np.argmax</code> function to find out the action number corresponding to highers Q-Table value. Implement this strategy and see if it improves the balancing.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#assignment","title":"Assignment","text":"<p>Train a Mountain Car</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/#conclusion","title":"Conclusion","text":"<p>We have now learned how to train agents to achieve good results just by providing them a reward function that defines the desired state of the game, and by giving them an opportunity to intelligently explore the search space. We have successfully applied the Q-Learning algorithm in the cases of discrete and continuous environments, but with discrete actions.</p> <p>It's important to also study situations where action state is also continuous, and when observation space is much more complex, such as the image from the Atari game screen. In those problems we often need to use more powerful machine learning techniques, such as neural networks, in order to achieve good results. Those more advanced topics are the subject of our forthcoming more advanced AI course.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/assignment/#train-mountain-car","title":"Train Mountain Car","text":"<p>OpenAI Gym has been designed in such a way that all environments provide the same API - i.e. the same methods <code>reset</code>, <code>step</code> and <code>render</code>, and the same abstractions of action space and observation space. Thus is should be possible to adapt the same reinforcement learning algorithms to different environments with minimal code changes.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/assignment/#a-mountain-car-environment","title":"A Mountain Car Environment","text":"<p>Mountain Car environment contains a car stuck in a valley:</p> <p></p> <p>The goal is to get out of the valley and capture the flag, by doing at each step one of the following actions:</p> Value Meaning 0 Accelerate to the left 1 Do not accelerate 2 Accelerate to the right <p>The main trick of this problem is, however, that the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.</p> <p>Observation space consists of just two values:</p> Num Observation Min Max 0 Car Position -1.2 0.6 1 Car Velocity -0.07 0.07 <p>Reward system for the mountain car is rather tricky:</p> <ul> <li>Reward of 0 is awarded if the agent reached the flag (position = 0.5) on top of the mountain.</li> <li>Reward of -1 is awarded if the position of the agent is less than 0.5.</li> </ul> <p>Episode terminates if the car position is more than 0.5, or episode length is greater than 200.</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/assignment/#instructions","title":"Instructions","text":"<p>Adapt our reinforcement learning algorithm to solve the mountain car problem. Start with existing notebook.ipynb code, substitute new environment, change state discretization functions, and try to make existing algorithm to train with minimal code modifications. Optimize the result by adjusting hyperparameters.</p> <p>Note: Hyperparameters adjustment is likely to be needed to make algorithm converge. </p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement Q-Learning algorithm is successfully adapted from CartPole example, with minimal code modifications, which is able to solve the problem of capturing the flag under 200 steps. A new Q-Learning algorithm has been adopted from the Internet, but is well-documented; or existing algorithm adopted, but does not reach desired results Student was not able to successfully adopt any algorithm, but has mede substantial steps towards solution (implemented state discretization, Q-Table data structure, etc.)"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/solution/Julia/","title":"Index","text":"<p>This is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/8-Reinforcement/2-Gym/solution/R/","title":"Index","text":"<p>this is a temporary placeholder</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/","title":"Real World","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/#postscript-real-world-applications-of-classic-machine-learning","title":"Postscript: Real world applications of classic machine learning","text":"<p>In this section of the curriculum, you will be introduced to some real-world applications of classical ML. We have scoured the internet to find whitepapers and articles about applications that have used these strategies, avoiding neural networks, deep learning and AI as much as possible. Learn about how ML is used in business systems, ecological applications, finance, arts and culture, and more.</p> <p></p> <p>Photo by Alexis Fauvet on Unsplash</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/#lesson","title":"Lesson","text":"<ol> <li>Real-World Applications for ML</li> <li>Model Debugging in Machine Learning using Responsible AI dashboard components</li> </ol>"},{"location":"curricula/ml-for-beginners/9-Real-World/#credits","title":"Credits","text":"<p>\"Real-World Applications\" was written by a team of folks, including Jen Looper and Ornella Altunyan.</p> <p>\"Model Debugging in Machine Learning using Responsible AI dashboard components\" was written by Ruth Yakubu</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/","title":"Applications","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#postscript-machine-learning-in-the-real-world","title":"Postscript: Machine learning in the real world","text":"<p>Sketchnote by Tomomi Imura</p> <p>In this curriculum, you have learned many ways to prepare data for training and create machine learning models. You built a series of classic regression, clustering, classification, natural language processing, and time series models. Congratulations! Now, you might be wondering what it's all for... what are the real world applications for these models?</p> <p>While a lot of interest in industry has been garnered by AI, which usually leverages deep learning, there are still valuable applications for classical machine learning models. You might even use some of these applications today! In this lesson, you'll explore how eight different industries and subject-matter domains use these types of models to make their applications more performant, reliable, intelligent, and valuable to users.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#finance","title":"\ud83d\udcb0 Finance","text":"<p>The finance sector offers many opportunities for machine learning. Many problems in this area lend themselves to be modeled and solved by using ML.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#credit-card-fraud-detection","title":"Credit card fraud detection","text":"<p>We learned about k-means clustering earlier in the course, but how can it be used to solve problems related to credit card fraud?</p> <p>K-means clustering comes in handy during a credit card fraud detection technique called outlier detection. Outliers, or deviations in observations about a set of data, can tell us if a credit card is being used in a normal capacity or if something unusual is going on. As shown in the paper linked below, you can sort credit card data using a k-means clustering algorithm and assign each transaction to a cluster based on how much of an outlier it appears to be. Then, you can evaluate the riskiest clusters for fraudulent versus legitimate transactions. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#wealth-management","title":"Wealth management","text":"<p>In wealth management, an individual or firm handles investments on behalf of their clients. Their job is to sustain and grow wealth in the long-term, so it is essential to choose investments that perform well.</p> <p>One way to evaluate how a particular investment performs is through statistical regression. Linear regression is a valuable tool for understanding how a fund performs relative to some benchmark. We can also deduce whether or not the results of the regression are statistically significant, or how much they would affect a client's investments. You could even further expand your analysis using multiple regression, where additional risk factors can be taken into account. For an example of how this would work for a specific fund, check out the paper below on evaluating fund performance using regression. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#education","title":"\ud83c\udf93 Education","text":"<p>The educational sector is also a very interesting area where ML can be applied. There are interesting problems to be tackled such as detecting cheating on tests or essays or managing bias, unintentional or not, in the correction process.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#predicting-student-behavior","title":"Predicting student behavior","text":"<p>Coursera, an online open course provider, has a great tech blog where they discuss many engineering decisions. In this case study, they plotted a regression line to try to explore any correlation between a low NPS (Net Promoter Score) rating and course retention or drop-off. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#mitigating-bias","title":"Mitigating bias","text":"<p>Grammarly, a writing assistant that checks for spelling and grammar errors, uses sophisticated natural language processing systems throughout its products. They published an interesting case study in their tech blog about how they dealt with gender bias in machine learning, which you learned about in our introductory fairness lesson. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#retail","title":"\ud83d\udc5c Retail","text":"<p>The retail sector can definitely benefit from the use of ML, with everything from creating a better customer journey to stocking inventory in an optimal way.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#personalizing-the-customer-journey","title":"Personalizing the customer journey","text":"<p>At Wayfair, a company that sells home goods like furniture, helping customers find the right products for their taste and needs is paramount. In this article, engineers from the company describe how they use ML and NLP to \"surface the right results for customers\". Notably, their Query Intent Engine has been built to use entity extraction, classifier training, asset and opinion extraction, and sentiment tagging on customer reviews. This is a classic use case of how NLP works in online retail. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#inventory-management","title":"Inventory management","text":"<p>Innovative, nimble companies like StitchFix, a box service that ships clothing to consumers, rely heavily on ML for recommendations and inventory management. Their styling teams work together with their merchandising teams, in fact: \"one of our data scientists tinkered with a genetic algorithm and applied it to apparel to predict what would be a successful piece of clothing that doesn't exist today. We brought that to the merchandise team and now they can use that as a tool.\" Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#health-care","title":"\ud83c\udfe5 Health Care","text":"<p>The health care sector can leverage ML to optimize research tasks and also logistic problems like readmitting patients or stopping diseases from spreading.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#managing-clinical-trials","title":"Managing clinical trials","text":"<p>Toxicity in clinical trials is a major concern to drug makers. How much toxicity is tolerable? In this study, analyzing various clinical trial methods led to the development of a new approach for predicting the odds of clinical trial outcomes. Specifically, they were able to use random forest to produce a classifier that is able to distinguish between groups of drugs. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#hospital-readmission-management","title":"Hospital readmission management","text":"<p>Hospital care is costly, especially when patients have to be readmitted. This paper discusses a company that uses ML to predict readmission potential using clustering algorithms. These clusters help analysts to \"discover groups of readmissions that may share a common cause\". Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#disease-management","title":"Disease management","text":"<p>The recent pandemic has shone a bright light on the ways that machine learning can aid in stopping the spread of disease. In this article, you'll recognize the use of ARIMA, logistic curves, linear regression, and SARIMA. \"This work is an attempt to calculate the rate of spread of this virus and thus to predict the deaths, recoveries, and confirmed cases, so that it may help us to prepare better and survive.\" Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#ecology-and-green-tech","title":"\ud83c\udf32 Ecology and Green Tech","text":"<p>Nature and ecology consists of many sensitive systems where the interplay between animals and nature come into focus. It's important to be able to measure these systems accurately and act appropriately if something happens, like a forest fire or a drop in the animal population.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#forest-management","title":"Forest management","text":"<p>You learned about Reinforcement Learning in previous lessons. It can be very useful when trying to predict patterns in nature. In particular, it can be used to track ecological problems like forest fires and the spread of invasive species. In Canada, a group of researchers used Reinforcement Learning to build forest wildfire dynamics models from satellite images. Using an innovative \"spatially spreading process (SSP)\", they envisioned a forest fire as \"the agent at any cell in the landscape.\" \"The set of actions the fire can take from a location at any point in time includes spreading north, south, east, or west or not spreading.</p> <p>This approach inverts the usual RL setup since the dynamics of the corresponding Markov Decision Process (MDP) is a known function for immediate wildfire spread.\" Read more about the classic algorithms used by this group at the link below. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#motion-sensing-of-animals","title":"Motion sensing of animals","text":"<p>While deep learning has created a revolution in visually tracking animal movements (you can build your own polar bear tracker here), classic ML still has a place in this task.</p> <p>Sensors to track movements of farm animals and IoT make use of this type of visual processing, but more basic ML techniques are useful to preprocess data. For example, in this paper, sheep postures were monitored and analyzed using various classifier algorithms. You might recognize the ROC curve on page 335. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#energy-management","title":"\u26a1\ufe0f Energy Management","text":"<p>In our lessons on time series forecasting, we invoked the concept of smart parking meters to generate revenue for a town based on understanding supply and demand. This article discusses in detail how clustering, regression and time series forecasting combined to help predict future energy use in Ireland, based off of smart metering. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#insurance","title":"\ud83d\udcbc Insurance","text":"<p>The insurance sector is another sector that uses ML to construct and optimize viable financial and actuarial models. </p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#volatility-management","title":"Volatility Management","text":"<p>MetLife, a life insurance provider, is forthcoming with the way they analyze and mitigate volatility in their financial models. In this article you'll notice binary and ordinal classification visualizations. You'll also discover forecasting visualizations. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#arts-culture-and-literature","title":"\ud83c\udfa8 Arts, Culture, and Literature","text":"<p>In the arts, for example in journalism, there are many interesting problems. Detecting fake news is a huge problem as it has been proven to influence the opinion of people and even to topple democracies. Museums can also benefit from using ML in everything from finding links between artifacts to resource planning.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#fake-news-detection","title":"Fake news detection","text":"<p>Detecting fake news has become a game of cat and mouse in today's media. In this article, researchers suggest that a system combining several of the ML techniques we have studied can be tested and the best model deployed: \"This system is based on natural language processing to extract features from the data and then these features are used for the training of machine learning classifiers such as Naive Bayes,  Support Vector Machine (SVM), Random Forest (RF), Stochastic Gradient Descent (SGD), and Logistic Regression(LR).\" Reference</p> <p>This article shows how combining different ML domains can produce interesting results that can help stop fake news from spreading and creating real damage; in this case, the impetus was the spread of rumors about COVID treatments that incited mob violence.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#museum-ml","title":"Museum ML","text":"<p>Museums are at the cusp of an AI revolution in which cataloging and digitizing collections and finding links between artifacts is becoming easier as technology advances. Projects such as In Codice Ratio are helping unlock the mysteries of inaccessible collections such as the Vatican Archives. But, the business aspect of museums benefits from ML models as well.</p> <p>For example, the Art Institute of Chicago built models to predict what audiences are interested in and when they will attend expositions. The goal is to create individualized and optimized visitor experiences each time the user visits the museum. \"During fiscal 2017, the model predicted attendance and admissions within 1 percent of accuracy, says Andrew Simnick, senior vice president at the Art Institute.\" Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#marketing","title":"\ud83c\udff7 Marketing","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#customer-segmentation","title":"Customer segmentation","text":"<p>The most effective marketing strategies target customers in different ways based on various groupings. In this article, the uses of Clustering algorithms are discussed to support differentiated marketing. Differentiated marketing helps companies improve brand recognition, reach more customers, and make more money. Reference</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>Identify another sector that benefits from some of the techniques you learned in this curriculum, and discover how it uses ML.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#review-self-study","title":"Review &amp; Self Study","text":"<p>The Wayfair data science team has several interesting videos on how they use ML at their company. It's worth taking a look!</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/#assignment","title":"Assignment","text":"<p>A ML scavenger hunt</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/assignment/#a-ml-scavenger-hunt","title":"A ML Scavenger Hunt","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/assignment/#instructions","title":"Instructions","text":"<p>In this lesson, you learned about many real-life use cases that were solved using classical ML. While the use of deep learning, new techniques and tools in AI, and leveraging neural networks has helped speed up the production of tools to help in these sectors, classic ML using the techniques in this curriculum still hold great value.</p> <p>In this assignment, imagine that you are participating in a hackathon. Use what you learned in the curriculum to propose a solution using classic ML to solve a problem in one of the sectors discussed in this lesson. Create a presentation where you discuss how you will implement your idea. Bonus points if you can gather sample data and build a ML model to support your concept!</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/1-Applications/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A PowerPoint presentation is presented - bonus for building a model A non-innovative, basic presentation is presented The work is incomplete"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/","title":"Debugging ML Models","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#postscript-model-debugging-in-machine-learning-using-responsible-ai-dashboard-components","title":"Postscript: Model Debugging in Machine Learning using Responsible AI dashboard components","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#pre-lecture-quiz","title":"Pre-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#introduction","title":"Introduction","text":"<p>Machine learning impacts our everyday lives. AI is finding its way into some of the most important systems that affect us as individuals as well as our society, from healthcare, finance, education, and employment. For instance, systems and models are involved in daily decision-making tasks, such as health care diagnoses or detecting fraud. Consequentially, the advancements in AI along with the accelerated adoption are being met with evolving societal expectations and growing regulation in response. We constantly see areas where AI systems continue to miss expectations; they expose new challenges; and governments are starting to regulate AI solutions. So, it is important that these models are analyzed to provide fair, reliable, inclusive, transparent, and accountable outcomes for everyone.</p> <p>In this curriculum, we will look at practical tools that can be used to assess if a model has responsible AI issues. Traditional machine learning debugging techniques tend to be based on quantitative calculations such as aggregated accuracy or average error loss. Imagine what can happen when the data you are using to build these models lacks certain demographics, such as race, gender, political view, religion, or disproportionally represents such demographics. What about when the model's output is interpreted to favor some demographic? This can introduce an over or under representation of these sensitive feature groups resulting in fairness, inclusiveness, or reliability issues from the model. Another factor is, machine learning models are considered black boxes, which makes it hard to understand and explain what drives a model\u2019s prediction. All of these are challenges data scientists and AI developers face when they do not have adequate tools to debug and assess the fairness or trustworthiness of a model.</p> <p>In this lesson, you will learn about debugging your models using:</p> <ul> <li>Error Analysis: identify where in your data distribution the model has high error rates.</li> <li>Model Overview: perform comparative analysis across different data cohorts to discover disparities in your model\u2019s performance metrics.</li> <li>Data Analysis: investigate where there could be over or under representation of your data that can skew your model to favor one data demographic vs another.</li> <li>Feature Importance: understand which features are driving your model\u2019s predictions on a global level or local level.</li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#prerequisite","title":"Prerequisite","text":"<p>As a prerequisite, please take the review Responsible AI tools for developers</p> <p></p>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#error-analysis","title":"Error Analysis","text":"<p>Traditional model performance metrics used for measuring accuracy are mostly calculations based on correct vs incorrect predictions. For example, determining that a model is accurate 89% of time with an error loss of 0.001 can be considered a good performance. Errors are often not distributed uniformly in your underlying dataset. You may get an 89% model accuracy score but discover that there are different regions of your data for which the model is failing 42% of the time. The consequence of these failure patterns with certain data groups can lead to fairness or reliability issues. It is essential to understand areas where the model is performing well or not. The data regions where there are a high number of inaccuracies in your model may turn out to be an important data demographic.  </p> <p></p> <p>The Error Analysis component on the RAI dashboard illustrates how model failure is distributed across various cohorts with a tree visualization. This is useful in identifying features or areas where there is a high error rate with your dataset. By seeing where most of the model\u2019s inaccuracies are coming from, you can start investigating the root cause. You can also create cohorts of data to perform analysis on. These data cohorts help in the debugging process to determine why the model performance is good in one cohort, but erroneous in another.   </p> <p></p> <p>The visual indicators on the tree map help in locating the problem areas quicker. For instance, the darker shade of red color a tree node has, the higher the error rate.  </p> <p>Heat map is another visualization functionality that users can use in investigating the error rate using one or two features to find a contributor to the model errors across an entire dataset or cohorts.</p> <p></p> <p>Use error analysis when you need to:</p> <ul> <li>Gain a deep understanding of how model failures are distributed across a dataset and across several input and feature dimensions.</li> <li>Break down the aggregate performance metrics to automatically discover erroneous cohorts to inform your targeted mitigation steps.</li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#model-overview","title":"Model Overview","text":"<p>Evaluating the performance of a machine learning model requires getting a holistic understanding of its behavior. This can be achieved by reviewing more than one metric such as error rate, accuracy, recall, precision, or MAE (Mean Absolute Err) to find disparities among performance metrics.  One performance metric may look great, but inaccuracies can be exposed in another metric. In addition, comparing the metrics for disparities across the entire dataset or cohorts helps shed light on where the model is performing well or not. This is especially important in seeing the model\u2019s performance among sensitive vs insensitive features (e.g., patient race, gender, or age) to uncover potential unfairness the model may have. For example, discovering that the model is more erroneous in a cohort that has sensitive features can reveal potential unfairness the model may have.</p> <p>The Model Overview component of the RAI dashboard helps not just in analyzing the performance metrics of the data representation in a cohort, but it gives users the ability to compare the model\u2019s behavior across different cohorts.</p> <p></p> <p>The component's feature-based analysis functionality allows users to narrow down data subgroups within a particular feature to identify anomalies on a granular level. For example, the dashboard has built-in intelligence to automatically generate cohorts for a user-selected feature (eg., \"time_in_hospital &lt; 3\" or \"time_in_hospital &gt;= 7\"). This enables a user to isolate a particular feature from a larger data group to see if it is a key influencer of the model's erroneous outcomes.</p> <p></p> <p>The Model Overview component supports two classes of disparity metrics:</p> <p>Disparity in model performance: These sets of metrics calculate the disparity (difference) in the values of the selected performance metric across subgroups of data. Here are a few examples:</p> <ul> <li>Disparity in accuracy rate</li> <li>Disparity in error rate</li> <li>Disparity in precision</li> <li>Disparity in recall</li> <li>Disparity in mean absolute error (MAE)</li> </ul> <p>Disparity in selection rate: This metric contains the difference in selection rate (favorable prediction) among subgroups. An example of this is the disparity in loan approval rates. Selection rate means the fraction of data points in each class classified as 1 (in binary classification) or distribution of prediction values (in regression).</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#data-analysis","title":"Data Analysis","text":"<p>\"If you torture the data long enough, it will confess to anything\" - Ronald Coase</p> <p>This statement sounds extreme, but it is true that data can be manipulated to support any conclusion. Such manipulation can sometimes happen unintentionally. As humans, we all have bias, and it is often difficult to consciously know when you are introducing bias in data. Guaranteeing fairness in AI and machine learning remains a complex challenge. </p> <p>Data is a huge blind spot for traditional model performance metrics. You may have high accuracy scores, but this does not always reflect the underlining data bias that could be in your dataset. For example, if a dataset of employees has 27% of women in executive positions in a company and 73% of men at the same level, a job advertising AI model trained on this data may target mostly a male audience for senior level job positions. Having this imbalance in data skewed the model\u2019s prediction to favor one gender. This reveals a fairness issue where there is a gender bias in the AI model.  </p> <p>The Data Analysis component on the RAI dashboard helps to identify areas where there\u2019s an over- and under-representation in the dataset. It helps users diagnose the root cause of errors and fairness issues introduced from data imbalances or lack of representation of a particular data group. This gives users the ability to visualize datasets based on predicted and actual outcomes, error groups, and specific features. Sometimes discovering an underrepresented data group can also uncover that the model is not learning well, hence the high inaccuracies. Having a model that has data bias is not just a fairness issue but shows that the model is not inclusive or reliable.</p> <p></p> <p>Use data analysis when you need to:</p> <ul> <li>Explore your dataset statistics by selecting different filters to slice your data into different dimensions (also known as cohorts).</li> <li>Understand the distribution of your dataset across different cohorts and feature groups.</li> <li>Determine whether your findings related to fairness, error analysis, and causality (derived from other dashboard components) are a result of your dataset's distribution.</li> <li>Decide in which areas to collect more data to mitigate errors that come from representation issues, label noise, feature noise, label bias, and similar factors.</li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#model-interpretability","title":"Model Interpretability","text":"<p>Machine learning models tend to be black boxes. Understanding which key data features drive a model\u2019s prediction can be challenging.  It is important to provide transparency as to why a model makes a certain prediction. For example, if an AI system predicts that a diabetic patient is at risk of being readmitted back to a hospital in less than 30 days, it should be able to provide supporting data that led to its prediction. Having supporting data indicators brings transparency to help clinicians or hospitals to be able to make well-informed decisions. In addition, being able to explain why a model made a prediction for an individual patient enables accountability with health regulations. When you are using machine learning models in ways that affect people\u2019s lives, it is crucial to understand and explain what influences the behavior of a model. Model explainability and interpretability helps answer questions in scenarios such as:</p> <ul> <li>Model debugging: Why did my model make this mistake? How can I improve my model?</li> <li>Human-AI collaboration: How can I understand and trust the model\u2019s decisions?</li> <li>Regulatory compliance: Does my model satisfy legal requirements?</li> </ul> <p>The Feature Importance component of the RAI dashboard helps you to debug and get a comprehensive understanding of how a model makes predictions. It is also a useful tool for machine learning professionals and decision-makers to explain and show evidence of features influencing a model's behavior for regulatory compliance. Next, users can explore both global and local explanations validate which features drive a model\u2019s prediction. Global explanations lists the top features that affected a model\u2019s overall prediction. Local explanations display which features led to a model\u2019s prediction for an individual case. The ability to evaluate local explanations is also helpful in debugging or auditing a specific case to better understand and interpret why a model made an accurate or inaccurate prediction. </p> <p></p> <ul> <li>Global explanations: For example, what features affect the overall behavior of a diabetes hospital readmission model?</li> <li>Local explanations: For example, why was a diabetic patient over 60 years old with prior hospitalizations predicted to be readmitted or not readmitted within 30 days back to a hospital?</li> </ul> <p>In the debugging process of examining a model\u2019s performance across different cohorts, Feature Importance shows what level of impact a feature has across the cohorts. It helps reveal anomalies when comparing the level of influence the feature has in driving a model\u2019s erroneous predictions. The Feature Importance component can show which values in a feature positively or negatively influenced the model\u2019s outcome. For instance, if a model made an inaccurate prediction, the component gives you the ability to drill down and pinpoint what features or feature values drove the prediction. This level of detail helps not just in debugging but provides transparency and accountability in auditing situations. Finally, the component can help you to identify fairness issues. To illustrate, if a sensitive feature such as ethnicity or gender is highly influential in driving a model\u2019s prediction, this could be a sign of race or gender bias in the model.</p> <p></p> <p>Use interpretability when you need to:</p> <ul> <li>Determine how trustworthy your AI system\u2019s predictions are by understanding what features are most important for the predictions.</li> <li>Approach the debugging of your model by understanding it first and identifying whether the model is using healthy features or merely false correlations.</li> <li>Uncover potential sources of unfairness by understanding whether the model is basing predictions on sensitive features or on features that are highly correlated with them.</li> <li>Build user trust in your model\u2019s decisions by generating local explanations to illustrate their outcomes.</li> <li>Complete a regulatory audit of an AI system to validate models and monitor the impact of model decisions on humans.</li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#conclusion","title":"Conclusion","text":"<p>All the RAI dashboard components are practical tools to help you build machine learning models that are less harmful and more trustworthy to society. It improves the prevention of treats to human rights; discriminating or excluding certain groups to life opportunities; and the risk of physical or psychological injury. It also helps to build trust in your model\u2019s decisions by generating local explanations to illustrate their outcomes. Some of the potential harms can be classified as:</p> <ul> <li>Allocation, if a gender or ethnicity for example is favored over another.</li> <li>Quality of service. If you train the data for one specific scenario but the reality is much more complex, it leads to a poor performing service.</li> <li>Stereotyping. Associating a given group with pre-assigned attributes.</li> <li>Denigration. To unfairly criticize and label something or someone.</li> <li>Over- or under- representation. The idea is that a certain group is not seen in a certain profession, and any service or function that keeps promoting that is contributing to harm.</li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#azure-rai-dashboard","title":"Azure RAI dashboard","text":"<p>Azure RAI dashboard is built on open-source tools developed by the leading academic institutions and organizations including Microsoft are instrumental for data scientists and AI developers to better understand model behavior, discover and mitigate undesirable issues from AI models.</p> <ul> <li> <p>Learn how to use the different components by checking out the RAI dashboard docs.</p> </li> <li> <p>Check out some RAI dashboard sample notebooks for debugging more responsible AI scenarios in Azure Machine Learning. </p> </li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#challenge","title":"\ud83d\ude80 Challenge","text":"<p>To prevent statistical or data biases from being introduced in the first place, we should: </p> <ul> <li>have a diversity of backgrounds and perspectives among the people working on systems </li> <li>invest in datasets that reflect the diversity of our society </li> <li>develop better methods for detecting and correcting bias when it occurs </li> </ul> <p>Think about real-life scenarios where unfairness is evident in model-building and usage. What else should we consider? </p>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#post-lecture-quiz","title":"Post-lecture quiz","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#review-self-study","title":"Review &amp; Self Study","text":"<p>In this lesson, you have learned some of the practical tools of incorporating responsible AI in machine learning.  </p> <p>Watch this workshop to dive deeper into the topics: </p> <ul> <li>Responsible AI Dashboard: One-stop shop for operationalizing RAI in practice by Besmira Nushi and Mehrnoosh Sameki</li> </ul> <p></p> <p>\ud83c\udfa5 Click the image above for a video: Responsible AI Dashboard: One-stop shop for operationalizing RAI in practice by Besmira Nushi and Mehrnoosh Sameki</p> <p>Reference the following materials to learn more about responsible AI and how to build more trustworthy models: </p> <ul> <li> <p>Microsoft\u2019s RAI dashboard tools for debugging ML models: Responsible AI tools resources</p> </li> <li> <p>Explore the Responsible AI toolkit: Github</p> </li> <li> <p>Microsoft\u2019s RAI resource center: Responsible AI Resources \u2013 Microsoft AI </p> </li> <li> <p>Microsoft\u2019s FATE research group: FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research </p> </li> </ul>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/#assignment","title":"Assignment","text":"<p>Explore RAI dashboard </p>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/assignment/","title":"Assignment","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/assignment/#explore-responsible-ai-rai-dashboard","title":"Explore Responsible AI (RAI) dashboard","text":""},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/assignment/#instructions","title":"Instructions","text":"<p>In this lesson you learned about the RAI dashboard, a suite of components built on \"open-source\" tools  to help data scientists perform error analysis, data exploration, fairness assessment, model interpretability, counterfact/what-if assesments and causal analysis on AI systems.\" For this assignment, explore some of RAI dashboard's sample notebooks and report your findings in a paper or presentation.</p>"},{"location":"curricula/ml-for-beginners/9-Real-World/2-Debugging-ML-Models/assignment/#rubric","title":"Rubric","text":"Criteria Exemplary Adequate Needs Improvement A paper or powerpoint presentation is presented discussing RAI dashboard's components, the notebook that was run, and the conclusions drawn from running it A paper is presented without conclusions No paper is presented"},{"location":"curricula/ml-for-beginners/sketchnotes/","title":"Index","text":"<p>All the curriculum's sketchnotes can be downloaded here.</p> <p>\ud83d\udda8 For printing in high-resolution, the TIFF versions are available at this repo.</p> <p>\ud83c\udfa8 Created by: Tomomi Imura (Twitter: @girlie_mac)</p> <p></p>"},{"location":"curricula/ml-for-beginners/sketchnotes/LICENSE/","title":"LICENSE","text":"<p>Attribution-ShareAlike 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More_considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution-ShareAlike 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. BY-SA Compatible License means a license listed at      creativecommons.org/compatiblelicenses, approved by Creative      Commons as essentially the equivalent of this Public License.</p> <p>d. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>e. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>f. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>g. License Elements means the license attributes listed in the name      of a Creative Commons Public License. The License Elements of this      Public License are Attribution and ShareAlike.</p> <p>h. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>i. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>j. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>k. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>l. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>m. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. Additional offer from the Licensor -- Adapted Material.\n           Every recipient of Adapted Material from You\n           automatically receives an offer from the Licensor to\n           exercise the Licensed Rights in the Adapted Material\n           under the conditions of the Adapter's License You apply.\n\n        c. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n</code></pre> <p>b. ShareAlike.</p> <pre><code> In addition to the conditions in Section 3(a), if You Share\n Adapted Material You produce, the following conditions also apply.\n\n   1. The Adapter's License You apply must be a Creative Commons\n      license with the same License Elements, this version or\n      later, or a BY-SA Compatible License.\n\n   2. You must include the text of, or the URI or hyperlink to, the\n      Adapter's License You apply. You may satisfy this condition\n      in any reasonable manner based on the medium, means, and\n      context in which You Share Adapted Material.\n\n   3. You may not offer or impose any additional or different terms\n      or conditions on, or apply any Effective Technological\n      Measures to, Adapted Material that restrict exercise of the\n      rights granted under the Adapter's License You apply.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material,</p> <pre><code> including for purposes of Section 3(b); and\n</code></pre> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"data-structures/bignum/","title":"Bignum","text":""},{"location":"data-structures/binary-heap/","title":"Binary Heap","text":"<p>Time Complexity:</p> <ul> <li>Emplace: \\(O(\\log n)\\)</li> <li>Pop: \\(O(\\log n)\\)</li> </ul> Head FilesC++ Version <pre><code>#include &lt;cstddef&gt;\n#include &lt;algorithm&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> Template<pre><code>template &lt;typename Type, size_t Size&gt;\nclass heap {\nprivate:\n    int cnt;\n    Type val[Size];\n\npublic:\n    heap() {cnt=0;}\n\n    void emplace(int x) {\n        val[++cnt] = x;\n        int now = cnt;\n\n        while (now){\n            int fa = now &gt;&gt; 1;\n\n            if (val[fa] &gt; val[now]) {\n                swap(val[fa], val[now]);\n            } else {\n                break;\n            }\n\n            now = fa;\n        }\n    }\n\n    void pop() {\n        swap(val[cnt--], val[1]);\n\n        int now = 1;\n        while ((now &lt;&lt; 1) &lt;= cnt) { \n            int ls = now &lt;&lt; 1;\n\n            if (ls+1 &lt;= cnt &amp;&amp; val[ls+1] &lt; val[ls]) {\n                ++ls;\n            }\n            if (val[ls] &lt; val[now]) {\n                swap(val[now], val[ls]);\n            } else {\n                break;\n            }\n\n            now = ls;\n        }\n    }\n\n    int size() {\n        return cnt; \n    }\n\n    bool empty() {\n        return cnt == 0;\n    }\n\n    Type top() {\n        return val[1];\n    }\n};\n</code></pre>"},{"location":"data-structures/disjoint-set-union/","title":"Disjoint Set Union","text":"Head Files <pre><code>#include &lt;vector&gt;\n</code></pre> Template<pre><code>class dsu {\nprivate:\n    vector&lt;int&gt; fa;\n\npublic:\n    dsu(const int &amp;sz) {\n        fa.resize(sz+1, 0);\n\n        for (int i=1; i&lt;=sz; ++i) {\n            fa[i] = i;\n        }\n    }\n\n    inline int find(const int &amp;x) {\n        return x == fa[x] ? x : fa[x] = find(fa[x]);\n    }\n\n    inline void merge(const int &amp;x, const int &amp;y) {\n        int fx = find(x), fy = find(y);\n        if (fx != fy) {\n            fa[fx] = fy;\n        }\n    }\n};\n</code></pre>"},{"location":"data-structures/segment-tree/","title":"Segment Tree","text":""},{"location":"data-structures/segment-tree/#time-complexity","title":"Time Complexity:","text":"<ul> <li>Build: \\(O(n)\\)</li> <li>Query: \\(O(\\log n)\\)</li> <li>Update: \\(O(\\log n)\\)</li> <li>Modify: \\(O(\\log n)\\)</li> </ul>"},{"location":"data-structures/segment-tree/#template","title":"Template","text":"Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n#include &lt;functional&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre>"},{"location":"data-structures/segment-tree/#integrated-version","title":"Integrated Version","text":"Template<pre><code>template&lt;typename Type&gt;\nclass segment_tree {\nusing func_type = function&lt;Type(const Type &amp;, const Type &amp;)&gt;;\nprivate:\n    vector&lt;Type&gt; val;\n    vector&lt;Type&gt; add_tag;\n    vector&lt;Type&gt; set_tag;\n    vector&lt;bool&gt; is_set;\n    int len;\n\n    inline int ls(const int &amp;x) { return x &lt;&lt; 1; }\n    inline int rs(const int &amp;x) { return x &lt;&lt; 1 | 1; }\n\n    func_type opr;\n    static Type default_func_type(const Type &amp;x, const Type &amp;y) { return x + y; }\n\n    void push_up(const int &amp;x) {\n        val[x] = opr(val[ls(x)], val[rs(x)]);\n    }\n\n    void add_tag_func(const int &amp;x, const int &amp;l, const int &amp;r, const Type &amp;d) {\n        add_tag[x] += d;\n        val[x] += d * (r - l + 1);\n    }\n\n    void set_tag_func(const int &amp;x, const int &amp;l, const int &amp;r, const Type &amp;d) {\n        set_tag[x] = d;\n        val[x] = d * (r - l + 1);\n        add_tag[x] = 0;\n        is_set[x] = true;\n    }\n\n    void push_down(const int &amp;x, const int &amp;l, const int &amp;r) {\n        int mid = (l + r) &gt;&gt; 1;\n        if (is_set[x]) {\n            set_tag_func(ls(x), l, mid, set_tag[x]);\n            set_tag_func(rs(x), mid + 1, r, set_tag[x]);\n            is_set[x] = false;\n        }\n        if (add_tag[x] != 0) {\n            add_tag_func(ls(x), l, mid, add_tag[x]);\n            add_tag_func(rs(x), mid + 1, r, add_tag[x]);\n            add_tag[x] = 0;\n        }\n    }\n\n    void build(const vector&lt;Type&gt; &amp;s, const int &amp;x, const int &amp;l, const int &amp;r) {\n        add_tag[x] = 0;\n        set_tag[x] = 0;\n        is_set[x] = false;\n        if (l == r) {\n            val[x] = s[l];\n            return;\n        }\n\n        int mid = (l + r) &gt;&gt; 1;\n        build(s, ls(x), l, mid);\n        build(s, rs(x), mid + 1, r);\n        push_up(x);\n    }\n\n    Type query(const int &amp;L, const int &amp;R, const int x, const int &amp;l, const int &amp;r) {\n        if (L &lt;= l &amp;&amp; r &lt;= R) return val[x];\n        push_down(x, l, r);\n\n        Type res = Type();\n        int mid = (l + r) &gt;&gt; 1;\n\n        if (L &lt;= mid) res = opr(res, query(L, R, ls(x), l, mid));\n        if (R &gt; mid) res = opr(res, query(L, R, rs(x), mid + 1, r));\n\n        return res;\n    }\n\n    void update(const int &amp;L, const int &amp;R, const int &amp;x, const int &amp;l, const int &amp;r, const Type &amp;d) {\n        if (L &lt;= l &amp;&amp; r &lt;= R) {\n            add_tag_func(x, l, r, d);\n            return;\n        }\n\n        push_down(x, l, r);\n        int mid = (l + r) &gt;&gt; 1;\n        if (L &lt;= mid) update(L, R, ls(x), l, mid, d);\n        if (R &gt; mid) update(L, R, rs(x), mid + 1, r, d);\n\n        push_up(x);\n    }\n\n    void modify(const int &amp;L, const int &amp;R, const int &amp;x, const int &amp;l, const int &amp;r, const Type &amp;d) {\n        if (L &lt;= l &amp;&amp; r &lt;= R) {\n            set_tag_func(x, l, r, d);\n            return;\n        }\n\n        push_down(x, l, r);\n        int mid = (l + r) &gt;&gt; 1;\n        if (L &lt;= mid) modify(L, R, ls(x), l, mid, d);\n        if (R &gt; mid) modify(L, R, rs(x), mid + 1, r, d);\n\n        push_up(x);\n    }\n\npublic:\n    segment_tree(vector&lt;Type&gt; v, func_type _opr = default_func_type) {\n        val.resize(v.size() &lt;&lt; 2, Type());\n        add_tag.resize(v.size() &lt;&lt; 2, Type());\n        set_tag.resize(v.size() &lt;&lt; 2, Type());\n        is_set.resize(v.size() &lt;&lt; 2, false);\n        len = v.size();\n        opr = _opr;\n\n        v.insert(v.begin(), Type());\n        build(v, 1, 1, len);\n    }\n\n    int size() const {\n        return len;\n    }\n\n    Type query(const int &amp;L, const int &amp;R) {\n        return query(L, R, 1, 1, len);\n    }\n\n    void update(const int &amp;L, const int &amp;R, const Type &amp;d) {\n        update(L, R, 1, 1, len, d);\n    }\n\n    void modify(const int &amp;L, const int &amp;R, const Type &amp;d) {\n        modify(L, R, 1, 1, len, d);\n    }\n};\n</code></pre> Usage<pre><code>signed main() {\n    vector&lt;int&gt; a;\n    int b[]={5, 4, 3, 2, 1};\n\n    for (int i=0; i&lt;5; ++i) {\n        a.emplace_back(b[i]);\n    }\n    segment_tree&lt;int&gt; sg(a);\n\n    cout &lt;&lt; sg.query(1, 4) &lt;&lt; endl;\n    sg.update(1, 2, 2);\n    cout &lt;&lt; sg.query(1, 4) &lt;&lt; endl;\n    sg.modify(1, 2, 2);\n    cout &lt;&lt; sg.query(1, 4) &lt;&lt; endl;\n}\n</code></pre>"},{"location":"data-structures/segment-tree/#add-version","title":"Add Version","text":"<pre><code>class segment_tree {\nusing VI = vector&lt;int&gt;;\nusing CI = const int;\n\nprivate:\n    VI val, tag;\n    int len;\n\n    inline int ls(CI &amp;x) {\n        return x &lt;&lt; 1;\n    }\n    inline int rs(CI &amp;x) {\n        return x &lt;&lt; 1 | 1;\n    }\n\n    void push_up(CI &amp;x) {\n        val[x] = val[ls(x)] + val[rs(x)];\n    }\n\n    void add_tag(CI &amp;x, CI &amp;l, CI &amp;r, CI &amp;d) {\n        tag[x] += d;\n        val[x] += d * (l - r + 1);\n    }\n\n    void push_down(CI &amp;x, CI &amp;l, CI &amp;r) {\n        if (tag[x]) {\n            int mid = (l + r) &gt;&gt; 1;\n            add_tag(ls(x), l, mid, tag[x]);\n            add_tag(rs(x), mid+1, r, tag[x]);\n            tag[x] = 0;\n        }\n    }\n\n    void build(const VI &amp;s, CI &amp;x, CI &amp;l, CI &amp;r) {\n        tag[x] = 0;\n        if (l == r) {\n            val[x] = s[x];\n            return;\n        }\n\n        int mid = (l + r) &gt;&gt; 1;\n        build(s, ls(x), l, mid);\n        build(s, rs(x), mid+1, r);\n        push_up(x);\n    }\n\n    int query(CI &amp;L, CI &amp;R, CI &amp;x, CI &amp;l, CI &amp;r) {\n        if (L &lt;= l &amp;&amp; r &lt;= R) {\n            return val[x];\n        }\n        push_down(x, l, r);\n\n        int ret = 0;\n        int mid = (l+r) &gt;&gt; 1;\n\n        if (L &lt;= mid) ret += query(L, R, ls(x), l, mid);\n        if (R &gt; mid) ret += query(L, R, rs(x), mid+1, r);\n\n        return ret;\n    }\n\n    void update(CI &amp;L, CI &amp;R, CI &amp;x, CI &amp;l, CI &amp;r, CI &amp;d) {\n        if (L &lt;= l &amp;&amp; r &lt;= R) {\n            add_tag(x, l, r, d);\n            return;\n        }\n\n        push_down(x, l, r);\n        int mid = (l+r) &gt;&gt; 1;\n\n        if (L &lt;= mid) update(L, R, ls(x), l, mid, d);\n        if (R &gt; mid) update(L, R, rs(x), mid+1, r, d);\n\n        push_up(x);\n    }\n\npublic:\n    segment_tree(VI &amp;s) {\n        val.resize(s.size() &lt;&lt; 2, 0);\n        tag.resize(s.size() &lt;&lt; 2, 0);\n        len = s.size();\n\n        s.emplace(s.begin(), 0);\n        build(s, 1, 1, len);\n    }\n};\n</code></pre>"},{"location":"data-structures/sparse-table/","title":"Sparse Table","text":"<p>Time Complexity:</p> <ul> <li>Build: \\(O(n \\log n)\\)</li> <li>Query: \\(O(1)\\)</li> </ul> Head FilesC++ Version <pre><code>#include &lt;vector&gt;\n#include &lt;algorithm&gt;\n#include &lt;functional&gt;\n#include &lt;cmath&gt;\n</code></pre> <pre><code>-std=c++11\n</code></pre> build log2 table<pre><code>vector&lt;int&gt; _log2;\nvoid build_log2(int x) {\n    if (x &lt; _log2.size()) return;\n\n    _log2.resize(x+1);\n    _log2[1] = 0;\n    for (int i=2; i&lt;=x; ++i) {\n        _log2[i] = _log2[i &gt;&gt; 1] + 1;\n    }\n}\n</code></pre> sparse_table<pre><code>template&lt;typename Type&gt;\nclass sparse_table {\nusing func_type = function&lt;Type(const Type &amp;, const Type &amp;)&gt;;\nprivate:\n    vector&lt; vector&lt;Type&gt; &gt; val;\n    static Type default_func_type(const Type &amp;x, const Type &amp;y) { return max(x, y); }\n    func_type opr;\n\npublic:\n    sparse_table(const vector&lt;Type&gt; &amp;v, func_type _opr = default_func_type) {\n        opr = _opr;\n        int row = v.size();\n\n        if (_log2.empty()) { build_log2(row); }\n\n        int col = ceil(_log2[row]) + 1;\n\n        val.assign(row, vector&lt;Type&gt;(col, 0));\n        for (int i=0; i&lt;row; ++i) {\n            val[i][0] = v[i];\n        }\n        for (int j=1; j&lt;col; ++j) {\n            int _j = (1 &lt;&lt; (j-1));\n            for (int i=0; i + _j &lt; row; ++i) {\n                val[i][j] = opr(val[i][j-1], val[i + (1 &lt;&lt; (j-1))][j-1]);\n            }\n        }\n    }\n\n    Type query(int l, int r) {\n        --l; --r;\n        int len = r-l+1;\n        int q = floor(_log2[len]);\n        return opr(val[l][q], val[r - (1 &lt;&lt; q) + 1][q]);\n    }\n};\n</code></pre>"},{"location":"data-structures/stack/","title":"Stack","text":"<p>Time Complexity:</p> <ul> <li>Emplace \\(O(1)\\)</li> <li>Pop: \\(O(1)\\)</li> </ul> mystack<pre><code>template &lt;typename Type, size_t Size&gt;\nclass mystack {\nprivate:\n    int cnt;\n    Type val[Size];\n\npublic:\n    mystack() {cnt=0;}\n\n    void emplace(int x) {\n        val[++cnt] = x;\n    }\n\n    void pop() {\n        --cnt;\n    }\n\n    Type top() {\n        return val[cnt];\n    }\n\n    bool empty() {\n        return cnt == 0;\n    }\n\n    void clear() {\n        cnt = 0;\n    }\n}\n</code></pre>"},{"location":"data-structures/tree/binary-tree-traversals/","title":"Binary Tree Traversals","text":"node<pre><code>struct node {\n    int val;\n    node *ls, *rs;\n}\n</code></pre>"},{"location":"data-structures/tree/binary-tree-traversals/#preorder-traversal","title":"Preorder Traversal","text":"<pre><code>void preorder(node *rt) {\n    cout &lt;&lt; rt -&gt; val &lt;&lt; endl;\n    preorder(rt -&gt; ls);\n    preorder(rt -&gt; rs);\n}\n</code></pre>"},{"location":"data-structures/tree/binary-tree-traversals/#inorder-traversal","title":"Inorder Traversal","text":"<pre><code>void inorder(node *rt) {\n    inorder(rt -&gt; ls);\n    cout &lt;&lt; rt -&gt; val &lt;&lt; endl;\n    inorder(rt -&gt; rs);\n}\n</code></pre>"},{"location":"data-structures/tree/binary-tree-traversals/#postorder-traversal","title":"Postorder Traversal","text":"<pre><code>void postorder(node *rt) {\n    postorder(rt -&gt; ls);\n    postorder(rt -&gt; rs);\n    cout &lt;&lt; rt -&gt; val &lt;&lt; endl;\n}\n</code></pre>"},{"location":"data-structures/tree/binary-tree-traversals/#get-preorder-traversal","title":"Get Preorder Traversal","text":""},{"location":"my-projects/my-projects/","title":"My Projects","text":""},{"location":"my-projects/my-projects/#lexigen","title":"LexiGen","text":"Your browser does not support the video tag.  <p>LexiGen, under GPL-3.0 license, is an AI-powered desktop application for generating educational fill-in-the-blank sentences.</p> <p>LexiGen transforms vocabulary practice and language learning by automatically generating contextual fill-in-the-blank sentences. Leveraging Ollama's AI models, it creates engaging educational materials with just a few clicks.</p>"},{"location":"my-projects/my-projects/#ollama-writing-tools","title":"Ollama Writing Tools","text":"<p>Ollama Writing Tools, under Apache-2.0 license, is a Windows application that enhances your writing with AI-powered assistance through Ollama. Simply select text anywhere, and get instant writing improvements with a single click. It is 100% free and open source, and even customizable, you can configure different prompts for different writing tasks.</p> <p> </p>"},{"location":"my-projects/my-projects/#moa-ollama-chat","title":"MoA-Ollama-Chat","text":"<p>MoA-Ollama-Chat, forked from severian42/MoA-Ollama-Chat.</p> <p>The improved UI version of the chat interface for severian42/MoA-Ollama-Chat.</p>"},{"location":"oi-tips/-qread-and-qwrite/","title":"qread and qwrite","text":""},{"location":"oi-tips/-qread-and-qwrite/#most-common-quick-read-write-function","title":"Most Common Quick Read &amp; Write Function","text":""},{"location":"oi-tips/-qread-and-qwrite/#quick-read-getchar","title":"Quick Read <code>getchar()</code>","text":"<p>head file: <code>&lt;cctype&gt;</code></p> intAll TypesMulti-Var <pre><code>int read() {\n    int x=0, f=1; char ch=getchar();\n    while (!isdigit(ch)) f = ((ch=='-') ? -1 : f);\n    while (isdigt(ch)) x = (x&lt;&lt;1) + (x&lt;&lt;3) + (ch ^ 48), ch = getchar();\n    return x * f;\n}\n</code></pre> <pre><code>template&lt;typename type&gt;\nvoid read(type &amp;x) {\n    x=0; bool f(0); char ch=getchar();\n    while(!isdigit(ch)) f = ch =='-', ch =getchar();\n    while(isdigit(ch)) x = (x&lt;&lt;1) + (x&lt;&lt;3) + (ch^48), ch=getchar();\n    f ? x=-x : 0;\n}\n</code></pre> <pre><code>template&lt;typename type, typename ..._type&gt;\nvoid read(type &amp;x, _type&amp;...y) {read(x), read(y);}\n</code></pre> <p>Add code above under the \"All Types\" code.</p>"},{"location":"oi-tips/-qread-and-qwrite/#quick-write-putchar","title":"Quick Write <code>putchar()</code>","text":"intAll Types <pre><code>void write(int x) {\n    x&lt;0 ? x=-x, putchar('-') : 0;\n    x&gt;9 ? putchar(x/10) : 0;\n    putchar(x%10|48);\n}\n</code></pre> <p>head file: <code>&lt;cctype&gt;</code></p> <pre><code>template&lt;typename type&gt;\nvoid write(type x, bool md=1) {\n    x&lt;0 ? x=-x, putchar('-') : 0; static short bf[50], tp(0);\n    do bf[++tp] = x%10, x /= 10; while(x);\n    while(tp) putchar(bf[tp--]|48);\n    md ? putchar('\\n') : putchar(' ');\n}\n</code></pre> <p>md=0 for space</p> <p>md=1 for new line</p>"},{"location":"oi-tips/-qread-and-qwrite/#even-faster-fread","title":"Even Faster: <code>fread()</code>","text":"<p>We will just need to modify the <code>getchar()</code> function in the qread template above.</p>"},{"location":"oi-tips/-qread-and-qwrite/#fread","title":"<code>fread()</code>","text":"Since C99<pre><code>size_t fread( void *restrict buffer, size_t size, size_t count,\n    FILE *restrict stream );\n</code></pre>"},{"location":"oi-tips/-qread-and-qwrite/#parameters","title":"Parameters","text":"<p>buffer  -   pointer to the array where the read objects are stored</p> <p>size    -   size of each object in bytes</p> <p>count   -   the number of the objects to be read</p> <p>stream  -   the stream to read</p>"},{"location":"oi-tips/-qread-and-qwrite/#return-value","title":"Return Value","text":"<p>Number of objects read successfully, which may be less than <code>count</code> if an error or end-of-file condition occurs.</p> <p>If <code>size</code> or <code>count</code> is zero, fread returns zero and performs no other action.</p> <p>fread does not distinguish between end-of-file and error, and callers must use feof and ferror to determine which occurred.</p>"},{"location":"oi-tips/-qread-and-qwrite/#new-variables-needed","title":"New Variables Needed","text":"<pre><code>char buf[1&lt;&lt;20], *p1=buf, *p2=buf;\n</code></pre> <ul> <li><code>buf</code>: buffer.</li> <li><code>p1</code>: points to the currently read element.</li> <li><code>p2</code>: points to the end of the buffer.</li> </ul>"},{"location":"oi-tips/-qread-and-qwrite/#redefined-getchars-function","title":"Redefined <code>getchars()</code> Function","text":"<pre><code>#define getchar() (p1==p2&amp;&amp;(p2=(p1=buf)+fread(buf,1,1&lt;&lt;20,stdin),p1==p2)?EOF:*p1++)\n</code></pre>"},{"location":"oi-tips/-qread-and-qwrite/#even-faster-fwrite","title":"Even Faster: <code>fwrite</code>","text":"<p>We will just need to modify the <code>putchar()</code> function in the qread template above.</p>"},{"location":"oi-tips/-qread-and-qwrite/#fwrite","title":"<code>fwrite()</code>","text":"<pre><code>size_t fwrite( const void* restrict buffer, size_t size, size_t count,\n    FILE* restrict stream );\n</code></pre>"},{"location":"oi-tips/-qread-and-qwrite/#parameters_1","title":"Parameters","text":"<p>buffer  -   pointer to the first object in the array to be written</p> <p>size    -   size of each object</p> <p>count   -   the number of the objects to be written</p> <p>stream  -   pointer to the output stream</p>"},{"location":"oi-tips/-qread-and-qwrite/#return-value_1","title":"Return Value","text":"<p>Number of objects read successfully, which may be less than <code>count</code> if an error or end-of-file condition occurs.</p> <p>If <code>size</code> or <code>count</code> is zero, fread returns zero and performs no other action.</p> <p>fread does not distinguish between end-of-file and error, and callers must use feof and ferror to determine which occurred.</p>"},{"location":"oi-tips/-qread-and-qwrite/#new-variables-needed_1","title":"New Variables Needed","text":"<pre><code>char buf[1&lt;&lt;20], *p3=buf;\n</code></pre>"},{"location":"oi-tips/-qread-and-qwrite/#redefined-putchar-function","title":"Redefined <code>putchar()</code> Function","text":"<p>We implement a <code>flush()</code> function to output the buffer, so that it can be called many times in the future.</p> flush() Function<pre><code>#define flush() (fwrite(p3=out,1,1&lt;&lt;20,stdout))\n</code></pre> <p>You can actually take advantage of the principle of calling destructors at the end of a program by defining a class that calls flush() at the end of the program.</p> Destructor flush()<pre><code>class Flush{public:~Flush(){flush();}}_;\n</code></pre> <p>Now here's the redefined <code>putchar()</code> function </p>The Redefined putchar() Function<pre><code>#define putchar(ch) (p3==out+SIZE&amp;&amp;flush(),*p3++=(ch))\n</code></pre>"},{"location":"oi-tips/accelerate-ios/","title":"iostream Acceleration","text":""},{"location":"oi-tips/accelerate-ios/#untie","title":"Untie","text":"<pre><code>ios::sync_with_stdio(0);\ncin.tie(0);\ncout.tie(0);\n</code></pre> <p>Tip</p> <p>The untied cin &amp; cout are actually faster than scanf &amp; printf.</p> <p>Warning</p> <p>You CANNOT use functions in <code>&lt;stdio&gt;</code> after untie, including <code>printf()</code>, <code>scanf()</code>, <code>puts()</code>, <code>freopen()</code>.</p>"},{"location":"oi-tips/accelerate-ios/#endl","title":"endl","text":"<p>endl can be about 10 times slower than the \"\\n\".</p> <pre><code>#define endl '\\n'\n</code></pre>"},{"location":"oi-tips/elapsed-time/","title":"Elapsed Time Measurement","text":"Head File<pre><code>#include &lt;chrono&gt;\n</code></pre> global variables<pre><code>auto chrono_start_time = chrono::high_resolution_clock::now();\n</code></pre> Start Measuring<pre><code>void start_measuring() {\n    chrono_start_time = chrono::high_resolution_clock::now();\n}\n</code></pre> MillisecondsSecondsMinutes End Measuring<pre><code>void end_measuring() {\n    auto chrono_end_time = chrono::high_resolution_clock::now();\n    chrono::duration&lt;double, milli&gt; chrono_elapsed_seconds = chrono_end_time - chrono_start_time;\n    double chrono_elapsed_ms = chrono_elapsed_seconds.count();\n    cout &lt;&lt; \"Elapsed time: \" &lt;&lt; chrono_elapsed_ms &lt;&lt; \"ms\" &lt;&lt; endl;\n}\n</code></pre> End Measuring<pre><code>void end_measuring() {\n    auto chrono_end_time = chrono::high_resolution_clock::now();\n    chrono::duration&lt;double&gt; chrono_elapsed_seconds = chrono_end_time - chrono_start_time;\n    double chrono_elapsed_ms = chrono_elapsed_seconds.count();\n    cout &lt;&lt; \"Elapsed time: \" &lt;&lt; chrono_elapsed_ms &lt;&lt; \"s\" &lt;&lt; endl;\n}\n</code></pre> End Measuring<pre><code>void end_measuring() {\n    auto chrono_end_time = chrono::high_resolution_clock::now();\n    chrono::duration&lt; double, ratio&lt;60&gt; &gt; chrono_elapsed_seconds = chrono_end_time - chrono_start_time;\n    double chrono_elapsed_ms = chrono_elapsed_seconds.count();\n    cout &lt;&lt; \"Elapsed time: \" &lt;&lt; chrono_elapsed_ms &lt;&lt; \"min\" &lt;&lt; endl;\n}\n</code></pre>"},{"location":"oi-tips/file-read-and-write/","title":"File Read & Write","text":""},{"location":"oi-tips/file-read-and-write/#c-file-freopen","title":"C: FILE <code>freopen()</code>","text":"<p>head file: `</p> Definition<pre><code>std::FILE* freopen( const char* filename, const char* mode, std::FILE* stream );\n</code></pre>"},{"location":"oi-tips/file-read-and-write/#file-access-mode-string","title":"File Access Mode String","text":"<p>From CPPReference</p> File access mode string Meaning Explanation Action if file  already exists Action if file  does not exist \"r\" read Open a file for reading read from start return NULL and set error \"w\" write Create a file for writing destroy contents create new \"a\" append Append to a file write to end create new \"r+\" read extended Open a file for read/write read from start return NULL and set error \"w+\" write extended Create a file for read/write destroy contents create new \"a+\" append extended Open a file for read/write write to end create new <p>Note</p> <p>std::freopen is the only way to change the narrow/wide orientation of a stream once it has been established by an I/O operation or by std::fwide.</p> Example <pre><code>#include &lt;cstdio&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n\nint main() {\n    freopen(\"in.in\", \"r\", stdin);\n    freopen(\"out.out\", \"w\", stdout);\n\n    int a, b;\n    cin &gt;&gt; a &gt;&gt; b;\n    cout &lt;&lt; a * a + b * b &lt;&lt; endl;\n    return 0;\n}\n</code></pre> <p>Warning</p> <p>If you have used the untie operation, you shouldn't use freopen because you would have already disabled <code>&lt;cstdio&gt;</code>.</p> Tip <p>If you are using an Online Judge, you can add this macro definition to your code:</p> ONLINE_JUDGE<pre><code>#ifdef ONLINE_JUDGE\n#else\n#endif\n</code></pre> <p>Most OJ will use this macro definition, while your computer won't have one, thus you can add freopen in ONLINE_JUDGE so that you can use freopen as it'll be disabled on your OJ.</p> Example <pre><code>int main() {\n    #ifdef ONLINE_JUDGE\n    #else   // when run on local\n        freopen(\"in.in\", \"r\", \"stdin\");\n        freopen(\"out.out\", \"w\", \"stdout\");\n    #endif\n}\n</code></pre>"},{"location":"oi-tips/file-read-and-write/#c-fstream-fiostream","title":"C++: fstream <code>fiostream</code>","text":""},{"location":"oi-tips/file-read-and-write/#headfile-fiostream","title":"headfile: <code>&lt;fiostream&gt;</code>","text":"ReadWriteRead &amp; Write <pre><code>ifstream in(\"FILENAME\", ios::in);\n</code></pre> <pre><code>ofstream out(\"FILENAME\", ios::out);\n</code></pre> <pre><code>fstream foi(\"FILENAME\", ios::in|ios::out);\n</code></pre>"},{"location":"oi-tips/file-read-and-write/#function-open","title":"function <code>open()</code>","text":"General UsingProtocol <pre><code>void open(const char * filename,\n    ios_base::openmode mode = ios_base::in | ios::base::out);\n</code></pre> <pre><code>void open(const wchar_t *_Filename,\n    ios_base::in | ios_base::out, int prot = ios_base::_Openprot);\n</code></pre> Parameters modeprot <pre><code>    ios::app: //open the file as append  \n\n    ios::ate: //Locate the file to the end of the file when it is opened. ios:app includes this property.  \n\n    ios::binary: //Open the file as binary, the default is text. See the previous section for the difference between the two methods  \n\n    ios::in: // the file is opened as input (file data is entered into memory)  \n\n    ios::out: //files are opened as output (memory data is output to the file)  \n\n    ios::nocreate: //doesn't create the file, so it fails to open if the file doesn't exist  \n\n    ios::noreplace: // doesn't overwrite the file, so opening the file fails if the file exists  \n\n    ios::trunc: // set file length to 0 if file exists\n</code></pre> <pre><code>    0: Ordinary file, open access  \n    1: Read-only file  \n    2: Implicit files  \n    4: system file \n</code></pre> <p>Tip</p> <p>You can use \"or\" or \"+\" to connect the above attributes, such as 3 or 1 | 2 is to open the file with read-only and implicit attributes.</p>"},{"location":"oi-tips/file-read-and-write/#status-indicator","title":"Status Indicator","text":"<pre><code>is_open() //whether the file is normally open\nbad() // read and write process whether the error\nfail() // read and write process whether the error \neof() // read the file to reach the end of the file, return true\ngood () // any of the above return true, this will return false\n</code></pre>"},{"location":"oi-tips/gcc-optimize/","title":"GCC Optimize","text":""},{"location":"oi-tips/gcc-optimize/#difference-between-gcc-optimizations","title":"Difference Between GCC Optimizations","text":"<ul> <li>O1: Enable basic optimizations, including function inlining and loop unrolling.</li> <li>O2: Enable more optimizations, including function inlining, loop unrolling, constant propagation, dead code removal, etc.</li> <li>O3: Enable more advanced optimizations, including function inlining, loop unrolling, constant propagation, dead code removal, vectorization, etc.</li> <li>Os: Enable optimizations with code size reduction as the main goal.</li> </ul> <p>Warning</p> <p>Enabling higher-level optimization options may result in increased compilation times and, in some cases, may result in less efficient code execution.</p> <p>Warning</p> <p>Enabling GCC optimization manually is not allowed in Luogu OJ</p>"},{"location":"oi-tips/gcc-optimize/#usage","title":"Usage","text":"<p>Tip</p> <p>If you have STL in your code, you'd better turn on O2 or even O3 optimization.</p> O2 Optimization<pre><code>#pragma GCC optimize(2)\n</code></pre>"},{"location":"oi-tips/qread-and-qwrite/","title":"Quick Read & Write","text":"Quick Read<pre><code>char *P1,*P2,BUF[100000];\n#define NC() (P1==P2 &amp;&amp; (P2 = (P1=BUF) + fread(BUF, 1, 100000, stdin), P1==P2) ? EOF : *P1++)\nint read() {\n    int x = 0, f = 1;\n    char CH = NC();\n    while(CH &lt; 48 || CH &gt; 57)\n    {\n        if(CH == '-')\n            f = -1;\n        CH = NC();\n    }\n    while(CH&gt;=48&amp;&amp;CH&lt;=57)\n        x = x*10 + CH-48, CH=NC();\n    return x*f;\n}\n</code></pre> Quick Write<pre><code>void write(int x) {\n    if(x &lt; 0)\n        putchar('-'), x = -x;\n    if(x &gt; 9)\n        qwrite(x/10);\n    putchar(x%10 + '0');\n    return;\n}\n</code></pre>"},{"location":"utilities/discord-spam-spoiler/","title":"Discord Spam Spoiler","text":"<p>Standalone Webpage with the Copy Function</p>                  Word Mode                               Character Mode"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2024/#2024","title":"2024","text":""},{"location":"blog/category/ai/","title":"Ai","text":""},{"location":"blog/category/ai/#ai","title":"AI","text":""}]}